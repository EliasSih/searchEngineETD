<add><doc><field name="title">Design, Implementation and Cryptanalysis of Modern Symmetric Ciphers</field><field name="creator">Henricksen, Matthew</field><field name="description">The main objective of this thesis is to examine the trade-offs between security and  efficiency within symmetric ciphers. This includes the influence that block ciphers  have on the new generation of word-based stream ciphers. By incorporating  block-cipher like components into their designs, word-based stream ciphers have  experienced hundreds-fold improvement in speed over bit-based stream ciphers,  without any observable security degradation. The thesis also emphasizes the importance of keying issues in block and stream ciphers, showing that by reusing components of the principal cipher algorithm in the keying algorithm, security  can be enhanced without loss of key-agility or expanding footprint in software memory.    Firstly, modern block ciphers from four recent cipher competitions are surveyed and categorized according to criteria that includes the high-level structure of the block cipher, the method in which non-linearity is instilled into each round, and the strength of the key schedule. In assessing the last criterion, a classification  by Carter [45] is adopted and modified to improve its consistency.    The classification is used to demonstrate that the key schedule of the Advanced Encryption Standard (AES) [62] is surprisingly flimsy for a national standard. The claim is supported with statistical evidence that shows the key schedule suffers from bit leakage and lacks sufficient diffusion. The thesis contains a replacement key schedule that reuses components from the cipher algorithm, leveraging existing analysis to improve security, and reducing the cipher's implementation footprint while maintaining key agility. The key schedule is analyzed from the perspective of an efficiency-security tradeoff, showing that the new schedule rectifies an imbalance towards e&#177;ciency present in the original.    The thesis contains a discussion of the evolution of stream ciphers, focusing on  the migration from bit-based to word-based stream ciphers, from which follows a commensurate improvement in design flexibility and software performance. It examines the influence that block ciphers, and in particular the AES, have had upon the development of word-based stream ciphers. The thesis includes a concise literature review of recent styles of cryptanalytic attack upon stream ciphers.  Also, claims are refuted that one prominent word-based stream cipher, RC4, suffers from a bias in the first byte of each keystream.    The thesis presents a divide and conquer attack against Alpha1, an irregularly clocked bit-based stream cipher with a 128-bit state. The dominating aspect of the divide and conquer attack is a correlation attack on the longest register. The internal state of the remaining registers is determined by utilizing biases in the clocking taps and launching a guess and determine attack. The overall complexity of the attack is 261 operations with text requirements of 35,000 bits and memory requirements of 2 29.8 bits.    MUGI is a 64-bit word-based cipher with a large Non-linear Feedback Shift Register (NLFSR) and an additional non-linear state. In standard benchmarks, MUGI appears to su&#174;er from poor key agility because it is implemented on an  architecture for which it is not designed, and because its NLFSR is too large relative to the size of its master key. An unusual feature of its key initialization algorithm is described. A variant of MUGI, entitled MUGI-M, is proposed to  enhance key agility, ostensibly without any loss of security.    The thesis presents a new word-based stream cipher called Dragon. This cipher uses a large internal NLFSR in conjunction with a non-linear filter to produce 64 bits of keystream in one round. The non-linear filter looks very  much like the round function of a typical modern block cipher. Dragon has a native word size of 32 bits, and uses very simple operations, including addition, exclusive-or and s-boxes. Together these ensure high performance on modern day processors such as the Intel Pentium family.    Finally, a set of guidelines is provided for designing and implementing symmetric ciphers on modern processors, using the Intel Pentium 4 as a case study. Particular attention is given to understanding the architecture of the processor,  including features such as its register set and size, the throughput and latencies of its instruction set, and the memory layouts and speeds. General optimization rules are given, including how to choose fast primitives for use within the cipher. The thesis describes design decisions that were made for the Dragon cipher with respect to implementation on the Intel Pentium 4.    Block Ciphers, Word-based Stream Ciphers, Cipher Design, Cipher Implementa-  tion, -</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Block Ciphers</field><field name="subject">Word-based Stream Ciphers</field><field name="subject">Cipher Design</field><field name="subject">Cipher Implementation</field><field name="subject">Cryptanalysis</field><field name="subject">Key Schedule Classifcation</field><field name="subject">Key Agility</field><field name="subject">Advanced Encryption Standard</field><field name="subject">RC4</field><field name="subject">Alpha1</field><field name="subject">MUGI</field><field name="subject">Dragon</field><field name="subject">Correlation Attacks</field><field name="subject">Divide and Conquer Attacks</field><field name="subject">Intel Pentium 4</field><field name="identifier">http://eprints.qut.edu.au/16055/</field><field name="validLink">True</field></doc><doc><field name="title">Novel Approaches to the Design of Domestic Solar Hot Water Systems</field><field name="creator">Guarnieri, Raniero Alberto</field><field name="description">Domestic solar hot water units, if properly designed, are capable of providing all hot water  needs in an environmentally friendly and cost-effective way. Despite 50 years of  development, commercial technology has not yet achieved substantial market penetration  compared to mainstream electric and gas options. Therefore, alternate designs are warranted  if they can offer similar or greater performance for a comparable cost to conventional units.  This study proved that such alternatives are possible by designing and testing two novel solar  hot water systems (SHWS).  The first system used compound parabolic collector (CPC) panels to concentrate solar  energy and produce steam. The steam moved from a rooftop downward into a heat exchange  pipe within a ground level water tank, heating the water, condensing and falling into a  receptacle. The operation was entirely passive, since the condensate was pulled up due to the  partial vacuum that occurred after system cooling. Efficiencies of up to 40% were obtained.  The second system used an air heater panel. Air was circulated in open and closed loop  configuration (air recycling) by means of a fan/blower motor and was forced across a  compact heat exchanger coupled to a water tank. This produced a natural thermosiphon flow  heating the water. Air recycling mode provided higher system efficiencies: 34% vs. 27%.  The concurrent development of an analytical model that reasonably predicted heat transfer  dynamics of these systems allowed 1) performance optimisation for specific input/starting  operating conditions and 2) virtual design improvements. The merit of this model lay in its  acceptable accuracy in spite of its simplicity.  By optimising for operating conditions and parameter design, both systems are capable of  providing over 30 MJ of useful domestic hot water on clear days, which equates roughly to  an increase of 35&#176;C in a 200 L water tank. This will satisfy, on average, daily hot water  requirements for a 4-person household, particularly in low-latitude regions (eg. Queensland).  Preliminary costing for these systems puts them on par with conventional units, with the  passive, remotely coupled, low maintenance, CPC SHWS comparable to higher end models.  The air heater SHWS, by contrast, was much more economical and easier to build and  handle, but at the trade-off cost of 1) the need for an active system, 2) increased maintenance  and running costs and 3) the requirement for a temperature control mechanism that would  protect the panel body by dumping hot air trapped inside if stagnation were to occur.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Domestic Solar Hot Water Systems</field><field name="subject">Concentrating Optics</field><field name="subject">Compound Parabolic Collectors</field><field name="subject">Solar Selective Surface</field><field name="subject">Self-Pump</field><field name="subject">Air Heater Panel</field><field name="subject">Compact Heat Exchanger</field><field name="subject">Sun-Earth Geometry</field><field name="identifier">http://eprints.qut.edu.au/16056/</field><field name="validLink">True</field></doc><doc><field name="title">Stochastic Modelling of Financial  Processes with Memory and Semi-Heavy  Tails</field><field name="creator">Pesee, Chatchai</field><field name="description">This PhD thesis aims to study financial processes which have semi-heavy-tailed  marginal distributions and may exhibit memory. The traditional Black-Scholes  model is expanded to incorporate memory via an integral operator, resulting in  a class of market models which still preserve the completeness and arbitragefree  conditions needed for replication of contingent claims. This approach is  used to estimate the implied volatility of the resulting model.    The first part of the thesis investigates the semi-heavy-tailed behaviour of  financial processes. We treat these processes as continuous-time random walks  characterised by a transition probability density governed by a fractional Riesz-  Bessel equation. This equation extends the Feller fractional heat equation  which generates a-stable processes. These latter processes have heavy tails,  while those processes generated by the fractional Riesz-Bessel equation have  semi-heavy tails, which are more suitable to model financial data. We propose  a quasi-likelihood method to estimate the parameters of the fractional Riesz-  Bessel equation based on the empirical characteristic function.  The second part considers a dynamic model of complete financial markets in  which the prices of European calls and puts are given by the Black-Scholes formula.  The model has memory and can distinguish between historical volatility  and implied volatility. A new method is then provided to estimate the implied  volatility from the model.  The third part of the thesis considers the problem of classification of financial  markets using high-frequency data. The classification is based on the  measure representation of high-frequency data, which is then modelled as a  recurrent iterated function system.  The new methodology developed is applied to some stock prices, stock  indices, foreign exchange rates and other financial time series of some major  markets. In particular, the models and techniques are used to analyse the SET  index, the SET50 index and the MAI index of the Stock Exchange of Thailand.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Alpha stable distribution</field><field name="subject">L&#180;evy distribution</field><field name="subject">the Feller fractional heat equation</field><field name="subject">the Riesz-Bessel distribution</field><field name="subject">volatility</field><field name="subject">the Anh-Inoue model</field><field name="subject">the tick test</field><field name="subject">recurrent iterated function systems</field><field name="subject">memory</field><field name="subject">semi-heavy tails</field><field name="subject">long-range dependence</field><field name="subject">fractional Brownian motion</field><field name="identifier">http://eprints.qut.edu.au/16057/</field><field name="validLink">True</field></doc><doc><field name="title">The integration between design and maintenance of office building automation : a decision support approach</field><field name="creator">Lin, Frank Ching-Shou</field><field name="description">This research explores the barriers and limitations of the interaction between building development processes in an attempt of an integrated decision support approach to improve building design for effective maintenance in the field of office building automation. 
 
 Extensive coverage of literature and practice in office building industry over the last two decades indicates a wide diffusion and application of the information and communication technologies (ICT). While this has resulted in the adoption of advanced system integration in buildings, system redundancy and excessive expenditures are causing a major impact on the overall efficiency and has burdened building owners and occupiers with escalating maintenance costs. This phenomenon stimulates and warrants the re-examination of integrated building development, not just on system integration but also on the interdisciplinary development process integration particularly linking design and maintenance.
 
 Studies in this field revealed existing problems such as the inherent professional fragmentation, lack of historical information and service data, the first cost mentality of owners and developers, difficulties in forecasting future conditions and changes early in the design stage. With extensive use of qualitative information, this situation presents a great potential for the development of a decision support system exploring the communication and integration of design and maintenance phases, which has been one of the primary objectives of this research.
 
 In addition to literature studies, a questionnaire survey and a case study to identify industry concerns, feasible solutions, and  practical procedure oriented approaches through knowledge extractions were carried out. A set of guidelines, a checklist for its implementation and prototype system for computerized decision support to design and maintenance of building automation systems were also produced. These strategic approaches to balance design and maintenance will help facilitate appropriate decision making in the early design stage for sustainable maintenance of buildings.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Office building</field><field name="subject">Intelligent buildings</field><field name="subject">Integration</field><field name="subject">Design</field><field name="subject">maintenance</field><field name="subject">Information and communication Technology (ICT)</field><field name="subject">Decision support system</field><field name="subject">Building Automation System (BAS)</field><field name="subject">building performance</field><field name="subject">energy conservation</field><field name="subject">maintainability</field><field name="subject">sustainable</field><field name="identifier">http://eprints.qut.edu.au/16058/</field><field name="validLink">True</field></doc><doc><field name="title">Near-Real-Time GPS Sensing of Atmospheric Water Vapour</field><field name="creator">Bai, Zhengdong</field><field name="description">An important goal in modern weather prediction is to improve short-term weather  forecasts, especially of severe weather and precipitation. However, the ability to  achieve this goal is hindered by the lack of timely and accurate observations of  atmospheric water vapour, which is one of the most poorly measured and least  understood constituents of the Earth's atmosphere due to its high temporal and spatial  variability. This situation is being addressed by the Global Positioning System (GPS)  technology. GPS radio signals are slowed and bent by changes in temperature,  pressure and water vapour in the atmosphere. Traditionally, the GPS signal  propagation delay is considered a nuisance parameter that is an impediment to  obtaining precise coordinates using GPS. Recent development in GPS precise  positioning and orbit determination has enabled the atmospheric parameters to be  determined to a high degree of accuracy on a routine basis, using continuous tracking  data from ground-based GPS receivers.  The aim of this research is to address several critical scientific challenges in  estimating the atmospheric water vapour content in near-real-time (NRT) in  Australia. Contributions are made to the field of GPS meteorology in the following  five areas:  First of all, research efforts were made to develop a technical platform for the  ground-based GPS meteorology studies and demonstration of GPS Precipitable  Water Vapour (PWV) estimation using observations from Australian Regional GPS  Networks (ARGN). Methods of estimation of water vapour from GPS and  radiosonde data have been developed and tested. GAMIT-based GPS data processing  strategies and compare analysis with radiosonde water vapour solutions from the  Australia Upper Air Network (AUAN) were undertaken, providing an effective  technical basis for further studies.  Secondly, the research has developed techniques to allow estimation of atmospheric  water vapour from GPS data and surface meteorological observations collected  around the GPS sites. Ideally a dedicated meteorological sensor is installed adjacent  to the GPS antenna. However, meteorological sensors are normally not installed at  most Australian GPS stations. Installing a new meteorological sensor at each GPS  station would involve additional cost at the level of one-third or half of the geodetic  GPS receiver cost. We have experimentally developed and demonstrated  interpolation methods for making use of hourly collected surface meteorological data  from the Australian Automatic Weather Station (AWS) network operated by the  Bureau of Meteorology (BOM) to estimate atmospheric water vapour.  Thirdly, the research has studied ocean tidal loading and its effects on GPS derived  precipitable water vapour estimates. The periodic motion of the Earth's surface due  to ocean loading is one of the largest periodic motions. However, very little work has  been done to quantify their effects on GPS-derived solutions at the GPS sites in the  Australian region surrounded by ocean waters. The research presents the theoretical  analysis and experimental results from the ARGN network, focusing on ocean  loading and its effects on GPS derived precipitable water vapour estimates.  The fourth important effort was the development of techniques for estimating highrate  Slant Water Vapour (SWV) values for future operational meteorological  applications in Australia, including addressing such issues as slant-path delay  recovery from post-fit double-difference residuals, and overcoming site multipath  effects. The experimental results have demonstrated the efficiency of the proposed  methods.  Finally, in order to address the meteorological applications with the existing and  anticipated GPS reference stations in the Australian region, and measure the  atmospheric water vapour content in near-real-time, the technical issues to  implement NRT GPS water vapour estimation were identified and discussed,  including the data requirements for meteorological and climate applications, NRT  data processing and quality control procedures for GPS orbits. The experimental  GPS PWV results from NRT and post data processing are compared and presented.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">GPS</field><field name="subject">Global positioning system</field><field name="subject">NRT</field><field name="subject">near-real-time</field><field name="subject">PWV</field><field name="subject">Precipitable Water Vapour</field><field name="subject">ARGN</field><field name="subject">Australian Regional GPS Networks</field><field name="subject">GAMIT-based</field><field name="subject">AUAN</field><field name="subject">Australia Upper Air Network</field><field name="identifier">http://eprints.qut.edu.au/16059/</field><field name="validLink">True</field></doc><doc><field name="title">The Impact of Housing on people with Schizophrenia</field><field name="creator">Browne, Graeme</field><field name="description">Mental health services in Australia (and in most western countries) have undergone considerable changes in the past 20 years. These changes have  included the closing or downsizing of the old tertiary institutions and a move towards community treatment of people with a mental illness (consumers). Consumers no longer live in hospitals; as a consequence housing has become an important aspect of their lives.    Research has demonstrated that when consumers live in good quality housing of their own choosing they report improved quality of life, more satisfying supportive social relationships, and have fewer admissions.    People with schizophrenia are the largest psychiatric diagnostic group treated by the public health system in Australia. As a result of their illness people with schizophrenia often have difficulty in maintaining reasonable  quality accommodation and supportive social relationships.    A review of the available literature on housing options indicates that, for people with a mental illness, boarding houses are the least desirable type of community housing and that living in their own home is the most desirable.  These were the two types of housing chosen for the study.    Aims of the study    This study aimed to explore the impact of housing on the mental health of people with schizophrenia.    Study Design  Stage 1  For the initial stage of the project archival data was used to investigate the relationship between types of accommodation and illness patterns of people with schizophrenia.  The hypotheses for stage 1 of the project were:  1. Admission rates will be significantly different for people with schizophrenia who are discharged to a private home when compared  to those discharged to a boarding house.  2. Length of stay in hospital will not be significantly different for people with schizophrenia discharged to a private home when  compared to those discharged to a boarding house.  3. Symptoms, as measured by scores on HoNOS scale, will be significantly different for people with schizophrenia living in a private home when compared to those living in a boarding house. 4. The level of functioning, measured using an LSP 16, will be significantly different for people with schizophrenia living in a private home when compared to those living in a boarding house. Inclusion Criteria  The subjects included were between 18 and 65 years of age and had a principal diagnosis of schizophrenia.  Findings  Findings indicate that people with schizophrenia are more likely to be admitted to hospital if discharged to a boarding house. Surprisingly, results also indicated that while there were no differences in the level of psychiatric  symptoms experienced, people with schizophrenia living in boarding houses had less access to social support, meaningful activities and work and had lower levels of global functioning. These findings contradict the conventional wisdom that people with schizophrenia resort to living in boarding houses because of their level of disability.  Stage 2  Stage 2 of the study further explored the impact of housing type on the mental health of people with schizophrenia by examining the experience of  thirteen people living independently in private homes or in a boarding house. The study aimed to use the experiences of the participants to develop a grounded theory explanation of the impact of housing on people with schizophrenia.  Findings from Stage 2 indicated a strong desire amongst all participants to live in their own home. Participants living in their own home had access to more opportunities and resources for staying well than participants living in boarding houses. Those participants who lived in their own home felt they belonged, they felt safe and most importantly they had greater opportunities to make and maintain supportive social relationships with friends and family. Participants reported that stable housing and supportive relationships helped them to stay well.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Consumers of mental health services</field><field name="subject">Schizophrenia</field><field name="subject">Housing</field><field name="subject">Boarding houses</field><field name="subject">Own home</field><field name="subject">Grounded theory</field><field name="subject">Admission rates</field><field name="subject">Social support</field><field name="identifier">http://eprints.qut.edu.au/16060/</field><field name="validLink">True</field></doc><doc><field name="title">Out of the Shadows: The Mezzotints of Graeme Peebles</field><field name="creator">Craig, Gordon</field><field name="description">Out of the Shadows: The Mezzotints of Graeme Peebles investigates Victorian printmaker Graeme Peebles' engagement with the mezzotint medium since the early 1970s.  Over fifty works from the artist's oeuvre of nearly 300 mezzotints are examined to demonstrate Peebles' high quality technical skills and his unique approach to subject matter. This has ranged from enigmatic, surrealist-inspired subject matter to landscapes of the Lake Eucumbene region in the Kosciusko National Park, which range from the ominous and foreboding to the romantic and sublime.  In this thesis I explore the intellectual groundwork on which much of Peebles work is based. In doing so I am redressing the imbalance between the popularity of Peebles' work and the lack of critical writing about his art. While his work has been widely collected (see for instance the list of Public Collections that contain holdings of Peebles' work, on page 96), to date his work has not received the attention as deserved by a master of their chosen medium. In reviewing his work in such a manner I believe that Peebles deserves greater recognition in contemporary Australian Art.  In conjunction with this thesis I have curated an exhibition bearing the same title, which was displayed at the QUT Art Museum, Brisbane, 12 March - 30 May 2004. It then toured to the Latrobe Regional Gallery, Warrnambool Art Gallery, Geelong Gallery, Gold Coast City Art Gallery and Perc Tucker Regional Gallery. A 16-page colour catalogue was also produced to accompany the exhibition.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Peebles</field><field name="subject">Graeme; Young</field><field name="subject">Bill; art; printmaking; mezzotint; Melbourne; Point Lonsdale; Eucumbene; metaphysics</field><field name="identifier">http://eprints.qut.edu.au/16061/</field><field name="validLink">True</field></doc><doc><field name="title">Automatic Fault Diagnosis of Rolling Element Bearings Using Wavelet Based Pursuit Features</field><field name="creator">Yang, Hongyu</field><field name="description">Today's industry uses increasingly complex machines, some with extremely demanding performance criteria. Failed machines can lead to economic loss and safety problems due to unexpected production stoppages. Fault diagnosis in the condition monitoring of these machines is crucial for increasing machinery availability and reliability.    Fault diagnosis of machinery is often a difficult and daunting task. To be truly effective, the process needs to be automated to reduce the reliance on manual data interpretation. It is the aim of this research to automate this process using data from machinery vibrations. This thesis focuses on the design, development, and application of an automatic diagnosis procedure for rolling element bearing faults. Rolling element bearings are representative elements in most industrial rotating machinery. Besides, these elements can also be tested economically in the laboratory  using relatively simple test rigs.    Novel modern signal processing methods were applied to vibration signals collected  from rolling element tests to destruction. These included three advanced timefrequency  signal processing techniques, best basis Discrete Wavelet Packet Analysis (DWPA), Matching Pursuit (MP), and Basis Pursuit (BP). This research presents the first application of the Basis Pursuit to successfully diagnosing rolling element faults. Meanwhile, Best basis DWPA and Matching Pursuit were also benchmarked with the Basis Pursuit, and further extended using some novel ideas particularly on the extraction of defect related features.    The DWPA was researched in two aspects: i) selecting a suitable wavelet, and ii) choosing a best basis. To choose the most appropriate wavelet function and decomposition tree of best basis in bearing fault diagnostics, several different wavelets and decomposition trees for best basis determination were applied and  comparisons made. The Matching Pursuit and Basis Pursuit techniques were effected by choosing a powerful wavelet packet dictionary. These algorithms were also studied in their ability to extract precise features as well as their speed in achieving a result. The advantage and disadvantage of these techniques for feature extraction of bearing faults were further evaluated. An additional contribution of this thesis is the automation of fault diagnosis by using Artificial Neural Networks (ANNs). Most of work presented in the current literature has been concerned with the use of a standard pre-processing technique - the spectrum. This research employed additional pre-processing techniques such as the spectrogram and DWPA based Kurtosis, as well as the MP and BP features that were subsequently incorporated into ANN classifiers. Discrete Wavelet Packets and Spectra, were derived to extract features by calculating RMS (root mean square), Crest Factor, Variance, Skewness, Kurtosis, and Matched Filter. Certain spikes in Matching Pursuit analysis and Basis Pursuit analysis were also used as features. These various alternative methods of pre-processing for feature extraction were tested, and evaluated with the criteria of the classification performance of Neural  Networks.    Numerous experimental tests were conducted to simulate the real world environment.  The data were obtained from a variety of bearings with a series of fault severities. The mechanism of bearing fault development was analysed and further modelled to evaluate the performance of this research methodology.    The results of the researched methodology are presented, discussed, and evaluated in the results and discussion chapter of this thesis. The Basis Pursuit technique proved to be effective in diagnostic tasks. The applied Neural Network classifiers were designed as multi layer Feed Forward Neural Networks. Using these Neural Networks, automatic diagnosis methods based on spectrum analysis, DWPA,  Matching Pursuit, and Basis Pursuit proved to be effective in diagnosing different conditions such as normal bearings, bearings with inner race and outer race faults, and rolling element faults, with high accuracy.    Future research topics are proposed in the final chapter of the thesis to provide perspectives and suggestions for advancing research into fault diagnosis and condition monitoring.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Rolling element bearing</field><field name="subject">Fault diagnosis</field><field name="subject">Feature extraction</field><field name="subject">Discrete Wavelet Packet Analysis (DWPA)</field><field name="subject">Matching Pursuit</field><field name="subject">Basis Pursuit</field><field name="subject">Neural Network</field><field name="identifier">http://eprints.qut.edu.au/16062/</field><field name="validLink">True</field></doc><doc><field name="title">Structural investigations into the relationships of insulin-like growth factors (IGFs) and IGF binding proteins (IGFBPs) with vitronectin (VN)</field><field name="creator">Kricker, Jennifer Ann</field><field name="description">Previous studies demonstrated that IGF-II binds directly to vitronectin (VN) while IGF-I binds poorly. However, binding of VN to integrins has been demonstrated to be essential for a range of IGF-I-stimulated biological effects including IGF binding protein-5 (IGFBP-5) production, IGF type-1 receptor autophosphorylation and cell  migration. Thus, this study examined the hypothesis that a link between IGF-I and  VN must occur and may be mediated through IGFBPs. Studies using competitive  binding assays with VN and [125I]-labelled IGFs in the absence and presence of  IGFBPs revealed IGFBP-4, IGFBP-5 and non-glycoyslated IGFBP-3 significantly  enhance binding of IGF-I to VN, while IGFBP-2 and glycosylated IGFBP-3 had a  smaller effect. Furthermore, binding studies with analogues indicate that  glycosylation status of IGFBP-3 and the heparin-binding domains of IGFBP-3 and  IGFBP-5 are important in this interaction. The functional significance of IGFs  binding to VN on cell migration in MCF-7 breast carcinoma cells was examined and  cell migration was found to be enhanced when VN was pre-bound to IGF-I in the  presence of IGFBP-3, -4 and -5. The effect required IGF:IGFBP:VN complex  formation; this was demonstrated by use of a non-IGFBP-binding analogue, des(1-  3)IGF-I. Additionally, higher doses of IGFs in the presence of VN also could  stimulate cell migration. Together, these data indicated the importance of IGFBPs  in modulating IGF-I binding to VN and that this binding has functional  consequences in cells. Future directions for this work include investigations into the  mechanisms underlying formation of the trimeric complex and the associated  signalling pathways involved.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Insulin growth factors</field><field name="subject">IGF-I</field><field name="subject">vitronectin</field><field name="subject">VN</field><field name="subject">IGF-I</field><field name="subject">binding proteins</field><field name="subject">IGFBPs</field><field name="identifier">http://eprints.qut.edu.au/16063/</field><field name="validLink">True</field></doc><doc><field name="title">Towards a New Employment Relationship Model: Merging Changing Needs and Interests of Organisation and Individual</field><field name="creator">Baker, Timothy Bond</field><field name="description">This research investigates the new psychological contract phenomenon in an organisational case study. The research question underpinning this study is - What are the core attributes of the new employment relationship? To investigate this research question, the researcher applied Noer's (1997) new employment relationship model to a disproportionate stratified sample of 19 participants from three organisational perspectives in an Australian-based international travel retail organisation, Flight Centre Limited, which specialises in the sale of discount international airfares. Data from a survey instrument were analysed using a "Multi-source Assessment" instrument. The data analysis method was used to create a schema to guide and inform a series of focus groups. The research findings validated Noer's five attributes of Flexible Employment, Customer-focus, Focus on Performance, Project-based Work and Human Spirit &amp; Work. In addition, three other attributes of the new employment relationship emerged from the data, namely, Loyalty &amp; Commitment, Learning &amp; Development and Open Information. The research findings validate eight core attributes of the new employment relationship and therefore make a contribution to the expanding body of research in this field.  The research approach also provides organisational practitioners with a unique consulting methodology to merge the changing needs and interests of individual and organisation.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Employment relationship</field><field name="subject">psychological contract</field><field name="subject">human resource development</field><field name="subject">organisational change</field><field name="subject">multi-source assessment</field><field name="subject">focus groups</field><field name="subject">flexible employment</field><field name="subject">customer-focus</field><field name="subject">focus on performance</field><field name="subject">project-based work</field><field name="subject">human spirit and work</field><field name="subject">loyalty and commitment</field><field name="subject">learning and development</field><field name="subject">open information</field><field name="identifier">http://eprints.qut.edu.au/16064/</field><field name="validLink">True</field></doc><doc><field name="title">Self-defeating eating : the role of hypnotizability and its correlates in its aetiology and treatment</field><field name="creator">Hutchinson-Phillips, Susan</field><field name="description">Dietary habits which seriously erode health and quality of life are widespread.  Effective clinical strategies for overweight, obese and eating disordered individuals are needed.  Such treatment options are usually based on constructs generated by theoretical models of causation and maintenance. Underpinning the current enquiry, the Hypno-socio-cultural model hypothesises links between the aetiology of dysfunctional eating behaviours and higher levels of hypnotic susceptibility, fantasy ability and dissociative capacity, as well as acknowledging the social genesis of the self-defeating approach to diet. Empirical evidence has supported the socio-cognitive theory of causation and remediation, on which this research is based.  The literature has suggested that hypnotic, imaginative and dissociative strategies have contributed to clinical efficacy, and that aetiology and maintenance of such self-defeating eating might be linked to higher than average hypnotic susceptibility, imaginative ability and dissociative capacity.  Generalization of research findings across studies is limited by the uncertainty introduced by the variety of measuring instruments utilized, and gender and age differences which have emerged.  As well, possible individual preferences for specificity of hypnotic suggestions, which may affect responsivity levels, could dictate a need for reinterpretation of the results of relevant research.  
 
 
 
 As an initial step in exploration of these issues, a group of University students responded to a number of assessment instruments, designed to tap self-perceptions in relation to weight, shape and size concerns, eating behaviours, and use of imaginative, dissociative and hypnotic capacities, as well as responding to hypnotic suggestions embedded in a formal assessment thereof.  
 
 
 
 In this current research, expected relationships between elements of the Hypno-socio-cultural model were probably affected by a complex array of factors, which are difficult to measure using current instruments. Case studies drawn from the participants in this study have further elucidated the possible connections underlying the proposed Hypno-Socio-Cultural model, as well as highlighting the complexity of the relationships of all the factors involved. The Phenomenology of Consciousness Inventory, which was used to access the subjective experience of the individual&#8217;s responsivity to hypnotic suggestion, and which also tapped imaginative and dissociative experiences in relation to same, appears to have unique potential for further exploration of issues related to the connections highlighted in this study
 
 
 
 Findings in the current study suggested that some widely used assessments were not measuring the same constructs. Because of such factors, results which suggested links between weight, shape and eating measures, and those assessing hypnotic susceptibility, fantasy-proneness and dissociative capacity, although in the expected direction, were not as strong as was expected.  In light of the anecdotal evidence of effective clinical use of imaginative, dissociative and hypnotic techniques with self-defeating eaters, the results were reassessed.    It seemed feasible to interpret these results as suggesting that higher reliance on self-protective and defensive modes of using imaginative and dissociative capacities may mark the self-defeating eater.  A modified Hypno-Socio-Cultural model, incorporating such a possibility, has been proposed as the basis for further study.
 
 
 
 It is recommended that such research be undertaken, employing a variety of relevant measures, with a larger group of participants of both genders with DSM-IV criterion diagnosed self-defeating eating.   The importance to clincial work of investigating the proposed model as a basis for treatment remains paramount in this field of self-defeating eating.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Eating Disorders</field><field name="subject">Dissociative Capacity</field><field name="subject">Fantasy</field><field name="subject">Hypnotic Susceptibility</field><field name="subject">Self-Defeating</field><field name="identifier">http://eprints.qut.edu.au/16065/</field><field name="validLink">True</field></doc><doc><field name="title">Assessing the spatial impacts of multi-combination vehicles on an urban motorway</field><field name="creator">Lennie, Sandra Christine</field><field name="description">Multi-combination vehicles (MCVs) in urban areas impact on productivity, safety, infrastructure, congestion and the environment.  However, psychological effects of MCVs on other drivers may also influence the positioning of vehicles and congestion.  A literature review revealed little information on the psychological effects of heavy vehicles on other road users.  This research can be used to quantify some psychological impacts of MCVs.
 
 
 
 A testing program was undertaken on the Gateway Motorway to observe passenger car behaviour around MCVs in a lateral and longitudinal sense.  Video footage was collected on a four lane divided urban motorway section which was level, straight and away from any off/on ramps.  It experiences high traffic volumes with a one-way AADT of approximately 33,500.  The route is currently designated for B-doubles, which is the most common MCV in urban areas.  
 
 
 
 In a lateral sense, the research showed that passenger car behaviour changes around heavy vehicles (prime mover semi-trailer combination and B-doubles); however, there is no statistical difference in passenger car behaviour around semi-trailers and B-doubles.  Longitudinally it was found that, even though passenger cars shy away from B-doubles more than semi-trailers, B-doubles are still more efficient in a spatial sense since they carry more freight.  
 
 
 
 The outcomes of this research indicate that there is no further psychological impact on passenger cars, when travelling around B-doubles compared with semi-trailers.  Where the results identified longitudinal behaviour changes, it was still concluded that B-doubles were more efficient at transporting freight when the passenger car equivalent (PCE) per tonne of freight was considered.  
 
 
 
 Tracking ability testing was undertaken in a rural area to determine the lateral spatial requirements of three different MCVs.  The rural testing was considered appropriate since parts of the urban network have similar characteristics to rural networks.  A model was developed as a part of this project to process the data collected by Haldane (2002), but results could not be relied upon due to poor quality data.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Multi-combination vehicle (MCV)</field><field name="subject">spatial</field><field name="subject">urban</field><field name="subject">motorway</field><field name="subject">B-double</field><field name="subject">driver behaviour</field><field name="subject">shy distance</field><field name="subject">lateral position</field><field name="subject">lateral separation</field><field name="subject">longitudinal position</field><field name="subject">following behaviour</field><field name="subject">headway</field><field name="subject">passenger car equivalent (PCE)</field><field name="subject">tracking ability</field><field name="subject">lane width</field><field name="subject">lateral displacement</field><field name="identifier">http://eprints.qut.edu.au/16066/</field><field name="validLink">True</field></doc><doc><field name="title">Physical Activity and Health Promotion in Midlife Women</field><field name="creator">Mirzaiinajmabadi, Khadigeh</field><field name="description">Objectives: This study specifically focused on health promotion and physical activity in midlife women. Health promotion in midlife women was examined to determine if exercise could improve the menopausal symptoms and health status in midlife women and if a multi-modal intervention might improve the level of activity in midlife women. The objectives of the study included 1) To identify the relationship between physical activity, menopausal symptoms and health status in midlife women, and 2) To determine the effect of a multi-modal intervention on increasing levels of exercise in midlife women.  Methods: The study was conducted in two phases. The first phase included a secondary data analysis of 886 women who took part in the Queensland Midlife Women Health Survey (QMWHS) aged 45-60 years, who were randomly selected from South-East Queensland. In the second phase a randomised, controlled study was conducted on a subset of women who participated in the QMWHS. Women who were allocated to the intervention group (n=47) received an intervention, which combined a multi-modal program of physical activity with health education. Women in the control group continued their normal physical activities (n=66).  Results: Findings of this study indicated that increasing exercise was associated with lower psychological and somatic symptoms in midlife women. The study found that exercise was associated with decreasing menopausal symptoms. In the area of health status, significant differences were found between exercise and mental health, vitality, general health and physical function. This study revealed that a multi modal intervention could increase the level of activity in midlife women. There were significant differences in monthly exercise and vigorous activity between the intervention and control groups 3 months after the intervention. Women stated that they felt physical and mentally better and the program motivated them into being more active. They mentioned that the program was easy to understand and follow and the concept of the program was well organized and useful for them. Conclusion: This study showed that exercise might provide a wider health effect on midlife women's health by decreasing menopausal symptoms and improving health status. Exercise counselling is an essential component of healthcare, especially among middle-aged women who are experiencing physical, emotional, and social changes. Health professionals and nurses are in a good position to assist midlife women through providing information about the health effect of exercise. Physical activity should be encouraged for the prevention and reduction of risks for chronic disease and the improvement of health in midlife women. The multi-modal program was effective in increasing levels of activity in midlife women. This is an important finding as exercise is difficult health behaviour to change. Study implications suggest that this type of intervention may provide an effective, clinically manageable therapy for women who choose a self-directed approach to increase their level of activity. This program may offer implications for designing and implementing exercise interventions in further studies.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Physical Activity</field><field name="subject">Health Promotion</field><field name="subject">Women</field><field name="identifier">http://eprints.qut.edu.au/16067/</field><field name="validLink">True</field></doc><doc><field name="title">Effectiveness of Health Promotion Interventions Upon High Risk Lifestyle Behaviours of Adult Clients of Health Benefits Organisations</field><field name="creator">Dzenis, Haralds (Jack)</field><field name="description">Over the past 100 years the average life span of humans has increased in developed countries. Mortality rates have changed because of the virtual eradication of infectious diseases, such as polio and smallpox, and the increase in chronic diseases. Chronic diseases, such as coronary heart disease, are related to lifestyle behaviour, a factor over which the individual has some control. Matarazazo (1984) believes that 'behavioural pathogens are the key to understanding health behaviours of the individual and subsequently designing more effective methods of dealing with chronic disease and illness. Fries (1980) suggests another approach to dealing with chronic disease, through the strategy of 'compressed morbidity'. This refers to the postponement of chronic infirmity relative to average life duration. By achieving compressed morbidity, it is expected that health costs will decrease and improvement of quality of life will occur. This may be possible in at least two ways: firstly, by self-empowerment of the individual and secondly by the development of health self-efficacy. Thus giving the individual the power to act upon certain health-damaging behaviours as well as the confidence to influence behavioural change and persistence to cope with difficulties whilst the process of change is occurring. Thirdly, as a result of this, behaviour changes will occur and this would lead to a reduction in health cost which would be of overall benefit to the community. One method of reducing these health care costs is through health promotion and health education. Improvements in health knowledge and skills through health education and health promotion has been shown to facilitate changes in lifestyle and so reduce the incidence of various diseases. This study examined the effectiveness of two types of self-care models, health self-care and medical self-care. Health self-care refers to individuals assuming more responsibility for prevention, detection and the treatment of health problems using self-care information. Medical self-care involves the use of General Practitioners (GP) offering advice to their patients and subsequently patients making informed decisions about their health. The health self-care model Healthtrac, attempts to provide an effective use of the Australian health care system. Healthtrac is an information and skills based mail delivery program designed to assist individuals in elevating their perceptions of health self-efficacy and improve their lifestyle behaviours. Better Health is the medical self-care model which is designed with the perspective that GP's are the best suited as the initiators of change in individual health self-care. Participants (N = 864) are adult males and females. The methodology for this study involved 864 high risk of chronic disease participants who have been identified using the Healthtrac Health Risk Assessment (HRA) instrument. There were (n = 343) participants in the health self-care group, (n =66) in the medical self-care group and (n = 455) in the control group. This instrument was designed to identify individuals who have or are at high risk of developing chronic disease. These participants were part of the Better Health promotion program of a Health Insurance company. All the participants received a letter of advice detailing the presence of certain risk factors as determined by their health risk appraisal. They were requested to visit their local GP who recommended the necessary behavioural changes and medical support required for medically satisfactory outcomes. They were encouraged to follow the advice of the GP and received a second HRA after 6 months and again12 months after the start of the project. The Healthtrac component of the study involved 343 subjects who completed the HRA instrument. Participants in this group were matched with the Better Health subjects for variables such as age, gender, employment, disease or lifestyle and educational level. Baseline impact variables were calculated and compared with the same variables at 6 monthly intervals during the 12 month period of the study. Process variables such as user satisfaction were determined by a questionnaire. Investigation of the Health Benefits Organisation records were used to gather data on the number of claims for hospitalisation and other medical costs. A control group of 455 participants were matched with the same variables as those participants in the health self-care model and medical self-care groups. The analysis of results indicate that variables such as number of doctor's visits, days spent in hospital and total risks scores for the health self-care model were lower than the Medical model scores. The variable, cost of disease findings indicate that there were no significant differences between the two experimental groups, from the baseline data (Q1) to the 12 month period (Q3). The cost of diseases for heart disease was able to be lowered more by participants in the health self-care than the medical self-care model. The opposite occurred for the blood pressure condition. The health self-efficacy questionnaire results indicate that the health self-care group participants reported higher self-efficacy scores, therefore they were more confident about the self-management of their health behaviours than the members of the medical self-care group. No significant differences occurred among the experimental and control groups on such variables as achievement of outcomes and management of disease on self-efficacy scores. Both experimental groups, health self-care and the medical self-care model philosophies have strengths and weaknesses. Health self-care provides health information and support through printed materials whereas the medical self-care model provides health information through GP's. Both health promotion programs are important in making the individual aware of methods needed to improve health and in developing the knowledge necessary to modify clients health behaviours. This in turn is an important factor in the reduction of medical costs and the prevention of some diseases.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Health promotion</field><field name="subject">health self-care</field><field name="subject">medical self-care</field><field name="subject">health self-efficacy</field><field name="identifier">http://eprints.qut.edu.au/16068/</field><field name="validLink">True</field></doc><doc><field name="title">Analysing E-mail Text Authorship for Forensic Purposes</field><field name="creator">Corney, Malcolm W.</field><field name="description">E-mail has become the most popular Internet application and with its rise in use has come an inevitable increase in the use of e-mail for criminal purposes. It is possible for an e-mail message to be sent anonymously or through spoofed servers. Computer forensics analysts need a tool that can be used to identify the author of such e-mail messages.
 
 
 
 This thesis describes the development of such a tool using techniques from the fields of stylometry and machine learning. An author's style can be reduced to a pattern by making measurements of various stylometric features from the text. E-mail messages also contain macro-structural features that can be measured. These features together can be used with the Support Vector Machine learning algorithm to classify or attribute authorship of e-mail messages to an author providing a suitable sample of messages is available for comparison.
 
 
 
 In an investigation, the set of authors may need to be reduced from an initial large list of possible suspects. This research has trialled authorship characterisation based on sociolinguistic cohorts, such as gender and language background, as a technique for profiling the anonymous message so that the suspect list can be reduced.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">E-Mail</field><field name="subject">Computer Forensics</field><field name="subject">Authorship Attribution</field><field name="subject">Authorship Characterisation</field><field name="subject">Stylistics</field><field name="subject">Support Vector Machine</field><field name="identifier">http://eprints.qut.edu.au/16069/</field><field name="validLink">True</field></doc><doc><field name="title">The Origin and Setting of the National Goals and Directive Principles in the process of writing the Constitution of Papua New Guinea</field><field name="creator">Kari, Sam Sirox</field><field name="description">This thesis reveals the origins and meaning of the National Goals and Directive Principles, the processes leading to their tabling, discussion and drafting and the role of the Constitutional Planning Committee and Australia in this process. This thesis investigates for the first time the vision embedded in the National Goals and Directive Principles. The vision of the five National Goals and Directive Principles compelled post- independence governments to deliver social, economic and political development with consideration to equality, economic self-reliance, national sovereignty and protection of the natural environment. The goals were integrated in the constitution of the Independent State of Papua New Guinea, however the National Goals and Directive Principles were ignored or only given passing acknowledgement by successive governments. The National Goals and Directive Principles were a road map, which the new nation could follow when the colonial rulers Australia had departed, but some subsequent policies actually contradicted the aspirations, advice and nationalist blueprint declared in the constitution.  The translation of the National Goals and Directive Principles to policies implemented by government departments and debated in the House of Assembly comprises the final, but significant, element of this investigation. There has been no major study on the declaration of the National Goals and Directive Principles although 29 years has passed since independence. This thesis reveals the genesis of a national vision and ideas expressed by an educated indigenous elite in Papua New Guinea but mostly influenced by expatriates and foreign consultants over the brief period between responsible government and full independence (1959-1975). The thesis argues that it was more a foreign than home-grown idea that Papua New Guinea would be a viable nation. It identifies the origin of the idea that a nation needed a unifying set of guiding principles and how this vision ended up being embedded in the constitution of the new nation. The central assertion of this thesis is that a vision of the new nation was never agreed upon nor did it emerge from the unique cultures, knowledge and history of Papua New Guinea's people. It argues that Papua New Guinea went through the expected, conventional process of decolonisation and constitution writing, and that declaring a national vision was never central to the rapid development of a political structure. The National Goals and Directive Principles were made to look like a collective indigenous vision, but they emerged from foreign ideas, theory and practice and were used by an educated elite obsessed with and overwhelmed by the rush to take over political and economic power. There was no long-term national vision merely the continuation of the colonial order and the maintenance of borrowed, western ideas, disguised as a national discourse.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Papua New Guinea</field><field name="subject">national goals</field><field name="subject">directive principles</field><field name="subject">constitution</field><field name="subject">Department of Trade and Industry and Commerce</field><field name="subject">independence</field><field name="identifier">http://eprints.qut.edu.au/16071/</field><field name="validLink">True</field></doc><doc><field name="title">Novel Analytical Techniques For the Assessment of Degradation of Silicone Elastomers in High Voltage Applications</field><field name="creator">Sovar, Robert D.</field><field name="description">Over the last 20 years "composite" insulators have been increasingly used in high voltage applications as an alternative traditional materials.  More recently, polydimethylsiloxane (PDMS) have been used as weather sheds on these composite insulators.  The main attraction with PDMS is that the surface hydrophobicity can be recovered following pollution or surface discharges.  Among the possible mechanisms for recovery the most likely is the migration of low molecular weight silicone oil (LMWS) from the bulk to the surface encapsulating pollutant particles.  Although it is widely recognised that the migration of LMWS is the cause of this recovery of hydrophobicity, the mechanism of what actually occurs is not well understood.  It is also not known for how long this process will continue.  The main objective of this study program was to gain improved understanding of the surface hydrophobic recovery process that is unique to polydimethlysiloxane high-voltage insulators. Fundamental knowledge of this mechanism has been increased through the development of the Contact Angle DRIFT Electrostatic Deposition (CADED) novel analytical technique. This technique enabled study of the degradation of silicone elastomers subjected to high voltage environments by closely following LMWS migration from the bulk material to the surface and linking it to the contact angle measurements. The migration rate data showed that the aged material recovered faster that the virgin material.  Differences in the rate and maximum surface levels of silicone were seen between materials from different manufacturers. This has significant implications for the life-time of these materials  A model system has been developed to examine LMWS diffusion through the bulk material and into the interface of surface and pollutant.  This was achieved by examining theoretical and empirically derived equations and using existing experimental data to better understand the mechanism of recovery.  This diffusion was  Fickian in the initial stages of recovery. X-ray photoelectron spectroscopy (XPS) and contact angle measurements were used to substantiate the degree of degradation in in-field silicone insulators by quantifying the levels of the major degradation products: silica and silica-like material and alumina.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Composite insulators</field><field name="subject">polydimethylsiloxane (PDMS)</field><field name="subject">low molecular weight silicone oil (LMWS)</field><field name="subject">polydimethlysiloxane high-voltage insulators</field><field name="subject">Contact Angle DRIFT Electrostatic Deposition (CADED)</field><field name="subject">hydrophobicity</field><field name="subject">Silicone Elastomers</field><field name="subject">high voltage</field><field name="subject">applications</field><field name="identifier">http://eprints.qut.edu.au/16072/</field><field name="validLink">True</field></doc><doc><field name="title">Understanding the Experiences of Primary Caregivers Who Care for a Ventilator-Dependent Child at Home</field><field name="creator">Wang, Kai-Wei (Katherine)</field><field name="description">The research investigates, qualitatively, the experience of primary caregivers of children who are ventilator-dependent and cared for at home.  Advances in medical and nursing knowledge and technology have improved the biological outcome of children who are critically ill.  As a result, there is an increasing number of children in hospital who are medically stable, however dependent upon long-term respiratory support.  Due to the increasing change from healthcare delivery to home care, some ventilator-dependent children are discharged to their primary caregivers who undertake the medical and technical care of the children in their home.  A review of the literature indicates limited research examining and addressing issues of pediatric home ventilation.  Information concerning the experience and needs of the primary caregivers of an in-home ventilator-dependent child is thus unavailable for effective and appropriate clinical interventions and policy implementation. To address the gap in the literature, a phenomenographic research approach was used to identify and describe a limited number of qualitatively different ways in which the primary caregivers understood their experience of caring for a ventilator-dependent child at home.  An in-depth interview was undertaken with each of those seventeen participants and recorded on audiotape for transcribing verbatim.  Data was sorted using a qualitative software program--ATLAS.ti.--and analysed using a series of seven analytical steps recommended for a phenomenographic research (Dahlgren and Fallsberg, 1991).  The outcomes of the research are seven categories of description with each representing a conception of the experience, and all categories combined constituting an outcome space that presents the structural relations between conceptions.  The seven categories of description representing the care-giving experiences of the primary caregivers are: (1) 'Hospital is another world to me'; (2) 'It's a new world'; (3) An ambiguous social identity;(4) The medical technology associated with my child is frightening but necessary;(5) 'The difficulty is having the carers at home'; (6) Social isolation; and (7) The experience of changing as a person.  Discussions on the outcomes of the research indicate a need for increased understanding of the 'new world' of the primary caregivers and a recognition and acknowledgement of the distinctive nature of the experience in caring for a ventilator-dependent child at home.  Hence, increased financial, respite, psychological and social support are of central importance, in addition to ongoing healthcare research, education, and practice for appropriate policy development, implementation and evaluation.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Paediatric home ventilation</field><field name="subject">technology</field><field name="subject">community nursing</field><field name="subject">ventilator-dependent children</field><field name="subject">caregivers</field><field name="subject">family care.</field><field name="identifier">http://eprints.qut.edu.au/16073/</field><field name="validLink">True</field></doc><doc><field name="title">Effectiveness of Preservice Music Teacher Education Programs: Perceptions of Early-Career Music Teachers</field><field name="creator">Ballantyne, Julie</field><field name="description">The quality of teaching occurring in schools is directly linked to the quality of preservice preparation that teachers receive (Darling-Hammond, 2000). This is particularly important in the area of music teacher education, given the unique challenges that classroom music teachers commonly face (Ballantyne, 2001).  This thesis explores early-career music teachers' perceptions of the effectiveness of their preservice teacher education programs in Queensland.  It also explores influences impacting upon early-career music teachers' perceptions of effectiveness and early-career music teachers' perceived needs in relation to their preservice preparation.    The study addresses the research questions through the use of questionnaires and semi-structured interviews.  In Stage 1 of the research, questionnaires were completed by 76 secondary classroom music teachers in their first four years of teaching in Queensland, Australia.  In Stage 2 of the research, 15 of these teachers were interviewed to explore findings from the questionnaire in depth.  Findings suggest that preservice teachers perceive a need for teacher education courses to be contextualised, integrated and allow for the continual development of knowledge and skills throughout their early years in schools.  This research provides an empirical basis for reconceptualising music teacher education courses and raises important issues that music teacher educators need to address in order to ensure that graduates are adequately prepared for classroom music teaching.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Music teacher education</field><field name="subject">teacher education</field><field name="subject">curriculum</field><field name="subject">music education</field><field name="subject">early-career teachers</field><field name="identifier">http://eprints.qut.edu.au/16074/</field><field name="validLink">True</field></doc><doc><field name="title">A Women's Investment Club: A Case Study Investigating the Process of Empowerment by Active Participation in a Group Learning Environment</field><field name="creator">Elsworth, Jill</field><field name="description">Over the last two decades research into the notion of empowerment has been focused on the three primary dimensions of process, outcomes and environment within the contexts of the individual, community groups and business organisations.  As a psychological attribute, empowerment at the individual level has been investigated significantly by such theorists as Rappaport (1995) and Zimmerman (2000).  However, studies in this field neglect deep understanding of the reality of the individual's experiences of the empowerment process.  Definitions within the literature refer to empowerment as being a process which occurs over time for the individual who is personally challenged to achieve power and control within his/her own life context by the application and reflection of learning new knowledge and skills.    The purpose of this investigative case study is to examine the reality of the empowerment process as it occurs in the individual lives of a group of women who have actively participated in the learning environment of an investment club over a 2 year period in Brisbane.  The three dimensions of empowerment support the structure of the study with the findings evidencing 'authentic empowerment' is achieved when the individual seeks to operate within the dual learning environments of the supportive group as well as the solo learning environment.  The reality of individual authentic empowerment proved to be a continuum of experience dependent upon the individual's levels of motivation, energy, decision-making abilities, knowledge, risk taking, confidence, time and goals.  Sustainability of empowerment related to the participant's level of active involvement in the dual learning environments while accepting complete responsibility for actions and consequences.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">individual empowerment</field><field name="subject">adult learning</field><field name="subject">women&#146;s ways of knowing</field><field name="subject">power</field><field name="subject">transformational learning</field><field name="subject">empowerment</field><field name="subject">self-growth</field><field name="subject">motivation</field><field name="subject">authentic empowerment</field><field name="subject">praxis</field><field name="subject">feminist pedagogy</field><field name="subject">supportive groups</field><field name="subject">investment clubs</field><field name="subject">case study</field><field name="subject">spiritual</field><field name="subject">postpositivism</field><field name="subject">constructivism.</field><field name="identifier">http://eprints.qut.edu.au/16075/</field><field name="validLink">True</field></doc><doc><field name="title">Onboard Orbit Determination Using GPS Measurements for Low Earth Orbit Satellites</field><field name="creator">Zhou, Ning</field><field name="description">Recent advances in spaceborne GPS technology have shown significant advantages in many aspects over conventional technologies. For instance, spaceborne GPS can realize autonomous orbit determination with significant savings in spacecraft life cycle, in power, and in mass. At present, the onboard orbit determination in real time or near-real time can typically achieve 3D orbital accuracy of metres to tens metres with Kalman filtering process, but 21st century space engineering requires onboard orbit accuracy of better than 5 metres, and even sub-metre for some space applications. The research focuses on the development of GPS-based autonomous orbit determination techniques for spacecraft. Contributions are made to the field of GPS-based orbit determination in the following five areas:  Techniques to simplify the orbital dynamical models for onboard processing have been developed in order to reduce the computional burden while retaining full model accuracy. The Earth gravity acceleration approximation method was established to replace the traditional recursive acceleration computations. Results have demonstrated that with the computation burden for a 55&#215; spherical harmonic gravity model, we achieve the accuracy of a 7070&#215; model. Efforts were made for the simplification of solar &amp; lunar ephemerides, atmosphere density model and orbit integration. All these techniques together enable a more accurate orbit integrator to operate onboard. Efficient algorithms for onboard GPS measurement outlier detection and measurement improvement have been developed.  In addition, a closed-form single point position method was implemented to provide an initial orbit solution without any a priori information.  The third important contribution was made to the development of sliding-window short-arc orbit filtering techniques for onboard processing. With respect to the existing Kalman recursive filtering, the short-arc method is more stable because more measurements are used. On the other hand, the short-arc method requires less accurate orbit dynamical model information compared to the long-arc method, thus it is suitable for onboard processing. Our results have demonstrated that by using the 1 ~ 2 revolutions of LEO code GPS data we can achieve an orbit accuracy of 1 ~ 2 metres. Sliding-window techniques provide sub-metre level orbit determination solutions with 5~20 minutes delay. A software platform for the GPS orbit determination studies has been established. Methods of orbit determination in near-real time have been developed and tested. The software system includes orbit dynamical modelling, GPS data processing, orbit filtering and result analysis modules, providing an effective technical basis for further studies.  Furthermore a ground-based near-real time orbit determination system has been established for FedSat, Australia's first satellite in 30 years. The system generates 10-metre level orbit solution with half-day latency on an operational basis. This system has supported the scientific missions of FedSat such as Ka-band tracking and GPS atmosphere studies within the Cooperative Research Centre for Satellite System (CRCSS) community. Though it is different from the onboard orbit determination, it provides important test-bed for the techniques described in previous section. This thesis focuses on the onboard orbit determination techniques that were discussed in Chapter 2 through Chapter 6. The proposed onboard orbit determination algorithms were successfully validated using real onboard GPS data collected from Topex/Poseidon, CHAMP and SAC-C satellites.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">GPS measurements</field><field name="subject">Low Earth Orbit Satellites</field><field name="subject">GPS technology</field><field name="subject">onboard orbit determination</field><field name="subject">orbital dynamical models</field><field name="subject">onboard processing</field><field name="identifier">http://eprints.qut.edu.au/16076/</field><field name="validLink">True</field></doc><doc><field name="title">Regimes of truth : documentary photography in the margins</field><field name="creator">Mitropoulos, Maria Michael</field><field name="description">This thesis consists of two parts. The first is a series of photographic essays documenting the lived experience of a woman who is HIV positive and a group of young females who are socially marginalised. 
 
 The written component attempts to underlabour in a philosophical sense for the artistic/creative element of the thesis. That is, it seeks to take on a range of theoretical issues that cluster around the practice of documentary photography. By clarifying these issues the thesis endeavours to act as a stimulus to artistic practice and also to explain and introduce that practice to a wider audience. 
 
 Among the theoretical issues addressed is the ontological status of the documentary photograph. Here, the thesis draws upon Roy Bhaskar's Critical Realism to suggest a rational alternative to postmodernist scepticism and naive realism. 
 
 The thesis also takes on a range of ethical problems. Most important of these is the question whether the relationship between the photographer and her subject is inherently exploitative. The thesis attempts, in this case, to unite Emmauel Levinas' philosophy of the Other with Critical Realist Ethics. Here, the thesis advances a novel differentiation of the Other and combines this with the Critical Realist notion of ontological depth. The argument of the thesis is that the nature of the contract between the photographer and her subject depends on which Other the subject is regarded as. 
 
 In addition, the thesis explores the social and gender dimensions of documentary photography concentrating  in particular on the Farm Security Admininstration photography in America in the 1930s, and the radical self-imaging of the British photographer Jo Spence and the Pop Star Madonna.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">Other</field><field name="subject">documentary photography</field><field name="subject">truth</field><field name="subject">Critical Realism</field><field name="subject">Bhaskar</field><field name="subject">ethics</field><field name="subject">suffering</field><field name="subject">aesethetics</field><field name="subject">love</field><field name="subject">social marginality</field><field name="subject">HIV/AIDS</field><field name="identifier">http://eprints.qut.edu.au/16077/</field><field name="validLink">False</field></doc><doc><field name="title">A Framework for the Specification and Execution of Composite Trading Activities</field><field name="creator">Si, Yain Whar</field><field name="description">In this thesis, a framework for the specification and execution of composite trading activities is presented. We begin by introducing the basic concepts and characteristics of elementary and composite trading activities. Based on these characteristics, we identify the issues associated with composite trading activities and argue the requirements of a frame- work for the specification and execution of those trading activities. In the second chapter, the most relevant work on negotiation protocols, software specification approaches, and recent work on trading activity specification is reviewed. In the third chapter, we analyse the characteristics of negotiation protocols and the information required to adequately represent composite trading activities.   In the next two chapters, we introduce two alternative approaches (myopic and forward- looking) for specifying composite trading activities by means of constraints, such as the number of required successful negotiations, the limit price for the items to be traded, and the temporal constraints imposed by all trading parties. A special interface is also defined in each framework to homogenise trading activities with differing negotiation protocols.  In myopic trading, composite activities are synchronised according to the information available on the constituent negotiation processes at any point in time. Myopic trading supports iterative negotiation in which trading activities can be renegotiated with new constraints. Myopic trading is suitable for situations in which finer control over the negotiation process is preferred by the trader, and information on previous negotiations as well as future negotiation opportunities are unavailable.  Forward-looking trading is based on the generation of negotiation plans detailing the exact time and duration for which trading activities are going to be executed. These plans are generated based on the histories of previous negotiations and future negotiation opportunities. In forward-looking trading, a planning and execution model is designed to maximise the expected utility of the trader. Forward-looking trading is suitable for situations in which a well-planned negotiation process is possible.  In the following chapter, two case studies are given to illustrate the applicability of the proposed framework. In the final chapter, we review our framework based on the set of requirements defined for the specification and execution of composite trading activities. In conclusion, we believe that composite trading activities can be effectively specified and executed based on the homogenisation of the various negotiation protocols involved and systematic planning of how these activities are going to be executed.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Trading Activities</field><field name="subject">Negotiation Protocols</field><field name="subject">Trading Specification</field><field name="subject">Trading Execution And Synchronisation.</field><field name="identifier">http://eprints.qut.edu.au/16078/</field><field name="validLink">True</field></doc><doc><field name="title">Effects of Professional Development on Teachers' Integration of ICT in Teaching in Hong Kong</field><field name="creator">Leung, Kin Ping</field><field name="description">This study produced a theoretically grounded model of professional development suited for supporting teachers in Hong Kong to embed Information and Communication Technologies into the Primary School Curriculum. The model was developed and tested over two years through an intervention based on participatory action research involving school staff and the researcher as a critical friend. The model was tested through the analysis of extensive qualitative and quantitative analysis of teacher behaviours and curricular documents. Teachers' beliefs and practices were found to change significantly during the first year of the project and were further refined during the second year. Leadership, collegial support, physical infrastructure, teacher self-efficacy, and technical knowledge were identified as the most important factors underpinning the successful implementation of the program. The model addresses these factors and has considerable potential to impact on educational practice involving ICT in the Hong Kong context.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Staff Professional Development</field><field name="subject">Information and Communication Technology (ICT)</field><field name="subject">Teacher change</field><field name="subject">Integration of technology in teaching</field><field name="subject">Participatory Action Research</field><field name="subject">Self-Efficacy</field><field name="subject">Teachers&#146; Perceptions of own ICT Skills</field><field name="identifier">http://eprints.qut.edu.au/16079/</field><field name="validLink">True</field></doc><doc><field name="title">Measuring Intrinsic Fluorescence Of Airborne Particles For Real-Time Monitoring Of Viable Bioaerosols</field><field name="creator">Agranovski, Victoria</field><field name="description">Development of the advanced, real-time methods for monitoring of bioaerosols is becoming increasingly important. At present, the Ultraviolet Aerodynamic Particle Sizer (UVAPS, Model 3312, TSI, St. Paul., MN) is the only commercially available method for in-situ, continuous measurements of viable airborne microorganisms.  Research included in this thesis aimed towards comprehensive evaluation of the method over a wide range of operating conditions, linking the experimental results to  the theoretical basis of its design and operation, and to developing a scientific basis  for its application to real-time monitoring of bioaerosols. Specifically, due to a growing concern in the general community about the environmental and health aspects of biological aerosols originated from various types of agricultural operations including animal farming, this research was focussed on developing a research methodology/strategy for applying the method to the investigation of bioaerosols in the swine confinement buildings (SCB).    Investigations under controlled laboratory conditions were primarily concerned with  selectivity, sensitivity, counting efficiency, and detection limits of the spectrometer.  This study also examined the effect of physiological state (metabolic activity) of  bacteria on the performance characteristics of the method. The practical implications of the research findings are discussed in this thesis. Further field investigations undertaken on a pig farm advanced understanding of the UVAPS performance in the real-life environmental settings. The research also provided a new insight on the particle size distribution and the effect of on-farm-activities on aerosol load inside the SCBs, for both biological and non-biological aerosols.    This study has proved that the UVAPS is a powerful tool for investigation of viable bioaerosols in the environment. However, this method is limited to detection of active metabolising bacteria that excludes dormant bacterial spores. In addition, the method is very sensitive to physiological state of bacteria and to the effect of adverse environmental conditions on metabolic activity of airborne bacteria, which may decrease the amount of the intrinsic fluorophores in the cells below sensitivity level iv of the monitor. Possible limitations of this technology include also the lack of selectivity and thus interferences from the non-microbial organic components of airborne particles. In addition, the sensitivity of the method is insufficient for  monitoring viable bacteria in the environments with relatively low concentrations of bioaerosols. In order to increase sensitivity of the method, it would be desirable to concentrate the bioaerosols into a smaller volume with the aim of high-volume virtual impactors (aerosol concentrators) prior to the monitoring. Therefore, in the indoor environments where an application of the concentrator is not feasible, the utilisation of the UVAPS may be problematic. Due to the intrinsic limitations, the method is not recommended for the direct measurements of viable bioaerosols and should be used in conjunction with the conventional biosamplers for obtaining more realistic insights into the microbial air quality. Nevertheless, the UVAPS has been found to be an adequate method for the investigation of the dynamics of biological aerosols in real-time.    Overall, this thesis contributes to the advancing of the understanding of the method  and may assist in developing new, more advanced technologies for the real-time monitoring of viable bioaerosols, as well as in developing sampling strategies for the application of the method to various bioaerosol studies.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Bioaerosols</field><field name="subject">real-time monitoring</field><field name="subject">performance evaluation</field><field name="subject">intrinsic fluorescence</field><field name="subject">counting efficiency</field><field name="subject">sensitivity</field><field name="subject">detection limits</field><field name="subject">viable bacteria</field><field name="subject">metabolic state</field><field name="subject">particle size distribution</field><field name="subject">swine confinement buildings</field><field name="identifier">http://eprints.qut.edu.au/16080/</field><field name="validLink">True</field></doc><doc><field name="title">Virus Diversity and the Emergence of Dengue</field><field name="creator">Thu, Hlaing Myat</field><field name="description">The aims of this study were to investigate the role of the diversity of dengue virus populations in changing patterns of virus transmission and disease. Prior to the commencement of this study, dengue 2 virus (DENV-2) had been associated most frequently with severe disease, so the study commenced with this serotype. Because it was not possible to quantitate diversity in the entire 11 kb of the viral genome, the study focussed on the envelope (E) gene, because the E protein is the major protein on the surface of the virion and thus might be under strong selective pressure from the host immune system and from the requirement to engage specific receptors on host cells. This study was the first direct quantification of the diversity of dengue virus populations in individual hosts. The nucleotide sequences of more than 70 per cent of the E genes in each virus population differed from the consensus nucleotide sequence for the population. In the course of quantitating genetic diversity in DENV-2 virus populations in patients and in mosquitoes, recombinant DENV-2 and both parental virus populations  were detected in a single mosquito. This was the first such report. 	In 2001, just after the commencement of this study, Myanmar had the largest outbreak of dengue on record. Unlike previous outbreaks, 95 per cent of dengue viruses isolated from patients were of a single serotype, DENV-1. Despite the large number of cases of dengue, the proportion of patients with severe dengue was low. In the light of these observations, the direction of this study changed to focus on DENV-1. Phylogenetic analysis of the E genes of DENV-1 collected before and after the 2001 dengue outbreak suggested that some time before 1998, an early lineage of DENV-1 had become extinct and had been replaced by two new lineages. There was no evidence that these changes were due to selection or to recombination within the E protein genes of the old clade of viruses and the newly introduced viruses. 	A more detailed analysis was undertaken, of the entire genome of 11 human DENV-1 isolates and of 4 from mosquitoes recovered in Yangon between 1971 and 2002, to determine whether the extinction of the pre-1998 lineage of DENV-1   (clade A) and the appearance of the two new lineages (clades B and C) could have been due to selective pressures acting on genes other than E. Evidence of only weak selection was found in the NS5 gene (at amino acids 127,135 and 669) but the resultant amino acid changes did not distinguish all recent viruses from viruses belonging to the extinct clade. The phylogenetic relationships between individual genes from these viruses and between the open reading frames were similar. No evidence was found of recombination that might have given rise to two new clades of virus with enhanced fitness. Collectively, these data suggested that the extinction of clade A viruses and their replacement by the two new clades, between 1998 and 2000 was a stochastic event in an inter-epidemic period when rates of virus transmission were low. This was the first report of such an extinction of a lineage of DENV-1 and its replacement by new lineages.  	At about the same time as the 2001 outbreak of DENV-1 infection in Myanmar, an outbreak of DENV-1 began in the Pacific. A comparison of the nucleotide sequences of the E genes of viruses from the Pacific with those of viruses from throughout south-east Asia suggested that the outbreak in the Pacific was due to the introduction of multiple genotypes of DENV-1 from Asia and that some of these DENV-1 could have originated in Myanmar. 	The principal observations from this study are: -  (a) Dengue virus populations in individual hosts are extremely heterogenous and may contain a significant proportion of non-infectious genomes.  (b) Intra-serotypic recombination between dengue viruses may be far more common than the literature suggests but it may not be detected because of the almost universal use of consensus nucleotide sequences.  (c) Significant changes in dengue virus genotypes that occur at single localities may be due to genetic bottlenecks rather than to selection or to recombination.  (d) Dengue viruses can be transported more than 10,000 km to cause outbreaks in non-endemic areas.  Key words: Dengue viruses, diversity, recombination, selection, genetic bottleneck</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Virus</field><field name="subject">Virus Diversity</field><field name="subject">Dengue</field><field name="identifier">http://eprints.qut.edu.au/16081/</field><field name="validLink">True</field></doc><doc><field name="title">Factors Influencing the Implementation of Raised Floor System for the Fitout of Office Buildings in the Australian Context</field><field name="creator">Zhang, Guomin</field><field name="description">The study described in this thesis investigates how the implementation of raised floor system (RFS) for the fitout of office buildings can be promoted in the Australian construction industry. It essentially achieves this goal through justifying the RFS fitout advantages, improving industry practitioners' awareness of the innovative technology, and identifying the barriers hindering RFS application, and exploring integrated approaches to overcome these barriers.    Due to increasing levels of technological, environmental and organizational changes in office buildings, the traditional office building fitout method cannot deliver flexible services economically and in a timely manner. RFS is highlighted for its superior underfloor distribution technologies and ability to promote healthy workplace environments and organizational flexibilities. Despite the many benefits RFS may bring, this innovative technology has not been widely used. Therefore, for countries with potential growth in the office building market, including Australia, how to make this state-of-the-art fitout technology more acceptable is of great importance. To encourage the RFS implementation in office buildings, the research set up five objectives: (1) to justify the RFS advantages for office building fitout compared with traditional fitout method; (2) to identify and present appropriate specifications of RFS products and applications in order to improve industry practitioners' awareness on RFS fitout; (3) to identify and seek potential solutions to barriers hindering RFS fitout implementation; (4) to integrate the barriers and their solutions into RFS project delivery using constructability study; and (5) to formulate guidelines for RFS fitout implementation in office buildings in the Australian construction industry. A comprehensive research methodology consisting of questionnaire, semi-structured interview, site observations, focus groups, life cycle cost (LCC) comparison, and constructability study was structured to support the exploratory research.    With a combined qualitative and quantitative data analysis method, the questionnaire and interview surveys revealed the low level recognition of RFS within the industry, and identified 20 significant influence factors (SIFs) and 15 real problems associated with RFS fitout implementation. The site observations and focus groups validated the survey findings and justified the RFS fitout advantages. Then, the LCC comparison established a model and verified the LCC benefits of RFS fitout through a case study. The final discussion on the SIFs, real problems and their solutions uncovered 36 project level critical factors pertaining to RFS fitout design, construction, operation and maintenance. A constructability study was employed to integrate these key factors into RFS fitout project delivery, such as construction knowledge inputs, team skills, and RFS fitout programs. More importantly, five key issues with significant influences were revealed. Further investigation of these key issues led to a framework for the constructability implementation, a contracting strategy with nominated specialist contractors under CM/GC, and a process-based conceptual model for the selection of RFS products. Based on these findings, a set of guidelines for the RFS fitout implementation in office buildings was formulated as a contribution to practice. Questionnaires were again used to invite comments on the key issues and guidelines, and the results proved the validity of the research outcomes.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Raised Floor System</field><field name="subject">Fitout</field><field name="subject">Office Buildings</field><field name="subject">Constructability</field><field name="subject">Life Cycle Cost</field><field name="subject">Comparison</field><field name="subject">Guidelines</field><field name="subject">Australia</field><field name="identifier">http://eprints.qut.edu.au/16082/</field><field name="validLink">True</field></doc><doc><field name="title">Creative Industries and the Paper Industry  A Creative Industries approach to linking visual artists and the paper industry: A Case Study of New Possibilities for Paper</field><field name="creator">Ballinger, Christine Beth</field><field name="description">In the knowledge economy, the 'creative industries' are recognised as a new paradigm. They are industries which use creativity as an intangible asset to generate wealth. The creative industries are described as 'evolving' and their outcomes frequently categorised as 'intangibles'. The thesis outlines what I term a creative industries approach to the engagement of visual artists with industry.    The artist-in-industry program, a component of New Possibilities for Paper, was established with an explicit brief to generate creative products and contained an implicit agenda to breed intellectual capital. It was conceived as a means of crossfertilising hitherto siloed sectors -- an arts environment with entrenched attitudes towards the subsidy, proprietorship and authority of creativity and the traditionally conservative paper industry.    Establishing creative industries characteristics and indicators to describe and measure creative industries operation in this program required careful consideration, with the characteristics and indicators selected able to recognise trends or changes. The analysis of the seven partnerships confirmed that the artistin-industry program is a creative industries approach upon which future programs between visual artists and the paper industry could be constructed.    The research found that the creative industries processes in most need of being addressed, if visual artists are to maximise their benefits, included an understanding and utilisation of intellectual property, knowledge of commercialisation processes and a positive attitude towards commercialisation. For paper companies that invest in R&amp;D, there is recognition that potential tangible and intangible benefits can result from engaging in such partnerships. Additionally, a partnership in which the artist's role (or service) is focused on the industry's customers and contributes to employee knowledge was seen as being of greatest value to the paper industry.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">artist-in-industry partnerships</field><field name="subject">creative industries</field><field name="subject">cultural industries</field><field name="subject">intangibles</field><field name="subject">intellectual property</field><field name="subject">creative capital</field><field name="subject">structural capital</field><field name="identifier">http://eprints.qut.edu.au/16083/</field><field name="validLink">True</field></doc><doc><field name="title">Beyond the Divide: Relations between Teachers and Academics in a Collaborative Research Partnership</field><field name="creator">Hall, Graeme William</field><field name="description">The notion of "partnership" dominates contemporary school improvement and educational reform agendas. Most discourse about partnerships between schools and universities historically relates to the apparent divide between practice and theory, between practitioner and academy. This study departs from these traditional perspectives to move beyond the divide between teachers and academics. Designing strategies for re-visioning this historical divide within the education community, between teachers and academics, engages the profession at all levels. Instead of simply re-visioning this divide, however, we can envision a professional place where the divide does not exist. Addressing this divide requires teachers and academics, when they do come together for the purpose of collaborative work of any kind, to actively seek to understand each other's work.    This study examines one school and university partnership that was modelled on the principles of a Professional Development School. It investigates the meeting talk between groups of teachers and academics as they plan and report on a collaborative project aimed at improving Mathematics teaching practices in the school. Whereas most research investigating school and university partnerships addresses the outcomes of such partnerships, or attempts to describe and advocate for ideal partnerships, this study considers the actual interactional work of the participants as they engage in the everyday and ongoing activities of partnership. It shows how partnerships are constructed through talk and activity. Instead of considering the partnership as a predetermined and pre-existing phenomenon, this study adopts the view that the work of partnership is an ongoing accomplishment through the activity of the participants. In this way, this study shows the local social order of a partnership as it was built, maintained and transformed through the interactional work of the participants. Both the institutional setting and the participants' enactment of partnership work contribute to the establishment of the social and moral order of the partnership.    The principal question addressed in the study asks how participants accomplish the partnership work through their social interactions with one another. It considers the interactional resources that the partners (teachers, interns and academics) use to construct their talk and interactions with one another in the project; and how the partners construct themselves and the other members as members of the partnership, as academics/researchers and as teachers.    This study drew on ethnomethodological resources to develop understandings about how the participants accomplish the partnership work through their talk-in-interaction.  The specific focus is the talk of partnership that occurred in meetings between members of the school and of the university. These meetings were audio-recorded, transcribed, and finely analysed using the techniques and procedures of conversation analysis and membership category analysis. These methodological resources revealed the social and moral orders at work. Analysis of the meeting talk shows the specific activities and relationships developed by the principal of the school in the accomplishment of the partnership; the ways in which the various participants develop and use their claims to expertise (or lack of it) in doing partnership work; and how participants use the institutional resource of meeting talk to accomplish the partnership work.    The study is of significance to educators, teachers and academics. It provides new and rich understandings about how school and university partnerships are accomplished through the participants' meetings. It shows the resources that the participants use to construct and accomplish their different kinds of expertise, to enact the leadership activities required, and to co-construct the various features of partnership. The study offers analytic tools for uncovering the interactional resource of the participants. The ethnomethodological resources, particularly conversation analysis and membership category analysis, can be used to analyse in close detail the social interactions of participants in the institutional talk of meetings. In showing how the social and moral orders of partnerships are revealed and by offering understandings of the pragmatics of school and university partnership, the social structure of school and university partnerships is explicated. The study offers one example of what a school and university partnership can be like. Epistemologically, it explores and exposes the kinds of knowledge produced from this kind of accounting for school and university partnerships. It shows how the work of partnership can be accomplished by participants, rather than attempt to claim how it should be done.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">School-university partnership</field><field name="subject">Professional development</field><field name="subject">Meeting talk</field><field name="subject">Expertise</field><field name="subject">Leadership</field><field name="subject">Ethnomethodology</field><field name="subject">Conversation analysis</field><field name="subject">Membership category analysis</field><field name="identifier">http://eprints.qut.edu.au/16084/</field><field name="validLink">True</field></doc><doc><field name="title">Words and phrases used in written communication by eight personality types as measured by the Myers-Briggs type indicator : a contribution to the theory</field><field name="creator">Short, Elizabeth Anne</field><field name="description">Written communication is an integral part of any organisation regardless of size or the nature of its business. The writer chooses words that should be understood by the readers. However, these words have been chosen based on a variety of factors, one of which is personality type, and the writer's personality type may differ from that of the readers. The research question underpinning this study is - In what ways, if at all, do personality types (as determined by the Myers-Briggs Type Indicator&#61666; (MBTI) and most frequently found in management positions), select and use different words and phrases when writing business communication? To investigate this question, the psychological type theory of Jung, the personality type theory of Briggs and Myers, and organisational communication theory are applied. The methodology used is descriptive research with the documents analysed using content analysis, employing NUD.IST Vivo in conjunction with manual assessment. The research findings confirm that each personality type does use different words, validating personality type theory and therefore, making a contribution to the expanding body of research in this field. The knowledge gained from this study has significance in areas related to organisations as well as education and communication theory.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Myers-Briggs Type Indicator</field><field name="subject">MBTI</field><field name="subject">Psychological type</field><field name="subject">Personality type</field><field name="subject">Management</field><field name="subject">Managers</field><field name="subject">Business communication</field><field name="subject">Written communication</field><field name="subject">Communication channels</field><field name="subject">Words and phrases</field><field name="subject">Descriptive research</field><field name="subject">Content analysis</field><field name="subject">NUD.IST Vivo (NVivo)</field><field name="identifier">http://eprints.qut.edu.au/16085/</field><field name="validLink">True</field></doc><doc><field name="title">Electrical Characteristics of Aged Composite Insulators</field><field name="creator">Zhou, JianBin</field><field name="description">Composite insulators are widely being used in power industry to alternate traditional  porcelain-based insulators for their advantages, including better pollution performance, low  maintenance cost, light weight, compact line design. However, due to the short application  history and experience, the degradation of composite insulators in natural environment is a  big concern for the power utilities. The knowledge on the degradation of composite insulators is being studied world wide. The methods to assess the working conditions of composite insulators are being studied and created. In Queensland University of Technology (QUT), the approach based on chemical analysis methods was first developed. The work in this thesis based on the previous research work is focused on correlating electrical characteristics with chemical analysis results of the composite insulators and physical observations results. First,the electrical characteristics of composite insulators were presented and analysed, including leakage current, cumulative current, peaks of leakage current, the statistic results of the leakage current. Among them, the characteristics of leakage current were mainly studied. The  shape of waveforms was found to relate to the degree of discharge activities of the composite  insulators. The waveforms analysed by FFT revealed that the odd harmonic components  became obvious during the discharge activities. The correlations between the electrical  characteristics of composite insulators and chemical analysis results showed that the  composition of composite insulators plays significant roles in terms of electrical performance. The oxidation index (O.I.) and the ester/ketone ratio (E/K) differentiated the different degradation reasons of the composite insulators in the test conditions. Finally, the thesis presents one approach, which aims to assess the surface conditions of composite insulators in an easy manner and in short time.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">Composite insulator</field><field name="subject">Electrical characteristic</field><field name="subject">Aging</field><field name="subject">Fog chamber</field><field name="subject">EPDM insulator</field><field name="subject">Leakage</field><field name="identifier">http://eprints.qut.edu.au/16086/</field><field name="validLink">True</field></doc><doc><field name="title">Sequence Stratigraphic Interpretation integrated with 3-D Seismic Attribute Analysis in an Intracratonic Setting: Toolachee Formation, Cooper Basin, Australia</field><field name="creator">Krawczynski, Lukasz</field><field name="description">This study integrates sequence stratigraphy of the Late Permian Toolachee Formation in the non-marine intracratonic Permian-Triassic Cooper Basin, Australia with 3-D seismic attribute analysis to predict the extent of depositional environments identified on wireline and well core data. The low resolution seismic data (tuning thickness 23 - 31 m) comprised of six seismic horizons allowed the successful testing of sequence stratigraphic interpretations of the productive Toolachee Formation that were based on wireline data. The analysis of 29 well logs and three 20 m core intervals resulted in the identification of eleven parasequences that comprise the building blocks of an overall transitional systems tract, characterised by a gradual increase in accommodation. The parasequences reflect cyclic transitions between braided and meandering fluvial systems as a result of fluctuations in sediment flux, possibly driven by Milankovitch climatic-forcing. The seismic horizon attribute maps image mostly the meandering fluvial bodies within the upper parts of the parasequences, but some maps image the lower amalgamated sand sheets and show no channel structures. Categorisation of the fluvial bodies in the overbank successions reflects a gradual decrease in sinuosity, channel width, and channel belt width up-section, supporting the overall increase in accommodation up-section. Similar acoustic impedance values for shales and sands do not suggest successful seismic forward modelling between the two lithologies. Geological interpretations suggest most imaged channel fill to be made up predominantly of fine sediments, as channel avulsion and abandonment is common and increases with time. Seismic forward modelling resulted in the interpretation of carbonaceous shale as a possible channel fill, supporting the geological interpretations. The three major identified fluvial styles; braided, meanders, and distributaries are potential targets for future exploration.  Extensive sand sheets deposited from braided fluvial systems require structural traps for closure. Meandering and anastomosing channel systems represent excellent stratigraphic traps, such as the basal sands/gravels of laterally accreted point bars.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Toolachee Formation</field><field name="subject">Patchawarra Formation</field><field name="subject">Cooper basin</field><field name="subject">Eromanga basin</field><field name="subject">3D seismic reflection</field><field name="subject">seismic attribute analysis</field><field name="subject">nonmarine sequence stratigraphy</field><field name="subject">coal</field><field name="subject">fluvial systems</field><field name="subject">Permian</field><field name="subject">nonmarine parasequences</field><field name="subject">Queensland.</field><field name="identifier">http://eprints.qut.edu.au/16087/</field><field name="validLink">True</field></doc><doc><field name="title">Studies of enzymes from two protease families: Tissue Kallikreins, ADAMs and MMPs.</field><field name="creator">Manzetti, Sergio</field><field name="description">The human kallikrein family is a family of proteolytic enzymes, classified as serine proteases, that derive from chromosome 19, locus 13.3-13.4. These enzymes are widespread in pathophysiological processes such as cancer and neurodegenerative diseases; hence studies of catalytic sites and inhibitors are important in relation to the longer term of design of therapeutic drugs. One member of the family, human kallikrein 4 (hK4) which is thought to carry out crucial functions in the prostate, was expressed in this study as a secreted protein in a baculovirus expression system, bearing a His-tag and V5-epitope that were used for purification and detection respectively. Its mass was estimated to be 35kDa, ~2kDa less than the equivalent product expressed in monkey kidney cells. The protein was purified to 50-90% purity with a yield of 0.93mg/L-4.8mg/L based on methods derived from computational prediction of its properties, such as pI. Computational analysis was extended by applying high-performing computing techniques, such as molecular dynamics, and flexible ligand docking, to predict antigenic regions, the likely substrate specificity and putative inhibitors. These results show that hK4 has a loop, between Leu83-Ser94 that shows promise as a specific segment that can be exploited for generation of antibodies. Preferred substrates were also predicted to bear hydrophobic residues at the P'-region of the scissile bond and amphiphilic residues at the P-region. At the S-region, hK4 potentially involves its unique PLYH-motif in recognizing the P4/P5 position from the substrate. Flexible ligand-docking studies indicate that hK4 can be inhibited by inhibitors that carry a modified bulky hydrophobic sidechain with a guanidinium group at the P1-position and its own putative autoactivation region residues at the P2, P1' and P2' position. The computational study was extended to other members of the kallikrein family, predicting distinctions between these that could be used for future studies. These results show that 8 of the fifteen kallikrein members are very homologous in terms of specificity bearing typical trypsinlike activity and specificity, except for hK2, hK3, hK4, hK5, hK7, hK9, hK15 that retain certain distinct signatures in the binding pocket in terms of secondary specificity.  The principles of substrate-specificity analysis that were developed were further applied on three metzincins, MMP-3, ADAM-9 and ADAM-10. These three enzymes are metalloproteases, which are involved in tissue remodeling, intracellular signalling and cell-to-cell mediation. The substrate-specificity analysis was carried out on all three metzincins using the structure of a crystallized complex of the MMP-3 enzyme with the TIMP-1 natural inhibitor as template. In this specific enzyme-substrate complex, the challenge was to model and suggest a possible orientation of the P-region, which is not known. The interactions on the P/S-region are therefore unclear and need to be clarified. In order to suggest the arrangement of the enzyme-substrate complex and the undefined S-subsites, four new residues were added in an extended beta-sheet conformation to the P1' residue (derived originally from the TIMP-1 inhibitor) to create a full-length modeled substrate spanning P4'-P4. This new modeled region, in particular, was bound through backbone H-bonds with the enzyme at position 169 (MMP nomenclature) suggesting a new crucial residue for substrate binding, and satisfied steric and chemical restraints in the S'-region of the enzyme.  This modeling approach also indicated a putative presence of an S2/S3-pocket on these metzincins which is composed of different residues for MMP-3, ADAM-9 and ADAM-10, and which could prove useful for future drug design projects. Furthermore, the data argue against the involvement of a polarizable water molecule in catalysis, a mechanism that has been postulated by various groups. A new catalytic mechanism is suggested to involve an oxyanion anhydride transition state.  This study is a demonstration of the power of combining bioinformatics with wet-lab biochemistry.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Human kallikrein family</field><field name="subject">Prostate-cancer</field><field name="subject">Kallikrein 4</field><field name="subject">Baculovirus system</field><field name="subject">Purification</field><field name="subject">Metalaffinity</field><field name="identifier">http://eprints.qut.edu.au/16088/</field><field name="validLink">True</field></doc><doc><field name="title">Talking Past Each Other: The Impact of Cross-Cultural Communication on Construction Project Management in Samoa</field><field name="creator">Tone, Konelio</field><field name="description">Developing effective strategies for international construction projects requires knowledge and expertise that is technically, socially, politically, economically and culturally based (Fellows et al., 2002). These strategies all require effective communication to work. Communication in the international environment is further complicated by the differences in languages and cultures involved. The importance of effective communication cannot be overemphasised because it is the ultimate means by which behaviour is modified, change is effected, knowledge is acquired and shared, and goals are achieved (Howes and Tah, 2003). According to Loosemore and Al Muslmani (1999), communication problems will emerge as one of the most significant contemporary challenges facing construction project managers in an increasingly international construction market. However, Dieckmann (1996) points out that communication is also regarded as one of the most neglected and overlooked parts of international operations, and lack of communication has been cited as one of the biggest reasons for the failure of change projects to meet their expectations (Pardu, 1996). Cross-cultural communication is defined as "the process whereby individuals from different cultural backgrounds attempt to share meanings and feelings through the exchange of verbal and non-verbal messages" (Harris and Moran, 2000). This sequential explanatory mixed methods study investigates the impact of cross-cultural communication on construction project management systems in Samoa. The first phase involved an opinion questionnaire survey with predominantly quantitative questions addressing the impact of human and cultural influences on project management and crosscultural communication evaluation processes, as experienced by expatriates and local managers, who have worked or are working in Samoa across a number of industries. Qualitative interviews were used in the second phase to probe significant themes and  findings in the first phase by explaining and exploring aspects of the cross-cultural  communication process focusing on construction project managers and supervisors working in Samoa.  The quantitative results and qualitative findings generally confirmed the literature on crosscultural communication and related project management issues. The findings highlighted contrasting views between the different nationalities involved in projects in Samoa.  Specific 'new themes' to a small island nation such as Samoa were identified. This research developed a generic conceptual framework for cross-cultural communication evaluation in an international project environment. An integrated cultural framework was also formulated to identify central differences in culture. In conclusion, it is clearly evident from this study that international project management requires an effective process regarding communication evaluation. The findings indicate there is no single 'best solution' to effectively manage the impact of cross-cultural communication on management systems. Rather, it requires the application of appropriate strategies by the proactive practitioners with the necessary cross-cultural skills that best suit the host environment in which the projects are being carried out.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Culture</field><field name="subject">Cross-cultural</field><field name="subject">Communication</field><field name="subject">Human Factors</field><field name="subject">Project Management</field><field name="identifier">http://eprints.qut.edu.au/16089/</field><field name="validLink">True</field></doc><doc><field name="title">What are the roles of networks and clusters in the operation of an industry? The case of Queensland music</field><field name="creator">Ninan, Abraham</field><field name="description">The doctoral thesis examines Queensland's music industry in terms of concepts derived from cluster and network theories in the context of literature discussing creative industries. To this end, the thesis is conceived as one case study incorporating quantitative surveys, convergent interviews and document analyses as its units of investigation. This is necessary because it is the industry as a whole that is the object of theorizing (in terms of Porter and network theory). The 357 firms surveyed represent the creative content producers, distributors and suppliers that comprise Queensland's music industry. The sample for the survey was randomly selected from a universe of 10977 individuals and/or organisations involved in the following sectors of Queensland's music business: music publishing, record companies and distributors, recorded music retailing, other performing arts/music and theatre productions, music composition, and music performance. The data was analysed to understand and describe the nature of firms in the industry and investigate cluster and network dynamics in the operation of the industry. Twenty convergent interviews were also undertaken to further elaborate the qualitative dimensions of cluster and network dynamics in the industry, with particular attention to understanding how the factor input conditions of Porter's cluster model work in practice in the industry, as well as elucidating network effects not adequately addressed by Porter's theory. Policy and industry documents relating to Queensland's music industry were used to contextualise the findings. The conclusions articulate how Queensland's music industry operates as a cluster, and how innovation and creativity are facilitated. The thesis finds Porter's model insufficient to describe some key aspects of this industry's operation. Face-to-face communication, trust and informal networks combine explicit and tacit knowledge to bring about innovation. Thus the industry should be conceived of as a cluster of networks. Furthermore, the findings problematise the notion of distance in cluster and network theories. Traditionally, distance has been conceived in geographic terms; the findings suggest that in the music industry, distance must be understood as cognitive and cultural as well as geographic. The findings provide a detailed set of theoretical modifications to cluster and network theories. Implications are discussed for industry development and policy in Queensland's music industry.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Cluster</field><field name="subject">Cluster of networks</field><field name="subject">Cognitive distance</field><field name="subject">Communicative distance</field><field name="subject">Explicit knowledge</field><field name="subject">Geographic distance</field><field name="subject">Informal networks</field><field name="subject">Music industry</field><field name="subject">Networks</field><field name="subject">Policy</field><field name="subject">Queensland</field><field name="subject">Tacit knowledge</field><field name="subject">Theory of optimum distance</field><field name="identifier">http://eprints.qut.edu.au/16090/</field><field name="validLink">True</field></doc><doc><field name="title">The Ending Needs Work  AKA the Good, the Bad and the Ugly of being an independent filmmaker in Australia</field><field name="creator">Catling, Aaron</field><field name="description">Over the period of candidature, write and direct a feature film to completion. Furthermore, undertake a thorough reflective phase which involves the analysis of each aspect relating to those key components, writing and directing. Through this form of creative practice and utilising state of the art digital filmmaking techniques it is hoped that an addition to knowledge will be achieved.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Filmmaker</field><field name="subject">Australian film</field><field name="subject">Camera coverage</field><field name="subject">High Definition</field><field name="subject">Casting</field><field name="subject">Vision editing</field><field name="subject">Independent film</field><field name="subject">Directing/Director</field><field name="subject">Actors</field><field name="subject">Video</field><field name="subject">Location scouting</field><field name="subject">Sound editing</field><field name="subject">Low budget features</field><field name="subject">Writing/Writer</field><field name="subject">Rehearsal</field><field name="subject">Feature film</field><field name="subject">Composition</field><field name="subject">Screen performance</field><field name="identifier">http://eprints.qut.edu.au/16091/</field><field name="validLink">True</field></doc><doc><field name="title">Batavia and the Problem of Truth</field><field name="creator">Carr, Patrick</field><field name="description">The play Batavia re-tells the story of a Dutch East India Company ship, wrecked off the West Australian coast in 1628. In writing Batavia, I consider issues of ethics and pragmatics in deciding how best to use or adapt historical sources--choices often between historical accuracy and effectiveness on stage. The playscript illustrates choices made. The exegesis examines the literature surrounding these considerations, and looks at other writers' comments and approaches to the problem. It suggests a pragmatics of playwrighting is well grounded in philosophy and is a more fruitful approach than the traditional 'ethical' approach.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Batavia</field><field name="subject">shipwreck</field><field name="subject">Jeronimus Cornelius</field><field name="subject">Torrentius van der Beeck</field><field name="subject">Holocaust</field><field name="subject">pragmatic</field><field name="subject">ethics</field><field name="subject">pragmatics</field><field name="subject">Calvinism</field><field name="subject">Houtmans Abrollhos</field><field name="subject">accuracy</field><field name="subject">truth</field><field name="subject">cultural ownership</field><field name="subject">Dutch East India Company</field><field name="subject">Holland</field><field name="subject">Demidenko</field><field name="identifier">http://eprints.qut.edu.au/16092/</field><field name="validLink">True</field></doc><doc><field name="title">Aggressive Flesh: The Obese Female Other</field><field name="creator">Broom, Hannah</field><field name="description">My visual art practice explores the point at which a sense of bodily humour and revulsion may intersect in the world of the monstrous-feminine: the female grotesque, presented as my own obese (and post-obese) body. This exegesis is  a written elucidation of my visual art practice as research. As an artist I create performative photographic images featuring taboo or  otherwise 'inappropriate' subject matter, situations, materials and behaviours including bodily fluids, offal, internal organs and my own post-obese body. Through these modes of working, I establish and investigate the subjectivity of  flesh: Why are we repulsed by the female grotesque? How can this flesh be used to subvert readings of the female body? My research is informed by those understandings of the female body, sexuality and difference described in the work of feminist theorists including Julia Kristeva, Helene Cixous, Ruth Salvaggio and Elizabeth Grosz. I explore the work of influential artists such as Eleanor Antin, Carolee Schneeman, Cindy Sherman and Sarah Lucas. In this context, I present my own visual art practice as a point from which the monstrous-feminine can be given voice as sentient, intelligent flesh.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Visual Art</field><field name="subject">Practice-Led Research</field><field name="subject">Obesity</field><field name="subject">Fat</field><field name="subject">Monstrous-feminine</field><field name="subject">She-Monster</field><field name="subject">Female Grotesque</field><field name="subject">Other</field><field name="subject">Feminism</field><field name="subject">Psychoanalysis</field><field name="subject">Autobiography</field><field name="subject">Subjectivity</field><field name="subject">Abjection</field><field name="subject">Carnivalesque</field><field name="subject">Photography</field><field name="subject">Performance art</field><field name="subject">The Uncanny</field><field name="subject">Trauma</field><field name="subject">Identity</field><field name="subject">Trickster</field><field name="subject">Vampire</field><field name="subject">Young British Art</field><field name="subject">Sarah Lucas</field><field name="subject">Hayley Newman</field><field name="subject">Carolee Schneeman</field><field name="subject">Eleanor Antin</field><field name="subject">Ruth Salvaggio</field><field name="subject">Julia Kristeva</field><field name="subject">Sigmund Freud</field><field name="subject">Helene Cixous</field><field name="identifier">http://eprints.qut.edu.au/16093/</field><field name="validLink">True</field></doc><doc><field name="title">Leadership and Management in Child Care Services: Contextual Factors and Their Impact on Practice</field><field name="creator">Nupponen, Hannele</field><field name="description">There has been minimal Australian research focussed on the management and leadership aspects of directors' work in centre-based child care to date. In Australia, practices in early education have been largely drawn from studies in other cultural contexts, particularly research undertaken in the United States. It is timely that Australian research should inform its social policy about quality child care programs.  The focus of this research was on the nature and characteristics of effective management and leadership practices in centre-based child care. Research (Jorde Bloom, 1992b; Morgan, 2000; Poster &amp; Neugebauer, 2000; Rodd, 1994) indicates that quality of child care programs is influenced mostly by the leadership that the centre director can provide to staff within the centre.  The conceptual framework adopted in this study views leadership from a Social Systems framework. Central to a Social Systems framework is the notion that organisations do not exist in isolation rather, leadership and management in these settings are embedded in a broader social context. A Social Systems Model has received little attention in contemporary research on child care in Australia, and this study aims to build a framework for future studies in this area. The aim was to investigate leadership and management in child care in social, legislative and economic context. The findings seek to inform researchers, policy makers and practitioners. Eight directors were purposively selected from community-based and privately based centres in urban and rural areas, and from accredited centres in South East Queensland. The selection of varying locations allowed the researcher to gain a broader perspective of the directors' daily lives, as different contextual and environmental conditions were anticipated to influence management and leadership within the child care centres. Within this study, case studies of directors of child care centres were developed through interviews with the directors. The interview methodology focussed on exploratory semi-structured, open-ended questions in relation to management and leadership in centre-based child care. Directors were interviewed on two occasions within a three month period. In the current context of the delivery of child care services in a market driven climate, the language of business and organisational theory has entered the lexicon of the early childhood field (Press, 1999). The findings indicate that the director of a child care centre needs to have training and experience in business management and leadership to enhance their competencies for management of centres in today's competitive environment. Growth in child care franchises is significantly changing and truly developing a "child care industry" (Murdoch, 2004). Also, consideration needs to be given to increasing accountability in child care service delivery, and how to better support directors in their role as advocates in the broader early childhood field.  Further, families in specific communities have varying needs and early childhood programs should reflect the needs of the local community. Leadership models within child care centres should encompass the micro and macro influences on the operation of centres. Literature suggests that early childhood centres provide an opportune place to support families in a variety of ways through integrating support services to address the underlying social and policy factors that affect young children and their families (Commonwealth of Australia, 2003; Corter, 2001).</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Child care centres</field><field name="subject">leadership</field><field name="subject">management</field><field name="subject">child care centre directors</field><field name="subject">child care service delivery</field><field name="subject">Social Systems Model.</field><field name="identifier">http://eprints.qut.edu.au/16094/</field><field name="validLink">True</field></doc><doc><field name="title">Configuration and Implementation Issues for a Firewall System Running on a Mobile Handset</field><field name="creator">Martinsen, Pal-Erik</field><field name="description">Any device connected to the Internet needs to be protected. Using a firewall as a first line of defence is a very common way to provide protection. A firewall can be set up to protect an entire network or just a single host. As it is becoming more and more popular to connect mobile phones and other hand held devices to the  Internet, the big question is;"how to protect those devices from the perils of the Internet?" This work investigates issues with the implementation of a firewall system for protecting mobile devices. Firewall administration is an error prone and difficult task. Setting up a correctly configured firewall in a network setting is a difficult task for a network administrator. To enable an ordinary mobile phone user to set up a firewall configuration to protect his mobile phone it is  important to have a system that is easy to understand and warns the user of possible mistakes. Generic algorithms for firewall rule-set sorting and anomaly discovery are presented. This ensures that the rule-set is error free and safe to use. This is a vital part of any firewall system. The prototype developed can be used to find errors in existing firewall rule-sets. The rule-set can be in either a native firewall configuration format (currently only IPF is supported) or in a generic XML format. This generic XML format was developed as a part of this research project. Further a new graphical visualization concept that allows the end user to configure an advanced firewall configuration from a device with a small screen and limited input possibilities is presented.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Firewall</field><field name="subject">rule-set</field><field name="subject">sorting</field><field name="subject">anomaly detection</field><field name="subject">visualization</field><field name="subject">mobile handset</field><field name="identifier">http://eprints.qut.edu.au/16095/</field><field name="validLink">True</field></doc><doc><field name="title">Mediation of Osteoblast Responses to Titanium Roughness by Adsorbed Proteins</field><field name="creator">Wilson, Cameron</field><field name="description">Stable fixation of implants such as artificial teeth depends on the direct apposition of bone to the implanted material. While endosseous implants were traditionally allowed to "osseointegrate" over several months without carrying load, clinical and experimental data show that prostheses with roughened surfaces allow successful integration when subject to earlier loading and more challenging implant sites.  However, to design implant surfaces for an optimal biological response requires an understanding of the mechanism by which roughened surfaces promote osseointegration. Research into this mechanism has, to date, focussed primarily on the response of osteoblastic cells to surface topography in vitro. While these have demonstrated some consistent trends in cell behaviour, the fundamental means by which cells sense and respond to roughness remain unclear. It has been suggested that cell responses to changes in topography may relate to differences in the proteins adsorbed from serum (in vitro). While experimental evidence indirectly suggests that physical features can affect protein adsorption, few studies have examined this with respect to surface roughness, particularly as a mediator of cell responses. To address this issue, cell culture and protein adsorption experiments were  conducted on a limited range of surface textures. Titanium samples were ground to  produce morphologically similar surfaces with three grades of roughness. A duplicate set of specimens were heated at 600&#176;C for one hour, with the aim of masking potential variations in physicochemical properties with differing degrees of grinding. Osteoblast attachment and proliferation studies were conducted over a short time-frame of 48 hours or less, to highlight the effects of proteins adsorbed from serum rather than secreted by adherent cells. Gel electrophoresis provided a profile of the proteins adsorbed to each surface after 15 minutes, corresponding to the time by which the cells had settled onto the surface. Finally, confocal microscopy was used to examine cell morphology on each surface, and to visualize specific interactions between cellular structures and adsorbed adhesion-mediating proteins. Although the effects were inconsistent, attachment assays showed some indications that fewer cells attached in the first 90 minutes as roughness increased. This inverse cell number-roughness trend was significant at 48 hours; however, the variability in attachment assays prevented reliable separation of attachment and proliferation rate effects. While the reduction in cell number with increasing roughness is consistent with previous reports, it is typically observed at later time points, and thus may be increasingly confounded by contact inhibition and differentiation. Thermal oxidation of the titanium did not impact on osteoblast responses to roughness, although it significantly slowed cell proliferation. The latter result was unexpected on the basis of previous reports. One-dimensional gel electrophoresis revealed no significant differences in the composition of adsorbed layers with variations in roughness. However, as expected on account of wettability changes, the heat-treatment did correspond to significant changes in the adsorption profile. While this was not a highly sensitive analysis, it suggests that the cell responses to roughness changes were not governed by broadscale differences in the proteins initially available to adhering cells.  In addition to the composition of the adsorbed layer, the distribution of proteins may also vary with topography. The immunofluorescence methods were not sufficiently sensitive to reveal the distribution of adsorbed adhesion proteins (vitronectin and fibronectin). However, the lack of clear labelling does suggest an absence of large accumulations due to specific topographic features. Further work is required to address this issue conclusively. Observations of cell morphology were consistent with widely-reported contact guidance phenomena on grooved surfaces, with elongation and alignment (with topography) increasing with groove depth. Cell elongation was also enhanced on the more hydrophilic, heat-treated titanium, but this effect diminished over time.  Although increased elongation at 90 minutes corresponded to lower cell numbers at 48 hours, no causal relationship has yet been established.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Biomaterials</field><field name="subject">Cell attachment</field><field name="subject">Cell morphology</field><field name="subject">Cell proliferation</field><field name="subject">Cell spreading</field><field name="subject">Fibronectin</field><field name="subject">Heat treatment</field><field name="subject">Osteoblasts</field><field name="subject">Protein adsorption</field><field name="subject">Roughness</field><field name="subject">Surface topography</field><field name="subject">Thermal oxidation</field><field name="subject">Titanium</field><field name="subject">Vitronectin.</field><field name="identifier">http://eprints.qut.edu.au/16096/</field><field name="validLink">True</field></doc><doc><field name="title">La Belle au Bois Dormant (The Sleeping Beauty) Tchaikovsky-Pletnev and Stravinsky's Petrouchka: a study of piano transcriptions comprising performances and analyses.</field><field name="creator">Yang, Vicky (Chia-Yi)</field><field name="description">As the costs for mounting opera, ballet and orchestral concerts rise and as their audiences  dwindle, piano transcriptions of works orchestrated for such concerts can be a viable way of disseminating the music more widely than if the music was presented only in its original  form. With this in mind, it can be argued that piano transcriptions of music originally  written for instrumental ensemble is still a viable form of musical expression, because the  piano is still the most widely used medium for the performance of art music in the Western  world. Transcriptions of instrumental and vocal music expand the listening audience for a  composer's music while they also increase the repertoire of music for the piano for both  amateurs and professionals. The CD recording has the aim of providing a reference on which to base an appreciation of Pletnev's work. As the orchestral score is quite well known, the differentiation created by Pletnev, and the quality of his work, can be immediately perceived by hearing the execution of his scores and being able to cross reference his reductions with the original score. Timing references for the piano score have been included to further facilitate this cross-referencing. This thesis comprises two parts:  1. A performance CD of Stravinsky's Petrouchka (1922 piano four-hand version) and Tchaikovsky's Sleeping Beauty (1999 solo piano transcription by Mikhail Pletnev). This accounts for 75% of the thesis.  2. An exegesis, analysing selected portions of the orchestral score of Tchaikovsky's The  Sleeping Beauty Op.66 and Pletnev's piano transcription suite, prefaced by an overview  of piano transcriptions from Liszt to Pletnev. This accounts for 25% of the thesis. The exegesis argues that, while seeking to recreate the colour and drama of Tchaikovsky's orchestral score within the context of a virtuosic piano solo, Pletnev has managed to transcribe Tchaikovsky's score faithfully with minimal alterations.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Piano</field><field name="subject">Arrangement</field><field name="subject">Transcription</field><field name="subject">Orchestral Suite</field><field name="subject">Tchaikovsky</field><field name="subject">Pletnev</field><field name="subject">Sleeping Beauty</field><field name="subject">Stravinsky</field><field name="subject">Liszt</field><field name="subject">Alteration</field><field name="subject">Analyses</field><field name="subject">Introduction</field><field name="subject">Waltz</field><field name="subject">Rhythm</field><field name="subject">Dynamic</field><field name="subject">Omission</field><field name="subject">Harmony.</field><field name="identifier">http://eprints.qut.edu.au/16097/</field><field name="validLink">True</field></doc><doc><field name="title">Practitioner perceptions of the effectiveness of dramatized interpretaton</field><field name="creator">Adcock, Lynne Therese</field><field name="description">Interpretation has the potential to play an important role in involving the general public in
 
 the dialogue about sustainability, and what this may mean for the future of humans on the earth. Yet interpreters often fail to address this issue. In fact, it can be argued that much
 
 interpretation fails to truly engage its audiences or provoke serious thought about our
 
 relationship with the rest of nature or our future lifestyles. How can interpretation be made
 
 more engaging and provocative, and contribute to the dialogue about sustainability? How can it reach this potential? Some educators and interpreters advocate the use of drama to help people connect with natural and cultural heritage. Powerful dramatic experiences can become embedded in the emotions and leave enduring impressions. Drama is used as an educational tool around the world. Can it be used by interpreters to expand visitors&#8217; conceptions of the human-nature culture milieu? This study addresses the paucity of empirical evidence regarding the effectiveness of
 
 dramatized interpretation. Ten practitioners of dramatized interpretation were interviewed
 
 to explore the current use of drama in interpretation in Queensland, Australia, and in
 
 particular, the practitioners&#8217; perceptions of these practices and their effectiveness. Current
 
 practice was evaluated according to the drama, interpretation and education literature,
 
 particularly recent theoretical developments. Practitioners displayed a strong understanding of the importance of engagement in interpretation, using a variety of drama
 
 forms and strategies to create resonant experiences and strengthen visitors&#8217; connections
 
 with natural, historic and cultural heritage. In addition, they designed their programs to provoke thought and foster deep understanding of environmental and conservation issues, and obtained evidence of provocation and conceptual enhancement. Notwithstanding this, it is concluded that dramatized interpretation could have a greater impact on conceptual enhancement if practitioners designed their programs according to constructivist, group learning and sociocultural perspectives. Practitioners could also make a greater contribution to general environmental education if they explicitly addressed the issue of sustainability, using drama to tell stories that encapsulate the concept of sustainability and provide a vision of sustainable living. A checklist is provided to assist practitioners in the design and evaluation of dramatized programs. Recommendations are also given for interpreters wishing to explore the application of drama to their interpretive setting.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Interpretation; environmental interpretation; environmental education; story; drama; dramatized interpretation; ecological sustainability; interconnectedness; The &#147;Big Story&#148;; dialogue; reconnection; visitors; practitioners; perceptions; effectiveness;</field><field name="identifier">http://eprints.qut.edu.au/16098/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation into a school-based ICT PD program</field><field name="creator">Birks, Peter</field><field name="description">This two-year longitudinal study sought to describe and evaluate a newly developed  information and communication technology (ICT) environment and the associated schoolbased ICT professional development (PD) project within a State Government primary school. The overall aim of the research study was to investigate the most effective requirements to support teachers to be skilled, knowledgeable and confident in the use of ICT in their teaching roles. The teachers were the focus of the Research Study and not the students. The ICT environment and the professional development project's effectiveness was evaluated using data collected from participating teachers and the literature regarding components of effective ICT professional development. The Research Study used qualitative and interpretive methods to illuminate and expand on what it means to provide effective ICT PD within the primary school context. The components of the ICT-enhanced environment were studied in detail to provide feedback and findings that may also be useful in other educational settings with modification. The study provided evidence that, apart from providing and developing individual  ICT PD components, a collection of inter-related components was necessary at the same time for successful ICT PD to be achieved. The components of the PD project have been discussed individually and collectively in terms of their effect on the research subjects, the teachers themselves. Four global factors were identified for effective ICT PD and they were used as a  framework for the study. These were teacher characteristics, authenticity, support and the  ICT-enhanced environment.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">information and communication technology</field><field name="subject">ICT</field><field name="subject">school-based</field><field name="subject">professional development</field><field name="subject">PD</field><field name="subject">teachers</field><field name="subject">global factors</field><field name="subject">investigation</field><field name="subject">education settings</field><field name="identifier">http://eprints.qut.edu.au/16099/</field><field name="validLink">True</field></doc><doc><field name="title">Evaluation of the effectiveness of a clinical pathway for bronchiolitis</field><field name="creator">Cheney, Joyce Louise</field><field name="description">Objective:  This study examines the use of a clinical pathway in the management of infants hospitalised with bronchiolitis. Study Design: A clinical pathway for the care of infants with bronchiolitis was developed from pathways used in tertiary paediatric institutions in Australia. 229 infants admitted to hospital with acute viral bronchiolitis and prospectively managed using a pathway protocol were compared with a retrospective analysis of 207 infants managed without a pathway in three regional and one tertiary hospital.  Results: There were no differences between groups in demographic factors or clinical severity. The pathway had no effect on length of stay or time in oxygen. Readmission to hospital was significantly lower in the pathway group (P = 0.001). Administration of supplemental fluids (P = 0.001) and use of steroids was lower (P = 0.005) in the pathway group. Identification of parental smoking status was higher in the pathway group (P = 0.029). Data from the pathway demonstrated that boys were three times more likely to return to oxygen after weaning to air (OR = 3.30; 95%CI 1.39 - 7.81) after adjusting for admission oxygen saturation.  Documentation of variances from the pathway was misunderstood by staff.  Conclusions: A clinical pathway specifying local practice guidelines and discharge criteria can reduce the risk of readmission to hospital, the use of inappropriate therapies, and help with assessment of readiness for discharge.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">paediatrics</field><field name="subject">respiratory</field><field name="identifier">http://eprints.qut.edu.au/16100/</field><field name="validLink">True</field></doc><doc><field name="title">Metateams in Major Information Technology Projects: A Grounded Theory on Conflict,  Trust, Communication, and Cost.</field><field name="creator">Fernandez, Walter Daniel</field><field name="description">Metateams are both largely unexplored in the IS literature and economically important to major corporations and their IT vendors.   Metateams are temporary groups composed of two or more geographically and inter-organisationally dispersed teams, commercially linked by project-specific agreements and enabled by electronic means of communication.  Each one of these teams fulfils a particular and measurable objective, enshrined in the team's goal hierarchy and contractual obligations.  The combination of efforts from every team in a metateam, contributes to achieving a common distant goal of project implementation.  Thus, metateams are temporary teams (or groups) of distributed teams working across distance, firms, and cultures.  In metateams, each participant team works with other teams on organisationally heterogeneous collaborative projects. Metateams are new and potentially powerful work structures resulting from the convergence of outsourcing, virtual organisations, and demands for global competitiveness.  They promise to build IT solutions of high complexity, by integrating expertise from different fields and organisations.  With the assistance of communication technologies, metateams can conquer barriers of time and space, enabling collaborative endeavours across a nation or across the globe.  In a global business environment that demands innovation, flexibility, and responsiveness, metateams represent a revolution in the way organisations and practitioners do IT projects.  However, as this study found, managing metateams presents unique difficulties due to conflicting demands arising from multiple realities. This dissertation presents an empirical research using a grounded theory approach that studies a major IT project performed by a metateam.  The conceptual account emerges from an exploratory study of a major IT development and implementation project in the telecommunication industry.  The project involved three key organisations and teams based in Australia, the Middle East, and Eastern Europe.  The core pattern emerging from this study is one of constant conflict discovery and resolution, a process that progressively, and at a cost, allows the project to evolve from its initial incongruence into either a working solution or into project abandonment.  This theory-building study presents a theoretical model, grounded on rich empirical data, interrelating key concepts of cost, conflict, communication, and trust, which serves to explain the pattern of actions and to propose a number of practical conclusions and recommendations. This research was guided by two key research objectives: (a) to add theoretical content to the understanding of key processes enacted by metateams in performing IT project work; and (b), to develop a framework that assists researchers and practitioners in predicting, explaining, and evaluating events and process associated with metateams. To the author's best knowledge, this study describes for the first time in the IS literature, the metateam organisation and the significant contextual issues they confront.  In doing so, the study develops an understanding, grounded on rich empirical data from the substantive field of metateams.  This new understanding contributes to both IS research and practice and provides guidance for future research.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">Metateams</field><field name="subject">Project Management</field><field name="subject">IS/IT Development Projects</field><field name="subject">Collaborative Projects</field><field name="subject">Boundary Spanning Projects</field><field name="subject">Virtual Collaboration</field><field name="subject">Emerging Organisations</field><field name="subject">Virtual Teams</field><field name="subject">Multi-team Systems</field><field name="subject">Grounded Theory Studies.</field><field name="identifier">http://eprints.qut.edu.au/16101/</field><field name="validLink">True</field></doc><doc><field name="title">Defining the molecular basis of host range in Papaya ringspot virus (PRSV) Australia</field><field name="creator">Jayathilake, Nishantha</field><field name="description">The potyvirus Papaya ringspot virus (PRSV) is widespread throughout the world in cucurbits (such as zucchini, watermelon, pumpkin etc) and papaya (papaw). There are two serologically indistinguishable strains of PRSV, which can only be differentiated on the basis of host range. PRSV-P is able to infect both papaya and cucurbits whereas PRSV-W only infects cucurbits. Both infections drastically reduce the yield and market quality of the fruit.  Australian isolates of PRSV-P and -W are very closely related and there is evidence that PRSV-P arose by mutation from PRSV-W. The aim of this project was to investigate the molecular basis of the host range difference between Australian isolates of PRSV-P and -W.  The close relationship between Australian PRSV-P and -W isolates at the molecular level made this an ideal system to investigate molecular host range determinants through the development of full-length infectious cDNA clones.  Initially, the complete genomes of PRSV-P and -W were each incorporated into two overlapping clones; one included the CaMV 35S promoter fused to the 5' one third of the PRSV genome and the second included the 3' two thirds of the genome (including a 33 nucleotide poly(A) tail) fused to a CaMV35S terminator. Full-length clones could not be obtained from subcloning of these fragments due to apparent toxicity in E.coli. Several approaches were subsequently undertaken to overcome this problem.  In an attempt to prevent transcription of potentially toxic sequences, a plant intron (St-Ls1 IV2 intron) was engineered into the first coding region (P1) of the PRSV-W genome. Although clones were obtained using this strategy these could not be effectively maintained in E.coli. An alternative strategy involved subcloning of the genome into a low copy number vector, pACYC177, to minimise expression of toxic sequences. Again this resulted in clones that produced very small colonies, which were hard to culture and which gave very low plasmid yields.  These plasmids were also difficult to maintain in E. coli.  A final, successful strategy was developed using overlapping long distance PCR (OE-LD PCR) to generate full-length infectious PCR products of both PRSV-P (rPRSV-P) and -W (rPRSV-W) incorporating a CaMV 35S promoter and terminator. Infectious PCR products of both strains were inoculated onto squash cotyledons in vitro by microprojectile bombardment and subsequently mechanically inoculated to squash with greater than 86% efficiency.  RPRSV-P subsequently infected papaya with 96% efficiency while, as expected, rPRSV-W was unable to infect papaya.    Once a system for generating infectious clones was developed, both sequence analysis and recombination of infectious clones was utilised to investigate the underlying host range mechanism. The complete genomes of PRSV-P and -W were sequenced and compared to each other and to five full- length sequences of overseas PRSV isolates that were available.  Sequence analysis confirmed the close relationship between the Australian PRSV isolates (97.8% nucleotide and 98.4% amino acid identity over the whole genome), supporting the mutation theory between both Australian and Asian P and W pairs. However, there was no consistent amino acid difference over the whole genome that correlated with host range or a single site that could be implicated, suggesting that the mutation and possibly the position of the mutation is different at least between Asian and Australian isolates and potentially differs at each mutation event.  To better localise the P/W mutation within the PRSV genome, five different recombinant hybrid PRSVs (rhPRSV1-5) were generated in which 5', middle or 3' regions of the PRSV-P and -W genomes were exchanged. Infectivity of all hybrids was confirmed in squash, however, only hybrids including the 3' third of the PRSV-P genome were able to infect papaya, suggesting that this region encodes the papaya host range determinant. The region implicated encodes the genome-linked protein (VPg), NIa protease, replicase (NIb), coat protein (CP) and 3' UTR. While further identification of the host range determinants was not possible due to time constraints, based on studies with other potyviruses, there is a strong basis for implication of the VPg. Sequence analysis identified only 2 amino acid differences between the VPg of Australian PRSV-P and -W isolates in regions previously implicated in pathogenicity.  These will be targeted for mutagenesis in ongoing studies.  Identification of the genes/sequences involved in the determination of host range in PRSV will provide valuable information as to the sequence of events that lead to infection and will lead to a better understanding of the significance of changing hosts in the molecular evolution of PRSV, an essential requirement for the development of long-term sustainable control strategies against PRSV.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Papaya ringspot virus (PRSV)</field><field name="subject">Australia</field><field name="subject">potyvirus</field><field name="subject">PRSV-P</field><field name="subject">PRSV-W</field><field name="identifier">http://eprints.qut.edu.au/16102/</field><field name="validLink">True</field></doc><doc><field name="title">Food Autonomy: The Paradox to Cereal-Based Food Choice</field><field name="creator">Brown, Rosemarie Ann</field><field name="description">Certain aspects of our modern diet have been implicated in thedevelopment of non-communicable diseases. For instance, energyconsumed in excess of an individual's physiological requirements maylead to an increased risk of obesity, diabetes mellitus, gall bladder disease,coronary heart disease, high blood pressure, and possibly some cancers.Although many of these diet-related diseases can be controlled by modernmedicine, they cannot be cured. Instead, prevention through public healthstrategies is the only satisfactory solution. One of the major strategies forprevention of diet-related diseases in Australia is to modify the nationaldiet (Rogers 1987).  In April 1979, the Commonwealth Department of Health responded to theWorld Health Organisation's call for the development of national food andnutrition polices by proposing the Dietary Guidelines for Australians. "TheDietary Guidelines for Australians provide advice to the general populationabout healthy food choices, so that their usual diet contributes to ahealthy life-style and is consistent with minimal risk for the developmentof diet-related diseases" (National Health and Medical Research Council1992:ix). However, in order to achieve the aim of the dietary guidelines,supporting educational programs are required. This is because it isbelieved that as consumers become more informed about food, nutrition,health, and the dietary guidelines, they are more likely to begin changingtheir diet in the directions recommended by the CommonwealthDepartment of Health and Family Services (1998a).  Public health professionals believe that behaviour-change theories arebeneficial in gaining an understanding of the evolution of peoples' foodand nutrition behaviours. Behaviour-change theories are typicallyintegrated into dietary interventions as a means of educating theAustralian population about healthy food choices. However, attempts tochange Australians' food and nutrition behaviours by applying behaviour-change theories have been adiaphorous. Therefore, public health professionals need to explore traditional food and nutrition practices inorder to determine more effective dietary change strategies for the Australian population.  Qualitative research is complementary to existing quantitative studies onbehaviour-change. Since qualitative methodologies focus on the whole ofhuman experience and the meaning ascribed by individuals living theexperience, these methodologies permit broader understanding and deeperinsight into complex human behaviours such as food consumption thanwhat might be obtained from grossly measured quantitativeclassifications. Grounded theory was the qualitative methodology chosenfor this study because it allowed me to theorise about the rationale forconsumers' current food choices. Bread and Cereal consumption waschosen as an important staple food group in which to explore thisphenomenon. Thus, this research was designed to discover, understand,and theorise about the rationale for consumers' current Bread and Cerealfood choices. Semi-structured, in-depth interviews were conducted with22 participants living in South-East Queensland. Adult males and femalesfrom three-generational families of varying ethnicity were recruited frommy personal network of associates. Interviews were analysed usinggrounded theory methodology for data analysis.  The resulting Grounded Substantive Theory of Food Autonomy posits thatconsumers have different levels of power when it comes to selecting theBreads and Cereals they want to eat and that their power to choose themis governed by micro- and macroenvironmental forces.Microenvironmental forces envelop sociofamilial powers such as parents,partner, and offspring whereas macroenvironmental forces envelop thesociopolitical powers of the food industry, health professionals, andinstitutions. These forces influence a consumer's capacity to select theBreads and Cereals they want to eat. Consumers engage in the process ofinformation gathering in order to overcome these prevailing influences.  The significance of the Grounded Substantive Theory of Food Autonomy asa means for explaining how consumers acquire food autonomy fromprevailing influences in order to eat the Breads and Cereals they desirehas important implications for public health nutrition education andpractice. An understanding of the life long nature underpinning a person'sfood behaviour will help nutrition and dietetic professionals understandbetter the range of change that is likely to be possible, and the best waysto facilitate food autonomy through appropriate education and compatibledietary interventions. Autonomy is not a new concept but when associatedwith food it introduces the public health professional to a paradoxicalperspective for studying consumers' food behaviour, which has beencustomarily looked at via the decision making process of food choice andbehaviour-change theories with adiaphorous effects.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Food autonomy</field><field name="subject">behaviour change</field><field name="subject">breads and cereals</field><field name="subject">consumers</field><field name="subject">education</field><field name="subject">food choice</field><field name="subject">food identity</field><field name="subject">grounded theory</field><field name="subject">lifecourse</field><field name="subject">nutrition</field><field name="subject">public health</field><field name="subject">qualitative.</field><field name="identifier">http://eprints.qut.edu.au/16103/</field><field name="validLink">True</field></doc><doc><field name="title">Creating Contexts, Characters, and Communication: Foreign Language Teaching and Process Drama</field><field name="creator">Marschke, Renee</field><field name="description">The foundational premise of communicatively-based foreign language teaching approaches is that the activities used in the classroom are 'communicative'; that the language learned is being used to 'communicate'. Genuine communication however is difficult to establish in a traditional classroom setting consisting of desks, chairs and textbooks. This project examines how a specific form of Drama in Education - process drama - can be used to create more authentic communicative situations and learning experiences in the foreign language classroom; experiences that are both intellectually and affectively engaging. It begins with a review of the literature pertaining to the three main areas that provide the backdrop to the project's central research proposition, namely second language acquisition, second language methodology and aesthetic education. The three main protagonists are then introduced, namely social interactionist theories of language acquisition, communicative language teaching approaches (the main focus being on task-based methodology), and process drama. The two supporting characters, change and motivation, also make their entrance.  The curtain is then raised to reveal a performance of various teaching and learning experiences of the use of process drama in first and second language settings. This illustrates how process drama operates on a practical level and explores the offered potential for more authentic communication when this approach comes into contact with second language task-based methodology. Literature surrounding unit and lesson planning frameworks from the fields of both second language acquisition and process drama is then examined before the spotlight falls on the proposed 'Foreign language and Process drama' Unit and Lesson planning Framework. Illustrative models of the innovative framework together with concrete examples of its use are provided to represent more clearly how it can facilitate the creation of characters and contexts through which to communicate more authentically in the FL classroom. The closing curtain falls on a reflection of the entire project, which includes recommendations and possibilities for further research.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Foreign Language Teaching</field><field name="subject">Process Drama</field><field name="subject">Contexts</field><field name="subject">Characters</field><field name="subject">Communication</field><field name="subject">communicatively-based</field><field name="subject">Drama in Education</field><field name="identifier">http://eprints.qut.edu.au/16104/</field><field name="validLink">True</field></doc><doc><field name="title">Characterisation of Potential Fungal Disease Resistance Genes in Banana</field><field name="creator">Taylor, Kay M.</field><field name="description">Bananas are an extremely important crop, serving as both a staple food in developing countries and as a dessert fruit in Western society. Two of the most devastating pathogens currently affecting both commercial and subsistence banana production are Fusarium oxysporum (Foc; causal agent of Fusarium wilt) and Mycosphaerella species (causal agent of black and yellow Sigatoka). Conventional breeding programs designed to improve the disease resistance characteristics of the commercially elite Cavendish cultivar have, thus far, been largely unsuccessful. Genetic engineering is now regarded as the most promising method to generate enhanced disease resistance in banana. In other crops and model species, strategies to enhance disease resistance have included the transgenic expression of defense-related genes such as; disease resistance genes (R genes), downstream signaling genes (eg. NPR1, non-pathogenesis related) and antimicrobial peptides (AMPs). The overall aims of this research were to amplify and compare the nucleotide binding site (NBS) domains of potential disease resistance genes from disease resistant and disease susceptible banana cultivars. To isolate and compare complete R gene sequences from these cultivars. To generate transgenic Lady Finger banana plants expressing the D4E1 antimicrobial peptide under the control of two different promoters and finally to assess extracts from these plants for their ability to inhibit the growth of Foc Race1. Using degenerate primers, the NBS domains of six resistance gene candidate (RGC) sequences were amplified from the disease resistant cultivar Calcutta 4 (C4) and the disease susceptible cultivar Cavendish (Cav). The RGC 1, 2, 5 and 6 sequences showed similarity to previously characterized R gene sequences isolated from monocotyledonous plant species, while RGCs 3 and 4 showed similarity to R genes which form part of the Fusarium wilt resistance locus isolated from the dicotyledonous species, Lycopersicon esculentum; as well as other monocotyledonous R genes.  RGCs 1-4 and 6 were present and transcriptionally active in both C4 and Cav, whereas RGC-5 was present in Cav only and was not transcribed. The transcripts could not be detected by Northern analysis, which is consistent with previous reports that R genes are constitutively transcriptionally active at only low levels. The NBS domains of RGCs 1-6 showed less than 65% similarity (amino acid level) to one another but when each individual RGC isolated from the C4 and Cav gDNA and cDNA templates was compared the sequences showed greater than 97% similarity (amino acid level). Comparative sequence analysis revealed amino acid positions that were consistently different between the C4 and Cav clones. Southern analysis revealed that RGC 1-5 were present in both the C4 and Cav genomes in only low copy number (1-2 gene copies with 1-3 alleles), whereas RGC-6 showed high copy number in both cultivars. Complete RGC sequences were subsequently amplified by RNA-ligase-mediated (RLM) -RACE and 3'-RACE using specific primers designed to each of the RGC 1-4 NBS domains. Amplicons for each RGC were assembled to form potentially complete RGC sequences. Analysis of the sequences revealed the presence of coiled coil (CC) motifs in two of the amino terminal sequences while leucine rich repeats (LRRs) were identified at the carboxy terminal of all sequences. Multiple 3'-RACE products were amplified for each RGC sequence. Although the polyadenylated products were of different lengths, the sequences were greater than 98% identical at the amino acid level (except an RGC 3 clone which was 91-95% identical to the other RGC 3 clones due to a 37 amino acid deletion). Specific primers used to amplify each complete RGC sequence from both C4 and Cav DNA revealed that: RGC 1 (3.53 kbp) could be amplified from both C4 and Cav; RGCs 2 (2.99 kbp) and 4 (4.44 kbp) could be amplified from only Cav, however, the proposed truncations of these sequences (RGC 2: 1.3 kbp, RGC 4: 2.8 kbp and 2.9 kbp) could be amplified from both cultivars; RGC 3 (4.57 kbp) could not be amplified from either C4 or Cav, however, the three shorter sequences (1.96 kbp, 1.34 kbp and 1.28 kbp) could be amplified from both templates. The functional significance of the truncated sequences is currently unknown, however, truncated sequences have been detected in a number of R gene families isolated from other crops. No major sequence differences, such as deletions/insertions or early stop codons, were identified between the RGC sequences amplified from C4 as compared to Cav (greater than 91% amino acid similarity) and no sequence was identified as being present in the susceptible but absent from the resistant cultivar. However, comparative analysis of multiple clones isolated from C4 and Cav did reveal amino acid residues that were consistently different between the two cultivars. These differences may result in differing resistance capabilities, functional genomics studies would need to be undertaken to determine this.    It has been proposed that CC-NBS-LRR type R genes employ NDR1/HIN1-like (NHL) proteins, after pathogen invasion is detected, in the signaling process that ultimately leads to the elaboration of a defense response. A NHL partial sequence (420 bp) was amplified from the C4 banana cultivar. The complete sequence of this gene (termed NHL-1) was isolated using RLM and 3'-RACE technologies (576 bp and 535 bp amplicons, respectively) and subsequently the 1.106 kbp sequence was PCR amplified from both the C4 and Cav cultivars. The banana NHL-1 gene contained conserved motifs/domains previously identified within other NHL-type gene sequences. These included a signal peptide motif, a transmembrane domain and three previously identified conserved motifs. Based on current research into NHL type genes, the banana NHL-1 sequence may not be useful as a transgene to enhance disease resistance in elite cultivars. However, it potentially plays an important role in the defense response signal transduction pathway and therefore will further our understanding of plant-pathogen interactions in banana. Transgenic Lady Finger banana plants expressing the D4E1 antimicrobial peptide under the control of either the maize polyubiquitin (Ubi) or banana bunchy top virus (BBTV) DNA-6 (Bt6.1) promoters were generated. These plants were subsequently assessed for the ability of their crude protein extracts to inhibit the germination of Fusarium oxysporum f.sp. cubense Race1 conidia in vitro. These anti-fungal bioassays revealed that fungal colony growth was reduced by 37-100% using extracts from the pUbi-D4E1 transgenic lines and 89-99% using extracts from the pBt6.1-D4E1 transgenic lines. The transgenic lines are currently undergoing multiplication in preparation for glasshouse and small plant challenge trials for resistance to Fusarium wilt. These preliminary results suggest that D4E1 may be useful in enhancing disease resistance in banana.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">banana</field><field name="subject">disease resistance</field><field name="subject">genetic engineering</field><field name="subject">fungal disease.</field><field name="identifier">http://eprints.qut.edu.au/16105/</field><field name="validLink">True</field></doc><doc><field name="title">Improving Perception From Electronic Visual Prostheses</field><field name="creator">Boyle, Justin Robert</field><field name="description">This thesis explores methods for enhancing digital image-like sensations which might be similar to those experienced by blind users of electronic visual prostheses. Visual prostheses, otherwise referred to as artificial vision systems or bionic eyes, may operate at ultra low image quality and information levels as opposed to more common electronic displays such as televisions, for which our expectations of image quality are much higher. The scope of the research is limited to enhancement by digital image processing: that is, by manipulating the content of images presented to the user. The work was undertaken to improve the effectiveness of visual prostheses in representing the visible world.  Presently visual prosthesis development is limited to animal models in Australia and prototype human trials overseas. Consequently this thesis deals with simulated vision experiments using normally sighted viewers. The experiments involve an original application of existing image processing techniques to the field of low quality vision anticipated from visual prostheses.  Resulting from this work are firstly recommendations for effective image processing methods for enhancing viewer perception when using visual prosthesis prototypes. Although limited to low quality images, recognition of some objects can still be achieved, and it is useful for a viewer to be presented with several variations of the image representing different processing methods. Scene understanding can be improved by incorporating Region-of-Interest techniques that identify salient areas within images and allow a user to zoom into that area of the image. Also there is some benefit in tailoring the image processing depending on the type of scene.  Secondly the research involved the construction of a metric for basic information required for the interpretation of a visual scene at low image quality. The amount of information content within an image was quantified using inherent attributes of the image and shown to be positively correlated with the ability of the image to be recognised at low quality.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Image Processing</field><field name="subject">Visual Prostheses</field><field name="subject">Bionic Eye</field><field name="subject">Artificial Human Vision</field><field name="subject">Visual Perception</field><field name="subject">Subjective Testing</field><field name="subject">Visual Information</field><field name="identifier">http://eprints.qut.edu.au/16106/</field><field name="validLink">True</field></doc><doc><field name="title">Spectroscopic Studies of Nano-Structures of AI and Fe Phases, Bauxite and Their Thermally Activated Products</field><field name="creator">Ruan, Huada</field><field name="description">This thesis is made as it is submitted as a sum of published papers by the candidate.  Aluminium hydroxides including gibbsite, boehmite and diaspore, are the major components, while iron hydroxides/oxides and kaolinite are the major impurities in bauxite. The dehydroxylation pathways during thermal activation of bauxite have been debated for decades.  Phase transformation during thermal activation or calcination of bauxite to achieve high yields of alumina has been an important goal for the refining industry.  This study deals with natural and synthetic aluminium and iron hydroxides using vibrational spectroscopy in conjunction with X-ray diffraction and electron microscopy, followed by the characterisation of the phase transformation in activated bauxite.  In the Raman spectra, gibbsite shows four bands at 3617, 3522, 3433 and 3364 cm-1, and bayerite shows seven bands at 3664, 3652, 3552, 3542, 3450, 3438 and 3420 cm-1 in the hydroxyl stretching region.  Five bands at 3445, 3363, 3226, 3119 and 2936 cm-1 for diaspore and four at 3371, 3220, 3085 and 2989 cm-1 for boehmite are present.  The far infrared spectrum of boehmite resembles that of diaspore in the 300-400 cm-1 region.  Boehmite has two characteristic bands at 366 and 323 cm-1 while diaspore has five at 354, 331, 250, 199 and 158 cm-1.  The far infrared spectrum of gibbsite resembles that of bayerite in the 230-300 cm-1 region.  Gibbsite shows three characteristic bands at 371, 279 and 246 cm-1 whereas bayerite shows six at 383, 345, 326, 296, 252 and 62 cm-1.  The far infrared spectra are in-harmony with the FT-Raman spectra, allowing the study and differentiation of the stretching of AlO4 units to characterize these four alumina phases.  The surface properties of kaolinite and gibbsite are studied using Fourier transform infrared photoacoustic spectroscopy (FTIR-PAS).  The FTIR-PAS spectra of kaolinite are recorded at mirror velocities of 0.05, 0.1, and 0.2 cm s-1, and compared to the gibbsite spectra recorded at mirror velocity of 0.2 cm s-1.  It is found that the hydroxyl surface spectra are a function of depth.  For the FTIR spectroscopy of thermal dehydroxylation of goethite to form hematite, the intensity of hydroxyl stretching and bending vibrations decreased with the extent of dehydroxylation of goethite.  Infrared absorption bands clearly show the phase transformation between goethite and hematite, in particular the migration of excess hydroxyl units from goethite to hematite.  Data from the band component analysis of FT-IR spectra indicate that the hydroxyl units mainly affect the a- plane in goethite and the equivalent c- plane in hematite. A larger amount of non-stoichiometric hydroxyl unit is found to be associated with a higher aluminium substitution.  A shift to a higher wavenumber of bending and hydroxyl stretching vibrations is attributed to the effects of aluminium substitution associated with non-stoichiometric hydroxyl units on the a-b plane relative to the b-c plane of goethite.  The dehydroxylation pathways of both the aluminium hydroxides and the impurities are intensively studied.  Gibbsite completely decomposed at 250 &#176;C, followed by boehmite and kaolinite at 500 &#176;C.  No phase transformations were observed for hematite, anatase, rutile or quartz up to 800 &#176;C.  Small amounts of gibbsite transformed to boehmite but the majority transformed to chi (&#967;) alumina, a disordered transition alumina phase, after dehydroxylation at 250 &#176;C.  The dehydroxylation pathways of crystalline gibbsite follow the orders: (a) gibbsite (&amp;lt250 &#176;C) to boehmite (250-450 &#176;C) to gamma alumina (&#947;) (500-800 &#176;C); or (b) gibbsite (&amp;lt250 &#176;C) to chi alumina (&#967;) (250-800 &#176;C) to chi (&#967;) + kappa alumina (&#954;) (700-800 &#176;C).  Boehmite completely altered to gamma alumina (&#947;), while kaolinite altered to metakaolinite at 500 &#176;C.    The vibrational spectroscopy including FT-IR and FT-Raman, is a rapid, accurate and non-destructive technique in characterising both single and mixed mineral phases.  In particular, the vibrational spectroscopy has shown its advantages over other techniques in terms of its sensitivity to hydroxyl groups.  Future work on the simulation of bauxite dehydroxylation with emphasis on the studies of transition aluminas is proposed.  The application of the advanced technique synchrotron x-ray spectroscopy, in addition to those techniques used in the present study, is recommended.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Spectroscopic Studies</field><field name="subject">Bauxite</field><field name="subject">Thermally Activated Products</field><field name="identifier">http://eprints.qut.edu.au/16107/</field><field name="validLink">True</field></doc><doc><field name="title">Songs of Knowledge: Sirens in Theory and Performance</field><field name="creator">Robson, Julie</field><field name="description">This inquiry is a two-tongued performance as research project asking &amp;quotWhy was the voice of the Sirens deadly?" and &amp;quotHow can the Sirens inform contemporary feminist theatre praxis?". The two questions in constant dialectic have been explored in a written dissertation as well as in a one-hour original and ensemble performance called The Quivering: a Matter of Life and Death. Analysing references in mythology, art and history, the written component suggests how the Siren's sonic qualities are manifest in distinct cultural icons and embodied by actual female performers. Four Siren vocalities are identified and theorised: The Monster vocality is evidenced in the figure of the femme fatale; the Lamenter exists in traditional funerary singers and contemporary torch songs; the sound of the Diva is heard in the opera queen; and the Lullaby Maker acoustics oscillate between the banter of Mother Goose and the 'red hot mamas' of the blues.  Pursuing what is deadly about each of these embodied voices, the thesis articulates why female sound, like the Siren song of knowledge, is so ambivalently received - its evocation of otherness (Monster), liminality (Lamenter), jouissance (Diva) and contra-diction (Lullaby Maker) is both feared and revered. These four vocalities have grown in and out of The Quivering, a performance odyssey that has interrogated aesthetic, content, characterisation, narrative and devising practice, all with an ear to the Siren's 'deadly' sonority. Subverting portrayals of death as a woman and a taboo, its comic-tragic heroines exist in a liminal landscape as lamenters who confront and facilitate the audience's death passage. In counterpoint to Homeric legacy, it has been designed as an open text, which, combined with its heightened physicality and musicality, make for an 'other' aesthetic or contemporary Siren 'song'. The Quivering is pitched at the same tone as the distilled Siren vocalities or 'blue notes', and, as a performance as research project, also re-sounds provocatively within traditional academic discourse. The 'deadliness' of the female voice, in myth, in theory and in performance thus resides in its dissolution of logos and certainty. It quivers with the pleasure and trauma of a corporeal jouissance that exceeds narrative and linguistic frames with its full-bodied, acoustic and imagistic resonance.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Sirens</field><field name="subject">Feminist Theatre</field><field name="identifier">http://eprints.qut.edu.au/16108/</field><field name="validLink">True</field></doc><doc><field name="title">Applications of Spatio-temporal Analytical Methods in Surveillance of Ross River Virus Disease</field><field name="creator">Hu, Wenbiao</field><field name="description">The incidence of many arboviral diseases is largely associated with social and environmental conditions. Ross River virus (RRV) is the most prevalent arboviral disease in Australia. It has long been recognised that the transmission pattern of RRV is sensitive to socio-ecological factors including climate variation, population movement, mosquito-density and vegetation types. This study aimed to assess the relationships between socio-environmental variability and the transmission of RRV using spatio-temporal analytic methods.  Computerised data files of daily RRV disease cases and daily climatic variables in Brisbane, Queensland during 1985-2001 were obtained from the Queensland Department of Health and the Australian Bureau of Meteorology, respectively.  Available information on other socio-ecological factors was also collected from relevant government agencies as follows: 1) socio-demographic data from the Australia Bureau of Statistics; 2) information on vegetation (littoral wetlands, ephemeral wetlands, open freshwater, riparian vegetation, melaleuca open forests, wet eucalypt, open forests and other bushland) from Brisbane City Council; 3) tidal activities from the Queensland Department of Transport; and 4) mosquito-density from Brisbane City Council.  Principal components analysis (PCA) was used as an exploratory technique for discovering spatial and temporal pattern of RRV distribution. The PCA results show that the first principal component accounted for approximately 57% of the information, which contained the four seasonal rates and loaded highest and positively for autumn. K-means cluster analysis indicates that the seasonality of RRV is characterised by three groups with high, medium and low incidence of disease, and it suggests that there are at least three different disease ecologies. The variation in spatio-temporal patterns of RRV indicates a complex ecology that is unlikely to be explained by a single dominant transmission route across these three groupings.  Therefore, there is need to explore socio-economic and environmental determinants of RRV disease at the statistical local area (SLA) level. Spatial distribution analysis and multiple negative binomial regression models were employed to identify the socio-economic and environmental determinants of RRV disease at both the city and local (ie, SLA) levels. The results show that RRV activity was primarily concentrated in the northeast, northwest and southeast areas in Brisbane. The negative binomial regression models reveal that RRV incidence for the whole of the Brisbane area was significantly associated with Southern Oscillation Index (SOI) at a lag of 3 months (Relative Risk (RR): 1.12; 95% confidence interval (CI): 1.06 - 1.17), the proportion of people with lower levels of education (RR: 1.02; 95% CI: 1.01 - 1.03), the proportion of labour workers (RR: 0.97; 95% CI: 0.95 - 1.00) and vegetation density (RR: 1.02; 95% CI: 1.00 - 1.04). However, RRV incidence for high risk areas (ie, SLAs with higher incidence of RRV) was significantly associated with mosquito density (RR: 1.01; 95% CI: 1.00 - 1.01), SOI at a lag of 3 months (RR: 1.48; 95% CI: 1.23 - 1.78), human population density (RR: 3.77; 95% CI: 1.35 - 10.51), the proportion of indigenous population (RR: 0.56; 95% CI: 0.37 - 0.87) and the proportion of overseas visitors (RR: 0.57; 95% CI: 0.35 - 0.92). It is acknowledged that some of these risk factors, while statistically significant, are small in magnitude. However, given the high incidence of RRV, they may still be important in practice. The results of this study suggest that the spatial pattern of RRV disease in Brisbane is determined by a combination of ecological, socio-economic and environmental factors.  The possibility of developing an epidemic forecasting system for RRV disease was explored using the multivariate Seasonal Auto-regressive Integrated Moving Average (SARIMA) technique. The results of this study suggest that climatic variability, particularly precipitation, may have played a significant role in the transmission of RRV disease in Brisbane. This finding cannot entirely be explained by confounding factors such as other socio-ecological conditions because they have been unlikely to change dramatically on a monthly time scale in this city over the past two decades.  SARIMA models show that monthly precipitation at a lag 2 months (&#61538;=0.004,p=0.031) was statistically significantly associated with RRV disease. It suggests that there may be 50 more cases a year for an increase of 100 mm precipitation on average in Brisbane. The predictive values in the model were generally consistent with actual values (root-mean-square error (RMSE): 1.96). Therefore, this model may have applications as a decision support tool in disease control and risk-management planning programs in Brisbane.  The Polynomial distributed lag (PDL) time series regression models were performed to examine the associations between rainfall, mosquito density and the occurrence of RRV after adjusting for season and auto-correlation. The PDL model was used because rainfall and mosquito density can affect not merely RRV occurring in the same month, but in several subsequent months. The rationale for the use of the PDL technique is that it increases the precision of the estimates. We developed an epidemic forecasting model to predict incidence of RRV disease. The results show that 95% and 85% of the variation in the RRV disease was accounted for by the mosquito density and rainfall, respectively. The predictive values in the model were generally consistent with actual values (RMSE: 1.25). The model diagnosis reveals that the residuals were randomly distributed with no significant auto-correlation. The results of this study suggest that PDL models may be better than SARIMA models (R-square increased and RMSE decreased). The findings of this study may facilitate the development of early warning systems for the control and prevention of this widespread disease.  Further analyses were conducted using classification trees to identify major mosquito species of Ross River virus (RRV) transmission and explore the threshold of mosquito density for RRV disease in Brisbane, Australia. The results show that Ochlerotatus vigilax (RR: 1.028; 95% CI: 1.001 - 1.057) and Culex annulirostris (RR: 1.013, 95% CI: 1.003 - 1.023) were significantly associated with RRV disease cycles at a lag of 1 month. The presence of RRV was associated with average monthly mosquito density of 72 Ochlerotatus vigilax and 52 Culex annulirostris per light trap. These results may also have applications as a decision support tool in disease control and risk management planning programs. As RRV has significant impact on population health, industry, and tourism, it is important to develop an epidemic forecast system for this disease. The results of this study show the disease surveillance data can be integrated with social, biological and environmental databases. These data can provide additional input into the development of epidemic forecasting models. These attempts may have significant implications in environmental health decision-making and practices, and may help health authorities determine public health priorities more wisely and use resources more effectively and efficiently.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Classification and regression trees</field><field name="subject">cluster analysis</field><field name="subject">generalised linear model</field><field name="subject">geographic information system</field><field name="subject">interpolation</field><field name="subject">polynomial distributed lag model</field><field name="subject">principal components analysis</field><field name="subject">Ross River virus disease</field><field name="subject">seasonal auto-regressive integrated moving average</field><field name="subject">socio-ecological factors</field><field name="subject">time series analysis</field><field name="identifier">http://eprints.qut.edu.au/16109/</field><field name="validLink">True</field></doc><doc><field name="title">A Study of the Cutting Performance in Abrasive  Waterjet Contouring of Alumina Ceramics and  Associated Jet Dynamic Characteristics</field><field name="creator">Liu, Hua</field><field name="description">Abrasive waterjet (AWJ) cutting is one of the most recently developed nontraditional manufacturing technologies. It has been increasingly used in industry owing to its various distinct advantages over the other cutting technologies. However, many aspects of this technology require to be fully understood in order to increase its capability and cutting performance as well as to optimize the cutting process.  This thesis contains an extensive literature review on the investigations of the various aspects in AWJ machining. It shows that while considerable work has been carried out, very little reported research has been found on the AWJ contouring process although it is a common AWJ cutting application. Because of the very nature of the AWJ cutting process, the changing nozzle traverse direction involved in AWJ contouring results in kerf geometrical or shape errors. A thorough understanding of the AWJ contouring process is essential for the reduction or elimination of these shape errors. It also shows that a lack of understanding of the AWJ hydrodynamic characteristics has limited the development of cutting performance models that are required for process control and optimization.  Accordingly, a detailed experimental investigation is presented in this thesis to study the various cutting performance measures in AWJ contouring of an 87% alumina ceramic over a wide range of process parameters. For a comparison purpose, the study also considers AWJ straight-slit cutting. The effects of process parameters on the major cutting performance measures in AWJ contouring have been comprehensively discussed and plausible trends are amply analysed. It finds that the taper angles on the two kerf walls are in different magnitudes in AWJ contouring.  The kerf taper on the outer kerf wall increases with the arc radius (or profile curvature), while that on the inner kerf wall decreases. Moreover, the depth of cut increases with an increase in arc radius and approaches the maximum in straight cutting for a given combination of parameters. The other process variables affect the AWJ contouring process in a way similar to that in straight cutting. The analysis has provided a guideline for the selection of process parameters in the AWJ contouring of alumina ceramics.  In order to predict the cutting performance in process planning and ultimately optimize the cutting process, mathematical models for the major cutting performance measures in both straight-slit cutting and contouring are developed using a dimensional analysis technique. The models are then verified by assessing both qualitatively and quantitatively the model predictions with respect to the corresponding experimental data. It shows that the models can adequately predict the cutting performance measures and form the essential basis for developing strategies for selecting the optimum process parameters in AWJ cutting.  To achieve an in-depth understanding of the jet dynamic characteristics such as the velocity and pressure distributions inside a jet, a Computational Fluid Dynamics (CFD) simulation is carried out using a Fluent6 flow solver and the simulation results are validated by an experimental investigation. The water and particle velocities in the jet are obtained under different input and boundary conditions to provide an insight into the jet characteristics and a good understanding of the kerf formation process in AWJ cutting. Various plausible trends and characteristics of the water and particle velocities are analysed and discussed, which provides the essential knowledge for optimizing the jet performance through optimizing the jetting and abrasive parameters.  Mathematical models for the water and particle velocity distributions in an AWJ are finally developed and verified by comparing the predicted jet characteristics with the corresponding CFD simulation data. It shows that the jet characteristics models can yield good predictions for both water and particle velocity distributions in an AWJ.  The successful development of these jet dynamic characteristics models is an essential step towards developing more comprehensive mathematical cutting performance models for AWJ cutting and eventually developing the optimization strategies for the effective and efficient use of this advanced manufacturing technology.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Abrasive waterjet contouring</field><field name="subject">dimensional analysis</field><field name="subject">cutting performance model</field><field name="subject">dynamic characteristics of abrasive waterjet</field><field name="subject">computational fluid dynamics</field><field name="subject">jet characteristics model</field><field name="identifier">http://eprints.qut.edu.au/16110/</field><field name="validLink">True</field></doc><doc><field name="title">Build-up and wash-off process kinetics of PAHs and heavy metals on paved surfaces using simulated rainfall</field><field name="creator">Herngren, Lars Fredrik</field><field name="description">The research described in the thesis details the investigation of build-up and wash-off process kinetics of Polycyclic Aromatic Hydrocarbons (PAHs) and heavy metals in urban areas. It also discusses the design and development of a rainfall simulator as an important research tool to ensure homogeneity and reduce the large number of variables that are usually inherent to urban water quality research. The rainfall simulator was used to collect runoff samples from three study areas, each with different land uses. The study areas consisted of sites with typical residential, industrial and commercial characteristics in the region. Build-up and wash-off samples were collected at each of the three sites. The collected samples were analysed for a number of chemical and physico-chemical parameters. In addition to this, eight heavy metal elements and 16 priority listed PAHs were analysed in five different particle size fractions of the build-up and wash-off samples. The data generated from the testing of the samples were evaluated using multivariate analysis, which reduced the complexity involved in determining the relative importance of a single parameter in urban water quality. Consequently, variables and processes influencing loadings and concentrations of PAHs and heavy metals in urban stormwater runoff from paved surfaces at any given time were identified and quantified using Principal Component Analysis (PCA). Furthermore, the process kinetics found were validated using a multivariate modelling approach and Partial Least Square (PLS) regression, which confirmed the transferability of chemical processes in urban water quality.    Fine particles were dominant in both the build-up and wash-off samples from the three sites. This was mirrored in the heavy metal and PAH concentrations at the three sites, which were significantly higher in particles between 0.45-75&#956;m than in any other fraction. Thus, the larger surface area and electrostatic charge of fine particles were favourable in sorbing PAHs and heavy metals. However, factors such as soil composition, total organic carbon (TOC), the presence of Fe and Mn-oxides and pH of the stormwater were all found to be important in partitioning of the metals and PAHs into different fractions. Additionally, PAHs were consistently found in concentrations above their aqueous solubility, which was attributed to colloidal organic particles being able to increase the dissolved fraction of PAHs. Hence, chemical and physico-chemical parameters played a significant role in the distribution of PAHs and heavy metals in urban stormwater. More importantly, the research showed the wide range of factors that distribute metals and PAHs in an urban environment. Furthermore, it indicated the need for monitoring these parameters in urban areas to ensure that urban stormwater management measures are effective in improving water quality. The build-up and wash-off process kinetics identified using PCA at the respective land uses were predicted using PLS and it was found that the transferability of the governing processes were high even though the PAHs and metal concentrations and loads were highly influenced by the source strength at each site. The increased transferability of fundamental concepts in urban water quality could have significant implications in urban stormwater management. This is primarily attributed to common urban water quality mitigation strategies relying on studies based on physical concepts and processes derived from water quantity studies, which are difficult to transfer between catchments. Hence, a more holistic approach incorporating chemical processes compared to the current piecemeal solutions could significantly improve the protection of key environmental values in a region. Furthermore, urban water quantity mitigation measures are generally designed to reduce the impacts of high-flow events. This research suggests that fairly frequent occurring rainfall events, such as 1-year design rainfall events, could carry significant heavy metal and PAH concentrations in both particulate and dissolved fractions. Hence, structural measures, designed to decrease quantity and quality impact on receiving waters during 10 or 20-year Average Recurrence Interval (ARI) events could be inefficient in removing the majority of PAHs and heavy metals being washed off during more frequent events.    The understanding of physical and chemical processes in urban stormwater management could potentially lead to significant improvements in pollutant removal techniques which in turn could lead to significant socio-economic advantages. This project can serve as a baseline study for urban water quality investigations in terms of adopting new methodology and data analysis.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Urban water quality</field><field name="subject">Rainfall simulation</field><field name="subject">Polycyclic Aromatic Hydrocarbons</field><field name="subject">Heavy metals</field><field name="subject">Process kinetics</field><field name="subject">Build-up</field><field name="subject">Wash-off</field><field name="identifier">http://eprints.qut.edu.au/16111/</field><field name="validLink">True</field></doc><doc><field name="title">Early childhood education and care : parent conceptions of ECEC services and choice of services</field><field name="creator">Noble, Karen</field><field name="description">This study details a phenomenographic and grounded theory investigation aimed at generating new knowledge of an under-researched area, namely that of parental choice of early childhood education and care services. Given the complexity and range of choice of early childhood services, and the diversity of family situations, research eliciting parent conceptions of their choices of early childhood services is both necessary and timely. Findings from this study may be used to inform early childhood professionals by expanding their awareness of the variation that exists in the way that parents conceptualise early childhood services and make choices for young children. This study addresses both the dilemmas of individual parents in conceptualising and choosing services for their children and the implications of their individual decisions in aggregate.
 
 Single in-depth, semi-structured interviews were conducted with 23 parents from the local area of Boyne Island, Central Queensland, Australia. The sample of parents comprised mothers only, although mothers and fathers were invited initially to join the study. The parents were drawn from the four local early childhood education and care (ECEC) services that operate in this area. In the first stage of the analysis, a phenomenographic framework was used to develop an outcome space to describe the eight parent conceptions of ECEC services. These categories describe the way parents see ECEC services as:
 
 Demographically convenient,
 
 Safe, secure and hygienic,
 
 Providing a routine,
 
 Caring and nurturing,
 
 Having trained and qualified staff,
 
 Valuing parents and keeping them informed,
 
 Preparing for further learning,
 
 Providing socialisation.
 
 These eight categories of description are understood and distinguished in terms of three dimensions, those being physical, personnel and personal. The physical dimension refers to the location and availability of services catering to the needs of the family. The personnel dimension refers to how ECEC services are judged according to the personnel who work within that environment. The personal dimension refers to how the ECEC service is judged according to how the individual children and their family are catered for and responded to within the environment.
 
 In the second stage of analysis, an orthodox grounded theory approach was used to explore how parents understood their choice of ECEC services for their young children. This later analysis found that parent choice is influenced by:
 
 Relationship with child;
 
 Influence of significant others;
 
 Understandings of childhood;
 
 Maximising the child's potential.
 
 The grounded theory that developed as a result of this stage of analysis was that parents make complex and pragmatic choices within social contexts.
 
 An understanding of the relationships between parent conceptions and the influences that they consider when choosing ECEC services was used to develop a model. This model demonstrates the complexities of choice of service juxtaposed with parent conceptions of ECEC services. Tensions for parents and their choice of service arose when their conceptions of ECEC services were compromised. Therefore, central to the model presented is the understanding that the ECEC services were located within a specific societal context and as such, any one, or combination of, the dimensions of conceptions of service, impact upon choice.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">early childhood education and care services, parent conceptions, choice, qualitative research, phenomenography, phenomenographic research, grounded theory, orthodox grounded theory</field><field name="identifier">http://eprints.qut.edu.au/16112/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation of the assumptions that inform contemporary hospital infection control programs.</field><field name="creator">Macbeth, Deborough Anne</field><field name="description">The purpose of the study was to investigate the assumptions that underpin contemporary hospital infection control programs from the perspective of the influence of clinical culture on the integration and ownership of the infection control program.    The results of numerous studies have linked low levels of adherence with infection control principles amongst health care providers as the most significant factor contributing to nosocomial infection. Despite early successes in reducing nosocomial infection rates, results derived from current research demonstrate that nosocomial infection has remained a challenge to healthcare providers and patients alike and outbreaks are regularly reported in the infection control literature.    Serious economic and social impact has resulted from the increasing levels of antibiotic resistance that have been reported amongst pathogens associated with nosocomial infection.    This interpretive study takes an ethnographic approach, using multiple data sources to provide insight into the culture and context of infection control practice drawing upon clinicians' work and the clinician's perspective.    There were three approaches to data collection. A postal survey of surgeons was conducted, a group of nurses participated in a quality activity, and a clinical ethnography was conducted in an intensive care unit and an operating theatre complex.    Data were analysed in accordance with the qualitative and quantitative approaches to data management.    Findings indicate that the clinical culture exerts significant influence over the degree to which the infection control program activities change practice and that rather than imposing the infection control program on the clinical practice setting from outside, sustained practice change is more likely to be achieved if the motivation and impetus for change is culturally based. Moreover surveillance, if it is to influence clinicians and their practice, must provide confidence in its accuracy. It must be meaningful to them and linked to patient care outcomes.    Contemporary hospital infection control programs, based on assumptions about a combination of surveillance and control activities have resulted in decreased nosocomial infection rates. However, sustained infection control practice change has not been achieved despite the application of a range of surveillance and control strategies. This research project has utilized an ethnographic approach to provide an emic perspective of infection control practice within a range of practice contexts. The findings from this study are significant within the context of spiraling health costs and increasing antibiotic resistance associated with nosocomial infection.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Infection Control</field><field name="subject">Ethnography</field><field name="subject">Antisepsis</field><field name="subject">Health Geography</field><field name="subject">Space</field><field name="subject">Infection Surveillance</field><field name="subject">Clinical Governance</field><field name="subject">Data Awareness</field><field name="subject">Data Ownership</field><field name="subject">Clinical Culture</field><field name="subject">Technology</field><field name="subject">Environmental Cues</field><field name="subject">Emergency Context</field><field name="identifier">http://eprints.qut.edu.au/16113/</field><field name="validLink">True</field></doc><doc><field name="title">The economic basis of syndicated lending</field><field name="creator">Wild, William</field><field name="description">This work undertakes the first comprehensive theoretical assessment of syndicated loans. It is shown that syndicated and bilateral (single lender) loans should be good substitutes in meeting a borrower's financing requirements, but that syndicated loans are more complex and impose additional risks to the parties in the way they are arranged. The existing explantions of loan syndication - that they are hybrids of private bank loans and public debt instruments, that syndication is a portfolio management tool,
 
 and that loans are syndicated where they are too large to be provided bilaterally - are unable to substantially explain both the nature of syndicated loans and practice in the loan markets. A rigorous new explanation is developed, which shows that syndication reduces the rate of lending costs, so that the return to the loan originator is greater, and the borrower's cost of financing is lower, where a loan is syndicated rather than provided bilaterally. This explanation is shown to hold in competitive loan markets and to be consistent with the observation that syndicated loans are generally larger than other loans. Incidental to this new explanation, new expressions of the return to a bank from providing a loan on a bilateral basis and from originating a syndicated
 
 loan are also developed. New algorithms are also developed for determining the distribution
 
 of the commitments from syndicate participants and thus the originator's final hold, the amount it must lend itself, where the loan is underwritten. This provides, for the first time, a rigorous basis for assessing the expected return, and the risk, for the originator of a given syndicated loan. Finally, empirical testing finds that a bank's observed lending history is significant to its decision to participate in a new syndicated loan but that predictions of participation, which are fundamental inputs into the final hold algorithms, based on this information have relatively little power. It follows that
 
 there is competitive advantage to loan originators that have access to other, private
 
 information on potential participants' lending intentions.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Syndicated Loan</field><field name="subject">Lending</field><field name="subject">Commerical Bank</field><field name="subject">Loan Pricing</field><field name="subject">Underwriting</field><field name="subject">Arranger</field><field name="subject">Borrower</field><field name="subject">Participant</field><field name="subject">Credit Risk</field><field name="subject">Capital Charge</field><field name="subject">Credit Exposure Limits</field><field name="subject">Final Hold</field><field name="subject">Relationship Banking</field><field name="identifier">http://eprints.qut.edu.au/16114/</field><field name="validLink">True</field></doc><doc><field name="title">Nursing services in the Rockhampton district, 1911 - 1957</field><field name="creator">Madsen, Wendy Lee</field><field name="description">Throughout the twentieth century, nursing services gradually moved from being located within the community to being concentrated in institutions, such as hospitals. The aim of this thesis is to identify those nursing services that existed within the Rockhampton region from 1911 to 1957; to document the evolution of the services; and to explore those factors that influenced this evolution. In particular, an emphasis is placed on social and political factors. The nursing services explored in this thesis include private duty nursing, private hospitals, church and charity facilities, public hospitals and public community services. These services represent most nursing opportunities during the first half of the twentieth century. However, this thesis takes a unique position by exploring all services in detail within a limited location. In order to accomplish this, an empirical historical method is utilised, based on a wide range of documentary primary sources drawn from archival collections relating to Rockhampton and the nursing profession.    By examining a limited geographical area, this thesis highlights the complexity of nursing in regards to who nursed, how nursing was practiced and what factors influenced nursing. A particular feature that emerges within this thesis is the important role untrained nurses played within nursing services throughout the period under review. This group dominated private duty nursing and lying-hospitals in the Rockhampton region, although were gradually restricted to facilities for the aged and chronically ill. Trained nurses also became more institutionalised throughout the period, gradually losing former levels of autonomy as they gained more controlled working conditions, wages and career structures. Finally, this thesis highlights variations in nursing services between metropolitan and regional areas of Queensland.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">nursing</field><field name="subject">nursing services</field><field name="subject">regional Australia</field><field name="subject">history</field><field name="identifier">http://eprints.qut.edu.au/16115/</field><field name="validLink">True</field></doc><doc><field name="title">Risk-Based Approach to On-site Wastewater Treatment System Siting Design and Management</field><field name="creator">Carroll, Steven Paige</field><field name="description">The use of on-site wastewater treatment systems (OWTS) for the treatment and dispersal of domestic effluent is common in urban fringe areas which are not serviced by centralised wastewater collection systems. However, due to inappropriate siting and soil characteristics, the failure of these systems has become a common scenario. The current standards and guidelines adopted by many local authorities for assessing suitable site and soil conditions for OWTS are increasingly coming under scrutiny due to the public health and environmental impacts caused by poorly performing systems, in particular septic tank-soil adsorption systems. In order to achieve sustainable on-site wastewater treatment with minimal impacts on the environment and public health, more appropriate means of assessment are required.    The research described in the thesis details the processes adopted for the development and implementation of an integrated risk based approach to OWTS siting, design and management. This involved detailed investigations into resolution of some of the inherent deficiencies identified in the existing OWTS codes and guidelines, including more thorough site and soil assessment and data analysis, integration of the key risk facets of OWTS siting and design, environmental and public health, and the incorporation of scientific knowledge into the assessment processes. The research undertaken focused on four key research areas; (i) assessment of soil suitability for providing adequate treatment and dispersal of domestic wastewater; (ii) contamination of ground and surface waters as a result of OWTS failure and the major factors influencing contaminant fate and transport; (iii) assessment of environmental and public health risks due to poor OWTS performance; and (iv) the development of an integrated risk assessment framework for OWTS siting, design and management. The research conducted was multidisciplinary in nature, with detailed investigations of the physical, chemical and biological processes involved in on-site wastewater treatment and dispersal. This involved extensive field investigations, sampling, laboratory testing and detailed data analysis across the fields of soil science, groundwater and surface water quality, chemical and microbiological contamination, and contaminant fate and transport processes. The interactions between these different disciplines can be complex, resulting in large amounts of data being generated from the numerous field investigations and sampling processes undertaken. In order to understand the complex relationships that can occur, multivariate statistical techniques were utilised. The use of these techniques were extremely beneficial, as not only were the respective relationships between investigated parameters identified, but adequate decisions based on the respective correlations were formulated. This allowed a more appropriate assessment of the influential factors, and subsequently the inherent hazards related to OWTS, to be conducted.    The primary research objectives for this research were investigated through a series of scientific papers centred on these key research disciplines. The assessment of soil suitability was achieved through extensive soil sampling throughout the study area and detailed laboratory testing and data analysis. The studies undertaken are described in Chapters 3, 4 and 5. Paper 1 (Framework for soil suitability evaluation for sewage effluent renovation) outlines a framework for assessing the renovation ability of the major soil groups located throughout Southeast Queensland. This framework formed the basis for the assessment of OWTS siting and design risks employed in the developed risk framework. Paper 2 (Use of Chemometric Methods and Multicriteria Decision-Making for Site Selection for Sustainable On-site Sewage Effluent Disposal) details and justifies the multivariate data analysis techniques used in establishing the soil framework. Paper 3 (Assessment of soil suitability for effluent renovation using undisturbed soil columns) describes investigations of the use of undisturbed soil cores for the assessment of long term soil renovation ability. This study was undertaken to validate the research outcomes achieved through the established framework developed in Paper 1. Papers 4, 5 and 6 (Chapters 6 - 8) focus on contamination issues of ground and surface waters resulting from poor OWTS treatment performance, and the different factors that influence pollutant fate and transport. The investigation of ground and surface water contamination, detailed in Paper 4 (Assessment of High Density of Onsite Wastewater Treatment Systems on a Shallow Groundwater Coastal Aquifer using PCA) and Paper 5 (Environmental and anthropogenic factors affecting fecal coliforms and E. coli in ground and surface waters in a coastal environment) was achieved through extensive ground and surface water sampling and testing from several monitored study sites. Analysis of the resulting data indicated that several key factors, including rainfall, site and soil conditions and on-site system density can significantly influence the fate and transportation of pollutants emitted from OWTS. An additional issue found during this research in assessing faecal contamination of water resources was the necessity to ensure that the respective sources of contamination were actually OWTS. The inherent difficulty in identifying the actual source of contamination was resolved by employing a source tracking method, namely antibiotic resistance analysis of faecal coliforms (Paper 6; Sourcing fecal pollution from onsite wastewater treatment systems in surface waters using antibiotic resistance analysis). Finally, Paper 7 (Integrated Risk Framework for On-site Wastewater Treatment Systems) describes the development of the final generic integrated risk assessment framework and how the outcomes, as discussed through the previous 6 papers, were combined to assess the environmental and public health risks inherent in OWTS siting and design.    The outcomes of this research have significantly contributed to knowledge of best practice in OWTS siting, design and management. The developed soil suitability framework allows more appropriate assessment of soil characteristics for providing effluent renovation. This is generally not done in the current assessment techniques for OWTS. Additionally, the use of this framework incorporates scientific knowledge into the assessment of OWTS, allowing a more rigorous and scientifically robust assessment process. The processes and techniques used in the soil suitability framework, although based on the common soil types typical of South East Queensland, can be implemented in other regions, provided appropriate soil information is collected for the area of interest.    The integrated risk framework has also been developed on a generic level, allowing easy implementation into most assessment processes. This gives the framework the flexibility to be developed for other areas specifically targeting the most influential OWTS siting and design factors, and the potential environmental and public health hazards within those regions. The resulting research outcomes achieved through the studies undertaken were subsequently applied to a case study for the development of the integrated risk framework for the Gold Coast region. The developed framework, based on scientific research, has allowed a more appropriate means of assessing site suitability for OWTS and appropriate management and mitigation of the environmental and public health risks inherent with poor OWTS performance</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">On-Site Wastewater Treatment Systems</field><field name="subject">Risk Assessment</field><field name="subject">Risk Management</field><field name="subject">Multivariate Analysis</field><field name="subject">Groundwater</field><field name="subject">Contamination</field><field name="identifier">http://eprints.qut.edu.au/16116/</field><field name="validLink">True</field></doc><doc><field name="title">The Formation and Growth of Marine Aerosols and the Development of New Techniques for their In-situ Analysis.</field><field name="creator">Johnson, Graham Richard</field><field name="description">Marine aerosols have attracted increasing attention over the past 15 years because of  their potential significance for global climate modelling. The size distribution of these  aerosols extends from super-micrometer sea salt mode particles down through 150 nm  accumulation mode particles, 40 nm Aitken mode particles and nucleation mode  particles which extend from 25 nm right down to clusters of a few molecules. The  process by which the submicrometer modes form and grow and their composition  have remained topics of debate throughout this time in large part because of the  difficulties associated with determining their composition and relating it to proposed  models of the formation process.    The work compared the modality of marine aerosol influencing the South-east-Queensland region with that of other environmental aerosols in the region. The aerosol was found to be consistent with marine aerosols observed elsewhere with  concentrations below 1000 cm-3 and frequently exhibiting the distinct bimodal structure associated with cloud processing, consisting of an Aitken mode at approximately 40 nm, an accumulation mode in the range 100-200 nm and a coarse mode attributed to sea salt between 600 and 1200 nm.    This work included the development of two new techniques for aerosol research. The first technique measures aerosol density using a combination of aerosol size distribution and gravimetric mass concentration measurements. This technique was used to measure the density of a number of submicrometer aerosols including  laboratory generated NaCl aerosol and ambient aerosol. The densities for the laboratory generated aerosols were found to be similar to those for the bulk materials used to produce them. The technique, extended to super-micrometer particle size range may find application in ambient aerosol research where it could be used to discriminate between periods when the aerosol is dominated by NaCl and periods  when the density is more representative of crustal material or sulfates. The technique  may also prove useful in laboratory or industrial settings for investigating particle  density or in case where the composition is known, morphology and porosity.    The second technique developed, integrates the existing physicochemical techniques  of volatilisation and hygroscopic growth analysis to investigate particle composition  in terms of both the volatilisation temperatures of the chemical constituents and their  contribution to particle hygroscopic behaviour. The resulting volatilisation and humidification tandem differential mobility analyser or VH-TDMA, has proven to be a valuable research tool which is being used in ongoing research.    Findings of investigations relating the composition of the submicrometer marine  aerosol modes to candidate models for their formation are presented. Sea salt was not  found in the numerically dominant particle type in coastal nucleation mode or marine  Aitken and accumulation modes examined on the Southeast Queensland coast during  periods where back trajectories indicated marine origin. The work suggests that all  three submicrometer modes contain the same four volatile chemical species and an  insoluble non-volatile residue. The volatility and hygroscopic behaviours of the  particles are consistent with a composition consisting of a core composed of sulfuric  acid, ammonium sulfate and an iodine oxide coated with a volatile organic compound.  The volume fraction of the sulfuric acid like species in the particles shows a strong  dependence on particle size.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Aerosol size distribution</field><field name="subject">modality</field><field name="subject">environmental aerosols</field><field name="subject">marine aerosols</field><field name="subject">aerosol density</field><field name="subject">ambient aerosol</field><field name="subject">VH-TDMA</field><field name="subject">particle hygroscopic growth</field><field name="subject">volatility</field><field name="subject">iodine oxides</field><field name="subject">non sea salt sulfate</field><field name="subject">sea salt aerosols</field><field name="subject">coastal aerosol</field><field name="subject">marine biota</field><field name="subject">algae</field><field name="subject">photolysis</field><field name="subject">photochemical</field><field name="subject">thermal decomposition</field><field name="subject">volatilisation and humidification tandem differential mobility analyser</field><field name="subject">ultra fine particles.</field><field name="identifier">http://eprints.qut.edu.au/16117/</field><field name="validLink">True</field></doc><doc><field name="title">Teachers Scaffolding Children Working with Computers : An Analysis of Strategies</field><field name="creator">Masters, Jennifer Ellen</field><field name="description">It is often assumed that the introduction of computers will transform teaching and  learning in a primary classroom. However, in many classrooms, the effective use of  computers to support teaching and learning is yet to be realised. The study described  in this thesis is premised on the notion that simply providing access to computers will  not change classroom processes and that the agent of change is a teacher's pedagogy  and practice.    This study initially examined the practices of a group of primary school teachers who  were considered to be exemplary in the use of computers in their classroom. It then  progressed to a focus on one teacher for indepth investigation of the strategies she  used as she supported children to complete an extended computer-based task.  Particular attention was given to the use of " scaffolding" as a teacher support strategy  for children working with computers.    The study adopted a qualitative methodology and was based on a Constructivist  Inquiry model (Guba &amp; Lincoln, 1989) with a Grounded Theory approach (Strauss &amp;  Corbin, 1990) for data analysis. It incorporated three phases of investigation which  included:    (a) a theoretical immersion, which was based on the literature;  (b) a functional immersion, which examined the practices and understandings  of eight teachers; and  (c) a practical immersion, in which the support strategies of the focus teacher  were observed during the implementation of the task over a period of eight  weeks. These observations were enhanced by " stimulated recall" interviews  where video vignettes were reviewed with the teacher.    A detailed coding of teacher support strategies was developed during the study and  eleven research constructs emerged from the final analysis of the data. These constructs represented the outcomes of the study and were grouped into four themes:  (a) teacher expertise, (b) teacher understanding of support strategies, (c) the nature of  scaffolding, and (d) the role of the computer.    The results of the study suggested that a teacher needs to conscientiously select and  implement strategies in order to support students working with computers. They also  indicated that a teacher should plan for opportunities where teacher scaffolding can be  used to support and extend students. Further, the results suggested that classroom  teachers would benefit from knowing about scaffolding and how it can be  implemented with children working with computers.    The introduction of computers into the classroom invokes the need for conscious and  deliberate changes to teacher pedagogy and practice to sure that effective use is made  of the opportunities provided by the technology. Although teachers do require a  measure of computer confidence, it seems that a teacher who successfully implements  computers in the classroom is essentially focused on the implementation of effective  teaching and learning practices. Therefore, it is important that pedagogy is  foregrounded in any consideration of using computers in the classroom.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Scaffolding</field><field name="subject">Computer</field><field name="subject">Teacher Support Strategies</field><field name="subject">Exemplary Computerusing Teacher</field><field name="subject">Primary Education</field><field name="subject">Pedagogy</field><field name="identifier">http://eprints.qut.edu.au/16118/</field><field name="validLink">True</field></doc><doc><field name="title">Massively Multiplayer Online Games Productive Players and their Disruptions to Conventional Media Practices</field><field name="creator">Humphreys, Alison Mary</field><field name="description">This thesis explores how massively multiplayer online games (MMOGs), as an exemplary new media form, disrupt practices associated with more conventional media. These intensely social games exploit the interactivity and networks afforded by new media technologies in ways that generate new challenges for the organisation, control and regulation of media. The involvement of players in constituting these games - through their production of game-play, derivative works and strong social networks that drive the profitability of the games - disrupts some of the key foundations that underlie other publication media. MMOGs represent a new and hybrid form of media - part publication and part service. As such they sit within a number of sometimes contradictory organising and regulatory regimes. This thesis examines the negotiations and struggles for control between players, developers and publishers as issues of ownership, governance and access arise out of the new configurations. Using an ethnographic approach to gather information and insights into the practices of players, developers and publishers, this project identifies the characteristics of the distributed production network in this experiential medium. It explores structural components of successful interactive applications and analyses how the advent of player agency and the shift in authorship has meant a shift in control of the text and the relations that surround it. The integration of social networks into the textual environment, and into the business model of the media publishers has meant commerce has become entwined with affect in a new way in this medium. Publishers have moved into the role of both property managers, of the intellectual property associated with the game content, and community managers. Intellectual property management is usually associated with the reproduction and distribution of finished media products, and this sits uneasily with the performative and mutable form of this medium. Service provision consists of maintaining the game world environment, community management, providing access for players to other players and to the content generated both by the developers and the other players. Content in an MMOG is identified in this project as both the 'tangible' assets of code and artwork, rules and text, and the 'intangible' or immaterial assets of affective networks.  Players are no longer just consumers of media, or even just active interpreters of media. They are co-producing the media as it is developed. This thesis frames that productiveness as unpaid labour, in an attempt to denaturalise the dominant discourse which casts players as consumers. The regulation of this medium is contentious. Conventional forms of media regulation - such as copyright, or content regulation regimes are inadequate for regulating the hybrid service/publication medium. This thesis explores how the use of contracts as the mechanism which constitutes the formal relations between players, publishers and developers creates challenges to some of the regimes of juridical and political rights held by citizens more generally. This thesis examines the productive practices of players and how the discourses of intellectual property and the discourses of the consumer are mobilised to erase the significance of those productive contributions. It also shows, using a Foucauldian analysis of the power negotiations, that players employ many counter-strategies to circumvent the more formal legal structures of the publishers.  The dialogic relationship between players, developers and publishers is shown to mobilise various discursive constructions of the role of each. The outcome of these ongoing negotiations may well shape future interactive applications and the extent to which their innovative capacities will be available for all stakeholders to develop.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Computer Games</field><field name="subject">Massively Multiplayer Online Game</field><field name="subject">MMOG</field><field name="subject">interactive media</field><field name="subject">interactive software</field><field name="subject">players</field><field name="subject">labour</field><field name="subject">intellectual property</field><field name="subject">contract</field><field name="subject">End User Licence Agreement</field><field name="subject">EULA</field><field name="subject">media ownership</field><field name="subject">media production</field><field name="subject">new media</field><field name="subject">ethnography</field><field name="identifier">http://eprints.qut.edu.au/16119/</field><field name="validLink">True</field></doc><doc><field name="title">Mathematical Modelling of the Biomechanical Properties of Articular Cartilage</field><field name="creator">Nguyen, Thanh Cong</field><field name="description">Articular cartilage is the translucent, heterogeneous three-component biological load processing gel that overlays the end of the articulating bones of mammalian joints. Normally, healthy intact articular cartilage performs two biomechanical functions very effectively. These are (i) redistribution of stresses due to loads acting on the joint; (ii) act as a near-frictionless interface between contacting bone ends. These principal functions are enabled by its highly elastic properties. Under normal physiological conditions, these essential biomechanical functions are provided over the lifetime of a mammalian joint with little or no degenerative changes. However, certain levels of physiological and traumatic loads and degenerative processes induced by activities such as running, walking, extreme sport, and aging can alter the composition and structure of the tissue, leading to changes in its biomechanical properties. This, inturn, influences its functional characteristics. The most common degenerative change in articular cartilage is osteoarthritis and the management and treatment of this disease is pivotal to all research targeted toward articular cartilage. Several scientific groups around the world have developed models of articular cartilage to predict its fundamental and functional responses to load and altered biochemical conditions through both in vivo and in vitro studies. The most predominant of these models are the biphasic and triphasic models, which are based on the conceptualisation of articular cartilage as a dispersed mixture of its three main components namely collagen fibrils proteoglycan aggregates and water. The triphasic model is an extension of the biphasic model and incorporates swelling as a separate identifiable component of the tissue's biomechanical response. While these models are capable of predicting the elastic and viscoelastic behaviour and certain aspects of the swelling characteristics of articular cartilage, they are incapable of accounting for its short-term responses where the fluid component is the main carrier of the applied pressure. The hydrostatic and swelling components of the fluid content determine the manner of stress-sharing and hence transient load processing within the matrix as stress is transmitted to the underlying structure. Furthermore, the understanding of the nature of this stress-sharing between fluid and solid components of the tissue is fundamental to the comprehension of the nature of degeneration and its biomechanical consequence in the function of the articulating joint. The inability of the biphasic and triphasic theories to predict, in accordance with experimental results, the transient behaviour of the loaded matrix fluid requires a more representative model. This imperative therefore forms the basis for the research work presented in this thesis.  In this thesis, a new mathematical model of articular cartilage load carriage is presented which can predict the transient load-induced responses. The model is based on a continuum framework invoking the principle of mechanical consolidation of fluid-saturated, swollen porous elastic materials. The cartilage matrix is conceptualised as a heterogeneous anisotropic fluid-saturated porous material in which its solid component responds to load as a hyperelastic material and whose interaction with the swelling component produces a partially distributed time-varying permeability.    In accordance with the principle of consolidation, a phenomenological approach is adopted for developing both analogue/engineering models and mathematical models for the tissue. The models are then used to predict both bulk matrix responses and the properties of the hypothetical layers of the tissue when subjected to physiological loading conditions. Ultimately, the generalized mathematical model is used to analyse the effect of superficial layer laceration on the stress-processing or stress-sharing characteristic of normal healthy articular cartilage. Finally, predicted results are shown to compare with experimental data demonstrating that the new models for swelling deformation, the hyperelastic law for solid skeletal structure and the distributed, time-dependent permeability are representative of the articular cartilage.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Anisotropy</field><field name="subject">Articular Cartilage</field><field name="subject">Continuity</field><field name="subject">Consolidation</field><field name="subject">Damage</field><field name="subject">Heterogeneity</field><field name="subject">Hyperelasticity</field><field name="subject">Laceration</field><field name="subject">Mathematical Model</field><field name="subject">Permeability</field><field name="subject">Rheological Analogue.</field><field name="identifier">http://eprints.qut.edu.au/16120/</field><field name="validLink">True</field></doc><doc><field name="title">Microfluctuations of Wavefront Aberrations of the Eye</field><field name="creator">Zhu, Mingxia</field><field name="description">The human eye suffers various optical aberrations that degrade the retinal image. These aberrations include defocus and astigmatism, as well as the higher order aberrations that also play an important role in our vision.  The optics of the eye are not static, but are continuously fluctuating.  The work reported in this thesis has studied the nature of the microfluctuations of the wavefront aberrations of the eye and has investigated factors that influence the microfluctuations.  The fluctuations in the ocular surface of the eye were investigated using high speed videokeratoscopy which measures the dynamics of the ocular surface topography.  Ocular surface height difference maps were computed to illustrate the changes in the tear film in the inter-blink interval.  The videokeratoscopy data was used to derive the ocular surface wavefront aberrations up to the 4th radial order of the Zernike polynomial expension.  We examined the ocular surface dynamics and temporal changes in the ocular surface wavefront aberrations in the inter-blink interval.  During the first 0.5 sec following a blink, the tear thickness at the upper edge of the topography map appeared to thicken by about 2 microns.  The influence of pulse and instantaneous pulse rate on the microfluctuations in the corneal wavefront aberrations was also investigated.  The fluctuations in ocular surface wavefront aberrations were found to be uncorrelated with the pulse and instantaneous heart rates.  In the clinical measurement of the ocular surface topography using videokeratoscopy, capturing images 2 to 3 seconds after a blink will result in more consistent results. To investigate fluctuations in the wavefront aberrations of the eye and their relation to pulse and respiration frequencies we used a wavefront sensor to measure the dynamics of the aberrations up to the Zernike polynomial 4th radial order.  Simultaneously, the subject's pulse rate was measured, from which the instantaneous heart rate was derived.  An auto-regressive process was used to derive the power spectra of the Zernike aberration signals, as well as pulse and instantaneous heart rate signals.  Linear regression analysis was performed between the frequency components of Zernike aberrations and the pulse and instantaneous heart rate frequencies.  Cross spectrum density and coherence analyses were also applied to investigate the relation between fluctuations of wavefront aberrations and pulse and instantaneous heart rate.  The correlations between fluctuations of individual Zernike aberrations were also determined.  A frequency component of all Zernike aberrations up to the 4th radial order was found to be significantly correlated with the pulse frequency (all &gt; 2R0.51, p&lt;0.02), and a frequency component of 9 out of 12 Zernike aberrations was also significantly correlated with instantaneous heart rate frequency (all&gt;2R0.46, p&lt;0.05).  The major correlations among Zernike aberrations occurred between second order and fourth order aberrations with the same angular frequencies.  Higher order aberrations appear to be related to the cardiopulmonary system in a similar way to that reported for the accommodation signal and pupil fluctuations.   A wavefront sensor and high speed videokeratoscopy were used to investigate the contribution of the ocular surface, the effect of stimulus vergence, and refractive error on the microfluctuations of the wavefront aberrations of the eye.  The fluctuations of the Zernike wavefront aberrations were quantified by their variations around the mean and using power spectrum analysis.  Integrated power was determined in two regions: 0.1 Hz &#9472; 0.7 Hz (low frequencies) and 0.8 Hz &#9472; 1.8 Hz (high frequencies).  Changes in the ocular surface topography were measured using high speed videokeratoscopy and variations in the ocular wavefront aberrations were calculated. The microfluctuations of wavefront aberrations in the ocular surface were found to be small compared with the microfluctuations of the wavefront aberrations in the total eye.  The variations in defocus while viewing a closer target at 2 D and 4 D stimulus vergence were found to be significantly greater than variations in defocus when viewing a far target.  This increase in defocus fluctuations occurred in both the low and high frequency regions (all p&lt;0.001) of the power spectra.  The microfluctuations in astigmatism and most of the 3rd order and 4th order Zernike wavefront aberrations of the total eye were found to significantly increase with the magnitude of myopia.    The experiments reported in this thesis have demonstrated the characteristics of the microfluctuations of the wavefront aberrations of the eye and have shown some of the factors that can influence the fluctuations.  Major fluctuation frequencies of the eye's wavefront aberrations were shown to be significantly correlated with the pulse and instantaneous heart rate frequencies.  Fluctuations in the ocular surface wavefront aberrations made a small contribution to those of the total eye.  Changing stimulus vergence primarily affected the fluctuations of defocus in both low and high frequency components.  Variations in astigmatism and most 3rd and 4th order aberrations were associated with refractive error magnitude.  These findings will aid our fundamental understanding of the complex visual optics of the human eye and may allow the opportunity for better dynamic correction of the aberrations with adaptive optics.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">corneal topography</field><field name="subject">ocular aberrations</field><field name="subject">wavefront</field><field name="subject">Zernike aberrations</field><field name="subject">accommodation</field><field name="subject">microfluctuations.</field><field name="identifier">http://eprints.qut.edu.au/16121/</field><field name="validLink">True</field></doc><doc><field name="title">GPS L1 Carrier Phase Navigation Processing</field><field name="creator">Bruggemann, Troy S.</field><field name="description">In early 2002, Queensland University of Technology (QUT) commenced to develop its own low-cost Global Positioning System (GPS) receiver with the capability for space applications such as satellites in Low Earth Orbits, and sounding rockets.  This is named the SPace Applications Receiver (SPARx).  This receiver development is based on the Zarlink (formerly known as Mitel) GP2000 Chip set and is a modification of the Mitel Orion 12 channel receiver design.  Commercially available GPS receivers for space applications are few and expensive. The QUT SPARx based on the Mitel Orion GPS receiver design is cost effective for space applications.  At QUT its use is being maximized for space applications and carrier phase processing in a cost-effective and specific way.
 
 
 
 To build upon previous SPARx software developments made from 2002 to 2003, the receiver is required to be modified to have L1 carrier phase navigation capability.  Such an improvement is necessary for the receiver to be used in 3-axis attitude determination and relative navigation using carrier phase.  
 
 
 
 The focus of this research is on the implementation of the L1 carrier phase measurement capability with SPARx.  This is to enable the use of improved navigation algorithms.  Specific emphasis is given to the areas of time synchronization, the carrier phase implementation and carrier phase differential GPS with SPARx.  Test results conducted in the area of time synchronization and comparisons with other carrier phase capable GPS receivers are given, as well as an investigation of the use of SPARx in carrier phase differential GPS.  Following these, conclusions and recommendations are given for further improvements to SPARx.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">GPS</field><field name="subject">Mitel Orion</field><field name="subject">Timing</field><field name="subject">Carrier phase</field><field name="subject">Differential GPS</field><field name="subject">CDGPS</field><field name="subject">Attitude determination</field><field name="identifier">http://eprints.qut.edu.au/16122/</field><field name="validLink">True</field></doc><doc><field name="title">An Examination of the Common Law Obligation of Good Faith in the Performance and Enforcement of Commercial Contracts in Australia</field><field name="creator">Dixon, William Michael</field><field name="description">This examination of the common law obligation of good faith in the performance and enforcement of commercial contracts in Australia seeks to achieve a number of objectives.    First, to chart the historical development of the implied good faith obligation.    Secondly, to identify a number of issues that remain unresolved at Australian lower court level.    Thirdly, to consider five doctrinal approaches that could be adopted by the High Court when ultimately confronted by the competing claims and tensions that have proven divisive in the courts below.    Fourthly, to assess each approach against three identified benchmarks.    The essential thesis is that good faith should be implied, as a matter of law, in commercial contracts that are relational in nature with an additional call being made for the High Court to explicitly recognise that the underlying basis of the implied good faith obligation is the reasonable expectations of the contractual parties.  This approach is the one approach that satisfies all three benchmarks and provides the most satisfactory resolution of the issues that presently bedevil the commercial good faith debate in Australia.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Contract law</field><field name="subject">Australia</field><field name="subject">commercial contracts</field><field name="subject">common law obligation of good faith in contractual performance and enforcement</field><field name="subject">implied term</field><field name="subject">origins</field><field name="subject">meaning</field><field name="subject">basis of the implied obligation</field><field name="subject">reasonable expectations</field><field name="subject">community standards</field><field name="subject">obligation to act reasonably</field><field name="subject">fiduciary obligation</field><field name="subject">correlation with equitable and/or statutory unconscionability</field><field name="subject">class of contract</field><field name="subject">discrete-relational continuum</field><field name="subject">empirical studies</field><field name="subject">content</field><field name="subject">drafting implications</field><field name="subject">judicial licence</field><field name="subject">future approaches.</field><field name="identifier">http://eprints.qut.edu.au/16123/</field><field name="validLink">True</field></doc><doc><field name="title">The Impact of Change Communication on Change Receptivity : Two Cases of Continuous Change</field><field name="creator">Frahm, Jennifer Anne</field><field name="description">Communication is inextricably linked with the process of organisational change (Lewis, 1999).  However, managers report that communication of organisational change is challenging, particularly with the advent of continuously changing organisations (Buchanan, Claydon &amp; Doyle, 1999). Continuously changing organisations are those that seek to be more flexible, more innovative and more responsive to the dynamic external environment. One of the problems associated with continuous change is the resultant impact of successive downsizings, re-engineering efforts and culture changes on employee receptivity to change. Despite the unquestioning adoption of continuous change efforts (Zorn, Christensen, &amp; Cheney, 1999) there is a paucity of research on communication during this type of change. This thesis addresses this knowledge gap by situating the research within a continuous change context. The primary research question is 'how do change communication models impact on employee receptivity to change within a continuous change context', and this question considers issues pertaining to how accurately previous change communication models reflect and explain what occurs within change processes. This topic is examined within two case-study organisations through the use of multiple methods. The analysis occurs through an interpretive framework and utilises Langley's (1999) alternate templates as a strategy to manage the process based research. A model of change communication during continuous change is presented, with the central constructs of the model being monologic change communication, dialogic change communication and the background talk of change. Further, Van de Ven and Poole's (1995) Process Theories of Change are extended to consider the sequencing of the three constructs. The findings suggest that the sequencing of the dominant change communication models is informed by an alignment of individual communication competences and change communication expectations.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Change Communication</field><field name="subject">Change Receptivity</field><field name="subject">Continuous Change</field><field name="subject">change</field><field name="subject">Process Theories of Change</field><field name="identifier">http://eprints.qut.edu.au/16124/</field><field name="validLink">True</field></doc><doc><field name="title">Diffraction Tomographic Imaging of Shallowly Buried Targets using Ground Penetrating Radar</field><field name="creator">Hislop, Gregory Francis</field><field name="description">The problem of subsurface imaging with Ground Penetrating Radar (GPR) is a challenging one.  Due to the low-pass nature of soil sensors must utilise wave-lengths that are of the same order of magnitude as the object being imaged.  This makes imaging difficult as straight ray approximations commonly used in higher frequency applications cannot be used.  The problem becomes even more challenging when the target is shallowly buried as in this case the ground surface reflection and the near-field parameters of the radar need to be considered.  This thesis has investigated the problem of imaging shallowly buried targets with GPR.  Two distinct problems exist in this field radar design and the design of inverse scattering techniques.  This thesis focuses on the design of inverse scattering techniques capable of taking the electric field measurements from the receiver and providing accurate images of the scatterer in real time.    The thesis commences with a brief introduction to GPR theory.  It then provides an extensive review of linear inverse scattering techniques applied to raw GPR data.  As a result of this review the thesis draws the conclusion that, due to its strong foundations in Maxwell's equations, diffraction tomography is the most appropriate approach for imaging shallowly buried targets with GPR.  A three-dimensional diffraction tomographic technique is then developed.  This algorithm forms the primary contribution of the thesis.    The novel diffraction tomography technique improves on its predecessors by catering for shallowly buried targets, significant antenna heights and evanescent waves.  This is also the first diffraction tomography technique to be derived for a range of antenna structures.  The advantages of the novel technique are demonstrated first mathematically then on synthetic and finally practical data.  The algorithm is shown to be of high practical value by producing accurate images of buried targets in real time.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Born approximation</field><field name="subject">diffraction tomography</field><field name="subject">GPR</field><field name="subject">Ground Penetrating Radar</field><field name="subject">inverse electromagnetics</field><field name="subject">inverse scattering</field><field name="subject">landmine detection</field><field name="subject">non-destructive testing</field><field name="subject">remote sensing</field><field name="subject">subsurface imaging.</field><field name="identifier">http://eprints.qut.edu.au/16125/</field><field name="validLink">True</field></doc><doc><field name="title">Moderators of the effects of perceived job insecurity: A comparison of temporary and permanent employees</field><field name="creator">Clark, Lynette Joy</field><field name="description">Perceived job insecurity is receiving increasing recognition as an important determinant of employee work outcomes.  Empirical research consistently shows that job insecurity perceptions are associated with adverse reactions by employees, in terms of reduced psychological well-being (De Witte, 1999), job satisfaction (O'Quin &amp; LoTempio, 1998), and organisational commitment (Rosenblatt &amp; Ruvio, 1996).  Turnover intentions for the job-insecure are higher (Tivendell &amp; Bourbonnai, 2000) as well.  It is therefore important to understand what may increase or decrease such detrimental effects of job insecurity.  Even so, it was not until the late 1990s that much academic literature was published in the field (De Witte &amp; N&#228;swall, 2003).  Employees not only worry about their assessment of the likelihood of job loss, but also about the consequences of such an occurrence (Burchell, 2002).  This dissertation argues that perceived job insecurity is a function of what an individual believes is an acceptable risk of job loss given their individual circumstances.  Based on the literature, a model is developed proposing a number of moderators of the effects of job insecurity.  One of those moderators is temporary job status.  Little research is available that examines how job insecurity influences the work attitudes and behaviours of temporaries (De Witte, 1999; Kinnuen &amp; N&#228;tti, 1994; Sloboda, 1999).  Few studies compare temporaries' reactions to those of traditional, permanent employees.  Study one examined whether temporaries had higher job insecurity than permanents in a sample of three hundred and ninety-one employees (122 temporary and 269 permanent) in low to medium level non-academic positions at two Australian universities.  No significant differences were found.  However, temporaries and permanents reacted differently to job insecurity when a number of individual differences were also considered.    The temporary employment literature consistently shows that individuals that prefer temporary work have more positive work outcomes (Feldman, 1990, 1995).  Thus the extent of choice temporaries had in their job status was chosen as a potential moderator of job insecurity relationships.  Findings indicate that choice in job status differentially influenced the contextual performance, continuance commitment, and turnover intentions of temporaries and permanents, as predicted.  For example, when temporaries preferred temporary work and felt secure, they had similar turnover intentions to permanents.  Explanations why individuals involuntarily accept temporary work include a lack of job alternatives.  Thus another moderator tested was employability, concerning perceptions about finding comparable employment in the event of job loss.  Employability influenced the continuance commitment and intention to change job status of temporaries and permanents differently.  In particular, the findings suggest that the negative effects of job insecurity worsened for highly employable temporaries, decreasing their continuance commitment, since when secure, highly employable temporaries and permanents had similar continuance commitment levels.  Subjective job dependency, as a moderator of job insecurity, affected temporaries and permanents in the same way.  Specifically, the more insecure and the less dependent the employee was the lower was their contextual performance.  Two sources of social support were also tested in study one.  One source, social support from supervisors and co-workers was shown to differentially influence the contextual performance of temporaries and permanents.  Specifically, the negative effects of job insecurity were alleviated for temporaries with high organisational social support, such that their contextual performance was higher than that of permanents.  Family social support and temporary job status also moderated the relationship between job insecurity and job satisfaction, though not as predicted.  For temporaries, the level of family social support did not influence the effects of job insecurity on job satisfaction.  For permanents though, family social support alleviated the effects of job insecurity, such that the more family social support experienced the higher the job satisfaction.  A follow-up study (n = 116) was conducted one year later.  The longitudinal effects of job insecurity were examined.  Of the work outcomes assessed, only continuance commitment was predicted by Time 1 job insecurity, once prior levels of the outcome variables were controlled.  A second purpose of study two was to test job embeddedness - a measure of employee retention - as a moderator of the relationship between job insecurity and work outcomes.  The results indicate that the negative effects of job insecurity were exacerbated when employees perceived their organisation-related sacrifices to be great, lessening both their affective commitment and contextual performance contributions.  Theoretical and practical implications of the results of both studies are discussed.  For instance, these findings suggest that temporary job status should not be used as a proxy measure of job insecurity.  Finally, directions for future research are proposed.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">job insecurity</field><field name="subject">job satisfaction</field><field name="subject">organisational commitment</field><field name="subject">turnover</field><field name="subject">temporaries</field><field name="subject">permanents</field><field name="identifier">http://eprints.qut.edu.au/16126/</field><field name="validLink">True</field></doc><doc><field name="title">Nurses' and Parents' Attitudes toward Pain       Management and Parental Participation in Postoperative Care of Children</field><field name="creator">Chen, Wen-Lin</field><field name="description">Over the last 25 years, inadequate pain management for postoperative children continues to be reported in the literature. Inadequate postoperative pain management leads to detrimental physiological and psychological effects, and lengthens children's hospitalisation. Parental participation can improve the quality of care in hospital and after discharge. Both pain management and parental participation are influenced by the attitudes of nurses and parents. However, only little attention has been paid to this field particularly in Taiwan.    The purpose of the present study was: firstly, to understand nurses' and parents' attitudes toward pain management and parental participation in postoperative child care. Secondly, to explore the personal factors affecting their attitudes to pain management and parental participation. The third purpose was to compare nurses' and parents' attitudes toward pain management and parental participation in postoperative care of children in Taiwan. A descriptive, cross sectional design was used to survey paediatric nurses (n=63) and parents (n=133) of children from 0 to 17 years old who had undergone surgery in three Taiwan teaching hospitals.    The findings indicate that misconceptions about pain medications were found in both parents and nurses. Both parents and nurses held neutral to positive attitudes towards parental participation and postoperative pain management. Both parents and nurses who had higher education levels had more positive attitudes toward the use of pain medication.  Parents who were younger, had a higher education level, had previous experience of caring for their child during hospitalisation, had previous experience with their child having surgery and who had younger children, had more positive attitudes toward parental participation. Nurses who had more working experience with children had more positive attitudes toward parental participation. Nurses and parents all had higher agreement in using non-pharmacological methods for children's postoperative pain relief. Nurses had more agreement than the parents in the subscale of "parent-professional collaboration" and another five items in the PPAS questionnaire which included parents being allowed to change simple dressings, restrain their child, and feed their baby; parents being informed; and enhanced professional-patient relationship with parental involvement. Parents had more positive attitudes than nurses to the subscale of "parent presence" and the parents were more in favour than nurses of the provision of facilities such as free meals or parking fees.    Improvement in the quality of children's pain management requires more education to enhance nurses' and parents' knowledge and attitudes toward children's pain management and parental participation. Additional programs are needed that target nurses with less paediatric experience as well as older parents to develop more positive attitudes to parental participation. Paediatric nurses need to be aware and satisfy parents' desire to be present during their child's hospitalisation, as well as help parents to clarify their misconceptions about side effects and tolerance of analgesics utilisation.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Children</field><field name="subject">Postoperative</field><field name="subject">Pain management</field><field name="subject">Parental participation</field><field name="subject">Attitude</field><field name="subject">Knowledge</field><field name="subject">Nurse</field><field name="subject">Parent</field><field name="subject">Taiwan</field><field name="identifier">http://eprints.qut.edu.au/16127/</field><field name="validLink">True</field></doc><doc><field name="title">Organising Mobility: A Sociological Investigation of the Operations of an International Airport</field><field name="creator">Parker, Kenneth William</field><field name="description">Mobility on a global scale as a product of increased interconnectivity has been a subject of interest for writers working within various disciplines in the social sciences and beyond.  Few accounts, however, examine how mobility is performed by the operations of international airports.  Through data acquired in interviews conducted with the management of an international airport administration, this project adds to existing accounts of mobility with an examination of the strategies, techniques, and performances that allow an international airport to operate, and which in turn, enable transportation worldwide.  To analyse an airport as an organisation, this project employs a model advocated in John Law's (1994) influential study Organizing Modernity.  Law's (1994) framework focuses attention on the often hidden performances within organisations that strain towards governance, regulation, durability, and routine.  Incorporating Law's (1994) framework, this project illuminates aspects of an airport's operation in four thematic chapters, 'Ordering'; 'Communication'; 'Materials'; and 'Space'.  Overall, this project depicts the international airport as a complex socio-technical assemblage that requires multiple, varied, and interwoven ordering performances to operate effectively.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Mobility</field><field name="subject">Airports</field><field name="subject">Organisation</field><field name="subject">Actor Network</field><field name="subject">Ordering</field><field name="identifier">http://eprints.qut.edu.au/16128/</field><field name="validLink">True</field></doc><doc><field name="title">So What is Flexibility?  Toward a Multi-Level Theory of Organisational, Group, and Individual Flexibility</field><field name="creator">Jones, Renae Allison</field><field name="description">Flexibility is a term that is presumed to be meaningful across different levels of analysis in an organisation. It has been suggested that flexibility is required by organisations, groups, and individuals to deal with an increasingly complex and dynamic organisation and global environment. Authors have proposed that organisational flexibility enables a firm to achieve a better 'fit' with their environment and create a sustainable competitive advantage. The group level literature promotes flexibility at this level of analysis as important for group effectiveness and successful project completion. The individual flexibility literature suggests that people who are flexible are more likely to be satisfied and effective than individuals who are inflexible. Despite the importance placed on the construct of flexibility, it is a relatively under explored construct, both theoretically and empirically. This is due in part to the lack of definitional precision and inconsistency in the operationalisation of flexibility at each level of analysis. Consequently, little is known about the meaning of flexibility and the relationship of this construct with contextual and performance variables. This research addresses the limitations of the current literature on flexibility by developing a testable multi-level framework of flexibility. Flexibility is defined in this research as an organisation's, group's, and individual's ability to be proactive, adaptable, and resilient. Three primary research questions were addressed in this thesis. The first question addressed what are the characteristics of flexibility at the organisation, group, and individual level of analysis. The second overarching research question of interest in this thesis examines how flexibility at each level of analysis is related to performance. The third overarching research question examined what factors impact flexibility at each level of analysis. To address these three research questions at each level of analysis, a theoretical review and an empirical study were conducted.  The first empirical study, focused on flexibility at the organisational level of analysis. This study involved the exploration of seven specific research questions that were developed from the theoretical review. This study used cross-sectional secondary data of private sector Australian organisations. Flexibility was defined as proactivity, adaptability, and resilience. This research examined the relationships between each of the flexibility components and improvements in several organisational level outcomes. Also, the impact of the contextual variables level of organisational control, degree of structure, and competition changes on the flexibility-performance relationship was investigated. Analysis techniques included moderated regression analysis. Results showed support for the positive association between flexibility and performance. Flexibility interacted with competition and structure to influence performance, but control was found to have no moderating effect on the flexibility-performance relationship.    The second empirical study investigated group flexibility. This study took a sequential, mixed method research approach, using qualitative data to explore group flexibility and quantitative analysis to explore the broad relationships found among variables from the qualitative research. Using this approach, this study addressed five specific research questions that were developed from a theoretical review, including defining group flexibility, the nature of group flexibility conceptualisation, the relationship between flexibility and group performance, factors that may enhance group flexibility, and factors that may reduce group flexibility. Findings showed group flexibility was described consistently between participants and the existing literature, proposing group flexibility is a group's ability to search and consider alternatives, be adaptable, and resilient. Results also suggested a positive relationship between group flexibility and several outcomes, including stakeholder satisfaction, personal development and satisfaction, group morale, and group confidence.  The final study examined individual level flexibility. Based on the theoretical exploration of individual flexibility, in this study, individual flexibility was defined as the ability to be proactive, adaptable, and resilient. This empirical research focused specifically on managerial level flexibility. Due to the similarities in descriptions of individual flexibility and managerial flexibility in the literature, the definition of individual flexibility was applied to the managerial level. The study investigated changes in flexibility levels over time using executive coaching as the literature promotes executive coaching as an individual flexibility developmental tool. This study examined eleven leaders undertaking executive coaching with individual flexibility being measured at three points in time, pre coaching, the middle of coaching, and post coaching. Findings were consistent with the proposition of the positive impact of executive coaching on flexibility as the data showed leaders' individual flexibility levels increased from pre coaching to post coaching, with a significant linear trend over time. The results of these three studies are integrated to inform the multi-level framework of flexibility which was developed in this thesis. This framework provides a systematic, comprehensive, and tangible definition of flexibility at each level of analysis, providing a rich description of the characteristics of each flexibility component. This research advances our understanding of flexibility, which I hope will encourage further research on the construct. For managers and practitioners, this research provides a clear description of flexibility at each level of analysis and offers indicators of flexibility at each level to encourage the measurement and development of organisational, group, and individual flexibility. Also, this research provides empirical evidence of the benefits of flexibility, helping to provide legitimacy for the inclusion of flexibility into the organisation, in areas including strategic planning, organisational design, group design, recruitment and selection, and training and development. Furthermore, this multi-level model allows practitioners to be more focused in developmental efforts for organisation, group, and individual flexibility. This research provides several interesting areas for future research.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">flexibility</field><field name="subject">individual flexibility</field><field name="subject">organisation</field><field name="subject">global environment</field><field name="subject">performance</field><field name="subject">Australian organisations</field><field name="subject">private sector</field><field name="identifier">http://eprints.qut.edu.au/16129/</field><field name="validLink">True</field></doc><doc><field name="title">A Multidisciplinary Approach to Highly Autonomous UAV Mission Planning and Piloting for Civilian Airspace</field><field name="creator">McManus, Iain Andrew</field><field name="description">In the last decade, the development and deployment of Uninhabited Airborne Vehicles (UAVs) has increased dramatically. This has in turn increased the desire to operate UAVs in civilian-airspace. Current UAV platforms can be integrated into civilian-airspace, with other air traffic, however they place a high burden on their human operators in order to do so. In order to meet the competing objectives of improved integration and low operator workload it will be necessary to increase the intelligence on-board the UAV. This thesis presents the results of the research which has been conducted into increasing the on-board intelligence of the UAV. The intent in increasing the on-board intelligence is to improve the ability of a UAV to integrate into civilian-airspace whilst also reducing the workload placed upon the UAV's operator. The research has focused upon increasing the intelligence in two key areas: mission planning; and mission piloting.  Mission planning is the process of determining how to fly from one location to another, whilst avoiding entities (eg. airspace boundaries and terrain) on the way. Currently this task is typically performed by a trained human operator. This thesis presents a novel multidisciplinary approach for enabling a UAV to perform, on-board, its own mission planning. The novel approach draws upon techniques from the 3D graphics and robotics fields in order to enable the UAV to perform its own mission planning. This enables the UAV's operator to provide the UAV with the locations (waypoints) to fly to. The UAV will then determine for itself how to reach the locations safely. This relieves the UAV's operator of the burden of performing the mission planning for the UAV. As part of this novel approach to on-board mission planning, the UAV constructs and maintains an on-board situational awareness of the airspace environment. Through techniques drawn from the 3D graphics field the UAV becomes capable of constructing and interacting with a 3D digital representation of the civilian-airspace environment. This situational awareness is a fundamental component of enabling the UAV to perform its own mission planning and piloting. The mission piloting research has focused upon the areas of collision avoidance and communications. These are tasks which are often handled by a human operator. The research identified how these processes can be performed on-board the UAV through increasing the on-board intelligence. A unique approach to collision avoidance was developed, which was inspired by robotics techniques. This unique approach enables the UAV to avoid collisions in a manner which adheres to the applicable Civil Aviation Regulations, as defined by the Civil Aviation Safety Authority (CASA) of Australia. Furthermore, the collision avoidance algorithms prioritise avoiding collisions which would result in a loss of life or injury.  Finally, the communications research developed a natural language-based interface to the UAV. Through this interface, the UAV can be issued commands and can also be provided with updated situational awareness information. The research focused upon addressing issues related to using natural language for a civilian-airspace-integrated UAV. This area has not previously been addressed. The research led to the definition of a vocabulary targeted towards a civilian-airspace-integrated UAV. This vocabulary caters for the needs of both Air Traffic Controllers and general UAV operators. This requires that the vocabulary cater for a diverse range of skill levels. The research established that a natural language-based communications system could be applied to a civilian-airspace-integrated UAV for both command and information updates. The end result of this research has been the development of the Intelligent Mission Planner and Pilot (IMPP). The IMPP represents the practical embodiment of the novel algorithms developed throughout the research. The IMPP was used to evaluate the performance of the algorithms which were developed. This testing process involved the execution of over 3000 hours of simulated flights. The testing demonstrated the high performance of the algorithms developed in this research.    The research has led to the successful development of novel on-board situational awareness, mission planning, collision avoidance and communications capabilities. This thesis presents the development, implementation and testing of these capabilities. The algorithms which provide these capabilities go beyond the existing body of knowledge and provide a novel contribution to the established research. These capabilities enable the UAV to perform its own mission planning, avoid collisions and receive natural language-based communications. This provides the UAV with a direct increase in the intelligence on-board the UAV, which is the core objective of this research. This increased on-board intelligence improves the integration of the UAV into civilian-airspace whilst also reducing the operator's workload.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Uninhabited Airborne Vehicles</field><field name="subject">UAVs</field><field name="subject">UAV platforms</field><field name="subject">civilian-airspace</field><field name="subject">on-board intelligence</field><field name="subject">mission planning</field><field name="subject">mission piloting</field><field name="subject">natural language-based interface</field><field name="subject">Intelligent Mission Planner and Pilot (IMPP)</field><field name="identifier">http://eprints.qut.edu.au/16130/</field><field name="validLink">True</field></doc><doc><field name="title">Characterisation of Proteinase Inhibitors from Canegrubs for Possible Application to Genetically Engineer Pest-Derived Resistance into Sugarcane</field><field name="creator">Nutt, Kerry Anne</field><field name="description">In 1931, Mungomery stated "whitegrubs have been for years past, and still are, the worst insect problem confronting the sugar industry".  This statement remains true to this day, with canegrubs costing the Australian sugar industry A$7.22 million in lost production and in use of insecticides.  The development of a sugarcane cultivar with resistance to canegrub attack would be a valuable addition to the recently implemented canegrub management program.  This thesis examined the possibility that natural inhibitors derived from canegrubs could be incorporated in sugarcane to reduce or prevent its destruction by canegrubs.  The research described here demonstrated that canegrub haemolymph contains inhibitors with activity against commercially purified enzymes and serine proteases found in crude midgut extracts.  A cDNA encoding a potential canegrub protease inhibitor (DA10 12) belonging to the Ascaris family was cloned, but it did not have activity against the major canegrub midgut proteases.  This protein does, however, still have potential for modification into a serine protease inhibitor suitable for use as a novel insect resistance transgene.  The possibility of using haemolymph derived inhibitors as novel antimetabolites in a canegrub management strategy based on transgenic plants was also explored.  The findings suggest that proteins with properties similar to those of DA10 12 will require the presence of a signal peptide and/or codon optimisation for successful expression in sugarcane.  The research outlined in this thesis is the first investigation of protease inhibitors in the haemolymph of scarab larvae, and is the first report of an Ascaris family inhibitor that does not inhibit a serine protease.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Proteinase Inhibitors</field><field name="subject">sugarcane</field><field name="subject">canegrubs</field><field name="subject">sugarcane cultivar</field><field name="subject">canegrub haemolymph</field><field name="subject">Ascaris family</field><field name="subject">scarab larvae</field><field name="subject">insect resistance transgene</field><field name="identifier">http://eprints.qut.edu.au/16131/</field><field name="validLink">True</field></doc><doc><field name="title">In-home preventive health assessment and telephone case management for over 75s living alone in independent living units: A cluster randomised controlled trial.</field><field name="creator">Henderson, Marjory Jean</field><field name="description">Background Many trials in the USA, Canada, Europe and Australia have attempted to evaluate the effectiveness of preventive in-home health assessment and home care programs for older people. Trials have differed widely in their processes, including the dependence levels of subjects, assessment components and locations (clinic/home), intensity of case management (frequency of contact, length of follow-up period, scope of interventions) and methods of case management (telephone/visits). Preventive programs use valuable health resources and, although there has been inconclusive evidence of their effectiveness, programs combining preventive in-home health assessment and home care for older people have been introduced into public policy in Australia and internationally.  Ongoing research is therefore essential in order to identify the positive benefits for older people, and establish their effectiveness with regard to health resource utilisation. Purpose The purpose of the study was to maintain the health status of older people living alone in the community by implementing a preventive health assessment and follow-up home care program.  Research Design  An experimental group was compared with a control group using a cluster randomised controlled trial methodology.  Health outcomes were measured pre and post intervention, including health perception, functional ability, psychosocial status, client satisfaction, and health resource utilisation.  Population and Sample  The population for this study consisted of people aged 75 years and over who lived alone in Independent Living Units within managed retirement facilities, and who were highly independent in their activities of daily living. The final sample totalled 124, comprising of an experimental group (n=61) and a control group (n=63).  The sample resided in South East Queensland.  Intervention  The intervention for the study "A Community Preventive Health Model for over 75s Living Alone" comprised of five major elements: 1) targeting before health and/or social crisis, and while community care needs were low; 2) linking clients with a community nurse; 3) comprehensive health assessments and identification of needs; 4) introduction of basic health care and community services and referrals if required; and 5) case management by three-monthly telephone contact.  Assessments and case management were carried out by experienced community care registered nurses, and case management was performed for a one year period.  The control group received health assessments and phone calls similar to the experimental group for data collection purposes, and to balance the risk of a Hawthorne effect due to regular contacts with participants.  However all aspects of case management were omitted from all episodes of contact with the control group.  For ethical reasons control group participants were supplied with a summary of their health assessment results to share with their GP if they wished.  Data Collection and Instruments  Measures of health perception, functional ability and psychosocial status occurred at two points (baseline and after 12 months).  Measures of health resource utilisation, mortality and client satisfaction were measured after twelve months.  A combination of several widely-used, valid and reliable instruments, as well as some newly developed data collection tools, were used to measure health outcomes. Data Analysis  Independent group t-tests and Chi-square tests were used to examine for baseline differences between the experimental and control groups, and also to analyse health resource utilisation data at Time 2.  A series of ANCOVA tests were applied to test the remaining hypotheses, so that the effects of Time 1 scores and potential confounding variables could be incorporated into the analyses.  Results  The experimental group and control group were homogenous at baseline for all demographic variables and all major outcome variables. The intervention model was applied for one year, with 66% (n = 40) in the experimental group having at least one unmet need identified and appropriate interventions undertaken.  Only a small proportion of interventions (16%) were recorded as not being followed through by clients, and the majority (59%) resulted in needs being met or problems resolved.  Results showed no benefits were gained from the program after one year for experimental group participants for the outcomes of health perception, functional ability, psychosocial status, health resource utilisation and mortality. However, the experimental group did show a statistically significantly higher level of satisfaction with care. Conclusions Comprehensive assessments performed by Registered Nurses with expertise in gerontology resulted in the identification of previously undetected unmet needs.  When comprehensive assessment was combined with low intensity case management for a one year period, higher levels of client satisfaction with care were achieved.  Therefore a model involving Registered Nurses with advanced knowledge and experience in aged care, working in collaboration with General Practitioners and community service organisations, could have considerable benefits in identifying unmet needs and improving client satisfaction.  However, no client benefit was detected for quality of life outcomes, nor was a reduction in health resource utilisation found. This result from an Australian cohort is consistent with findings from many other international trials (Van Haastregt et al., 2000). It is possible that methodological issues are masking the effect of the intervention.  Are we measuring appropriate outcomes? Are we expecting long-term outcomes in short time frames? Are we applying the model appropriately across a diverse older population?  Further research to explore these questions is recommended for the future.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Aged Care</field><field name="subject">Community Aged Care</field><field name="subject">Case Management</field><field name="subject">Health Assessment</field><field name="subject">Over 75</field><field name="subject">Preventive Health</field><field name="subject">Telephone</field><field name="identifier">http://eprints.qut.edu.au/16132/</field><field name="validLink">True</field></doc><doc><field name="title">Suicide Girls: Pedagogy and Praxis in the On-Line Writing Workshop</field><field name="creator">Bolland, Craig</field><field name="description">On-line writing workshops provide educational spaces within which aspiring writers can learn their craft. In order to understand the dialogic mechanisms behind that learning, this thesis examines ways in which one workshop, the Internet Writing Workshop (IWW), functions as a Freireian culture circle. The exegesis identifies several key characteristics that defined Paulo Freire's concept of the culture circle. It compares these characteristics with the structure and practice of interaction within the IWW. It unpacks some of Freire's ideas about dialogue as a means of achieving critical consciousness, and compares them to current learning theory and the ways in which dialogue takes place within the IWW community.    The exegesis also examines some of the political axioms behind Freire's pedagogy, and examines ways in which the IWW community might be viewed as emancipatory or liberatory. I examine these areas in light of the development of a novel, Suicide Girls. The second draft of this novel was influenced and informed by my participant-observation of the IWW. This working draft of the novel is provided as a process document to demonstrate findings made in the exegesis and is annotated to reflect relevant process and development issues.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Pedagogy</field><field name="subject">Freire</field><field name="subject">Novel</field><field name="subject">Situated learning</field><field name="subject">Experiential learning</field><field name="subject">Online Learning Community</field><field name="subject">Emergent Curriculum</field><field name="subject">Problem-posing learning</field><field name="subject">Community of practice</field><field name="subject">Culture circle</field><field name="subject">Dialogic learning</field><field name="subject">Dialogue</field><field name="subject">Writing workshop</field><field name="subject">Internet workshop</field><field name="identifier">http://eprints.qut.edu.au/16133/</field><field name="validLink">True</field></doc><doc><field name="title">Maximizing the Availability of Distributed Software Services</field><field name="creator">Clutterbuck, Peter</field><field name="description">In a commercial Internet environment, the quality of service experienced by a user is critical to competitive advantage and business survivability.  The availability and response time of a distributed software service are central components of the overall quality of service provided to users.  Traditionally availability is a measure of service down time.  Traditionally availability measures the probability that the service will be live and is expressed in terms of failure occurrence and repair or recovery time.  Response time is a measure of the time taken from when the service request is made, to when service provision occurs for the user.  Deteriorating response time is also a valuable indicator to denial of service attacks which continue to pose a significant threat to service availability.  The concept of the service cluster is increasingly being deployed to improve service availability and response time.  Cluster processor replication increases service availability.  Cluster dispatching of service requests across the replicated cluster processors increases service scalability and therefore response time. This thesis commences with a review of the research and current technology in the area of distributed software service availability.  The review aims to identify any deficiencies within that area and propose critical features that mitigate those deficiencies.  The three critical features proposed are in relation to user wait time, cluster dispatching, and the trust-based filtering of service requests.  The user wait time proposal is that the availability of a distributed service should reflect both liveness probability level and probabalistic user access time of the service.  The cluster dispatching proposal is that dispatching processing overhead is a function of the number of Internet Protocol (IP) datagrams/Transport Control  Protocol (TCP) segments that are received by the dispatcher in respect of each service request.  Consequently the number of IP datagrams/TCP segments should be minimised ideally so that for each incoming service request there is one IP datagram/TCP segment.  The trust-based filtering proposal is that the level of trust in respect of each service request should be identified by the service as this is critical in mitigating distributed denial of service attacks - and therefore maximising the availability of the service    A conceptual availability model which supports the three critical features within an Internet clustered service environment is then described.  The conceptual model proposes an expanded availability definition and then describes the realization of this definition via additional capabilities positioned within the Transport layer of the Internet communication environment.  The additional capabilities of this model also facilitate the minimization of cluster dispatcher processing load and the identification by the cluster dispatcher of request trust level.  The model is then implemented within the Linux kernel.  The implementation involves the addition of several options to the existing TCP specification and also the addition of several functions to the existing Socket API.  The implementation is subsequently evaluated in a dispatcher-based clustered service environment.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Availability</field><field name="subject">denial of service</field><field name="subject">wait time</field><field name="subject">replication</field><field name="subject">cluster</field><field name="subject">distributed service</field><field name="subject">trust</field><field name="subject">authentication</field><field name="subject">redirection</field><field name="subject">dispatching</field><field name="subject">scheduling</field><field name="subject">filtering</field><field name="subject">option</field><field name="identifier">http://eprints.qut.edu.au/16134/</field><field name="validLink">True</field></doc><doc><field name="title">Investigating the relationship between consumer societal knowledge and the purchase of socially-conscious products: Testing the assumptions of the societal marketing concept</field><field name="creator">Mulcahy, Natasha</field><field name="description">Societal marketing - marketing based on socially or environmentally conscious attributes, has for many years been considered an accepted chapter of marketing theory.  However, consumer response to many socially-conscious products never met expectations - prompting marketing researchers to re-examine the assumptions underpinning the societal marketing theory. One such assumption is that, given consumer concern for environmental and social issues, there is a positive, significant relationship between consumer societal knowledge and the purchase of socially-conscious products.  However, the few studies which have examined this relationship have failed to provide consistent results, and thus the nature of the relationship remains unclear.    It is argued within this thesis that the equivocation of results may have been a methodological artefact, as investigations often used general rather than specific measures and excluded moderating variables from their theoretical models.  Adopting a mixed-method approach, this study first used qualitative interviews to identify moderating variables which may impact the relationship between the knowledge and purchase.  The identified potential moderating variables were then incorporated into quantitative, survey research which was used to examine the nature of the relationship between consumer societal knowledge and the purchase of socially-conscious products.    The study found that the relationship between the variables is both positive and significant, but weak.  The results revealed that one contextual variable, Health, moderated the relationship between knowledge and purchase.  The results also suggest the more traditional product attribute of price remains the most significant predictor of purchase - far greater than the consumers' societal knowledge.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Consumer</field><field name="subject">societal</field><field name="subject">knowledge</field><field name="subject">marketing</field><field name="subject">purchase</field><field name="subject">socially-conscious</field><field name="subject">products</field><field name="subject">green</field><field name="subject">environment</field><field name="subject">ecological</field><field name="subject">kangaroo</field><field name="identifier">http://eprints.qut.edu.au/16135/</field><field name="validLink">True</field></doc><doc><field name="title">Understanding everyday internet experiences: Applications to social marketing theory and practice</field><field name="creator">Previte, Josephine</field><field name="description">Recently Alan Andreasen (2003) argued that social marketing is in the 'growth phase' of development following four decades of research and practice. During this same time period, marketing has also witnessed new theoretical ideas and practices that have evolved from the influence of new interactive technologies such as the internet. Only limited scholarly work however has been undertaken to draw these marketing sub-disciplinary areas together. The research undertaken in this thesis bridges this gap and explores the role of the internet as means to further extend social marketing theory and practice. Three research questions informed the study. The first of these questions focused on how internet users describe their experiences of the internet as an everyday technology. The second question investigated the different profiles of internet users' opinions, attitudes and actions, and the third question examined how social marketing can be more responsive to internet user behaviour.  To address these research questions the research design used both qualitative methods of focus groups and in-depth interviews together with Q methodology to quantitatively represent the structure and form of individual users' subjective disposition towards the internet. Although Q methodology is relatively absent from marketing literature, it was a useful method for identifying types of people with similar experiences and views of the advantages and disadvantages of internet interactions and relationships. The research process in the study was operationalised using a three-study design. The first study drew on sixteen interviews and two focus groups with internet users, the second study involved Q sorting with thirty-two internet users, and the third study engaged interviews with twenty social change agents.  This study of internet users is embedded in a particular theoretical and epistemological position. Three issues are relevant. First, a social constructionist epistemology is engaged. This emphasises that technology is a social process, patterned by the condition of its creation and use, and informed by human choices and actions. Second, the research is situated across disciplinary boundaries. Marketing practitioners initially adopted a commercial, albeit simplistic, lens when considering the value of social aspects, such as virtual communities and the social networks of connection that link internet users into longer term relationships and exchanges of knowledge, emotion and shared confidences online. However, the intangible non-material resources shared between customers, organisations and other users online are of import to understanding the value of the internet for social marketing strategy. This required looking beyond the social marketing theory and research, to the literature on the sociology of technology. The third way in which this research is different epistemologically and theoretically is in its interpretive focus. Accordingly, the thesis contributes to the shift in academic focus towards critical marketing, which Hastings and Saren (2003) argue provides a more detailed critique and understanding of social marketing processes and outcomes.    The main contribution of this thesis is the development of a strategy map for online social marketing. The map is derived from findings from the three studies. Study 1 explained that the internet is a social and personal technology which has been incorporated into users' everyday lives and activities. Study 2 identified different profiles of internet user opinions, attitudes and actions and interpreted these as internet user segments described as: the Internet Communitarian, the Information Networker and the Individualised Networker. Study 3 delineated the findings from the downstream users' perspective and presented a strategy map derived from the experiences of upstream internet users. Three principles inform this strategy map. First, social marketers need to adopt customer-centric marketing. Secondly, they should apply an exchange continuum that embraces a relational perspective. Thirdly, social marketers using the internet should plan online strategies that focus on the internet as a recombinant technology that can be "remade" by individual users' needs and desires.  Several identified limitations of the study should be considered when reviewing this study. Firstly, the study's interpretive methodological focus precludes quantification and generalisablity to larger populations. Secondly, sample bias in terms of age and gender demographics was evident. Thirdly, a further limitation of the study is the nature of the technology under investigation in this thesis: the recency, and hence the salience of the findings, are mitigated by the fact that the internet is a dynamic technology. Finally, the generalised rather than particularised perspective on social issues and problems adopted in this study as a means of discussing social marketing, may also be seen as a limitation. This research is of significance to both an academic and practitioner audience. In terms of scholarly significance, the study is important theoretically and methodologically. Social marketing theory has a well established view of the customer as an operand resource. This thesis is significant as it demonstrates the need to conceptualise customers as more than simply 'targets' of social marketing campaigns. It illustrates how social change customers become operant resources who produce effects, based on their sharing behaviours, and make online contributions to behaviour-change processes that give target audiences (operand resources) a sense that they can enact the behaviour. As well, the evolving customer roles -- user, social actor, co-creator, resource -- theorised from the study findings inform a shifting exchange continuum involving 'transactions' to 'relationships'. Finally, this research is of theoretical significance in elucidating the conceptualisation of the continuous-process perspective which reveals that exchanges are not just the discrete, 'transactional' variety, but rather are long in duration and reflect an ongoing relationship-development process.  Methodologically, the study has also demonstrated the potential value of Q methodology as a means of revealing subjective experiences and perspectives, which are the foundation of social products regularly dealt with by social marketers. For social marketing practitioners the study also demonstrates the need for engaging a more holistic view of the internet and its customers to facilitate social change campaigns. This, however, does not negate the fact that there may be potential challenges and unintended consequences facing social marketers in engaging the internet.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">social marketing</field><field name="subject">internet marketing</field><field name="subject">internet technology</field><field name="subject">interpretivism</field><field name="subject">Q methodology</field><field name="identifier">http://eprints.qut.edu.au/16136/</field><field name="validLink">True</field></doc><doc><field name="title">The operational implications of service customisation level</field><field name="creator">Shuter, Melanie</field><field name="description">THE OPERATIONAL IMPLICATIONS OF SERVICE CUSTOMISATION LEVEL  Customisation offers the opportunity for organisations to capitalise on the many potential benefits to both themselves and to clients, afforded by offering a greater choice of goods and services for customers. Many organisations have implemented increased customisation with the expectation of increased demand and profitability. However a critical analysis of the operational aspects involved in customising services reveals that different levels of customisation have distinct operational needs which render the adoption of different levels of customisation more difficult than is indicated in existing literature. Three distinct degrees of customisation are examined in this study. These are standardisation, medium customisation and high customisation. The study puts forward a comprehensive model which provides an insight into the organisational factors which potentially enable or impede an organisation in introducing different levels of customisation. This model builds on previous studies of factors which impact on the ability of an organisation to deliver customised services. Factors which are included in this model are: (a) the level and type of knowledge, skills and abilities (KSA's) held by employees involved in designing and delivering services (b) the degree of information distribution and exchange between employees and (c) goal clarity for staff involved in delivering the service. Initial case studies conducted in six organisations and a subsequent quantitative study which elicited 101 responses from 21 organisations, revealed that each level of customisation held a distinct configuration of these operational factors. Organisations offering high customisation were characterised by a low degree of information distribution and exchange between employees, a high level of KSA's about the service being provided and low goal clarity for service staff.  Organisations offering medium customisation were characterised by a high degree of information distribution and exchange between employees, a moderate level of KSA's about the service being provided and relatively high goal clarity for staff. Organisations offering standardised services were characterised by a low degree of information distribution and exchange between employees, a low level of KSA's required about the service being provided and high goal clarity for staff.    By examining the relationship between customisation and the identified operational implications, the study allows us to piece together a multi-faceted viewpoint of the same broad issue, which is answered by the overarching question 'how are organisations enabled to provide different levels of customisation'?  This study therefore provides us with a well-rounded insight as to how and why organisations can effectively implement different levels of service customisation.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Customisation</field><field name="subject">information distribution</field><field name="subject">collaboration</field><field name="subject">services</field><field name="subject">professional services</field><field name="subject">job design</field><field name="identifier">http://eprints.qut.edu.au/16137/</field><field name="validLink">True</field></doc><doc><field name="title">Investigation of the Nutritional Requirements of Australian Snapper Pagrus Auratus (Bloch &amp; Schneider, 1801)</field><field name="creator">Booth, Mark Anthony</field><field name="description">This thesis describes research designed to increase our knowledge of the nutritional requirements of Australian snapper Pagrus auratus and provide information on the potential of Australian feed ingredients to reduce the level of fishmeal in diets for this species. The apparent digestibility of organic matter (OM), crude protein (CP), crude fat (CF) and gross energy (GE) from selected animal, cereal or oilseed meals incorporated at different inclusion levels was determined. Snapper were extremely efficient at digesting the CP, CF and GE from fishmeal and rendered animal meals (range 80-100%) with the exception of meat meal, where CP and GE digestibility were lower (62-65%). The CP from oilseeds was better digested (87-91%) than OM (57%) or GE (64-67%). Digestibility of nutrients and GE from animal meals and fish oil was not influenced by inclusion level. The CP from extruded wheat was highly digestible (100-105%), but, the OM, CF and GE digestibility of extruded wheat declined as inclusion levels increased.  The interactive effects of inclusion level (150, 250, 350 or 450 g kg-1) and fish size (110 vs 375 g snapper) on the apparent digestibility of OM and GE from gelatinised wheat starch were investigated. The OM and GE digestibility of gelatinised wheat starch was high (89%) at low inclusion levels, but declined significantly in both fish sizes as the level of starch increased. There was no interaction between inclusion level and size of fish and the decline in GE digestibility could be predicted by the regression; GEADC = 104.97(&#177;3.39) - 0.109(&#177;0.010) x inclusion level (R2=0.86). Larger fish were more capable of digesting the GE from gelatinised starch than smaller fish.  Regardless of fish size, short and longer-term changes in the physiology of snapper fed or injected with carbohydrates were recorded. Liver and tissue glycogen concentrations and the hepatosomatic index (HSI) of snapper fed gelatinised starch were significantly elevated. The plasma glucose concentrations of fish injected intra-peritoneally with D-glucose increased from resting levels (0.4-4.6 mM) to 18.9 mM approximately 3 hours after injection and fish displayed a hyperglycaemic response for nearly 18 hours. In contrast, the post-prandial response to the uptake of glucose from normally digested gelatinised starch was more regulated.  A dose-response study to determine the effects of digestible energy (DE) content (15, 18 or 21 MJ kg-1) on the digestible protein (DP) requirements of juvenile snapper was assessed using a four parameter mathematical model for physiological responses (4-SKM). DP content of test diets ranged from 210 to 560 g kg-1. Weight gain and protein deposition was strongly dependent on the ratio of DP:DE. According to the fitted models, diets for snapper weighing between 30-90 g and reared at temperatures ranging from 20-25&#186;C should contain a minimum of 28 g DP MJ DE-1 to promote optimal weight gain and protein deposition.  The effect of varying the absolute content of DP and DE on the weight gain and performance of snapper (100-300 g) fed diets formulated with an optimal ratio of DP:DE was investigated. In addition, non-protein sources of DE were varied by adjusting the ratio of fish oil to gelatinised wheat starch in order to determine if different ratios of these ingredients affected performance. High-energy diets (22-23 MJ DE kg-1) suppressed feed intake, but provided DP intake was not limited by feed intake, maximum weight gain was approached. Lower-energy, lower-protien diets (15-18 MJ DE &amp; 315-390 DP) encouraged higher feed intake but DP intake was restricted, which reduced growth potential. Snapper performed best on high-energy, high-protein diets (490 DP &amp; 21 MJ DE), provided a significant proportion of DE was supplied as DP. Fish oil and pregelatinised wheat starch could be interchanged according to their DE values without unduly affecting fish performance in diets providing 390-490 g DP kg-1.  Two utilisation studies were undertaken to investigate the performance of snapper fed diets containing increasing levels of poultry offal meal, meat meal and soybean meal. All diets were formulated with similar DP and DE contents. Snapper readily accepted feeds containing high levels of poultry meal (360 g kg-1), meat meal (345 g kg-1) or soybean meal (420 g kg-1), before weight gain and performance was negatively affected. In combination, these feed ingredients were able to replace all but 160 g fishmeal kg-1 in commercially extruded test feeds for this species.  The research described in this thesis has extended knowledge of the nutritional requirements of Australian snapper by providing important information on the digestibility of Australian feed ingredients. These coefficients have been integral in formulating both experimental and semi-commercial test diets for snapper and will increase both the accuracy and flexibility of commercial diet formulations for this species. High performance feeds for snapper will contain high levels of DP, but must provide a significant proportion of DE in the form of protein. These constraints can be satisfied by using alternative, well-digested protein and energy sources that have the potential to replace all but 160 g kg-1 fishmeal.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Australian Snapper</field><field name="subject">Pagrus Auratus</field><field name="subject">nutritional requirements</field><field name="subject">fishmeal</field><field name="subject">diets</field><field name="identifier">http://eprints.qut.edu.au/16138/</field><field name="validLink">True</field></doc><doc><field name="title">The Indefinitive Self : Subject as Process in Visual Art</field><field name="creator">Pedersen, Courtney Brook</field><field name="description">THE INDEFINITIVE SELF:
 
 subject as process in visual art
 
 
 
 This doctoral study is comprised of both creative work and accompanying critical study and exegesis, each comprising 50 per cent of the total weight of submission. The body of research develops a feminist genealogical methodology to explore the study&#8217;s central idea: that envisioning the feminine subject as process rather than a fixed entity enables political agency without recourse to rigid essentialism.
 
 
 
 The creative work, a public space installation in South Brisbane Cemetery at Dutton Park, is titled Last Drinks Gentlemen Please and traces the life and character of my great, great aunt Cecilia Mary Tennant (1875-1938). Documentation and discussion of this work is included in the exegesis and can also be viewed online at the web address http://www.GMTplus10.info/.
 
 
 
 The thesis presents a critical contextualisation analysing the work of the artists Tracey Moffatt, Mona Hatoum and Pipilotti Rist, as well as my own practice, and identifies key strategies enabling the representation of identity as process. Finally, this study proposes the figure of the Aunt as an elective relationship that enables both intimacy and agency beyond patriarchal constructions of the feminine.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Indefinitive Self</field><field name="subject">Visual Art</field><field name="subject">subject as process</field><field name="subject">feminist</field><field name="subject">Tracey Moffatt</field><field name="subject">Mona Hatoum</field><field name="subject">Pipilotti Rist</field><field name="identifier">http://eprints.qut.edu.au/16139/</field><field name="validLink">True</field></doc><doc><field name="title">Urban floodplain land-use - acceptable risk? : A case study of flood risk perception on the Guragunbah (Carrara-Merrimac) floodplain, Gold Coast</field><field name="creator">Godber, Allison Maree</field><field name="description">In Australia, the developments of hazard-specific legislation, policy and guidelines aims to minimise community exposure to the adverse effects of natural hazards. This occurs under policies of ecologically sustainable development land-use planning processes, which must also now involve the assessment of hazard-risk. However the development occurring in potentially hazardous environments, for example urban floodplains susceptible to flooding, continues to occur as a result of contemporary land-use planning and risk management processes. Why is this an outcome of past and present risk management and land-use planning processes? This thesis finds that a significant factor contributing to this outcome is the discrepancy between the perception and management of risk, particularly acceptable risk, by stakeholders (Local Government, the development industry, risk managers and floodplain occupants).  The research is based on an Australian example of an urban floodplain currently under considerable development pressure, but at risk from flooding &#8211; Guragunbah (Carrara Merrimac Floodplain) and surrounding suburbs within the Nerang River catchment on the Gold Coast.  A case study methodology was adopted, involving a combination of survey data and secondary documents.
 
 A basis for the thesis was the modelling of the actual risk decision-making processes operating within the case study Local Government, and the comparison between actual observed process and the theoretical framework outlined by the existing hazard risk management and land-use planning policy, guidelines and legislation. This enabled the identification of key stakeholders and their roles within the risk management and land-use planning processes operating within the case study area.
 
 The scope of the results of this thesis indicate that a large proportion of stakeholders external to the Local Government (such as residents and some members of the development industry) do not understand the risks of flooding represented by the standards formally adopted by local government (1-in-100 year flood, for example) and as a result, misinterpret their levels of flood risk exposure. Importantly, the results also indicate that contrasts exist in the flood risks considered to be &#8216;acceptable&#8217; by the stakeholders, particularly when the potential consequences associated with events are described or illustrated in &#8216;non-technical&#8217; terms. The extent to which the formal standards are misinterpreted suggests that many stakeholders may potentially be exposed to risks greater than they consider to be &#8216;acceptable&#8217;, but they are assuming that the Local Government (in particular) is setting risk standards that are acceptable to them. 
 
 The thesis questions the true &#8216;acceptability&#8217; of the formal standards being adopted through floodplain management policy at the Local, State and Federal levels of Government and identifies management opportunities and constraints in addressing the issue.  Obstacles to management change include resource availability, lack of political will and stakeholder consultation.  Opportunities for management change include modifying: the approach adopted by Local Governments when constructing planning schemes; the existing planning standards and decisions associated with permissible individual land-use; the mitigation of existing flood risks and exposure; and the communication of flood risk information.  In the &#8216;real-world&#8217; Local Government context, as illustrated by this case study, the issue may be practically addressed by modifying the standards and processes followed to establish acceptable risk.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Acceptable risk</field><field name="subject">hazard perception</field><field name="subject">floodplain management</field><field name="subject">land-use planning</field><field name="identifier">http://eprints.qut.edu.au/16140/</field><field name="validLink">True</field></doc><doc><field name="title">Writing to Reach You: The Consumer Music Press and Music Journalism in the UK and Australia</field><field name="creator">Brennan, Marc Andrew</field><field name="description">The music press and music journalism are rarely subjected to substantial academic investigation. Analysis of journalism often focuses on the production of news across various platforms to understand the nature of politics and public debate in the contemporary era. But it is not possible, nor is it necessary, to analyse all emerging forms of journalism in the same way for they usually serve quite different purposes. Music journalism, for example, offers consumer guidance based on the creation and maintenance of a relationship between reader and writer. By focusing on the changing aspects of this relationship, an analysis of music journalism gives us an understanding of the changing nature of media production, media texts and media readerships.    Music journalism is dialogue. It is a dialogue produced within particular critical frameworks that speak to different readers of the music press in different ways. These frameworks are continually evolving and reflect the broader social trajectory in which music journalism operates. Importantly, the evolving nature of music journalism reveals much about the changing consumption of popular music. Different types of consumers respond to different types of guidance that employ a variety of critical approaches. This thesis, therefore, argues that the production of music journalism is one that is influenced by the practices of consumption.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Journalism</field><field name="subject">Performance</field><field name="subject">Readerships</field><field name="subject">Music</field><field name="subject">Consumers</field><field name="subject">Frameworks</field><field name="subject">Publishing</field><field name="subject">Dialogue</field><field name="subject">Genre</field><field name="subject">Branding Consumption</field><field name="subject">Production</field><field name="subject">Internet</field><field name="subject">Customisation</field><field name="subject">Personalisation</field><field name="subject">Fragmentation</field><field name="identifier">http://eprints.qut.edu.au/16141/</field><field name="validLink">True</field></doc><doc><field name="title">Novel Methods for Primality Testing and Factoring</field><field name="creator">Hammad, Yousef Bani</field><field name="description">From the time of the Greeks, primality testing and factoring have fascinated mathematicians,  and for centuries following the Greeks primality testing and factorization  were pursued by enthusiasts and professional mathematicians for their intrisic  value. There was little practical application. One example application was to determine  whether or not the Fermat numbers, that is, numbers of the form F;, = 2'" + 1  were prime. Fermat conjectured that for all n they were prime. For n = 1,2,3,4, the  Fermat numbers are prime, but Euler showed that F; was not prime and to date no F,,  n 2 5 has been found to be prime. Thus, for nearly 2000 years primality testing and  factorization was largely pure mathematics.  This all changed in the mid 1970's with the advent of public key cryptography.  Large prime numbers are used in generating keys in many public key cryptosystems  and the security of many of these cryptosystems depends on the difficulty of factoring  numbers with large prime factors. Thus, the race was on to develop new algorithms  to determine the primality or otherwise of a given large integer and to determine the  factors of given large integers. The development of such algorithms continues today.  This thesis develops both of these themes. The first part of this thesis deals with  primality testing and after a brief introduction to primality testing a new probabilistic  primality algorithm, ALI, is introduced. It is analysed in detail and compared to Fermat  and Miller-Rabin primality tests. It is shown that the ALI algorithm is more efficient  than the Miller-Rabin algorithm in some aspects.  The second part of the thesis deals with factoring and after looking closely at various  types of algorithms a new algorithm, RAK, is presented. It is analysed in detail and  compared with Fermat factorization. The RAK algorithm is shown to be significantly  more efficient than the Fermat factoring algorithm.  A number of enhancements is made to the basic RAK algorithm in order to improve  its performance. The RAK algorithm with its enhancements is known as IMPROVEDRAK.    In conjunction with this work on factorization an improvement to Shor's factoring  algorithm is presented. For many integers Shor's algorithm uses a quantum computer  multiple times to factor a composite number into its prime factors. It is shown that  Shor's alorithm can be modified in a way such that the use of a quantum computer is  required just once.  The common thread throughout this thesis is the application of factoring and primality  testing techniques to integer types which commonly occur in public key cryptosystems.  Thus, this thesis contributes not only in the area of pure mathematics but  also in the very contemporary area of cryptology.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">probabilistic primality test</field><field name="subject">Fermat's test</field><field name="subject">Miller-Rabin</field><field name="subject">Carmichael number</field><field name="subject">ALI primality test</field><field name="subject">composite integer factorization</field><field name="subject">Fermat factoring algorithm</field><field name="subject">RAK factoring algorithm</field><field name="subject">MPROVEDRAK</field><field name="subject">Shor's factoring algorithm</field><field name="subject">public key</field><field name="identifier">http://eprints.qut.edu.au/16142/</field><field name="validLink">True</field></doc><doc><field name="title">Acts of Translation: Young People, American Teen Dramas, and Australian Television 1992-2004</field><field name="creator">Green, Joshua Benjamin</field><field name="description">The thesis examines American teen dramas on Australian television in the period 1992 to 2004.  It explores the use of the genre by broadcasters and its uptake by teenagers in an environment where American popular culture has frequently been treated with suspicion and where there are perennial arguments about the Americanisation of youth and their vulnerability to cultural imperialism.  The thesis argues concerns about Americanisation and cultural imperialism in relation to youth culture, young people and the media are misplaced.  American teen dramas are investigated as an example of the ways imported programs are made to cohere with national logics within the Australian mediasphere (Hartley, 1996).  Utilising Yuri Lotman's (1990) theory of cultural 'translation' this thesis argues teen drams are evidence of dynamic change within the system of television and that this change does not result in a system dominated by imported product, but rather a system that situates foreign programming amongst domestic frames of reference.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Teen Dramas</field><field name="subject">Dawson&#146;s Creek</field><field name="subject">Heartbreak High</field><field name="subject">American Television Programs</field><field name="subject">Television Scheduling</field><field name="subject">Youth</field><field name="subject">Australian Television Broadcasting</field><field name="subject">Network Ten</field><field name="subject">Yuri Lotman</field><field name="subject">Translation</field><field name="subject">Semiosphere</field><field name="subject">Televisuality</field><field name="subject">Narrative Transparency</field><field name="identifier">http://eprints.qut.edu.au/16143/</field><field name="validLink">True</field></doc><doc><field name="title">Older Pedestrians in Brisbane Suburban Settings: Two Case Studies to Investigate the Concept of a "Safe and Attractive" Pedestrian Environment</field><field name="creator">Bopp, Jennifer</field><field name="description">Older Australians walk for many reasons: health, recreation and transport. However, road safety statistics show that pedestrians over 65 represent one-third of Australia's pedestrian deaths. As Australia's population ages in place and older people take up a walking regime for health and transportation reasons, they need a supportive suburban setting. Urban design theories discuss such "pedestrian-friendly" concepts as sense of place, sense of community, responsive environments, traditional neighbourhood design, transit-oriented development, and crime prevention through environmental design. To investigate these concepts in relation to older pedestrians, this study brings together two areas of literature - research into older pedestrians in relation to urban design theories.    Qualitative research methods were used in two case studies, to reveal how older people's interpretation of their local walking environment relates to urban design theories concerning walkable suburbs. The two Brisbane suburbs of Bulimba and Forest Lake were chosen for study, as they have different histories, topographies, street patterns, and other variations. Analysis of key themes gathered from two focus group discussions, one from each suburb, revealed the significance for participants of social interaction when walking for health. A photographic exercise performed by the Forest Lake focus group provided pictorial information for analysis, and revealed participants' interest in the lake's fauna and flora, and in its ongoing maintenance. The study was limited by an unforeseen failure to obtain the cooperation of the Bulimba group in the photographic exercise.    In support of the claims made in the literature review, it seems that when older pedestrians walk through suburban streets, they avoid steep hills, busy roads, and intersections where possible, and require footpaths with even surfaces and shelters. When walking for health reasons, participants in this study did not favour local streets, but preferred "natural" places designed exclusively for walkers. Forest Lake participants stated a preference for driving to places they deemed suitable for walking, which suggests a need for more detailed design attention to the urban design qualities of local streets, so that those older people without cars are not disadvantaged.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Road safety and older pedestrians</field><field name="subject">Urban design theories and older pedestrians</field><field name="subject">Sense of place and community</field><field name="subject">Master planned communities</field><field name="subject">Walkability</field><field name="subject">Walking for health</field><field name="subject">transport</field><field name="subject">and recreation</field><field name="subject">Older people and car-dependency</field><field name="subject">Pedestrian-friendly safe suburbs</field><field name="identifier">http://eprints.qut.edu.au/16144/</field><field name="validLink">True</field></doc><doc><field name="title">An Application of Sequence Stratigraphy in Modelling Oil Yield Distribution: The Stuart Oil Shale Deposit, Queensland, Australia</field><field name="creator">Pope, Graham John</field><field name="description">The Stuart Oil Shale Deposit is a major oil shale resource located near Gladstone on the central Queensland coast.  It contains an estimated 3.0 billion barrels of oil in place in 5.6 billion tonnes of shale.  Commissioning of a plant capable of producing 4,500 barrels per day has recently commenced.  The shale is preserved in Tertiary age sediments of The Narrows Beds in the southern part of The Narrows Graben.  The oil shale sequence consists of repetitive cycles composed of oil shale, claystone and lesser carbonaceous oil shale in the 400 metre thick Rundle Formation.  The formation is the main oil-shale bearing unit in the preserved half-graben sequence up to 1,000 metres thick.    Previous studies on the lacustrine sedimentology of the Rundle Oil Shale Deposit in the northern part of The Narrows Graben have recognised eight facies that exhibit unique and recognisable cycles.  The cycles and sequence for the Kerosene Creek Member of the Rundle Formation is correlatable between the Rundle and Stuart deposits. The nature of these facies and the cycles is reviewed in some detail.  In conjunction with the principles of sequence stratigraphy, the ideal oil shale cycle is described as the equivalent of a parasequence within a lacustrine system.  The lacustrine parasequence is bounded by lacustrine flooding surfaces. The organic material in the oil shale consists of both Type I (algal dominated) and Type III (higher plant matter dominated) kerogen.  Where Type I kerogen dominate, oil yields greater than about 100 litres per tonne are common.  In contrast where Type III kerogens are dominant, yields above 100 litres per tonne are rare.  The variation in oil yield is described for the Stuart lacustrine system.  The variation is consequent on the balance between production, preservation and degradation of the kerogen in the parasequences within systems tracts.  A system for the recognition of oil shale deposition in terms of lacustrine systems tracts is established based on oil yield assay parameters and the assay oil specific gravity.    The oil yield and oil specific gravity variation within the Rundle Formation is modelled by member and the nature and distribution of oil yield quality parameters in terms of the contribution of organic and inorganic source material are described. The presence of significant oil yield (greater than 50 litres per tonne) is dependent on the dominance of lacustrine transitional systems tracts and to a lesser extent, lacustrine highstand systems tracts within the parasequence sets deposited in a balanced lake system in a generally warm wet climate during the middle to late Tertiary.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">sequence stratigraphy</field><field name="subject">oil shale</field><field name="subject">oil yield</field><field name="subject">kerogen</field><field name="subject">Fischer Assay</field><field name="subject">computer modelling</field><field name="subject">lacustrine</field><field name="subject">lacustrine parasequence</field><field name="subject">Stuart Oil Shale Deposit</field><field name="subject">The Narrows Graben</field><field name="subject">Rundle Formation</field><field name="subject">Tertiary</field><field name="subject">Australia.</field><field name="identifier">http://eprints.qut.edu.au/16145/</field><field name="validLink">True</field></doc><doc><field name="title">The Cystine Binding Protein (BspA) of Lactobacillus fermentum BR11</field><field name="creator">Hung, Jacky</field><field name="description">BspA was first identified on the basis of being the major constituent of 5 M LiCl washes of whole Lactobacillus fermentum BR11 cells.  The bspA gene is encoded within a putative ATP-binding cassette (ABC) transport operon, and sequence analysis revealed that it is a member of the family III solute binding proteins.  Unlike the majority of solute binding proteins from Gram-positive bacteria, BspA is not tethered to a lipid anchor in the cell membrane, and hence is not a lipoprotein. Extraction of BspA with concentrated salt solutions such as 5 M LiCl is consistent with the notion that electrostatic interactions are responsible for securing it to the L. fermentum BR11 cell.    L. fermentum PNG201 is a BspA negative mutant strain created by disrupting bspA.  This strain was shown to be incapable of cystine uptake.  Thus, the genetic and biochemical evidence strongly suggests BspA is a cystine binding protein of an ABC transporter.  Measurement of the binding affinity between BspA and L-cystine has confirmed high affinity binding (dissociation constant is 0.2 &#181;M), and high specificity (over 100-fold excess of non-target amino acids did not disrupt BspA / L-cystine binding).  In addition, collagen did not appear to affect BspA/cystine binding, indicating extracellular matrix (ECM) binding capacity noted by other researchers may be unrelated to amino acid binding.    An interesting phenotypic characteristic of L. fermentum PNG201 is its apparent increased sensitivity to oxygen and the superoxide-generating chemical - paraquat compared to the parent L. fermentum BR11 strain.  Catalase supplemented aerobic cultures of L. fermentum BR11, and L. fermentum PNG201 were protected from oxidative stress, suggesting hydrogen peroxide is responsible for the observed oxidative stress.  It was found that addition of cystine to aerobic cultures of L. fermentum BR11 or L. fermentum PNG201 protected both strains from oxidative stress, with L. fermentum BR11 able to utilize smaller concentrations of cystine compared to L. fermentum PNG201.  Detection of hydrogen peroxide in aerobic cultures of L. fermentum BR11 and L. fermentum PNG201 confirmed the production of hydrogen peroxide is responsible for causing oxidative stress.  The BspA mutant strain L. fermentum PNG201 consistently produced more hydrogen peroxide per optical density compared with the wild type, indicating it overproduced hydrogen peroxide.  When 0.4 mM hydrogen peroxide has been accumulated by growing cell cultures, both L. fermentum BR11 and L. fermentum PNG201 enters stationary phase, suggesting both strains have a similar sensitivity to hydrogen peroxide.  Small epitopes from the HIV gp41 protein and the Chlamydia psittaci major outer membrane protein have been successfully displayed on the cell surface of L. fermentum BR11 as fusion proteins to the BspA molecule.  However, the capability of BspA in exporting larger polypeptides has not been tested.  In this study, the large extracellular enzyme - glucosyltransferase (GtfJ) from Streptococcus salivarius ATCC 25975 was fused to BspA to demonstrate that this expression system is capable of exporting large functional enzymes to the cell surface of L. fermentum BR11.  The native GtfJ is 160kDa in size and also contained an export signal, which was deleted in the cloning process and replaced with BspA, resulting in a fusion protein of 175kDa.  Export of the BspA/GtfJ fusion protein is dependant entirely on BspA's export signal.  Recombinant enzyme expression and glucosyltransferase activity were detected by measuring the glucan formed by sonicated cell extracts in acrylamide gels.  Enzyme activity measurements on whole cells has revealed the recombinant Lactobacillus was incorporating 20-40 nmol of sucrose-derived-glucose into glucan per ml of cell culture per OD unit, which is comparable to activity levels exhibited by the native bacteria that expressed this enzyme.  Comparison of GtfJ enzyme activity between whole cells and sonicated cell extracts of recombinant L. fermentum confirmed the extracellular location of BspA/GtfJ as enzyme activity was essentially identical.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Lactobacillus</field><field name="subject">ABC uptake system</field><field name="subject">cystine</field><field name="subject">affinity constant</field><field name="subject">oxidative stress</field><field name="subject">hydrogen sulfide</field><field name="subject">fusion protein</field><field name="subject">glucosyltransferase.</field><field name="identifier">http://eprints.qut.edu.au/16146/</field><field name="validLink">True</field></doc><doc><field name="title">Breaking the Fifth Wall: Enquiry into Contemporary Shadow Theatre</field><field name="creator">Kent, Lynne</field><field name="description">Practising Shadow Theatre in the West today means to subvert the predominantly negative view of shadow in the Western psyche, to transcend the faintly racist notion of shadow theatre as the quaint practice of traditional people of the East and to contend with the dominant influences of the electronic media on this once powerful and popular art form. This research is through creative practice in the form of the production, Cactus. This performance investigates the use of the screen in contemporary Shadow Theatre and the optimisation of the live theatrical experience. The performance also seeks to integrate mediatized and non-mediatized performance through the combination of live performance and projected images.    My research is a social constructivist process to creative practice as research using a pluralistic approach including elements of action research and autobiography. The literature included for review in this study includes work by Brook, Grotowski, Auslander, Sontag, and Schechner. The literature analysis and previous training with Italian company, Teatro Gioco Vita, served to inform the application of my theories as praxis. The central question of this research project is: How can I break the fifth wall (which is the screen) in shadow theatre performance?  Subsidiary questions are:  How can we harness the advantages of both mediatized and non-mediatized performance to produce a contemporary shadow theatre form catering to the needs of a twenty-first century audience?  How can I optimize the live theatrical experience?  What is contemporary Shadow Theatre?</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Shadow Theatre</field><field name="subject">puppetry</field><field name="subject">electronic media</field><field name="subject">screen</field><field name="subject">performance</field><field name="subject">live performance</field><field name="subject">cinema</field><field name="subject">lighting technology</field><field name="subject">mediatized and non-mediatized performance</field><field name="subject">performance as research</field><field name="subject">creative practice</field><field name="subject">Western genre</field><field name="identifier">http://eprints.qut.edu.au/16147/</field><field name="validLink">True</field></doc><doc><field name="title">Model Sensitivity, Performance and Evaluation Techniques for The Air Pollution Model in Southeast Queensland</field><field name="creator">Leishman, Natalie</field><field name="description">One important component for successful air quality modelling is the utilisation of a reliable meteorological simulator. Evaluating the model with respect to its overall performance in predicting natural processes is no easy task.  The problem is twofold, firstly there is the availability and suitability of field data with which to compare a model with and secondly there is the method of evaluation.  The Air Pollution Model (TAPM), developed by the CSIRO was used to simulate the winds in Southeast Queensland (SEQ). The complex nature of the airshed makes it difficult to compare modelled data with observational data as the observational data may be influenced by local phenomena. Evaluation of the model through the use of standard statistics and monthly and seasonal statistics illustrated that overall the model predicted the annual average wind speeds and temperatures well. Through the use of synoptic clustering, more detail on model performance was gained and it was found that TAPM predicted sea breezes that occurred on high pollution days. The sensitivity of the model to the selection of input parameters such as soil type, land use, vegetation, and rain processes was also investigated.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Meteorology</field><field name="subject">TAPM</field><field name="subject">statistics</field><field name="subject">synoptic cluster type</field><field name="subject">modelling</field><field name="subject">performance</field><field name="subject">wind speed</field><field name="subject">wind direction</field><field name="subject">temperature</field><field name="identifier">http://eprints.qut.edu.au/16148/</field><field name="validLink">True</field></doc><doc><field name="title">Quantitative MRI and Micro-CT of Bone Architecture: Applications and Limitations in Orthopaedics</field><field name="creator">Hopper, Timothy Andrew John</field><field name="description">The aim of this thesis was to investigate some methods for quantitative analysis of bone structure, particularly techniques which might ultimately be applied post-operatively following orthopaedic reconstruction operations. Initially it was decided to explore the efficacy of MRI in quantifying the bone structure at high resolution by comparing high resolution MRI against 'gold standards' such as Scanning Electron Microscopy (SEM) and optical histology. This basic study provided a measure of the distortions in the morphological bone parameters derived from MR images due to susceptibility artefacts and partial volume effects. The study of bone architecture was then extended to a model of advanced renal osteodystrophy in a growing rat. For this study, high-resolution micro computed tomography (microCT) was used and as a result of the high resolution images obtained, three new bone morphological parameters were introduced to characterise the bone structure. The desire to study bone architecture post-operatively in hip replacements led to a preliminary study on ex-vivo sheep acetabulae following total hip replacement, to determine the extent that the bone architecture could be investigated around the acetabulum. The motivation for studying the acetabulum was based on the high occurrence of debonding at the bone / prosthesis interface. This study demonstrated the superior nature of 3D MRI over conventional x-ray radiographs in early quantitation of fibrous membranes located between the host bone and the non-metallic implant and/or the bone cement. The presence of such fibrous membranes is strongly indicative of failure of the prosthesis. When using clinical MRI to image post-operative hip replacement, the image quality is severely affected by the presence of the metallic implant. The head of the prosthesis is shaped like a metal sphere and is located in the acetabular cup. This problem was investigated by performing simulations of MR images in the presence of the field perturbation induced by the presence of a metal sphere, with the effects of slice excitation and frequency encoding incorporated into the simulations. The simulations were compared with experimental data obtained by imaging a phantom comprising a stainless steel ball bearing immersed in agarose gel. The simulations were used to predict the effects of changing imaging parameters that influence artefact size and also to show how current metal artefact reduction techniques such as view angle tilting (VAT) work and to identify their limitations. It was shown that 2D SE and VAT imaging techniques should not be used when metallic prosthesis are present due to extreme slice distortion, whereas 3D MRI provided a method that has no slice distortion, although the effects of using a frequency encoding gradient still remain.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">MRI</field><field name="subject">microCT</field><field name="subject">orthopaedics</field><field name="subject">trabecular bone</field><field name="subject">cortical bone</field><field name="subject">architecture</field><field name="subject">morphological parameters</field><field name="subject">intra-and inter- trabecular porosity</field><field name="subject">view angle tilting</field><field name="subject">metal artefact</field><field name="subject">orthopaedic implants</field><field name="subject">slice distortion</field><field name="subject">magnetic susceptibilities</field><field name="subject">field inhomogeneity</field><field name="identifier">http://eprints.qut.edu.au/16149/</field><field name="validLink">True</field></doc><doc><field name="title">The relationship between market value and book value for five selected Japanese firms</field><field name="creator">Omura, Teruyo</field><field name="description">Studies of the value relevance of accounting number in capital market research are consistent with the simple view that, in equilibrium, book values are equal to or have some long-term relationship with market values, and that market returns are related to book returns. This dissertation examines the value relevance of annually-reported book values of net assets, earnings and dividends to the year-end market values of five Japanese firms between 1950 and 2004 (a period of 54 years). Econometric techniques are used to develop dynamic models of the relationship between markets, book values and a number of macro-economic variables. In constructing the models, the focus is to provide an accurate statistical description of the underlying relationships between market and book value. It is expected that such research will add to the body of knowledge on factors that are influential to Japanese stock prices.    The significant findings of the study are as follows: 1) well-specified models of the data generating process for market value based on the information set used to derive the models are log-linear in form. Additive, linear models in untransformed variables are not well-specified and forecast badly out of sample; 2) the book value of net assets has relevance for market value in the five Japanese firms examined, in the long run.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Error Correction Models</field><field name="subject">Equilibrium Correction Models</field><field name="subject">Market to Book Relationship</field><field name="subject">Time Series</field><field name="subject">Japanese Firms</field><field name="identifier">http://eprints.qut.edu.au/16150/</field><field name="validLink">True</field></doc><doc><field name="title">Ukulele Mekulele : Balancing Sole Authorship and Devised Approaches to Performance Making</field><field name="creator">Megarrity, David</field><field name="description">The creation of the performance work UKULELE MEKULELE is used as a site to uncover the interactions between the work of the sole author and group-devised processes. The increasing acceptance of the 'openness' in contemporary theatre practice has strong implications for the role of the sole author, who traditionally has been the provider of the 'closed' - known quantities that are subsequently 'realised' by a production. How can the sole author best write for the seemingly contradictory environment of the group-devised production?  Critical incidents from the performance are selected for study. These 'moments that work' and their provenance are utilized as examples of the interaction of the various forces at play in the performance making process.  The researcher's intimate contact with the artwork entails a unique vantage point from which to observe these forces at work. Their evocation and analysis will have relevance for the creators of live art in collaborative contexts.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Playwriting</field><field name="subject">Group devising</field><field name="subject">Collaboration</field><field name="subject">Sole authorship</field><field name="subject">Performance making</field><field name="identifier">http://eprints.qut.edu.au/16151/</field><field name="validLink">True</field></doc><doc><field name="title">Primary School educators' beliefs about suspension and exclusion of students with challenging behaviours</field><field name="creator">Howard, Judith</field><field name="description">A growing international research base is suggesting that there can be no more serious sanction taken against children of primary school age than to withdraw their rights to attend school through suspension and exclusion - referred to in Queensland as School Disciplinary Absence (SDA). The short and long-term detrimental consequences of SDA to student recipients, their families, and social structures are well documented. Yet, SDA remains as a controversial, often policy-supported means to manage challenging student behaviour increasingly used by Queensland government schools. To contribute to this growing research, this project examines the potential influence of an array of principals' and teachers' beliefs on their decisions regarding the use of SDA within five government primary schools in Queensland. The study adopts a multi-method, case-study approach and is informed by social constructionist and critical theory perspectives. It draws from Rokeach's (1968) conceptualisation of the human belief system as having a number of sections where particular stated beliefs may be influenced by more powerful beliefs situated within another part of the system, which may (in turn) influence decisions and actions. Data were drawn from school documents, surveys, and interviews. Survey data revealed strong support for the use of SDA but interview data suggested that most participants believed that SDA was ineffective and held overriding concerns for the wellbeing and education of students exhibiting challenging behaviours.  In some cases, particular beliefs were shown to override this unfavourable view of SDA and cause educators to become more likely to endorse its implementation. The study examines the complex construction of a variety of educator beliefs regarding SDA in general, the types of students who are more at risk of SDA, school and educator responsibility for supporting these students, and factors believed to prevent or make it difficult to avoid the use of SDA.  Also, participants' concerns and recommendations regarding SDA are examined and implications for professional practice and school reform are considered.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Primary school</field><field name="subject">educators</field><field name="subject">suspension</field><field name="subject">exclusion</field><field name="subject">student behaviour</field><field name="subject">Queensland</field><field name="subject">School Disciplinary Absence (SDA)</field><field name="subject">Milton Rokeach</field><field name="identifier">http://eprints.qut.edu.au/16152/</field><field name="validLink">True</field></doc><doc><field name="title">Antecedents of firm export performance: the role of export promotion programs</field><field name="creator">Shamsuddoha, A. K.</field><field name="description">This study empirically investigates the direct and indirect effects of export promotion programs (EPPs) on firm export performance. Government export promotion programs normally define the premise for successful exporting activities of the corporate sector and play a key role in stimulating international business activities of firms (Cavusgil and Michael, 1990; Marandu, 1995; Seringhaus and Rosson, 1990). While the extant literature on export performance mostly neglected EPPs as an antecedent of export performance, the literature on export promotion fails to relate it to export performance. A very few researchers in this area have focused on a direct relationship between EPPs and firm export performance, however, no study has investigated the effect of EPPs on other determinants of export performance toward establishing any indirect relation between EPPs and export performance. This study attempts to develop and test a comprehensive model of firm export performance that investigates how EPPs directly and indirectly influence firm export performance.    Theoretical foundations are drawn from internationalization process and resource-based theories as frameworks for the analysis of the study. The model integrates the use of EPPs, management perception of export market environment, export knowledge, export commitment, and export strategy that influence firm export performance and develops a number of hypotheses. Export promotion programs are classified into two categories according to their similarity of purpose- "market development", and "finance and guarantee" related programs. All other variables in the model are latent and are measured by a set of observed items. The model is tested on primary data obtained from a sample survey of exporting firms drawn from three major export oriented industries in Bangladesh. Structural Equation Modeling (SEM) techniques (in AMOS 5) are used to test the validity of the overall model and the relationship between variables hypothesized in the model. A two stage process is employed whereby the construct measurements are first evaluated, followed by an evaluation of the structural relationships.  Analysis of the structural relationships supports most of the hypothesized relationships. The dimensions of export promotion programs are found to positively impact overall export performance. The research findings demonstrate that the use of market development-related export promotion programs influence firm export performance directly as well as indirectly through management perception of the export market environment, export knowledge and commitment. However, finance and guarantee-related export promotion programs indirectly influence export performance through export commitment. The study provides a guideline for managers of firms suggesting how they can benefit from EPPs in improving their positive attitude towards the export market environment, building their knowledge and enhancing commitment to exporting for better success in their international operations. This study provides guidelines to policymakers in designing and targeting export promotion programs effectively. The study also contributes to the literature by examining the indirect impact of EPPs on firm export performance. Finally, the limitations of the study are considered and possible directions for further research outlined.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Antecedents of export performance</field><field name="subject">Impact of Export promotion programs</field><field name="subject">Export Assistance Programs</field><field name="subject">Developing country</field><field name="subject">Bangladesh.</field><field name="identifier">http://eprints.qut.edu.au/16153/</field><field name="validLink">True</field></doc><doc><field name="title">The Delivery of Multimedia Programmes Through LMS: An Australian Approach</field><field name="creator">Seah, Kenneth</field><field name="description">Australia's tertiary educational environment is changing; in the past decade, it has faced a new set of challenges and pressures (Cunningham et al., 1998) that are encroaching on the traditional definitions of what higher education is.    These challenges often dictate the directions in which the tertiary education environment evolves into.  Within the framework of institutional reforms, the adopted policies are often the best indicators of that transition.    Flexible delivery or learning has been espoused as a means of meeting and mediating some of those challenges.  With their emphasis on catering to the needs and expectations of the consumer in a consumerist society, flexible policies are becoming the norm in most institutes of higher learning.  However, of interest within the structure of the flexible delivery approach is the development of learner management systems (LMS).    The question is what are learner management systems? What do they represent and what do they offer to the learner that differentiates it from the traditional forms of learning?  In its basic form, a learner management system is essentially a series of processes that are developed and organised so as to efficiently provide the learner with the required access and interaction required to facilitate his or her learning.   However, what are the benefits of being aware of the capabilities and limitations afforded by such approaches?  How does it contribute to the process of teaching and learning in the context of higher education?    The effectiveness of how these learner management systems are used in context to its application in multimedia programmes is of importance.  Institutions are progressively introducing similar learning systems into their delivery framework.  The question as to whether a singular adaptive system or a customised option remains to be tested.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">LMS</field><field name="subject">Learning Management Systems</field><field name="subject">Australian</field><field name="subject">tertiary education</field><field name="subject">higher education</field><field name="subject">institutional reforms</field><field name="subject">policies</field><field name="subject">learning systems</field><field name="subject">delivery framework.</field><field name="identifier">http://eprints.qut.edu.au/16154/</field><field name="validLink">True</field></doc><doc><field name="title">Adolescent Peer Counselling</field><field name="creator">Geldard, Kathryn Mary</field><field name="description">Adolescent peer counselling as a social support strategy to assist adolescents to cope with stress in their peer group provides the focus for the present thesis. The prosocial behaviour of providing emotional and psychological support through the use of helping conversations by young people is examined. Current programs for training adolescent peer counsellors have failed to discover what skills adolescents bring to the helping conversation.  They ignore, actively discourage, and censor, some typical adolescent conversational helping behaviours and idiosyncratic communication processes. Current programs for training adolescent peer counsellors rely on teaching microcounselling skills from adult counselling models. When using this approach, the adolescent peer helper training literature reports skill implementation, role attribution and status differences as being problematic for trained adolescent peer counsellors (Carr, 1984; de Rosenroll, 1988; Morey &amp; Miller, 1993). For example Carr (1984) recognised that once core counselling skills have been reasonably mastered that young people " may feel awkward, mechanical or phoney" (p. 11) when trying to implement the new skills. Problematic issues with regard to role attribution and status differences appear to relate to the term 'peer counsellor' and its professional expectations, including training and duties (Anderson, 1976; Jacobs, Masson &amp; Vass, 1976; Myrick, 1976).  A particular concern of Peavy (1977) was that for too many people counselling was an acceptable label for advice giving and that the role of counsellor could imply professional status. De Rosenroll (1988) cautioned against creating miniature mirror images of counselling and therapeutic professionals in young people. However, he described a process whereby status difference is implied when a group of adolescent peer counsellors is trained and invited to participate in activities that require appropriate ethical guidelines including competencies, training, confidentiality and supervision. While Carr and Saunders (1981) suggest, "student resentment of the peer counsellor is not a problem" they go on to say, "this is not to say that the problem does not exist" (p. 21). The authors suggest that as a concern the problem can be minimised by making sure the peer counsellors are not 'forced' on the student body and by providing opportunities for peer counsellors to develop ways of managing resentment. De Rosenroll (1988) acknowledges that the adolescent peer counsellor relationship may fall within a paraprofessional framework in that a difference in status may be inferred from the differing life experiences of the peer counsellor when compared with their student peers. The current project aimed to discover whether the issues of skill implementation, role attribution and status differences could be addressed so that adolescent peer counselling, a valuable social support resource, could be made more attractive to, and useful for adolescents.  The researcher's goal was to discover what young people typically do when they help each other conversationally, what they want to learn that would enhance their conversational helping behaviour, and how they experience and respond to their role as peer counsellor, and then to use the information obtained in the development of an adolescent-friendly peer counsellor training program.  By doing this, the expectation was that the problematic issues cited in the literature could be addressed. Guided by an ethnographic framework the project also examined the influence of an adolescent-friendly peer counsellor training program on the non-peer counsellor students in the wider adolescent community of the high school.  Three sequential studies were undertaken. In Study 1, the typical adolescent conversational and communications skills that young people use when helping each other were identified. In addition, those microcounselling skills that young people found useful and compatible with their typical communication processes were identified.  In Study 2, an intervention research process was used to develop, deliver, and evaluate an adolescent-friendly peer counsellor training program which combined typical adolescent helping behaviours with preferred counselling microskills selected by participants in Study 1. The intervention research paradigm was selected as the most appropriate methodology for this study because it is designed to provide an integrated perspective for understanding, developing, and examining the feasibility and effectiveness of innovative human services interventions (Bailey-Dempsey &amp; Reid, 1996; Rothman &amp; Thomas, 1994). Intervention research is typically conducted in a field setting in which researchers and practitioners work together to design and assess interventions.  When applying intervention research methodology researchers and practitioners begin by selecting the problem they want to remedy, reviewing the literature, identifying criteria for appropriate and effective intervention, integrating the information into plans for the intervention and then testing the intervention to reveal the intervention's strengths and flaws. Researchers then suggest modifications to make the intervention more effective, and satisfying for participants.  In the final stage of intervention research, researchers disseminate information about the intervention and make available manuals and other training materials developed along the way (Comer, Meier, &amp; Galinsky, 2004).  In Study 2 an adolescent-friendly peer counsellor training manual was developed. Study 3 evaluated the impact of the peer counsellor training longitudinally on the wider school community. In particular, the project was interested in whether exposure to trained peer counsellors influenced students who were not peer counsellors with regard to their perceptions of self-concept, the degree of use of specific coping strategies and on their perceptions of the school climate. Study three included the development of A School Climate Survey which focused on the psychosocial aspects of school climate from the student's perspective. Two factors which were significantly correlated (p&lt;.01) were identified. Factor 1 measured students' perceptions of student relationships, and Factor 2 measured students' perceptions of teachers' relationships with students.  The present project provides confirmation of a number of findings that other studies have identified regarding the idiosyncratic nature of adolescent communication, and the conversational and relational behaviours of young people (Chan, 2001; Noller, Feeney, &amp; Peterson, 2001; Papini &amp; Farmer, 1990; Rafaelli &amp; Duckett, 1989; Readdick &amp; Mullis, 1997; Rotenberg, 1995; Turkstra, 2001; Worcel et al., 1999; Young et al., 1999). It extends this research by identifying the specific conversational characteristics that young people use in helping conversations.  The project confirmed the researcher's expectation that some counselling microskills currently used in training adolescent peer counsellors are not easy to use by adolescents and are considered by adolescents to be unhelpful. It also confirmed that some typical adolescent conversational helping behaviours which have been proscribed for use in other adolescent peer counsellor training programs are useful in adolescent peer counselling. The project conclusively demonstrated that the adolescent-friendly peer counsellor training program developed in the project overcame the difficulties of skill implementation identified in the adolescent peer counselling literature (Carr, 1984). The project identified for the first time the process used by adolescent peer counsellors to deal with issues related to role attribution and status difference.  The current project contributes new information to the peer counselling literature through the discovery of important differences between early adolescent and late adolescent peer counsellors with regard to acquiring and mastering counselling skills, and their response to role attribution and status difference issues among their peers following counsellor training. As a result of the substantive findings the current project makes a significant contribution to social support theory and prosocial theory and to the adolescent peer counselling literature. It extends the range of prosocial behaviours addressed in published research by specifically examining the conversational helping behaviour of adolescents from a relational perspective. The current project provides new information that contributes to knowledge of social support in the form of conversational behaviour among adolescents identifying the interactive, collaborative, reciprocal and idiosyncratic nature of helping conversations in adolescents. Tindall (1989) suggests that peer counsellor trainers explore a variety of ways to approach a single training model that can augment and supplement the training process to meet specific group needs. The current project responded to this suggestion by investigating which counselling skills and behaviours adolescent peer counsellor trainees preferred, were easy to use by them, and were familiar to them, and then by using an intervention research process, devised a training program which incorporated these skills and behaviours into a typical adolescent helping conversation.  A mixed method longitudinal design was used in an ecologically valid setting. The longitudinal nature of the design enabled statements about the process of the peer counsellors' experience to be made.  The project combined qualitative and quantitative methods of data gathering. Qualitative data reflects the phenomenological experience of the adolescent peer counsellor and the researcher and quantitative data provides an additional platform from which to view the findings. The intervention research paradigm provided a developmental research method that is appropriate for practice research. The intervention research model is more flexible than conventional experimental designs, capitalises on the availability of small samples, accommodates the dynamism and variation in practice conditions and diverse populations, and explicitly values the insights of the researcher as a practitioner. The project combines intervention research with involvement of the researcher in the project thus enabling the researcher to view and report the findings through her own professional and practice lens.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Adolescents</field><field name="subject">Communication</field><field name="subject">Conversation</field><field name="subject">Coping</field><field name="subject">Coping resources</field><field name="subject">Coping strategies</field><field name="subject">Counselling microskills</field><field name="subject">Counsellor training</field><field name="subject">Developmental stage differences</field><field name="subject">Emotional competence</field><field name="subject">Help seeking</field><field name="subject">Helping conversations</field><field name="subject">Intervention research</field><field name="subject">Peer counselling</field><field name="subject">Peer counsellor training</field><field name="subject">Prosocial behaviour</field><field name="subject">Resilience</field><field name="subject">Role attribution</field><field name="subject">School climate</field><field name="subject">Self-concept</field><field name="subject">Skill implementation</field><field name="subject">Social support</field><field name="subject">Status differences</field><field name="subject">Stress</field><field name="identifier">http://eprints.qut.edu.au/16155/</field><field name="validLink">True</field></doc><doc><field name="title">Secure Electronic Voting with Flexible Ballot Structure</field><field name="creator">Aditya, Riza</field><field name="description">Voting is a fundamental decision making instrument in any consensus-based society.  It is employed in various applications from student body elections, reality television shows, shareholder meetings, to national elections. With the motivation of better eciency, scalability, speed, and lower cost, voting is currently shifting from paper-based to the use of electronic medium. This is while aiming to achieve better security, such that voting result reflects true opinions of the  voters.    Our research focuses on the study of cryptographic voting protocols accommodating  a flexible ballot structure as a foundation for building a secure electronic voting system with acceptable voting results. In particular, we search for a solution suitable for the preferential voting system employed in the Australian Federal Election.    The outcomes of the research include: improvements and applications of batch  proof and verication theorems and techniques, a proposed alternative homomorphic  encryption based voting scheme, a proposed Extended Binary Mixing Gate (EBMG) mix-network scheme, a new threshold randomisation technique to achieve receipt-freeness property in voting, and the application of cryptographic  voting protocol for preferential voting.    The threats and corresponding requirements for a secure secret-ballot voting scheme are rst discussed. There are significant security concerns about the conduct of electronic voting, and it is essential that the voting results re  ect the true opinions of the voters - especially in political elections.    We examine and extend batch processing proofs and verifications theorems and proposed applications of the theorems useful for voting. Many instances of similar operations can be processed in a single instance using a batch technique based on one of the batch theorems. As the proofs and verications provide formal  assurances that the voting process is secure, batch processing offers great efficiency improvements while retaining the security required in a real-world implementation  of the protocol.    The two main approaches in cryptographic voting protocols, homomorphic encryption based voting and mix-network based voting, are both studied in this research. An alternative homomorphic voting scheme using multiplicative homomorphism  property, and a number of novel mix-network schemes are proposed. It is shown that compared to the mix-network approach, homomorphic encryption schemes are not scalable for straight-forward adaptation of preferential systems.    One important requirement of secret-ballot voting is receipt-freeness. A randomisation  technique to achieve receipt-freeness in voting is examined and applied in an ecient and practical voting scheme employing an optimistic mix-network. A more general technique using threshold randomisation is also proposed.    Combination of the primitives, both the homomorphic encryption and mixnetwork  approach, yields a hybrid approach producing a secure and ecient  secret-ballot voting scheme accommodating a exible ballot structure. The resulting  solution oers a promising foundation for secure and practical secret-ballot  electronic voting accommodating any type of counting system.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Secure Electronic Voting</field><field name="subject">Cryptographic Voting Protocols</field><field name="subject">Secret-ballot Voting Scheme</field><field name="subject">Receipt-free Voting</field><field name="subject">Australian Federal Election</field><field name="subject">Preferential Systems</field><field name="subject">Batch Theorems</field><field name="subject">Batch Zero-knowledge Proofs and Verifications</field><field name="subject">Efficient Voting Protocols</field><field name="subject">Homomorphic Encryption</field><field name="subject">Mix-network</field><field name="subject">Hybrid Scheme.</field><field name="identifier">http://eprints.qut.edu.au/16156/</field><field name="validLink">True</field></doc><doc><field name="title">Young Vietnamese Children's Conceptions of Play</field><field name="creator">Vujanovic, Suzan</field><field name="description">Children benefit in many ways from play.  Play provides children with an excellent way to express their feelings and conceptions of the world in which they live.  Play also provides a forum in which researchers can capture, understand and interpret children's voices and views.  Like many countries around the world, Vietnam is currently reforming their early childhood education curriculum to provide a play-based, child centred and outcomes focused approach to early childhood education.  In order to capture children's interest and promote child initiated and directed learning, educators and policy makers need to consider how children interpret their personal play lives.  This study presents data from children's programs in nine kindergartens and cultural programs in Hanoi and Ho Chi Minh City.  Children's drawings and stories were collected to document young children's conceptions of play in Vietnam at the turn of the millennium.  Through these 353 drawings and stories, key themes in the children's play lives were identified.    The purpose of this study is to examine children's views about play.  What do they like to play?  How do they define play?  How are young Vietnam's children's conceptions of their play influenced by cultural attitudes and expectations?  In addition, the study proposes some new play-based, child centred and outcomes focused approaches to curriculum development for Vietnamese early childhood programs.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Vietnam</field><field name="subject">Play</field><field name="subject">Phenomenography</field><field name="subject">Children&#146;s views</field><field name="subject">Children&#146;s stories</field><field name="subject">Children&#146;s art</field><field name="identifier">http://eprints.qut.edu.au/16157/</field><field name="validLink">True</field></doc><doc><field name="title">Visual, Aspect-Oriented Tools for Component Pascal in Eclipse</field><field name="creator">Singh, Abhishek</field><field name="description">Tools and environments have aided developers in producing software since compilers and  editors became standard offerings with operating systems. A major challenge for the tools  and environments community has been to find ways to build and integrate tools so that  they, or capabilities between them, can be easily adapted for use in new contexts.    The "Eclipse" Project is an open source software development project dedicated to providing a robust, full-featured, commercial-quality, industry platform for the development of highly integrated tools. The mission of the "Eclipse" Project is to adapt and evolve the eclipse technology to meet the needs of the eclipse tool building community and its users, so that the vision of eclipse as an industry platform is realized. "Eclipse" uses an innovative  plug-in architecture allowing near-infinite extensions to the base IDE. Unlike other opensource projects that don't allow proprietary derivative works, "Eclipse" can be extended with proprietary plug-ins, repackaged, and sold commercially.    Aspect-Oriented programming (AOP) is a new programming paradigm based on the idea  that computer systems are better programmed by separately specifying the various concerns of a system and some description of their relationships, and then relying on mechanisms in the underlying AOP environment to weave or compose them together into a coherent program. While the tendency in Object-Oriented Programming is to find commonality among classes and push it up in the inheritance tree, AOP attempts to realize scattered concerns as first-class elements, and eject them horizontally from the object structure. The primary goals of this research were 1. Incorporation of "Component Pascal" into "Eclipse". "Component Pascal"was a command line compiler that is targeted to a variety of platforms including JVM and.NET.  2. Research and design visual programming tools for "Component Pascal" in "Eclipse", in  particular visual tools that support aspect-oriented views of software.  These objectives are now complete and a plug-in has been developed that enables the  development of "Component Pascal" software within "Eclipse". Aspect-Orientation has  been incorporated directly into the "Component Pascal" compiler.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Visual</field><field name="subject">aspect-oriented</field><field name="subject">component</field><field name="subject">pascal</field><field name="subject">eclipse</field><field name="identifier">http://eprints.qut.edu.au/16158/</field><field name="validLink">True</field></doc><doc><field name="title">Satire and Self-help: The Satirical Potential of the Self-help Industry</field><field name="creator">Carpenter, Felicity</field><field name="description">This thesis combines a play, Getting Betterer all the Time, a satire about self-help, and an  exegesis examining the possibilities that self-help offers for satire and why. The self-help  industry has evolved into a massive social and economical phenomenon. The scope of  self-help is constantly expanding, indicating a society of individuals desperate for help in  all facets of life. As this movement has become more prevalent, self-help has attracted  criticism for the way it thrives on the exploitation of people's insecurities. By playing to  people's aspirations, many self-help practitioners have become wealthy, but there is a  danger that some self-help products can have a harmful effect on people, and at best give  rise to an insufferable hubris.  Consequently, we have witnessed a rise in popular texts that spoof the self-help  industry. The excesses of the self-help industry make it an easy target for satire. Self-help  is well matched to satire's function to provide social commentary by ridicule of targets  causing harm to the well-being of society. Self-help is an appropriate subject for satire  because of its focus on social behavior such as modern parenting, consumerism and status  anxiety. Self-help, in addition to providing these opportunities for social commentary,  also offers much comedic potential.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">self-help</field><field name="subject">satire</field><field name="subject">comedy</field><field name="subject">play script</field><field name="identifier">http://eprints.qut.edu.au/16159/</field><field name="validLink">True</field></doc><doc><field name="title">Evaluating the Impact of the School Environment on Teachers' Health and Job Commitment: Is the Health Promoting School a Healthier Workplace?</field><field name="creator">Lemerle, Kate Anne</field><field name="description">Despite having been endorsed by the World Health Organisation (WHO) almost a decade ago, and its widespread adoption as a model of "best practice" for school health promotion throughout the world, the Health Promoting Schools framework has not been subjected to widespread evaluation in a way that fully recognises its core tenets. Most evaluations have focused on individual targeted interventions addressing students' health behaviours, or implementation issues such as school health policies or access to services. No evaluations of this approach could be found which investigated the impact of the HPS model on teachers, as a critical factor influencing the school climate, or on organisational processes associated with employee wellbeing within the school setting. There is a vast literature pertaining to conditions of the work environment that affect employee health, including work-related stress. Teaching is considered a highly stressful occupation, and as social pressure continues to place teachers and schools in the role of "in loco parentis" for the socialisation of children, it seems timely to identify those characteristics of the school environment that promote positive health and wellbeing for all. In theory, the HPS model provides a set of principles and procedures that aim to promote health and wellbeing for all members of the school community, yet the impact on school staff has yet to be demonstrated.  This thesis reports on research investigating the extent to which adoption of the HPS approach creates a positive work environment for teachers, through enhanced organisational and social capital, and whether selected work environment variables impact on teachers' physical and mental wellbeing, health risk behaviours, job stress, and job commitment. After conducting a statewide audit of health promotion activities in Queensland primary schools, two samples of schools that differed significantly in the extent to which they were implementing organisational strategies consistent with the HPS approach were selected, one sample of 20 schools actively implementing HPS strategies, and a comparison sample of 19 schools not implementing the approach. Schools were matched on geographic location (rural/urban), school size (number of student enrolments), and socio-economic rank (IRSED). A cross-sectional design using a mail-out survey to 1,280 teachers was conducted, and statistical comparisons of the two groups were conducted. Apart from providing the samples of schools for the main research, the statewide audit provided a profile of health promotion activity in Queensland primary schools. Urban, rather than rural schools, and those with higher student enrolments, were most frequently implementing HPS strategies. Socio-economic ranking did not have any statistical bearing on adoption of these strategies. Implementation of school health policies was the most common strategy, although the social and physical environments were also addressed to some extent.  The instrument designed for the study, the HPS Audit Checklist, proved effective in distinguishing a continuum of HPS "total scores" and demonstrated good psychometric properties.  With respect to differences in measures of the school environment, mean scores for all 11 dimensions of school organisational health, and all 4 dimensions of school social capital, were statistically higher in High HPS, although differences between the two groups were not outstanding.  Trends in the results did, however, confirm that schools actively adopting a HPS approach provide a more positive work environment than non-health promoting schools. Effect size was most significant for School Morale, Decision Authority, and Co-worker Support. Both organisational and occupational commitment was higher for teachers in High HPS, and Turnover Intention (plans to leave the workforce/workplace) was lower for teachers in High HPS.  Teachers in High HPS reported less job strain and higher skill discretion, despite slightly greater job demands (work pressure) in these schools. They also reported significantly less general psychological distress on 5 measures, and significantly better self-rated mental and physical health. Job strain was most strongly associated with co-worker support, appreciation, and school morale in High HPS, but in Low HPS strain was most strongly associated with leadership style, school morale, and role clarity, suggesting more subtle differences between the two sets of schools. No statistically significant differences were found between teachers in High and Low HPS on self-reported weight, daily dietary habits, dental check-ups, preventive health screenings, alcohol consumption, smoking, cholesterol, BP and exercise. Although this research was limited by its dependence on self-report measures, the high response rate suggests that the results provide a valid profile of the health and psychological wellbeing of teachers in Health Promoting Schools in Queensland. These results also suggest that the HPS approach creates a more positive school environment through building social and organisational capital, and this is reflected in better mental health and stronger job commitment of the teaching workforce. Implications of these results for human resource management within the education sector are discussed. In addition, the implications of a healthier "learning environment", including less stressed and more connected teaching staff, for children's psychosocial and educational outcomes are considered in light of potential future directions for this research.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Health Promoting Schools</field><field name="subject">School environment</field><field name="subject">Teachers&#146; health</field><field name="subject">Job stress</field><field name="subject">Job commitment</field><field name="subject">Organisational health</field><field name="subject">Social capital</field><field name="identifier">http://eprints.qut.edu.au/16160/</field><field name="validLink">True</field></doc><doc><field name="title">Overruling the Underclass? Homelessness and the Law in Queensland</field><field name="creator">Walsh, Tamara</field><field name="description">The impact of the law on the lives of homeless people in Queensland has, to date, remained largely unexplored by legal academics and researchers. This is despite the fact that homeless people experience a number of legal difficulties that seriously affect their lives. This thesis by published papers aims to make a significant and original contribution to filling this gap in the research evidence by presenting the results of analyses of the legal, theoretical and practical issues that arise in the context of homeless persons' interactions with the legal system in Queensland. Most notably, it is comprised of three pieces of empirical research which identify those areas of law that impact most on homeless people in Queensland and explore the consequences of the operation of these laws on their lives. In sum, this thesis examines the extent of the law's influence on the lives of homeless people in Queensland, and finds that the consequences of the law's operation on homeless people in Queensland are serious.    The thesis first examines the effect on Queensland's homeless people of laws which regulate behaviour conducted in public space. The criminal offences of vagrancy, begging and public nuisance are analysed; their historical origins, the reasons for their retention on modern statute books, and arguments in favour of their repeal are discussed. The impact of 'public space law' on homeless people in Queensland is also explored through a survey of 30 homeless people residing in inner-city Brisbane. This part of the thesis concludes that public space law in Queensland results in breaches of homeless persons' human rights, as well as the contravention of rule of law principles.    The thesis then explores the impact of the law on homeless persons' experiences of citizenship. Empirical research and theoretical analysis demonstrate that the application of various laws, particularly public space laws, social security laws and electoral laws, encroaches on homeless persons' citizenship rights. The thesis then reports on the results of a unique survey of Queensland's homelessness service providers. This survey is the most extensive piece of empirical research ever conducted on the extent to which various laws impact on homeless people. Respondents were asked to indicate which areas of law impact most adversely on their homeless clients. Based on the research findings outlined above, the hypothesis was that criminal law issues, particularly public space offences, would be proven to impact particularly adversely on homeless people in Queensland. Somewhat unexpectedly, the findings of the survey indicated that fines law, debt law and family law difficulties are those legal difficulties most often encountered by homeless people in Queensland. Difficulties produced by criminal laws, social security laws and electoral laws, while still generally relevant, rated less highly. However, the survey did demonstrate that experiences differ between sub-groups within the homeless population, for example Indigenous homeless people were reported to be most affected by criminal law issues, while young homeless people were reported to be most affected by social security law issues.    Together, the five papers which comprise this thesis make an original and substantial contribution to knowledge by identifying empirically for the first time the various laws that have a significant impact on the lives of homeless people in Queensland, and analysing the consequences of this in terms of their effect on homeless persons' citizenship rights, human rights and rule of law entitlements.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Homelessness and the law</field><field name="subject">public space law</field><field name="subject">social security law</field><field name="subject">constitutional law</field><field name="subject">electoral law</field><field name="subject">citizenship</field><field name="subject">human rights</field><field name="subject">rule of law</field><field name="subject">vagrancy</field><field name="subject">begging</field><field name="subject">offensive language and offensive behaviour</field><field name="subject">public nuisance</field><field name="subject">social security breach penalties</field><field name="subject">fines</field><field name="subject">voting</field><field name="subject">political communication</field><field name="subject">T.H. Marshall&#146;s citizenship theory</field><field name="subject">right to equality before the law</field><field name="subject">right to freedom from arbitrary arrest</field><field name="subject">right to freedom from discrimination</field><field name="identifier">http://eprints.qut.edu.au/16161/</field><field name="validLink">True</field></doc><doc><field name="title">Public Education for Disaster Management: A Phenomenographic Investigation</field><field name="creator">Nielsen, Samuel William</field><field name="description">Many recent developments in education theory and the field of disaster management have left the meaning of public education as applied in the disaster management field fraught with uncertainty. This thesis addresses this uncertainty via a phenomenographic research study that sheds light on the meaning of public education, despite such uncertainty, by revealing a discrete number of qualitatively different ways in which disaster managers and disaster educators experience and understand public education. Transcriptions of interviews of 25 such senior Australian disaster managers and educators were analysed using phenomenographic methods and revealed a set of discrete, parsimonious and qualitatively different ways of experiencing public education. The referential component of the different ways of experiencing was revealed within ten emergent categories of description for public education: (i) a non-effective process; (ii) a way of managing a public issue; (iii) promoting an issue; (iv) issuing expert instructions; (v) changing individuals; (vi) strategic teaching and training; (vii) collaborative partnerships; (viii) empowering learners to make informed decisions; (ix) negotiation; and (x) element in societal learning. The structural component of the emergent ways of experiencing public education was presented in the form of a phenomenographic outcome space. Linkages between these findings about public education and current literature were made. The results suggested multiple ways to improve public education within the disaster management community and more widely. The need for clarity in communication amongst educators and professionals in regard to public education was confirmed by the research findings. Insights into phenomenography and education were included within the discussion.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Phenomenography; phenomenon; public education; community education; disaster; hazard; disaster management; risk; interpretive; experience; understanding</field><field name="identifier">http://eprints.qut.edu.au/16162/</field><field name="validLink">True</field></doc><doc><field name="title">Quality Assurance for in VIVO MR Spectroscopy and the Effects of a Gadolinium contrast Agent on  Metabolite Peak Amplitude Ratios</field><field name="creator">Bennett, Damon Dmitry</field><field name="description">Magnetic Resonance Spectroscopy (MRS) for the evaluation of in vivo cerebral metabolite ratios is a relatively new radiological modality, which permits the detection and evaluation of specific metabolites within the human body. As with all imaging modalities, the accuracy of the equipment to perform its given task is paramount and the effect of introduction of elements and/or contrast agents to a study, must be understood before a diagnosis or prognosis can be made with any degree of certainty.    The following chapters describe the development and testing of a phantom, the development and testing of metabolite simulating solutions and the experiments conducted to determine the spatial localisation accuracy of a MRS imaging system.    This thesis begins with a description of the steps undertaken to investigate a clinical MRS system's capacity to reliably produce spectra over both the long and short term.    Validation of the phantom construction, metabolite simulating solutions and spatial localisation accuracy is presented in detail. The construction of the localisation phantom resulted in a two compartment perspex phantom and the development of the aqueous metabolite solutions produced two solutions with distinct and separate metabolite peaks with comparable peak amplitudes and sufficient line width separation to prevent possible metabolite resonance cross contamination but without illustrating any significant susceptibility artefacts. Development of the metabolite simulating solutions was a major part of the work conducted.    Short and long term (1 year) reproducibility of the measured metabolite peak amplitudes were assessed for four different pulse sequences.  Of these, the most reproducible results were obtained with a TE 270ms PRESS sequence (coefficient of variation &lt; 0.6% (short term) and &lt; 3% (long term)).    The spatial localisation experiments illustrated a disturbing error in the placement of the user prescribed volume of interest (VOI) with respect to the actual VOI acquisition with a difference between the two volumes of interest of up to 3 mm or 15% of the VOI size in two axes. Possible effects of magnetic resonance imaging contrast agents, specifically Gd-DTPA were also investigated. Fifty patients were included in this study.  The metabolic peak amplitudes were measured pre and post-administration of the contrast agent for each subject. A paired  t-test demonstrated that there was no significant difference between the mean peak heights pre- and post- administration (0.07 &lt; p &lt; 0.9 for the various peak amplitudes measured).</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Spectroscopy</field><field name="subject">gadolinium</field><field name="subject">meabolite</field><field name="subject">VIVO</field><field name="subject">MR</field><field name="identifier">http://eprints.qut.edu.au/16163/</field><field name="validLink">True</field></doc><doc><field name="title">Bayesian Latent Variable Models for Biostatistical Applications</field><field name="creator">Ridall, Peter Gareth</field><field name="description">In this thesis we develop several kinds of latent variable models in order to address  three types of bio-statistical problem. The three problems are the treatment  effect of carcinogens on tumour development, spatial interactions between plant  species and motor unit number estimation (MUNE). The three types of data looked at are: highly heterogeneous longitudinal count data, quadrat counts of species on a rectangular lattice and lastly, electrophysiological data consisting  of measurements of compound muscle action potential (CMAP) area and amplitude.  Chapter 1 sets out the structure and the development of ideas presented  in this thesis from the point of view of: model structure, model selection, and  efficiency of estimation. Chapter 2 is an introduction to the relevant literature  that has in influenced the development of this thesis. In Chapter 3 we use the EM  algorithm for an application of an autoregressive hidden Markov model to describe  longitudinal counts. The data is collected from experiments to test the  effect of carcinogens on tumour growth in mice. Here we develop forward and  backward recursions for calculating the likelihood and for estimation. Chapter 4  is the analysis of a similar kind of data using a more sophisticated model, incorporating  random effects, but estimation this time is conducted from the Bayesian  perspective. Bayesian model selection is also explored. In Chapter 5 we move  to the two dimensional lattice and construct a model for describing the spatial  interaction of tree types. We also compare the merits of directed and undirected  graphical models for describing the hidden lattice. Chapter 6 is the application  of a Bayesian hierarchical model (MUNE), where the latent variable this time is  multivariate Gaussian and dependent on a covariate, the stimulus. Model selection  is carried out using the Bayes Information Criterion (BIC). In Chapter 7 we  approach the same problem by using the reversible jump methodology (Green,  1995) where this time we use a dual Gaussian-Binary representation of the latent  data. We conclude in Chapter 8 with suggestions for the direction of new  work. In this thesis, all of the estimation carried out on real data has only been  performed once we have been satisfied that estimation is able to retrieve the parameters  from simulated data.  Keywords: Amyotrophic lateral sclerosis (ALS), carcinogens, hidden Markov  models (HMM), latent variable models, longitudinal data analysis, motor unit  disease (MND), partially ordered Markov models (POMMs), the pseudo auto-  logistic model, reversible jump, spatial interactions.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Amyotrophic lateral sclerosis (ALS)</field><field name="subject">carcinogens</field><field name="subject">hidden Markov models (HMM)</field><field name="subject">latent variable models</field><field name="subject">longitudinal data analysis</field><field name="subject">motor unit disease (MND)</field><field name="subject">partially ordered Markov models (POMMs)</field><field name="subject">the pseudo auto-logistic model</field><field name="subject">reversible jump</field><field name="subject">spatial interactions</field><field name="identifier">http://eprints.qut.edu.au/16164/</field><field name="validLink">True</field></doc><doc><field name="title">Parent Conceptions of Their Role in Early Childhood Education and Care:  A Phenomenographic Study from Queensland, Australia</field><field name="creator">Irvine, Susan</field><field name="description">Over past decades, the face of Australian early childhood education and care (ECEC)has changed substantially. It has been shaped by two dominant policy discourses: the discourse of market theory, and, more recently, the discourse of parent and community participation. The intertwining of these two seemingly opposing  discourses has led to the positioning of parents both as consumers of ECEC and as participants in ECEC. Each of these perspectives promotes a particular way of fulfilling the role of parent in ECEC. Reflecting general marketing principles, the primary role of parent as consumer is seen as selecting the right service for their child and family. In contrast, while arguably more ambiguous in meaning, the role of  parent as participant promotes a partnership approach, and, increasingly, parental  involvement in decision making at both service and public policy levels. Each of  these roles has been constructed for parents by governments and policymakers, with  little reference to the views and experiences of parents using ECEC.    Seeking to address this gap in the ECEC knowledge base, the present study investigated the qualitatively different ways in which parents constitute their role in Australian ECEC. The study focused on two related aspects of the role of parents: (1) the role of parents in using ECEC services; and (2) the role of parents in shaping ECEC public policy. To describe these roles, as viewed and experienced by parents, and to reveal possible variation therein, the study engaged a phenomenographic  research approach (Bowden &amp; Walsh, 2000; Marton &amp; Booth, 1997).    Twenty-six parents participated in the study. Data were gathered through semistructured  interviews with individual parents and subjected to a rigorous process of phenomenographic analysis. The study results are presented in two parts. With respect to the role of parents using ECEC, the study led to the construction of five  categories of description, denoting five distinctly different ways of seeing and  experiencing this role. The role of parents was seen as: (1) selecting and using the  best service for their child (the service user conception); (2) knowing what's happening for their child in the service (the informed user conception); (3) paying for a service, and, thereby, enacting certain consumer rights (the consumer conception); (4) supporting their selected service and having some say in what happens for their child at the service (the partnership conception); and (5) working as a member of the service community for the benefit of all concerned, which includes participating in  decision making (the member of a service community conception). Taking a broader  perspective, the study again revealed variation in how parents constituted their role in  shaping ECEC policy, leading to the construction of four categories of description.  The role of parents was seen as: (1) no role in shaping ECEC public policy (the no  role conception); (2) being informed about policy that affects their child and family,  raising any concerns and/or seeking a change to current or proposed policy (the  raising concerns conception); (3) having some say in policy matters that affect their  child and family (the having some say conception); and (4) participating in policy  decision making, particularly where this is likely to affect their child and family (the  participating in policy decision making conception).    The study highlights variation in how these roles are constituted by parents, inclusive  of the basic concepts of parent as consumer and parent as participant. In addition, the  study offers an insider perspective on these two "dominant common-sense understandings" (Vincent &amp; Martin, 2000, p. 2) of the role of parents, prompting questions about their future in ECEC policy. As an example of "developmental  phenomenography" (Bowden, 2000b, p. 3), the study also identifies factors perceived  by parents as influencing their participation at various levels, and discusses implications for both policy and practice. Finally, the study extends the general phenomenographic area of interest, from education to public policy research. Within this area, phenomenography is seen to offer a useful and pragmatic research tool, facilitating the identification and consideration of different constituent views and  experiences, and, thereby, signifying more possible options for action.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Early childhood education and care (ECEC)</field><field name="subject">parents</field><field name="subject">participation</field><field name="subject">policy</field><field name="subject">Australia</field><field name="subject">phenomenography</field><field name="subject">variation</field><field name="subject">conceptions</field><field name="subject">categories of description</field><field name="subject">outcome space</field><field name="identifier">http://eprints.qut.edu.au/16165/</field><field name="validLink">True</field></doc><doc><field name="title">Integrated Approach to Characterisation of Coastal Plain Aquifers and Groundwater Flow Processes: Bells Creek Catchment, Southeast Queensland</field><field name="creator">Ezzy, Timothy Robert</field><field name="description">Low-lying coastal plains comprised of unconsolidated infill are internally complex  hydrogeological settings, due to the high level of heterogeneity in the infill material.  In order to resolve the hydrogeological processes active in these complex settings, an  integrated multi-disciplinary, geoscientific approach is required. This research  determines quantitatively, the effects of sedimentary aquifer heterogeneity on  groundwater flowpaths and groundwater processes within a heavily laterised, coastal  plain setting. The study site is the Bells Creek catchment in southeast Queensland,  Australia. The methodology developed in this study provides a new approach to  enable the determination of groundwater flowpaths and groundwater processes at  macroscale resolution within other shallow alluvial and coastal plain aquifers. The  multi-disciplinary approach utilises sedimentological, geophysical, chronological and  hydrogeological techniques (including hydrochemistry and groundwater flow  modelling) to develop a high-resolution aquifer framework, and to determine  accurately, both groundwater flowpaths and relative flow rates.  Sedimentary framework is confirmed to be the principal factor controlling the  distribution of aquifer permeability pathways in any given setting, and is therefore,  the dominant control over groundwater flow and processes. For the Bells Creek  catchment, interpretation of stratigraphic and sedimentary data allowed the  compilation of a detailed sedimentary framework. This interpretation demonstrated  that weathering of the low-lying arkose sandstone bedrock has developed thick  lateritic profiles. Within the weathering profiles, cemented, iron-rich horizons have  resisted erosion and developed raised and elongated ridges in the modern landscape,  while other clay-rich weathered layers have submitted to erosion and downgraded  around those iron-rich ridges. Consequently, alluvial deposition throughout the Late  Quaternary has been restricted to narrow, and relatively deep valleys containing sandrich  channels, and thin floodplains at shallow depth.  From a hydrogeological perspective, there is significant macroscopic aquifer  heterogeneity between fine-grained lateritic mixed clay layers, floodplain clays, ironcemented  ferricrete horizons, and permeable sand-rich alluvial aquifers. This  variability of aquifer material has created a complex subsurface arrangement of  permeability pathways. Application of Ground Penetrating Radar (GPR) in this setting enabled accurate definition of alluvial channel boundaries and the high degree  of connectedness within the channels themselves. Interpretation of a comprehensive  GPR dataset (that covered the entire catchment) allowed refinement of the  sedimentary framework previously established to develop a detailed threedimensional  aquifer framework.  Finite-difference groundwater modelling and particle tracking analysis (using  MODFLOW and MODPATH) has clearly demonstrated that the macroscopic  heterogeneity within the various aquifer materials of the plain has marked impacts on  groundwater pathways, and especially groundwater travel times. The variability  between a maximum residence time of 18 months for groundwater within the  alluvium, compared to hundreds of years for groundwater within the mixed clay  layers of the laterite, clearly demonstrates the importance of accurately defining the  spatial distribution of the various aquifer materials in a groundwater flow  investigation. In this setting, the interconnection of the narrow alluvial channels  feeding into a deeper alluvial delta has provided an effective conduit for shallow  groundwater flow. The role of the alluvial delta in discharging the bulk of fresh  groundwater from the central plain into the coastal and estuarine aquifers to the east,  is certainly critical in preventing saline intrusion from encroaching further west.  Hydrochemical and isotopic indicators have identified the dominant recharge  processes and groundwater flowpaths within the plain, and indicated that the  processes are strongly related to sub-surface permeability distributions determined in  the aquifer framework (and groundwater modelling), as well as seasonal fluctuations  in rainfall. In the northwest of the plain, sandstone hills provide a delayed and  slightly mineralized component of groundwater recharge into adjacent highly  permeable, unconfined alluvial aquifers; these aquifers also recharge directly via  precipitation. Aluminosilicate weathering in the bedrock hills and eastern peripheries  of the laterised bedrock are a source of excess Na, SiO2, and HCO3 to the alluvial  groundwater. As this groundwater flows down-gradient to the east, however, its  chemical composition evolves by sulfate reduction, silica equilibrium and ion  exchange processes into a more mature Na-Cl type.  Within the shallow coastal aquifers proximal to the eastern shoreline, sulfate  enrichment is occurring (associated with increases in Ca, HCO3, Fe and Al) resulting  in major deterioration in groundwater quality. The deterioration is produced by saline  intrusion from the adjacent estuary coupled with oxidation of sulfide materials in  shallow marine and estuarine clays. Reverses in salinity in those coastal aquifers have  been correlated with surges in fresh recharge waters from unconfined coastal dunes  and semi-confined landward alluvium, following significant rainfall events.  The multi-disciplinary methodology developed, provides an effective approach for  accurately defining the three-dimensional distribution of shallow aquifer material of  varying permeability via detailed stratigraphic interpretation and GPR analysis.  Utilising this aquifer framework, finite-difference groundwater modelling aided by  hydrogeological data and hydrochemical analysis, allows accurate determination of  groundwater flowpaths and groundwater processes. This research provides a new  hydrogeological analogue for alluvial channel aquifers within a laterised coastal plain  setting.  Key Words:  groundwater flow, aquifer heterogeneity, numerical modelling, hydrochemistry,  recharge, ground penetrating radar, coastal plain aquifers, weathering, alluvial  channels.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">groundwater flow</field><field name="subject">aquifer heterogeneity</field><field name="subject">numerical modelling</field><field name="subject">hydrochemistry</field><field name="subject">recharge</field><field name="subject">ground penetrating radar</field><field name="subject">coastal plain aquifers</field><field name="subject">weathering</field><field name="subject">alluvial channels</field><field name="identifier">http://eprints.qut.edu.au/16166/</field><field name="validLink">True</field></doc><doc><field name="title">The Nature of Educational Inclusion for Students Diagnosed Autistic Spectrum Disorder with Challenging Behaviours</field><field name="creator">Foster, Graham</field><field name="description">Increasing numbers of students with disabilities are being educated in mainstream schools in response to the international call for inclusive education. This study investigated the experiences of five students diagnosed with Autistic Spectrum Disorder (ASD) with challenging behaviours, and those who support them including parents, class and special education teachers, regarding inclusive education. At the time of the study, the five male students were all of upper primary school age, and attended state schools in Queensland, Australia. A multi-case study approach was adopted to better understand the nature of inclusion through engaging participants (students, class teacher, parents, and special education teachers) in "conversations" about their experiences of inclusion by means of semi-structured interviews. Students diagnosed ASD with challenging behaviours are testing the educational system as it attempts to meet their individual needs. This is due in part to the complexities associated with the disability of ASD and the many factors required in the delivery of effective inclusive practices. The findings of the research study reflected significant variance in the nature of inclusive schooling practices. Data collected from participants involved in a focus group interview and five case studies were used to describe the practices adopted in response to meeting the educational needs of individual students diagnosed ASD with challenging behaviours. There were five key findings that emerged from this study. Firstly, a range of practices was identified for each of the five children and these were posited along the continuum from inclusive to exclusive. Secondly, inclusive practices emerged from a number of interconnected processes including training, stakeholder collaboration, a school culture pursuing educational inclusion, and educator efficacy. Thirdly, educator efficacy appears to be the most crucial factor in the establishment of inclusive practices, without it exclusionary practices prevail. Fourthly, legislation and policy alone do not appear to result in the universal adoption of inclusive educational practices. Lastly, while all students had unique educational programming needs, this thesis found that there is a need for an appropriate model to be implemented to offer a foundation level of appropriate education interventions.  Implications for educational policy and practice relevant to inclusive education were discussed.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Autistic Spectrum</field><field name="subject">Austism</field><field name="subject">Behaviours</field><field name="subject">Inclusion</field><field name="identifier">http://eprints.qut.edu.au/16167/</field><field name="validLink">True</field></doc><doc><field name="title">Panning for gold: influencing the experience of web-based information searching</field><field name="creator">Edwards, Sylvia Lauretta</field><field name="description">Reporting the findings from a phenomenographic study of students' experiences of web-based information searching, this thesis describes how the identified four conceptions, and their structures of awareness, might influence future information literacy curriculum design and web based resources for academics, librarians, and students.  Alongside the reported study in this thesis, the first electronic outcome space is also outlined and presented. This electronic outcome space is an enhancement to ways of presenting phenomenographic study findings.    Using a phenomenographic approach, the project aimed to uncover variation in students' experiences of web-based information searching. Data gathering during 2000 - 2003 involved investigations of student diary work, video-filmed searching using a think-aloud protocol, and a series of interviews conducted over several semesters. Incorporating first year, third year, and postgraduate student perspectives, the participants, who were from the Queensland University of Technology, came from six of the eight university faculties. Different cultures, ages and genders were represented. During the interviews the students were asked to describe a recent search experience, and to describe how they learn to search for information using various web-based tools. Careful attention was paid during interviews to asking students to explain their interpretation of key concepts in the subject area. Analysis involved an iterative process of seeking meaning and structure. Amongst the group of students interviewed, four categories of explicit variation were discovered and these have been described drawing largely from the words of the participants. Two categories of implicit variation are also proposed. Each explicit category is presented in terms of referential and structural components constituted in terms of the critical dimensions of variation including focal elements, approaches to learning, and reflective practice. The possibility of implicit categories is proposed based on the findings and on the levels of IT skill amongst participants.    The study also sought to explore how this type of research into student learning can influence both the design of learning experiences and academic development resources, particularly in relation to teaching and learning information searching as part of the information literacy agenda.    Using the categories of description, which showed the variations in student's web-based information searching experiences, it is hoped that the further research outlined will enlighten attempts to design existing assessment to work more effectively, to bring about desired changes in students' experiences of information searching behaviour. The structure of awareness section of each category has revealed the elements that need to be attended to in re-designing assessment. It is hoped that in modifying assignments it will enable the simultaneous attention of students to the already identified relevant dimensions of the information searching experience.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">phenomenography</field><field name="subject">information literacy</field><field name="subject">information searching</field><field name="subject">information seeking and use</field><field name="subject">variation theory</field><field name="subject">learning and awareness</field><field name="subject">Internet</field><field name="subject">web-based information searching</field><field name="subject">phenomenographic method</field><field name="identifier">http://eprints.qut.edu.au/16168/</field><field name="validLink">True</field></doc><doc><field name="title">Elements influencing IS success in developing countries: a case study of organisations in Papua New Guinea</field><field name="creator">Kelegai, Limbie K</field><field name="description">Since the introduction of computers in to organisations in the 1950s, computer information systems have become powerful organisational instruments. The uptake of information technology including information systems (IS) and the impact of these technologies have been phenomenal, particularly in the least developed countries (LDCs). Organisations in these countries have continued to utilise IS as a development tool with the belief that it will enhance business processes, in many instances accelerated by foreign assistance. IS can have a positive effect on users, organisations and national development, measured economically or otherwise at the individual, organisational, and national levels. Yet IS implementation and the measure of its success is characterised by a high rate of failure and disagreement among scholars and practitioners.   The success of organisational IS is influenced by a fabric of many variables, including contextual elements. In this regard IS can be influenced by both the organisational context in terms of strategies, structures, politics and culture, and by the wider political socio-economic, cultural, and technological climate within which organisations exist. Understanding the contributing variables and the barriers that impede IS success, would better prepare organisations to overcome the inherent difficulties. There is a large body of work documenting the usefulness and consequences of IS. However, these studies have been concentrated in the developed countries (DCs), hence, little is known about IS implementation in LDCs. DCs and LDCs differ in their contextual and social settings, and a uniform analysis may not be applicable in their disparate settings. Indeed the paucity of research and data in the IS domain indicates that the study would benefit an LDC such as Papua New Guinea (PNG) and contribute to knowledge in understanding IS implementation in an LDC environment.    This thesis reports on a study that examined IS implementation success in PNG organisations in the context of an LDC. Computers were introduced to PNG in the 1960s, however, no studies have been undertaken to date in this domain that the author is aware of. Hence, the objective of this study was to provide detailed analysis of IS, the context in which it was implemented, its interaction with organisational and external settings, and elicit the underlying elements associated with its success. It also explores the emphasis placed on each of the elements and the extent to which organisations effectively addressed these elements to ensure IS success.                   The exploratory study employs a multi method design - beginning in Stage 1 with case studies, followed by a survey in Stage 2. Stage 1 adopted a multiple case study approach. Eight case studies were undertaken, however, results of only four case studies are reported in this thesis. Data obtained in the case studies provide a useful basis for the survey. The study in Stage 2 consolidated and expanded on the case study findings from the perspective of a wider population. All the organisations contacted but not involved in the Stage 1 study contributed by participating in the survey.  The study identified more than fifty elements that contributed to the success of IS in PNG organisations. There were significant similarities to the findings of studies in other DCs and LDCs despite the disparate contextual conditions. Several elements, not identified in prior studies, were also revealed. Based on this study, a set of principles pertaining to IS implementation and management in PNG were postulated. Similarly a set of recommendations were also outlined.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Information Systems (IS)</field><field name="subject">Information Systems Management</field><field name="subject">Information Systems Success</field><field name="subject">Information and Communication Technology (ICT)</field><field name="subject">Least Developed Countries (LDC)</field><field name="identifier">http://eprints.qut.edu.au/16169/</field><field name="validLink">True</field></doc><doc><field name="title">Lives are led: autobiographical film and the new documentary</field><field name="creator">Hookham, John Henry</field><field name="description">This thesis consists of two parts: an autobiographical documentary film and a written exegesis. The film, My Lovers Both, is a record of two journeys back to my native South Africa wherein I confront aspects of my past. These two trips offer a means to explore a personal history around the experiences of immigration, displacement and exile.    In the exegesis, I argue that autobiography is changing and rather than offering catalogues of public achievement, contemporary personal histories deal with sites of trauma and challenge dominant narratives of official memory. Likewise, the New Documentary is embracing fictional strategies and moving towards increased subjectivity and introspection. As a consequence, new forms are created that generate novel insights into causality and time.    The exegesis goes on to examine the major influences on my work as a filmmaker and then articulates a reflective analysis of the creative process which produced My Lovers Both.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">autobiographical film</field><field name="subject">documentary</field><field name="subject">South Africa</field><field name="subject">exile</field><field name="subject">immigration</field><field name="subject">autobiography</field><field name="subject">memoir</field><field name="subject">apartheid</field><field name="identifier">http://eprints.qut.edu.au/16170/</field><field name="validLink">True</field></doc><doc><field name="title">Integrated land capability for ecological sustainability of on-site sewage treatment systems</field><field name="creator">Al-Shiekh Khalil, Wael R.</field><field name="description">The research project was formulated to solve serious environmental and possible public health problems in rural and regional areas caused by the common failure of soil disposal systems used for application of effluent from on-site domestic sewage treatment systems. On-site sewage treatment systems adopt a treatment train approach with the associated soil disposal area playing a crucial role. The most common on-site sewage treatment system that is used is the conventional septic tank and subsurface effluent disposal system. The subsurface effluent disposal area is given high priority by regulatory authorities due to the significant environmental and public health impacts that can result from their failure. There is generally very poor householder maintenance of the treatment system and this is compounded by the failure of the effluent disposal area resulting in unacceptable surface and groundwater contamination. This underlies the vital importance of employing reliable science-based site suitability assessment techniques for effluent disposal. The research undertaken investigated the role of soil physico-chemical characteristics influencing the behaviour of effluent disposal areas.    The study was conducted within the Logan City Council area, Queensland State, Australia. About 50% of the Logan region is unsewered and the common type of on-site sewage treatment used is a septic tank with subsurface effluent disposal area. The work undertaken consisted of extensive field investigations, soil sampling and testing, laboratory studies and extensive data analysis.    In the field study, forty-eight sites were investigated for their effluent application suitability. The sites were evaluated based on the soil physico-chemical characteristics. The field investigation indicated that there were nine soil orders in the study area. These soil orders were Dermosols, Chromosols, Kandosols, Kurosols, Vertosols, Sodosols, Tenosols, Rudosols and Anthrosols. The soils in all the investigated sites were acidic soils in the pH range between 5 and 6.5.    The complexity of the large data matrix obtained from the  analysis was overcome by multivariate analytical methods to assist in evaluating the soils' ability to treat effluent and to understand the importance of various parameters. The analytical methods selected to serve this purpose were PROMETHEE and GAIA. The analysis indicated that the most suitable soils for effluent renovation are the Kandosols whilst the most unsatisfactory soil order was found to be Podosol. The GAIA analysis was in agreement with quantitative analysis conducted earlier.    An extensive laboratory column study lasting almost one year was undertaken to validate the results of the data analysis from the field investigation. The main objectives of this experiment were to examine the soil behaviour under practical effluent application and to investigate the long-term acceptance rate for these soils. Twelve representative soils were selected for the column experiment from the previously investigated sites and undisturbed soil cores were collected for this purpose. The results from the column study matched closely with the evaluation conducted at the earlier stages of the research. Soil physico-chemical analysis before and after effluent application indicated that the soils' acidity was improved toward neutrality after effluent application. The results indicated that soils have a greater ability to handle phosphorus than nitrogen. The most favorable cation exchange capacity for soils to treat and transmit effluent was between 15 and 40 meq/100g.    Based on the results of the column study, the long-term acceptance rate (LTAR) was determined for the investigated twelve soil types. Eleven out of twelve soils reported specific LTAR values between 0.18-0.22 cm/day. For the duration of the laboratory study, the Podosol order did not reach its LTAR value due to the extremely sandy nature of the soil. The time required to achieve LTAR varied between different soils from 40 to 330 days. The outcomes of this research was integrated into a soil suitability map for on-site sewage treatment systems for Logan City Council.  This will assist the authorities in providing sustainable solutions for on-site systems failure.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">sewage treatment systems</field><field name="subject">effluent disposal</field><field name="subject">septic tank</field><field name="subject">effluent disposal</field><field name="subject">groundwater contamination</field><field name="identifier">http://eprints.qut.edu.au/16171/</field><field name="validLink">True</field></doc><doc><field name="title">Experience design and automotive design</field><field name="creator">Gomez, Rafael</field><field name="description">This thesis centres on experience design and automotive design. The aim is to investigate the emotional experience of the driving activity. The research question driving the study is: "How can experience design influence the driving activity?" Experience design proposes to explore emotional aspects of interactions in context. A model of the human-product-environment relationship, using activity theory as its foundation, is presented. The model is used to situate the overall experience of driving.  An experiment exploring the overall emotional experience in real driving situations was conducted. Participants were required to drive around a specified route while performing particular tasks with the vehicle interface. A data triangulation approach was employed involving interviews, think-aloud protocols and observations.  Findings indicate that context together with the emotional state of the driver before driving impacts the overall emotional experience. Positive emotional states before driving with no interaction challenges in high-traffic contexts generated neutral overall experiences. However, positive emotional states before driving with interaction challenges in high-traffic contexts generated negative overall experiences. Negative emotional states before driving combined with interaction challenges in high-traffic contexts generated  positive emotional experiences. It appears that positive emotions associated with overcoming challenging interactions in high-traffic contexts reflect positively on the overall experience. Emotions elicited in low and mediumtraffic contexts did not affect the overall experience. Another finding suggests that extended visual interaction with interface in high-traffic context generates negative emotions.  It is proposed that vehicle interfaces should adapt appropriately to their surrounding context to support positive (and avoid negative) emotional experiences. In low and medium-traffic contexts interfaces may encourage interactions. In high-traffic contexts, if the driver is in a positive emotional state before driving interfaces may discourage challenging interactions. If the driver is in a negative emotional state before driving the interface may encourage challenging interactions.  In conclusion, this study proposes the application of current and upcoming technologies for future automotive interiors to enhance positive (and reduce negative) emotional experiences within the driving activity.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Experience design</field><field name="subject">automotive design</field><field name="subject">vehicle interface design</field><field name="subject">emotions</field><field name="identifier">http://eprints.qut.edu.au/16172/</field><field name="validLink">True</field></doc><doc><field name="title">The space between : representing 'youth' on the contemporary Australian stage</field><field name="creator">Jordan, Richard</field><field name="description">Young characters throughout the history of Australian theatre have traditionally been represented as tragic, transient, and dangerous; discourses which have defined and limited their construction.  'Youth' itself is a concept which has been invented and perpetuated within Western Art and Media for much of the twentieth century and beyond, creating an exclusive 'space' for young people: a space between childhood and a standard human being.  This thesis seeks to explore the implications of this space, as well as contextualise a new creative work - the stage play like, dead - within the canon of Australian theatre texts which portray young characters. like, dead will be shown to be a work which reappropriates clich&#233;d youthful discourses through the use of irony, humour, and a sense of postmodern 'performativity' among its characters.  In so doing it will demonstrate an alternative approach to representing young people on the Australian stage, by enhancing the constructedness of traditional images of 'youth' and pursuing the creation of young characters which are not solely defined by the term.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">youth culture</field><field name="subject">performance</field><field name="subject">theatre for young people</field><field name="subject">post-modern theatre</field><field name="subject">history of Australian theatre</field><field name="subject">Queensland theatre</field><field name="subject">performativity</field><field name="subject">television</field><field name="subject">creative practice as research</field><field name="identifier">http://eprints.qut.edu.au/16173/</field><field name="validLink">True</field></doc><doc><field name="title">The association between industry-level discretion and strategic variety: long-term strategic positions and current behaviours</field><field name="creator">Keegan, John Michael</field><field name="description">Executive discretion, the latitude for executives strategic decisions, is a powerful moderator of strategic decision making.  In spite of its potential contribution to strategic management studies, Hambrick and Finkelstein's (1987) socio-political model of executive discretion has received little empirical research effort.  Some of the basic propositions of the model, which incorporates industry, firm and individual characteristics as determinants of discretion have not been empirically tested.  The restricted research effort is partly attributable to the lack of quantitative measures for industry-level discretion.  This thesis initially uses the correlation between industry-level attentional homogeneity, the similarity in foci of attention of executives in an industry, and industry-level discretion to produce 116 new values for industry-level discretion for 23 U.S. 4-digit SIC coded industries for the years 1990 to1997.  Predictive validity for the new values is demonstrated using long-term debt data and annual accounts adjustment data.   Theil's (1992b) industry variety measure based on information theory is modified to produce strategic variety measures that permit pan-industry comparisons.  Strong support is demonstrated for a positive association between variety in long-term strategic positions and industry-level discretion.  Some weak evidence suggesting large firms in low discretion industries may compete using behaviours that impact on current accounts is also identified.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">industry-level discretion</field><field name="subject">strategic variety</field><field name="subject">information theory</field><field name="identifier">http://eprints.qut.edu.au/16174/</field><field name="validLink">True</field></doc><doc><field name="title">Yellow roses in Fortitude Valley</field><field name="creator">Rodda, Sally</field><field name="description">This exegesis interrogates the mental illness Pure Erotomania, the rare delusional disorder which presents with the sufferer having the delusional (and therefore unshakeable) belief that the person they objectify is in love with them. My play Yellow Roses in Fortitude Valley is about one woman's emotional journey as she is relentlessly stalked by a Pure Erotomanic male. It is a fascinating mental illness, which includes all the 'box office type' features, which make it an exciting and frightening subject to write a dramatic work about. It is confusing, illusory, surreal and frightening, but best of all for the writer and audience it is a real human condition. Yellow Roses in Fortitude Valley is written in a style that truthfully represents and portrays the journey and struggle for both the victim and the sufferer. The research undertaken for both the play and exegesis was a hybrid of many overlapping disciplines involved in the current discourse. As a recently diagnosed and recognized disorder, it is still new territory for professionals in the field and for audience members. I believe this makes it an opportune time for an academically researched creative project to enter into current discourse.  Previous creative works on this topic, some of which I have interrogated, have approached the issue of stalking as a predator/victim scenario, an unrequited love or a domestic violence situation. I wished to portray the stalking as a mental illness in the form of the psychiatric disorder Erotomania, my approach undertaking to explain victim impact and the prolonged and chronic course of Erotomanic stalking. I also wished to illustrate the underlying themes which I uncovered during my research, being; female victims of sex crimes; dominant patriarchal ideology; and the current interventions in stalking by the legal and mental health systems.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">stalking</field><field name="subject">erotomania</field><field name="subject">bi-polar disorder</field><field name="subject">sex crime</field><field name="subject">psychology</field><field name="subject">criminology</field><field name="subject">mental health system</field><field name="subject">legal system</field><field name="subject">playwright</field><field name="subject">drama in social enquiry</field><field name="subject">creative practice as research</field><field name="identifier">http://eprints.qut.edu.au/16175/</field><field name="validLink">True</field></doc><doc><field name="title">The influence of self-awareness of driving ability on on-road performance of persons with acquired brain injury</field><field name="creator">Mallon, Kerry Louise</field><field name="description">Previous research has shown that cognitive deficits arising from neurological impairment can impact on driving performance. The diverse nature of cognitive, perceptual and behavioural impairments experienced by drivers with neurological impairment and the resulting impact on driving ability has been the subject of extensive research involving the use of psychometric off-road measures, road safety statistics, actual on-road driving assessments and self-report. This research has shown that some drivers can compensate for limitations in their driving skills but this is dependent upon realistic self-appraisal of driving abilities. Few studies have investigated the role of self-awareness of driving abilities on on-road driving performance in persons with neurological impairment.  Aims:  To investigate the relationship between self-awareness of driving related abilities in neurologically impaired drivers and on-road driving performance.  Participants:  Retrospective data were collated on 79 participants who were referred for Occupational Therapy driving assessment, comprising 24 with Closed Head Injury (CHI) (mean age 24.67 + 5.57 yrs), 30 with Cerebrovascular Accident (CVA) (mean age 61.00 + 9.08 yrs) and 25 with 'Other' diagnosis (mean age 50.64 + 21.14 yrs).  All participants held a current driver's licence or learner's permit Results: Five predictor variables were significantly associated with the on-road driving assessment outcome including three demographic variables:- diagnosis (&#61539;2(2)= 7.69, p = 0.021), time since injury/illness onset (&#61539;2(2)= 6.40, p = 0.041), and mileage (&#61539;2(2)= 5.84, p = 0.05); and two self-awareness variables:-  reaction time (&#61539;2(2)= 8.04, p = 0.018), and impulse control (&#61539;2(2)= 13.47, p = 0.001). Logistic regression yielded a final best model containing two predictor variables (&#61539;2(4) = 20.81,  p = 0.000), including diagnosis (p = 0.02) and self-awareness of impulse control (p = 0.01). Discussion and Conclusion:  Participants who over-estimated their driving abilities were more likely to fail a driving assessment or require driving rehabilitation than participants who under-estimated or accurately predicted their performance and participants with a diagnosis of CVA were more likely to fail or require driving rehabilitation than those with a CHI or 'Other' diagnosis.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">neurological impairment</field><field name="subject">acquired brain injury</field><field name="subject">cerebrovascular accident</field><field name="subject">traumatic head injury</field><field name="subject">older driver</field><field name="subject">insight</field><field name="subject">self-awareness</field><field name="subject">cognition</field><field name="subject">rehabilitation</field><field name="subject">models of driving</field><field name="subject">driving assessment</field><field name="subject">driving simulator</field><field name="identifier">http://eprints.qut.edu.au/16176/</field><field name="validLink">True</field></doc><doc><field name="title">Secure, privacy assured mechanisms for heterogeneous contextual environments</field><field name="creator">Vasanta, Harikrishna</field><field name="description">Location information is used to provide a diverse range of services to users such as emergency, navigation, billing, security, information and advertising services. This information is derived from a broad range of indoor and outdoor technologies. The location information thus derived is of different granularity, different co-ordination system and is controlled by numerous service providers. In addition to this, broad selections of devices are used for providing these services. Having a diverse range of applications requiring location information at different levels of granularity, the need to export location information across multiple devices and the existence of different location determination technologies necessitates the need for heterogeneous location network. These networks derive location information from multiple sources and provides various location-based services to users irrespective of the medium, device or technology used. Security, user privacy and management of location information are some of the important issues that need to be addressed. The main contribution of this thesis is the design of a secure and privacy assured heterogeneous location architecture. A formal methodology was chosen to design the heterogeneous location architecture. The design of the architecture resulted in a novel key distribution protocol and a model for information flow that can be easily encapsulated into applications or architectures having similar requirements. The research also resulted in the enhancement of a proposed location framework for securing critical infrastructures using context-aware self-defending objects. The proposed enhanced framework helps to negate the security vulnerabilities introduced through the use of general-purpose computer systems in critical infrastructures.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">heterogeneous location networks</field><field name="subject">context aware computing</field><field name="subject">pervasive computing</field><field name="subject">ubiquitous computing</field><field name="subject">secure system design</field><field name="subject">network security</field><field name="identifier">http://eprints.qut.edu.au/16177/</field><field name="validLink">True</field></doc><doc><field name="title">Identification of a suspect before being charged: legitimate freedom of speech or a threat to a fair trial?</field><field name="creator">Burgess, Craig Neilson</field><field name="description">Identification of a person suspected of a heinous crime before being charged risks prejudicing a fair trial.  Present laws place this type of publicity outside the reach of sub judice contempt. This thesis argues there should be a change in the law of sub judice contempt making it an offence for the media to publish the fact that a person is under investigation until the person has been charged.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Contempt of court</field><field name="subject">subjudice</field><field name="subject">naming suspects before charge</field><field name="subject">effect of prejudicial pre- trial publicity</field><field name="subject">influence on jurors</field><field name="subject">memory</field><field name="subject">freedom of speech</field><field name="subject">open justice</field><field name="subject">public interest</field><field name="subject">public safety - fair trial</field><field name="subject">evidential problems - remedies for prejudicial publicity</field><field name="subject">preferred approach</field><field name="identifier">http://eprints.qut.edu.au/16178/</field><field name="validLink">True</field></doc><doc><field name="title">Institutionalising ethical cultures: an investigation of formal organisational approaches</field><field name="creator">Segon, Michael John</field><field name="description">This thesis examined the institutionalisation of ethics within Australian organisations. A particular focus is the role of the strategic apex, or executive level of the organisation, in establishing the environment in which an ethical culture can develop.  The literature review examined both organisational theory and existing approaches to developing organisational ethical culture using formal mechanisms such as written policies, procedures, training and development and reinforcement strategies. This revealed the polarisation of ethics literature between compliance and integrity based approaches. This is seen to be consistent with only two forms of organizations, the mechanistic and organic structures. This was identified as a major flaw in ethics literature as it does not inform organisations about appropriate ethical design for organisations that fall in between this continuum. The review of organisational theory concluded that components of organisational structure are used to discuss organisational moral responsibility and are also the components of the compliance and integrity approaches to organisational ethics. A tentative hypothesis was established that organisational ethics systems would be more effective if they are in fit with an organisation's structure.  The study utilised a qualitative case based research method, argued as appropriate given the focus being strategic alignment of organisational structure and ethics frameworks. Thus was also recognised as having limitations, specifically not addressing the behavioural impact of such strategies in a significant way. The study examined the ethical frameworks of three large organisations. This included: an analysis of background to the ethics strategy, the design process, who was given responsibility for design and implementation of the framework. The major characteristics of the program was considered, how it was encultured throughout the organisation and consideration of any evaluation mechanism. This was contrasted against the organization's structural characteristics to establish whether the ethical framework was in fit with the structure of the organization.  The analysis and discussion identified that senior management support was evident in all three case studies and crucial to the development of an ethical culture. Extensive written policies (codes of ethics and conduct) were identified in all three cases; however, the extent of appropriate support systems determined the degree to which these policies were effective. There was a general lack of understanding of ethical systems within the organisation with little expertise evident by those responsible for the programs in terms of appropriate strategies for enculturation. Ineffective strategies were mainly due to lack of appropriate support mechanisms (communication, training, reinforcement and reward and review) or inconsistency between support mechanisms and other organisational policies  A major conclusion of the thesis is that the strategies used for enculturation of ethics, are basic organisational design variables. As such ethical frameworks need to be informed by organisational theory so as to design systems that achieve fit which leads to greater effectiveness.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">ethics</field><field name="subject">morality</field><field name="subject">business ethics</field><field name="subject">codes of ethics</field><field name="subject">codes of conduct</field><field name="subject">organisational</field><field name="subject">ethics</field><field name="subject">integrity</field><field name="subject">compliance</field><field name="subject">aspirational</field><field name="subject">corporate responsibility</field><field name="subject">organisation</field><field name="subject">organisational structure and design</field><field name="subject">formalisation</field><field name="subject">centralisation</field><field name="subject">complexity</field><field name="subject">hierarchy</field><field name="subject">bureaucracy</field><field name="subject">machine organisation</field><field name="subject">professional organisation</field><field name="subject">diversified</field><field name="subject">organisation</field><field name="identifier">http://eprints.qut.edu.au/16179/</field><field name="validLink">True</field></doc><doc><field name="title">The effect of straightening and grinding of welds on track roughness</field><field name="creator">Bona, Melissa Ellen</field><field name="description">Rail is a very expensive component of the railway track.  Therefore, research methods extending rail life have great economic importance.  During the past thirty years and, particularly during the past ten years there has been an increasing awareness throughout most rail networks in the world of the need to introduce improved design criteria, better construction techniques and higher standard track generally.  This implies that quality control at all levels is mandatory if these objectives are to be achieved.  With the improved understanding of degradation of track, a more complete comprehension of the costs associated with different operating and infrastructure conditions should also be developed, aiding in the determination of efficient maintenance costs and their contribution to access charges.  Track and structures together account for 60% of maintenance costs, with 50% of the total being track.  The UIC has done a lot of work on comparative performance indicators, and these show what potential savings much be out there for the taking, just by adopting current best practice.  The old wisdom is that it's not enough o do things rights; we have to make sure that we do the right things.  These developments have largely resulted from the demand for higher speeds particularly in passenger services and the demand to accept heavier axle loads of freight traffic.  Whilst the conventional railway track structure is not likely to change significantly over the next ten years there will be a requirement over that period for better quality track infrastructure.  This means less rail surface defects, less internal defects and less wheels irregularities. The presence of rail surface defects generally increases the roughness of the track leading to a poor passenger ride and increased safety risk with freight traffic. In addition, rail surface defects will generally increase the degradation rate of other track components; however, not all defects will produce visible track deterioration.  Dynamic impacts produced by the rollingstock running over rail surface defects, such as poor welds, will, over time, create continuous rail defects, loosening of fastenings, abrasion and skewing of sleepers, crushing of ballast and loss of formation geometry.  It is only in the recent years that the importance of poor welds in track has been identified.  Dips and peaks must be recognised as a severe track irregularity that needs to be addressed and removed.  Current maintenance activities have little effect on removing misaligned welds in track and the improvement obtained after the maintenance works is generally short lived.  On the other hand, straightening operations have proven to solve the problem and maintain the results following 7 months of traffic.  As part of this project, a six kilometre test section was selected on the Mt Isa Line and all welds located in this region were monitored for over 9 months to increase the understanding of the effect of individual maintenance activities on the track roughness.  Three 2km Divisions were established; each Division had different maintenance activities and levels of intervention completed over the duration of the project.  Over 15,000 readings were recorded and analysed.  The following conclusions were drawn.  The effect of cycle tamping was clearly identified when comparing the means of weld located in Division 1, 2 to the mean of welds in Division 3.  Cycle tamping showed to have a significant positive effect on the dipped welds geometry and an increase in severity of peaked welds prior to their correction.  Straightening operations completed in Division 1 and 2 reduced the overall mean of weld misalignments. These Divisions were subjected to different levels of straightening intervention however they produced similar results. Division 1 all dips were straightened and Division 2 only dips &amp;gt0.3mm were straightened. This means that no additional benefit, in terms of overall misalignment of welds, can be gained when straightening operations target dips with a misalignment smaller than 0.3mm.  Cycle grinding proved to have little effect on the removal of both dips and peaks.  In fact, due to the configuration of the grinding machine, grinding operation produced a slight worsening of the dips misalignments and only a minor improvement of peaks.   Although long term monitoring of the site may show minor variations in weld geometry performance, after approximately 3.9 Mgt of traffic the mean of dipped welds in Division 1 and 2 appeared to remain unaltered, as Division 3 showed a minor worsening.  Furthermore, the mean of peaked welds in Division 1 and 2 appeared to remain unaltered, as Division 3 showed a minor worsening.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">ballast</field><field name="subject">corrugation</field><field name="subject">continuous welded rail (cwr)</field><field name="subject">flashbutt welds</field><field name="subject">formation</field><field name="subject">gauge</field><field name="subject">kilometre post</field><field name="subject">long welded rail (lwr)</field><field name="subject">maintenance machines</field><field name="subject">p2 forces</field><field name="subject">rail</field><field name="subject">rail grinder</field><field name="subject">resonance</field><field name="subject">rollingstock</field><field name="subject">sleeper</field><field name="subject">speed board</field><field name="subject">tamping machine</field><field name="subject">track condition index (tci)</field><field name="subject">thermite weld</field><field name="subject">top and line</field><field name="subject">top defects</field><field name="subject">track</field><field name="subject">track monuments</field><field name="subject">welded track</field><field name="identifier">http://eprints.qut.edu.au/16180/</field><field name="validLink">True</field></doc><doc><field name="title">Population structure and genetic diversity of Southeast Queensland populations of the Wallum Froglet, Crinia Tinnula (Tschudi)</field><field name="creator">Renwick, Juanita</field><field name="description">Genetic diversity is a fundamental attribute that contributes to a species evolutionary survival.  In recent times, conservation managers have recognized the need to preserve genetic diversity of declining species, and have also acknowledged the utility of genetic markers for describing genetic and ecological relationships within and among populations.  Information obtained from genetic studies can be used in conjunction with information on population demography, land use patterns and habitat distribution to develop effective management strategies for the conservation of species in decline.  The wallum froglet, Crinia tinnula, is one of Australia's smallest habitat specialist anurans.  In recent years there has been a dramatic decrease in population numbers of this species.  The habitat to which C.tinnula is endemic ('wallum' habitat) is restricted to low coastal plains along the southeast Queensland and northern New South Wales coastline.  As human populations in this region expanded, the coastal areas have undergone significant development and large areas of wallum habitat have been cleared.  The effect has been to convert once largely continuous patches of coastal heathland in to a matrix of small habitat patches within an area undergoing rapid urban expansion.  This study aimed to document levels and patterns of genetic diversity and to define the population structure of C.tinnula populations within southeast Queensland, with the objective of defining possible conservation management units for this species.  Results from 12S and COI mitochondrial markers clearly showed that two distinct evolutionary lineages of C.tinnula are present within southeast Queensland.  The high level of divergence between lineages and strict geographic partitioning suggests long term isolation of C.tinnula populations.  It is hypothesized that ancestral C.tinnula populations were once confined to wallum habitat refugia during the Pliocene resulting in phylogeographic delineation of 'northern' and 'southern' C.tinnula clades.  Populations within each geographic region show evidence of range contraction and expansion, with subsequent restricted gene flow.  Levels of genetic diversity appear, largely, to be the product of historical associations rather than contemporary gene flow. A revision of the current systematics of C.tinnula is required to ensure that discrete population groups are recognized as distinct evolutionary lineages and will therefore be protected accordingly.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Crinia tinnula</field><field name="subject">population genetic structure</field><field name="subject">phylogeography</field><field name="subject">Pliocene</field><field name="subject">mitochondrial DNA</field><field name="subject">12S</field><field name="subject">COI</field><field name="subject">wallum</field><field name="subject">Southeast Queensland</field><field name="identifier">http://eprints.qut.edu.au/16181/</field><field name="validLink">True</field></doc><doc><field name="title">The construction industry in Yemen : towards economic sustainability</field><field name="creator">Sultan, Basel Mohammed</field><field name="description">The construction industry is one of the most important components in the economic development of a developing country, being a major contributor to the national economy of many such countries. This industry is largely responsible for the physical provision of housing and infrastructure and, as such, can be the backbone of prosperous economies, providing social development and employment. The construction industry in the developing economy of Yemen is plagued by difficult economic and technical problems, which permeate most aspects of the industry. In addition, construction procedures in Yemen consume excessive capital, time and resources that have a direct flow-on effect for the national economy and the nation's socio-economic development. Macroeconomic problems in unemployment, inflation and an inequitable balance-of-payments all add to the existing difficult economic situation in the construction industry. Further, the lack of appropriate infrastructure, weak and inefficient legal, administrative and financial institutions are also major contributors. The recent global shift to sustainable development also requires that the construction industry in Yemen initiate important strategic developmental policies in order to meet future demand for economical and sustainable development. This research uses a comprehensive literature review to design and conduct a survey into the existing local development barriers and then obtains a census of expert opinions using the Delphi methodology to rank a set of sustainable developmental policies and strategies. The research then establishes a comprehensive list of recommendations for achieving economicly sustainable industry. Proposed policies and strategies are formulated from various international studies, including Agenda 21 for Sustainable Development. The proposed policies and strategies are specifically chosen as they are considered to be compatible with the Yemen case and are also seen to more readily integratable with cultural aspects of Yemen, particularly in focusing on the hardships of its local needs and capabilities.    The construction industry in the developing nation of Yemen appears aligned in many ways to the needs of other developing economies and, as such, it is expected that the findings of this research will be of great interest to professionals involved in the construction economies of other such developing nations.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">construction industry</field><field name="subject">Yemen</field><field name="subject">economic sustainability</field><field name="identifier">http://eprints.qut.edu.au/16182/</field><field name="validLink">True</field></doc><doc><field name="title">Ecology and bioenergetics of the gudgeon (Hypseleotris spp.) in Maroon Dam: a zooplanktivorous fish in a whole-lake biomanipulation</field><field name="creator">Meredith, Shaun Nicholas</field><field name="description">Gudgeon (Hypseleotris spp.) are the most widespread and abundant native Australian freshwater fish and the dominant zooplanktivore in Maroon Dam, the site of Australia's first whole-lake biomanipulation experiment. The spatial (littoral and pelagic) and temporal (diurnal and seasonal) distribution and diet of Hypseleotris was examined following the addition of 100,000 piscivorous Australian Bass (Macquaria novemaculeata) to Maroon Dam in the summer of 1998/99. A strong spatial and temporal ontogeny was observed, with smaller (&lt;16 mm SL) Hypseleotris dominating the pelagic, an intermediate (12-20 mm SL) size class diurnally migrating between littoral and pelagic, and larger fish (&gt;20 mm SL) remaining in the littoral throughout the day and night. Spatial ontogeny affected diet also, with fish consuming a decreasing proportion of zooplankton and an increasing proportion of macro-invertebrates as fish length increased and habitat use changed. A bioenergetics model was constructed to examine these distribution and diet patterns. Laboratory derived consumption and respiration parameters were combined with caloric densities and commonly accepted excretion and activity scalars to produce modeled growth estimates that were validated against Hypseleotris age-at-growth data collected from a diversity of habitats. Using this model, it was concluded that the spatial and temporal ontogeny and diet of Hypseleotris in Maroon Dam described the most energetically advantageous life history. Unlike many zooplanktivores in northern hemisphere lakes, Hypseleotris did not appear to engage in migratory predator avoidance behaviour. This is discussed in a context of Australia's paucity of pelagic piscivores. It is concluded that top-down biomanipulation by stocking of native piscivores has only a limited application in Australia, and that other biomanipulation techniques may prove more successful.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Hypseleotris</field><field name="subject">ontogeny</field><field name="subject">biomanipulation</field><field name="identifier">http://eprints.qut.edu.au/16184/</field><field name="validLink">True</field></doc><doc><field name="title">Going with the flow : Chinese travel journalism in change</field><field name="creator">Bao, Jiannu</field><field name="description">The thesis explores the evolution of Chinese travel journalism since 1978, the year China launched its economic reforms and opened to the international community and   examines its role in facilitating social changes.  Discussion is based on texts from the print, television and online media. Four case studies illustrate how Chinese media are influenced by the state, the market and readerships.  The central argument of this thesis is that Chinese travel journalism has established itself as a recognised genre of popular journalism due to rapid growth in tourism along with market-driven reforms. Travel journalism has developed within the official media  (the Party press), negotiated media (commercially oriented) and flexible (online) media. These divisions promote a range of information, advice and discussion available to  travellers and tourists. In the case of the official media, the information is framed by concerns to regulate; in the case of the negotiated media, there is more scope for commercial promotions; the flexible online media allows non-professional participation. As such, the development of travel journalism reflects the evolution of Chinese media from a propaganda institution to a modernising media industry, and more recently, to a platform for personal expression and alternative voices.    The government support for the development of the tourism market has been a strong spur for the growth of travel journalism, and the discourses of Chinese modernisation are carried through the popularisation of travel as a subject in the media. Chinese travel journalism provides advice on social conduct for travellers, both in domestic and international situations, and it influences national self-perceptions and international outlook. Developing in the broader context of social, economic and cultural changes, travel journalism provides a valuable gauge for the study of transformations in Chinese society and Chinese lifestyles.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">China</field><field name="subject">travel journalism</field><field name="subject">popular journalism</field><field name="subject">Chinese media</field><field name="subject">official media</field><field name="subject">negotiated media</field><field name="subject">flexible media</field><field name="subject">media representation</field><field name="subject">market influence</field><field name="subject">lifestyle change</field><field name="subject">experience economy</field><field name="subject">personal expression</field><field name="subject">Chinese national identity</field><field name="subject">nationalism</field><field name="subject">image of China</field><field name="subject">and social transformation.</field><field name="identifier">http://eprints.qut.edu.au/16185/</field><field name="validLink">True</field></doc><doc><field name="title">Virus recognition in electron microscope images using higher order spectral features</field><field name="creator">Ong, Hannah Chien Leing</field><field name="description">Virus recognition by visual examination of electron microscope (EM) images is time consuming and requires highly trained and experienced medical specialists. For these reasons, it is not suitable for screening large numbers of specimens. The objective of this research was to develop a reliable and robust pattern recognition system that could be trained to detect and classify different types of viruses from two-dimensional images obtained from an EM. This research evaluated the use of radial spectra of higher order spectral invariants to capture variations in textures and differences in symmetries of different types of viruses in EM images. The technique exploits invariant properties of the higher order spectral features, statistical techniques of feature averaging, and soft decision fusion in a unique manner applicable to the problem when a large number of particles were available for recognition, but were not easily registered on an individual basis due to the low signal to noise ratio. Experimental evaluations were carried out using EM images of viruses, and a high statistical reliability with low misclassification rates was obtained, showing that higher order spectral features are effective in classifying viruses from digitized electron micrographs. With the use of digital imaging in electron microscopes, this method can be fully automated.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">virus recognition</field><field name="subject">electron micrograph</field><field name="subject">higher order spectra</field><field name="subject">bispectrum</field><field name="subject">invariant features</field><field name="subject">feature averaging</field><field name="subject">texture and contour analysis</field><field name="identifier">http://eprints.qut.edu.au/16186/</field><field name="validLink">True</field></doc><doc><field name="title">On-line local load measurement based voltage instability prediction</field><field name="creator">Bahadornejad, Momen</field><field name="description">Voltage instability is a major concern in operation of power systems and it is well known that voltage instability and collapse have led to blackout or abnormally low voltages in a significant part of the power system.  Consequently, tracking the proximity of the power system to an insecure voltage condition has become an important element of any protection and control scheme. The expected time until instability is a critical aspect. There are a few energy management systems including voltage stability analysis function in the real-time environment of control centres, these are based on assumptions (such as off-line models of the system loads) that may lead the system to an insecure operation and/or poor utilization of the resources. Voltage instability is driven by the load dynamics, and investigations have shown that load restoration due to the on-load tap changer (OLTC) action is the main cause of the voltage instability. However, the aggregate loads seen from bulk power delivery transformers are still the most uncertain power system components, due to the uncertainty of the participation of individual loads and shortcomings of the present approaches in the load modeling. In order to develop and implement a true on-line voltage stability analysis method, the on-line accurate modeling of the higher voltage (supply system) and the lower voltage level (aggregate load) based on the local measurements is required. In this research, using the changes in the load bus measured voltage and current, novel methods are developed to estimate the supply system equivalent and to identify load parameters. Random changes in the load voltage and current are processed to estimate the supply system Thevenin impedance and the composite load components are identified in a peeling process using the load bus data changes during a large disturbance in the system. The results are then used to anticipate a possible long-term voltage instability caused by the on-load tap changer operation following the disturbance. Work on the standard test system is provided to validate the proposed methods.  The findings in this research are expected to provide a better understanding of the load dynamics role in the voltage stability, and improve the reliability and economy of the system operation by making it possible to decrease uncertainty in security margins and determine accurately the transfer limits.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">power system stability</field><field name="subject">voltage stability</field><field name="subject">long-term voltage instability</field><field name="subject">voltage collapse</field><field name="subject">supply system modeling</field><field name="subject">load restoration</field><field name="subject">composite load</field><field name="subject">induction motor load</field><field name="subject">constant impedance load</field><field name="subject">constant power load</field><field name="subject">load modeling</field><field name="subject">load peeling</field><field name="subject">load parameters estimation</field><field name="subject">on-load tap changers</field><field name="subject">system variations</field><field name="subject">signal processing</field><field name="subject">on-line identification</field><field name="identifier">http://eprints.qut.edu.au/16187/</field><field name="validLink">True</field></doc><doc><field name="title">Agency theory : an extended conceptualisation and reformation</field><field name="creator">Temel-Candemir, Nurcan</field><field name="description">The theory of Agency, specifically that developed by Jesen and Meckling (1976), will be the subject of examination. Agency theory has been the subject of extensive research since its introduction in modern form by Jensen and Meckling (1976). The generality of the theory of Agency appears unquestionable and it has been widely adopted. Surprisingly, however, the model correctly predicts particular phenomena under investigation in only the simplest of instances, and even in the simplest of instances there are cases where the simple agency model has limited success.    Possible reasons for this failure may lie in the assumed universalist foundation and in the common formulation regarding agent behaviour, that all agents are self-interested rationalists seeking to maximise their own utility to the disregard of their principal's interest. While the hypothesis of self-interested rationalism may be apt in some contexts it may be misleading or inadequate in others. This is especially so when the narrow interpretations of self-interested rationalism are used. Human beings are more complex in their totality than can be represented in any parsimonious model. This is particularly a problem when model predictions are not empirically supported. Aspects omitted in a model may be a source of the misfit between prediction and observation.    An extended conceptualisation and reformulation of agent behaviour is presented. An approach is developed that addresses the context of agent behaviour, the socio-environment within which the agent interacts. The context particularly refers to the institutional affiliations and interactions that influence agent behaviour through their belief structure (i.e., their Belief-Desire-Intention, BDI, model of rational action). Through the use of an institutional framework contextual analysis is incorporated into the theory of agency and ultimately agent behaviour. This agent is termed a socio-environmental rationalist agent (SERA) which is contrasted with the self-interested rationalist (SIR) agent in the existing agency literature.    This research utilises an object-oriented approach to develop a simulation of the extended conceptualisation and reformulation of agent behaviour. Simulations investigate agent behaviours and outcomes at the micro (specifically through individualised SERA and SIR formulations) and macro (specifically through a multi-agent SERA community formulation in the context of the EU financial accounting harmonisation process) levels. Netlogo is the simulation tool through which this is attained.    The simulation demonstrates how alternative formulations of rationality lead to different outcomes and these differences are evident at both levels. Importantly the extended model has outputs that are more in tune with current empirical evidence. The analysis thus demonstrates the plausibility of the extended conceptualisation and reformulation and the need to incorporate the context of behaviour more fully within the analysis of the principal-agent relationship.    Through this extended examination of agent behaviour further theoretical and practical insights regarding the understanding of agent behaviour, the principal-agent problem and relationship, multi-agent communities, and of business and society in general may be attained. This dissertation provides one step in advancing our fundamental understanding of the principal-agent problem. The scope and power of agency analysis can be substantially extended using the approach and methods outlined, particularly beyond that present in existing Agency research.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">agency theory</field><field name="subject">agent behaviour</field><field name="subject">Netlogo</field><field name="subject">multi-agent communities</field><field name="identifier">http://eprints.qut.edu.au/16188/</field><field name="validLink">True</field></doc><doc><field name="title">Mapping the effects of dry sclerophyll vegetation within the battlespace using the Leica ADS40 and GIS</field><field name="creator">Jackson, Anthony Edward</field><field name="description">1st Topographical Survey Squadron, Royal Australian Engineers, provides deployable geospatial support to the Australian Defence Force.  Part of this role is the production of products for use by commanders. These products provide commanders at all levels with mission specific and up to date knowledge of the terrain that he will encounter on the battlespace.  Currently 1st Topographical Survey Squadron provides products that contain manmade features, hydrography, slope, surface configuration and vegetation as displayed on current mapping products.  They do not provide an accurate portrayal of the effect that vegetation characteristics have on the battlespace.
 
 
 
 Introducing these types of features will give the commander a greater knowledge of the terrain and environment that he will encounter, and will greatly improve the planning and success of the campaign.
 
 
 
 This research explored to what extent the accuracy of the terrain analysis products currently produced by 1st Topographical Survey Squadron would increase by adding a more detailed portrayal of vegetation extracted from remote sensing data.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">terrain analysis</field><field name="subject">geographic information systems</field><field name="subject">remote sensing</field><field name="subject">vegetation</field><field name="identifier">http://eprints.qut.edu.au/16189/</field><field name="validLink">True</field></doc><doc><field name="title">IT Management Consulting in Australia: A Major Issues Study</field><field name="creator">Kennelly, Jason</field><field name="description">We are amidst a period of radical change in Management Consulting worldwide. The latter half of the twentieth century has seen major extensions to the range of services promoted under the umbrella of Management Consulting. The traditional Management Consulting Firms, such as McKinsey &amp; Co., tend to provide strategy consulting. By contrast, the other multinational Management Consulting Firms have focused on Business Process Re-engineering and other services with an Information Technology emphasis.  Significantly, several multinational Management Consulting Firms have come under the control of Information Technology companies. As yet, very little research has been conducted into the issues that Management Consultants face in Australia. This research project provides an empirical investigation aimed at identifying these issues.  In doing so, the study intends to answer the following research question "What are the major issues facing Management Consulting Firms in Australia?"   To assist in answering this overarching question the study endeavours to address three investigative questions (1) What is the relative severity of issues facing Management Consulting Firms in Australia? (2) What are the Knowledge Management related issues facing Management Consulting Firms in Australia? And (3) What distinctions can be made between Knowledge Management issues and approaches of small-medium sized Management Consulting Firms and large Management Consulting Firms?    This thesis is a compilation and comparison of evidence gathered from four separate but related sub-studies into the Management Consulting industry. The first, a Context Case Study of Management Consulting issues faced by small-medium sized firms, aimed to generate a rich, qualitative description of the study context, which, in turn, provides background to a larger follow-up Issues Delphi Study.  Interpretation of the data gathered for the Context Case Study focuses on gaps between the literature and observed practice.  The Issues Delphi Study garners response from members of the Institute of Management Consultants (IMC) in two survey rounds that inventory issues and then gauge their importance. In addition, an exploratory and descriptive case study was performed to investigate Knowledge Management Strategies and Practices in the Australian branch of Accenture, a well known International Management Consulting Firm.  Though the Accenture Case Study has an operational emphasis, both macro and micro issues of Knowledge Management are considered; macro issues pertain to the strategic leverage of Knowledge Assets, while micro issues pertain to creation, transfer and reuse of knowledge within the firm, and between the firm and its clients.   Knowledge Management is identified as essential to the achievement of sustained competitive advantage for all Professional Service Firms; of which Management Consulting Firms are a subset.  As such, a conceptual analysis of the Knowledge in Professional Service Firms model, developed by Empson and Morris (1998), was performed to enhance the researchers understanding of Knowledge Management in Management Consulting Firms.  The analysis of the model's constructs and their relationships assists the researcher's analysis of data gathered from the other three sub-studies.  In addition, the attempt to develop several model variants is explored and an argument for the resulting final model variant which incorporates a new construct, Knowledge Management, is presented.   Finally, the study compares the issues identified from the four separate sub-studies. The issues gathered are mapped into Knowledge in Professional Service Firms model, providing useful insights into the importance of sound Knowledge Management practices in small, medium and large Management Consulting Firms.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Management Consulting</field><field name="subject">Case Study Method</field><field name="subject">major issues study</field><field name="subject">Delphi Method</field><field name="subject">Knowledge Management</field><field name="subject">Professional Service Firms</field><field name="identifier">http://eprints.qut.edu.au/16190/</field><field name="validLink">True</field></doc><doc><field name="title">Case studies of the transfer of road safety knowledge and expertise from western countries to Thailand and Vietnam, using an ecological road safety space model : elephants in traffic and rice cooker helmets</field><field name="creator">King, Mark Johann</field><field name="description">International organisations such as the World Health Organisation highlight the road crash problem in less motorised (or developing, or low income) countries like those in Southeast Asia and recommend the adoption of Western road safety measures.  However, there are many differences between highly motorised and less motorised countries which raise questions about how successfully Western road safety knowledge and expertise can be transferred.-----  
 
 
 
 A review of the statistical information on road crashes shows a great deal of uncertainty about both the scale and likely trajectory of road fatalities globally, in less motorised countries and in Asia.  It is generally agreed, however, that Asia accounts for around half of all road fatalities, and analysis of the limited available data shows both that Southeast Asia is not an atypical region of Asia in road safety terms, and that Thailand and Vietnam are not atypical of Southeast Asian countries.-----  
 
 
 
 A literature review of recommended practice approaches to road safety transfer in Asia shows that there are many economic, institutional, social and cultural factors which potentially influence the success of transfer.  The review also shows that there is no coherent, comprehensive approach which either conceptualises these factors and their relationship to transfer outcomes, or uses an analysis of these factors to plan or modify transfer.  To address this gap, this thesis develops a 'road safety space' model as a tool for conceptualisation and analysis, based on a biological metaphor which views the transfer of road safety measures from one context to another as analogous to the transfer of a species into a new ecological space.  The road safety space model explicitly considers economic, institutional, social and cultural factors (from specific to broad) which influence the particular road safety issue which a particular road safety transfer effort seeks to address.  A central contention of this thesis is that the road safety space model is both a feasible and useful tool to improve the process of road safety transfer to less motorised countries.  Road safety space analysis is seen to have a role in a broader process of selection of road safety measures for transfer, along with knowledge of how the measures are considered to operate.-----
 
 
 
 The research reported in this thesis is comprised of three studies.  Study 1 reviewed evaluations of road safety transfer to Thailand and Vietnam.  Studies 2 and 3 were case studies of road safety transfer to Thailand and Vietnam respectively.-----
 
 
 
 Study 1 was an analysis of existing evaluations of road safety transfer to Thailand and Vietnam.  The aims were to analyse the evaluations for their consideration of contextual factors, as described in the road safety space model, and to discuss whether the road safety space model assisted in understanding the reasons for success or failure of transfer.  However, very few such evaluations exist, and those that were found generally lacked information on whether contextual factors were considered.  This indicated the need for a more detailed, in-depth qualitative investigation of particular cases of road safety transfer, in order to investigate the feasibility and utility of the road safety space model.-----
 
 
 
 Two case studies (Study 2 and Study 3) were conducted to test whether the road safety space approach was both feasible and useful as a means of improving road safety transfer efforts.  Study 2 was a case study of the development and implementation in Thailand of a road safety education program for school children, which involved the transfer of Western research and techniques.  The transfer agents (i.e. those who effected the road safety transfer) were Australian consultants working for the Australian Road Research Board (ARRB).  The transfer was funded by the World Bank and managed by the Thai Ministry of Education (MOE).  Study 3 was a case study of the development and implementation of a motorcycle helmet wearing program in Vietnam, which involved the transfer of Western knowledge, techniques and technology.  The transfer agents were staff of Asia Injury (AI), a non-government organisation (NGO), and the program was funded initially by a charitable fund, with the intention of becoming self-funding through operation of a helmet factory.-----
 
 
 
 The case studies employed background research into existing information on economic, institutional, social and cultural factors relevant to the road safety issues (road use behaviour of school children in Thailand and motorcycle helmet purchase and wearing in Vietnam), and collected data through interviews with key informants, analysis of secondary sources and observations.  This information was used to derive the road safety space for each road safety issue, to identify the road safety space recognised and addressed by the transfer agents (ARRB and AI), and to determine which factors they missed, or were aware of but took no action on.  The focus of this analysis was on the processes used in transfer, not on the road safety outcomes of transfer, although these provided information on the processes as well.  Available evaluation information was used to draw links between the omissions and the success of the transfer processes.  It was noted that information on how the transferred measures operate should come from a road safety space analysis in the originating country, although this raised questions about selection of country and time (when the measure was first introduced, or in its maturity).-----
 
 
 
 The feasibility and utility of the road safety space model were discussed.  It was clear that the model provided information on the cases which was missed by the transfer agents.  The questions examined next were whether this information could have been obtained from an exercise conducted before the transfer had commenced, whether the required effort and cost justified the potential benefits, and whether the information on the road safety space could have been useful for the transfer agents.  Comparisons between the road safety spaces for the two cases showed some areas of commonality, e.g. perceptions of police corruption, but also many differences.  It was considered likely that some broad factors could be generic, and the possibility was mooted that less motorised countries share issues with police enforcement.  This requires further research, however, and at this stage it is better to treat each road safety space as a unique combination of contextual factors influencing the road safety issue of interest.-----
 
 
 
 It is concluded that the road safety space model is feasible if used in such a way as to minimise the research involved, and useful, although the degree of utility needs to be further explored in a prospective study.  The limitation introduced by restricting informants to those who could speak English are discussed.  An approach using road safety space analysis is recommended, emphasising analysis of the country to which the road safety measure is being transferred, supplemented by analysis of the originating country road safety space.  Gaps in knowledge are identified for further research and development, in particular the theoretical and practical understanding of road use behaviours and their modification in less motorised countries in Southeast Asia.  Elaboration of the model is also recommended, to take into account the influence of the type of measure transferred, the role of the transfer agent, the area of road safety (education, engineering or enforcement), and the time dimension (the time which might be needed for a transfer to show its effects).-----
 
 
 
 The findings of this research are likely to be applicable to road safety transfer in other less motorised regions of the world, however prospective testing is needed.  They may also be relevant to issues of transfer for areas other than road safety, in particular public health and traffic engineering, where similar economic, institutional, social and cultural issues come together.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Road safety</field><field name="subject">traffic safety</field><field name="subject">transfer</field><field name="subject">technology transfer</field><field name="subject">enforcement</field><field name="subject">education</field><field name="subject">engineering</field><field name="subject">statistics</field><field name="subject">case study</field><field name="subject">qualitative research</field><field name="subject">World Bank</field><field name="subject">Asian Development Bank</field><field name="subject">World Health Organisation</field><field name="subject">motorcycle helmet</field><field name="subject">school children</field><field name="subject">road user behaviour</field><field name="subject">economic</field><field name="subject">institutional</field><field name="subject">social</field><field name="subject">cultural</field><field name="subject">context</field><field name="subject">ecology</field><field name="subject">Asia</field><field name="subject">Thailand</field><field name="subject">Vietnam</field><field name="identifier">http://eprints.qut.edu.au/16191/</field><field name="validLink">True</field></doc><doc><field name="title">School health services, health promotion and health outcomes: an investigation of the Health Promoting Schools approach as supported by school nurses</field><field name="creator">Carlsson, Dru</field><field name="description">Health promotion interventions in schools have grown in popularity and have demonstrated varying degrees of effectiveness on the health of the school and its individuals. The School Based Youth Health Nurse (SBYHN) Program introduced in 1999 by Queensland Health into state secondary schools supports and encourages use of the Health Promoting Schools (HPS) approach in addressing health issues, in addition to providing individual health consultations to the school community. This Program is unique in that a health service is entering into the education system with a role of supporting implementation of a comprehensive approach to addressing health issues.    The study investigates how SBYHNs support the implementation of the HPS approach in the secondary school setting and explores the health outcomes for the school community. A statewide survey of SBYHNs examines the variety of health promotion and HPS work being undertaken within schools and identifies key implementation and practice issues. Qualitative case studies of three schools further investigates the barriers faced by nurses in supporting HPS implementation, and explores the perceived outcomes of implementing the HPS approach that have begun to emerge within the school community.    Results found that nurses have the capacity to support the implementation of whole-of-school health promotion, with the presence of enablers influencing the comprehensiveness with which schools address health issues or decide to adopt the HPS approach. The study also indicated several outcomes of nurse and school-supported, comprehensive school health promotion across three major areas corresponding with the HPS framework (curriculum, teaching and learning; school organisation, ethos and environment; partnerships and services) and the addition of outcomes in specific health issues.    Implications for future developments in health promotion-orientated, school health service interventions and research into the evidence of effectiveness of the HPS approach are discussed.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">school health services</field><field name="subject">health promotion</field><field name="subject">health outcomes</field><field name="subject">school nurses</field><field name="subject">School Based Youth Health Nurse (SBYHN)</field><field name="subject">Queensland Health</field><field name="identifier">http://eprints.qut.edu.au/16192/</field><field name="validLink">True</field></doc><doc><field name="title">Modelling road and rail freight energy consumption: A comparative study</field><field name="creator">Parajuli, Ashis</field><field name="description">After reviewing land based freight growth trends nationally and internationally, this  thesis discusses the main parameters governing fuel consumption, as well as past  approaches in modelling road and rail energy consumption. Past work on comparing  these two main modes is also reviewed here. The review included ways of estimating  energy consumption of a complete freight task i.e., from origin to destination.  Mathematical models estimating modal energy consumption are presented in this thesis.  Modal energy consumption is a complex function to be approximated in practice due to numerous variables affecting their outcome. Energy demands are particularly sensitive to changes in vehicle characteristics such as mass and size; route parameters such as grade and curvature; traffic conditions such as level of congestion; and less sensitive to  ambient conditions, such as temperature and altitude.  There is a large set of energy estimation models available to transportation planners.  Unfortunately, unless simple relationships are established for energy estimation and  modal comparison, their application in freight movement planning and corridor  development becomes computationally prohibitive.  This thesis describes the development of a modal freight energy comparison tool to  quantify the energy advantage from mode choice, corridor development and vehicle  types and loading improvements. The thesis also describes the used modelling processes  and the trade-offs between model complexity and data quality.  The tool developed in this thesis is based on well established relationships between  energy consumption and traffic flow, route and vehicle operating characteristics for road freight movement. The rail freight component was developed from equations of motion together with parameters obtained from past studies. The relationships have been enhanced to fit the purpose of corridor level comparative analysis. The comparison tool has been implemented using a spreadsheet based approach developed specifically to calculate the total door to door energy consumption for given task options. A series of linked sheets enable the user to: specify all necessary inputs; estimate road and rail energy by trip segment. The outputs consist of trip segment energy demand and total energy efficiency of each option.  A case study approach, for aiding in model development and testing, is presented.  Toowoomba second range crossing in Southern Queensland, Australia (section between  below Postman's Ridge and Gowrie Junction) was selected. Four options considered  include existing and proposed road and rail corridors. The existing rail and road  corridors could be taken as a typical poor case, with very high grades and sharp  curvatures. The proposed new road section has a relaxed curvature and gradient. The  section of proposed rail corridor, under consideration here, still contains a high grade section. However, the proposed track length is considerably shorter than the base-case.  The new proposed train alignment was found as the most efficient mode and the existing  trains as the least efficient mode when measured based on absolute expected fuel gain (litres/tonnage of freight moved). This could be attributed to the improvement in  curvature and load carrying capacity. However, when the options are compared in terms of litres/1000 NTK, the new train option did not show a significant advantage.  Furthermore, the developed model was applied on some simulated cases to test the  functionality of other aspects of the model. The total door-to-door energy consumption  and the efficiency were compared for all the simulated cases. It showed that the energy  efficiency of scenarios varies exponentially with the variation in the ratio of road pickup and delivery legs to the rail line-haul length. In general, energy efficiency of the intermodal options was found to be better unless the best case of the road and the worst case of intermodal option was compared.  The modelling approaches presented in the thesis and the comparison model developed  in this study could be used for several purposes namely: to assess the energy (and hence greenhouse gas) implications of specific modal freight movements; to aid in the economic and environmental evaluation of transport options; and to assess the potential for energy efficiency gains from vehicle and infrastructure improvements. A number of suggested improvements to the model are also discussed.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">freight task</field><field name="subject">road freight energy consumption</field><field name="subject">rail freight energy consumption</field><field name="subject">pick-up leg</field><field name="subject">line-haul</field><field name="subject">delivery leg</field><field name="subject">payload</field><field name="identifier">http://eprints.qut.edu.au/16193/</field><field name="validLink">True</field></doc><doc><field name="title">SHV &#946;-lactamases : DNA diagnostics and evolution</field><field name="creator">Hammond, David Scott</field><field name="description">TEM and SHV &#946;-lactamases are the most prevalent &#946;-lactamases among Gram-negative bacteria. The introduction and widespread use of expanded-spectrum antibiotics, particularly third generation cephalosporins, has led to the evolution of bacterial strains expressing extended spectrum &#946;-lactamases (ESBLs). ESBLs emerge by genetic point mutation from non-extended spectrum precursors.  It was found that multiple &#946;-lactamase families within single isolates complicate the process of detecting the resistance status of isolate using non-quantitative DNA diagnostic methods. Preliminary phenotypic characterisation of probable &#946;-lactamase enzyme family types present in 100 isolates from the Asia-Pacific and South African locales showed that single isolates frequently contained multiple &#946;-lactamase families. SHV, TEM, AMPC and CTX-M &#946;-lactamase families were detected in these isolates using PCR detection methods. Ninety-eight percent of all isolates tested contained as least one &#946;-lactamase gene, with up to four to &#946;-lactamase gene families found to co-exist in single isolates. Kinetic PCR methods for interrogating the polymorphic sites at blaSHV codons 238 &amp; 240 and blaTEM codons 164, 238, 240 as well as promoter polymorphism were developed. A high proportion of blaSHV 238 and 240 mutant alleles was found to correlate with cefotaxime, ceftazidime and aztreonam resistance levels.  In an attempt to understand the molecular basis for the co-existence of multiple blaSHV alleles within single isolates, the blaSHV promoter region was cloned from one ESBL expressing isolate. Experimental results showed that blaSHV can exist downstream of two different promoters within a single isolate. Both promoters have previously been reported, and differ by the presence or absence of IS26, which results in a change in the transcription initiation site. The blaSHV gene copy numbers in cis with the different promoters were measured, and it was found that the copy number of the IS26::blaSHV promoter was positively correlated with resistance levels. Cloning and analysis of PCR products showed that different blaSHV variants existed in cis with promoters in individual isolates. However, mutant genes were more abundant downstream of the IS26 promoter. There were no ESBL+ isolates without this promoter. It was concluded that blaSHV in cis with the IS26 promoter is located on an amplifiable replicon, and the presence of the IS26 insertion may facilitate the acquisition of an ESBL+ phenotype.  To further confirm the role of IS26 in resistance acquisition, ESBL negative isolates were subjected to serial passage in vitro evolution experiments and fluctuation assays. Results confirm that the insertion of the IS26 element upstream of blaSHV is positively correlated with the ability to exhibit an ESBL phenotype, when such isolates also contain the critical G238S substitution. It was also found that IS26 can catalyse the duplication and mobilisation of blaSHV within an isolate. Fluctuation experiments have shown that the frequency at which such genomic events occur resulting in ESBL phenotypes is extremely low and requires many generations of selection under sub-lethal conditions.  A survey of a geographically diverse set of isolates has shown that IS26-blaSHV was found in all of the bacterial populations surveyed. However, it does not appear to be exclusively associated with SHV-mediated ESBL production.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">blaSHV</field><field name="subject">blaTEM</field><field name="subject">IS26</field><field name="subject">extended spectrum beta lactamase</field><field name="subject">ESBL</field><field name="subject">SENTRY</field><field name="subject">kinetic PCR</field><field name="subject">in vitro evolution</field><field name="subject">serial passage</field><field name="subject">MSS maximum likelihood</field><field name="subject">spontaneous mutagenesis</field><field name="subject">cefotaxime resistance</field><field name="subject">&#946;-lactamase</field><field name="subject">SHV</field><field name="identifier">http://eprints.qut.edu.au/16194/</field><field name="validLink">True</field></doc><doc><field name="title">The role of the spleen in Malaria : Cellular changes that affect the development of immunity</field><field name="creator">Beattie, Lynette</field><field name="description">Malaria, caused by the apicomplexan parasite Plasmodium, is a major cause of morbidity and mortality throughout the world. This study has focused on the role of the spleen in the control of the blood stage of infection. Three aspects have been examined specifically: the effect of infection on the architecture of the spleen, the role of the spleen in parasite clearance and the formation of B cell memory.  Firstly, the effect of infection on the splenic microarchitecture was examined. An  essential component of the splenic architecture is the marginal zone (MZ), an area of the spleen that separates the reticuloendothelial red pulp of the spleen from the lymphoid white pulp compartment. Two unique populations of macrophages are  found in the marginal zone: marginal zone macrophages (MZM) and marginal metallophilic macrophages (MMM). In the current study, parasitised red blood cells (pRBC) as well as normal RBC located to the MZ thirty minutes after intravenous injection and formed close associations with both MMM and MZM. Eight days after infection, at the time of peak parasitemia, a complete loss of both MMM and MZM was observed. Assays to detect cell death revealed that the loss of both MMM and MZM appeared to occur as a result of apoptosis. The apoptosis was not induced by  up regulation of the inflammatory cytokines tumour necrosis factor or interferon-&#947;  and could not be blocked by over expression of the apoptosis inhibitor Bcl2. Significantly, MMM were retained in the absence of CD8+ T cells implicating CD8+  T cells in the loss of MMM. Finally, infection of CD95-/- mice demonstrated that  CD95/CD95-ligand (Fas/Fas-ligand) interactions were responsible for some of the CD8+ T cell-mediated loss of MMM. These data provide evidence for a novel interaction between MMM and CD8+ T cellsfollowing infection with Plasmodium.  Secondly, the role of the spleen in the control of parasitemia and disease was  monitored with an emphasis on determining the role of splenic macrophage populations (MMM, MZM and red pulp macrophages [RPM]) in parasite clearance.  A clodronate liposome-mediated macrophage depletion technique was used, and caused a complete loss of all three macrophage sub-populations, as well as 50% of splenic dendritic cells, within 24 hours of administration. Each of the macrophage  populations, as well as splenic DC, demonstrated different repopulation kinetics following their depletion from the spleen and these kinetics were utilised to examine  each cell population in isolation. RPM depleted mice had significantly higher peak  parasitemias than the controls. This peak returned to the level observed in undepleted control animals only after the repopulation of RPM was complete, suggesting that RPM play a role in the control of peak parasitemia following infection. Neither MMM nor MZM played a role in the control of parasitemia. The role of non-splenic macrophages and splenic dendritic cells also was investigated and shown to be insignificant in the absence of splenic macrophages. Finally, the role of RPM in mice immune to infection was investigated and their role shown to be dispensable, with immune mice clearing parasitemia efficiently in the absence of RPM. RPM therefore are important for the innate control of infection with P. chabaudi but are dispensible once adaptive immunity is established.  Finally, the role of the spleen in the development of parasite-specific B cell memory was examined. Initial studies demonstrated that germinal centre (GC) development was compromised following infection with P. chabaudi, with an involution of B cell follicles noted early in infection. Adoptive transfer of memory B cells from immunised to na&#239;ve mice demonstrated that some protection was conferred on recipient mice by parasite-specific memory B cells. But, the memory B cells could not protect the host from developing parasitemia and did not produce significant amounts of parasite-specific immunoglobulin within seven days of challenge infection. Memory B cells could not be detected ten weeks after infection, indicating that the development, or survival, of parasite-specific memory B cells was compromised. The development of bystander memory B cells was not affected by  infection. Finally, long-lived plasma cells were shown to develop in response to  infection, although re-exposure of the cells to parasites in the form of recrudescent  parasitemia resulted in their loss. This study therefore has identified a defect in the development of long-term, B cell-mediated, protection against infection with P. chabaudi.  Each of these factors has significant implications for the understanding of how the spleen contributes to the control of infection with Plasmodium and potential  applications for the further development of malaria vaccines and treatment regimens.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Malaria</field><field name="subject">Plasmodium</field><field name="subject">spleen</field><field name="subject">splenic architecture</field><field name="subject">marginal zone</field><field name="subject">marginal metallophilic macrophages</field><field name="subject">marginal zone macrophages</field><field name="subject">immunopathology</field><field name="subject">cytotoxic T cells</field><field name="subject">red pulp macrophages</field><field name="subject">adaptive immunity</field><field name="subject">innate immunity</field><field name="subject">humoral memory</field><field name="subject">memory B cells</field><field name="subject">long-lived plasma cells</field><field name="identifier">http://eprints.qut.edu.au/16195/</field><field name="validLink">True</field></doc><doc><field name="title">System development and studies on utilization of concentrated solar beam radiation for polymer processing</field><field name="creator">Stoynov, Lou A.</field><field name="description">Various solar energy technologies are being developed to harness the available  environmentally friendly and sustainable solar radiation. New ways of utilizing this  "free" power for different energy consuming processes continue to be created. In  this thesis, a multi-stage solar energy concentrating system has been developed and  its feasibility as a radiation source for polymer processing has been explored. The  solar energy concentrator (SEC) facility comprises a modified Cassegrainian  configuration combined with auxiliary imaging and non-imaging optics, serving as  an alternative energy source for polymer joining, ageing and adhesive curing.  Modeling and improvement of various aspects of the operation and performance of the SEC facility have been implemented. Optical ray tracing models of the Cassegrainian concentrator with various conventional imaging components and nonimaging  concentrators have been created to optimize the optical layout and system efficiency. On their basis, combined 3D ray tracing computer models integrated with  the mechanical components have been developed to simulate the entire SEC facility and predict the image size, location and orientation. Additionally, the energy transfer, radiation absorption and heat generation and transfer in the irradiated polymer have been modeled in order to study the radiation-polymer interaction.  One novel contribution of this research is the enhancement of the image forming concentrator with non-imaging cone-like concentrators (conical and compound  parabolic concentrator (CPC)), utilizing their inherent disadvantage of excessive  length. Compared to the refractive type means of transmitting concentrated solar  radiation, the truncated cone and CPC concentrators have been found more efficient  enhancing further the concentration and widening the utilized spectral range.  The experimental studies have demonstrated that transparent and colored, similar and dissimilar polymers can be successfully joined using the SEC facility.  The especially developed through-transmission technique removes the need to use a special absorbing medium of the radiant energy required by current advanced welding techniques. The tensile strengths of the joints achieved are comparable to those achieved for similar polymers with other advanced plastic joining methods.  The results from the polymer ageing experiments have shown that ultraaccelerated  exposure to concentrated sunlight can be performed with the SEC facility without introducing spurious failure mechanisms. Based on the preliminary investigation on adhesive curing utilizing concentrated solar radiation, it has been concluded that with carefully chosen light-curing adhesives solar radiation can be a useful radiation source for adhesive curing.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">accelerated outdoor ageing</field><field name="subject">cassegrainian concentrator</field><field name="subject">solar radiation</field><field name="subject">thermoplastic joining</field><field name="identifier">http://eprints.qut.edu.au/16196/</field><field name="validLink">True</field></doc><doc><field name="title">The functional consequences of the interactions between insulin-like growth factors (IGFs), insulin-like growth factor binding proteins (IGFBPs) and vitronectin (VN) and their involvement in skin</field><field name="creator">Hyde, Carolyn Elizabeth</field><field name="description">The insulin-like growth factor (IGF) system plays an important role in a number of disease states, such as cancer, and has also been implicated in wound and burn healing processes. Two IGF receptors, the type-1 IGF and type-2 IGF receptors, as well as six insulin-like growth factor binding proteins (IGFBP-1 to 6), have well established roles in mediating IGF activity. Earlier studies in this laboratory demonstrated that IGF-II binds to the extracellular matrix (ECM) protein vitronectin (VN), and although IGF-I does not bind directly to VN it can bind indirectly via specific IGFBPs. Therefore the aim of the research described in this thesis was to determine whether binary and ternary complexes of IGF-I/II, IGFBPs and VN affect human keratinocyte cell function. The strategy of pre-binding these complexes to the culture dishes was adopted in this study in an attempt to more accurately reflect the extracellular environment in vivo. These studies demonstrated that the binary complex of IGF-II and VN and the ternary complexes comprised of IGF-I, IGFBP-2, or 3, or 4, or 5 and VN significantly stimulated HaCaT de novo cell protein synthesis in the human keratinocyte cell line. Interestingly, these latter experiments demonstrated that although large increases in protein synthesis were observed using the ternary complexes, IGF-I/IGFBP complexes alone were responsible for the significant increases in protein synthesis and these responses are mediated via the MAPK signaling pathway. In addition, both the dimeric and trimeric complexes significantly enhanced cell migration through 12 &#956;m TranswellsTM. Unlike the protein synthesis assays, VN was critically important in these migratory responses and highlighting the important role that integrins play in cell migration. Cell attachment assays on the other hand demonstrated that the interactions of IGFs with IGFBPs and VN did not affect cell attachment. The data encompassed within this thesis represent the first studies to provide a functional role for the interaction between IGFs, IGFBPs and VN in human keratinocytes. Taken together these results suggest that IGF/IGFBP/VN complexes may hold great potential in situations where enhanced keratinocyte cell migration and proliferation is required, such as in wound healing and skin engineering applications.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">insulin-like growth factors</field><field name="subject">insulin-like growth factor binding proteins</field><field name="subject">vitronectin</field><field name="subject">skin</field><field name="subject">cell function</field><field name="subject">cell migration</field><field name="subject">wound healing</field><field name="identifier">http://eprints.qut.edu.au/16197/</field><field name="validLink">True</field></doc><doc><field name="title">Thermo-oxidative degradation of polyamide 6</field><field name="creator">Grigg, Michael Nathan</field><field name="description">The thermo-oxidative degradation of unstabilized polyamide 6 (PA-6) was investigated by a number of novel techniques in an attempt to achieve a better understanding of the mechanisms involved in the oxidative degradation of polymers. Particular attention was given to the influence of end groups on PA-6 oxidation by studying samples that terminated predominantly in carboxylic, amine or methyl end groups.    The changes occurring in the oxidative stabilities and mechanisms of PA-6 as a result of altering the end groups of PA-6 were investigated by a technique termed CL-DSC, which simultaneously measures the chemiluminescence (CL) and heat flow (DSC) from a sample. When amine end groups were abundant in the PA-6 sample a chemically induced electron exchange luminescence (CIEEL) mechanism could occur directly and the CL intensity was proportional to the heat flow curve of the DSC. However, when amine end groups were absent it was the first derivative of the CL intensity that was proportional to the heat flow curve because the CIEEL mechanism could not operate until an easily oxidisable luminescent oxidation product was formed. Due to the dramatic effect end groups have on the oxidation mechanisms of PA-6 it was hypothesized that end groups could be sites analogous to the impurities in polyolefins that lead to heterogeneous oxidation. To test this hypothesis, CL Imaging was used to map the occurrence and extent of oxidation  across  samples  of  PA-6 to  display the influence end groups have on the homogeneous or heterogeneous nature of PA-6 oxidation. Sequences of FTIES spectra collected at specified time intervals during the in situ oxidation of PA-6 samples terminating in the different end groups were turned into oxidation product profiles. The differences between spectra related to significant points on the oxidation profiles were compared in an attempt to elucidate the chemical or physical changes occurring in the samples during oxidation.    To identify the species involved in the mechanistically different oxidation processes resulting from the different end groups, methods for the MALDI-TOF analysis of non-oxidized and oxidized PA- 6 samples were developed via trial and error. It was only possible to detect the occurrence of degradation products by MALDI-TOF MS after considerable oxidation as measured by chemiluminescence, by which time the species were the result of a number of oxidative processes. Therefore, identification of the species formed was not possible.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">thermo-oxidative degradation</field><field name="subject">polyamide 6</field><field name="subject">PA-6</field><field name="subject">polymer</field><field name="subject">oxidation</field><field name="identifier">http://eprints.qut.edu.au/16198/</field><field name="validLink">True</field></doc><doc><field name="title">Development of novel vaccines for the concurrent immunisation against multiple dengue virus serotypes</field><field name="creator">Liew, Steven Christopher</field><field name="description">A major obstacle to the development of dengue virus (DENV) vaccines has been the need to immunise concurrently against each of the four DENV serotypes in order to avoid sensitising recipients to developing severe DENV infections. A problem already encountered with live attenuated tetravalent DENV vaccines has been the difficulty in eliciting adequate immune responses against all four DENV serotypes in human hosts. This could have been due to variations in the antigenicity and/or the replication rates of the four DENV serotypes. Non-replicating DNA vaccines avoid the issue of different replication rates. Currently, only DENV-1 and DENV-2 DNA vaccines have been evaluated. In this study, a number of DNA vaccines for each of the four DENV serotypes were developed and their immunogenicity was evaluated in outbred mice. These vaccines included DNA vaccines encoding the DENV prM-E protein genes derived from the four DENV serotypes (pVAX-DEN1, -DEN2, -DEN3 and -DEN4), and DNA vaccines encoding DENV prM and hybrid-E protein genes derived from multiple DENV serotypes. The hybrid-E protein genes were constructed by substituting either domains I and II, domain III, and/or the stem-anchor region from the E protein of one DENV serotype with the corresponding region from another DENV serotype. A number of superior DNA vaccines against each of the four DENV serotypes were identified based on their ability to elicit high titres (&#8805;40, FFURNT50) of neutralising antibodies against the corresponding DENV in mice. The superior DNA vaccines against DENV-1 were pVAX-DEN1, pVAX-C2M2E211, pVAX-C2M2E122 and pVAX-C2M1E122. The superior DNA vaccine against DENV-2 was pVAX-C2M1E122 and the superior DNA vaccines against DENV-3 were pVAX-DEN3 and pVAX-C2M3E344. The superior DNA vaccines against DENV-4 were pVAX-C2M3E344, pVAX-C2M4E434 and pVAX-C2M4E433. Each of these DNA vaccines could provide effective protection against infection by the corresponding DENV serotypes. This is the first study to describe the development of DNA vaccines against DENV-3 and DENV-4.    However, mice immunised with a tetravalent DENV DNA vaccine, composed of a DNA vaccine encoding the prM-E protein genes from each of the four DENV serotypes (pVAX-DEN1-4), elicited high titres of neutralising antibodies against DENV-1 and DENV-3 only. Nevertheless, the results from this study suggested that a tetravalent DENV DNA vaccine, composed of pVAX-DEN1, pVAX-C2M1E122, pVAX-DEN3 and pVAX-C2M4E434, may provide effective concurrent protection against infection by each of the four DENV serotypes. In addition, mice immunised with pVAX-C2M1E122, which encoded a hybrid-E protein gene derived from DENV-1 and DENV-2, elicited high titres of anti-DENV-1 and anti-DENV-2 neutralising antibodies, and mice immunised with pVAX-C2M3E344, which encoded a hybrid-E protein gene derived from DENV-3 and DENV-4, elicited high titres of anti-DENV-3 and anti-DENV-4 neutralising antibodies. This result suggested that the co-immunisation of these two hybrid-E DNA vaccines also may provide effective concurrent protection against infection by each of the four DENV serotypes. Extracellular E proteins, believed to be in the form of recombinant subviral particles (RSPs), were recovered from the tissue culture supernatant of all DNA vaccine-transfected mammalian cells by ultracentrifugation, except for cells transfected with the pVAX-C2M2E122 hybrid-E DNA vaccine. Western blotting with the monoclonal antibody 4G2 (flavivirus cross-reactive) demonstrated that the extracellular E proteins expressed by the DNA vaccines were synthesized and cleaved in a manner similar to that of native DENV E proteins. In addition, mammalian cells transfected with pVAX-DEN1, pVAX-DEN2 or pVAX-DEN3 secreted higher amounts of extracellular E proteins than cells transfected with pVAX-DEN4. The amount of extracellular E protein secreted by pVAX-DEN4-transfected cells increased when the c-region of the prM/E signal peptidase cleavage site was made more polar. In contrast, decreasing the polarity of the c-region of the C/prM signal peptidase cleavage site of pVAX-DEN4 resulted in no detectable extracellular E proteins from pVAX-DEN4-transfected cells. This result suggested that the amount of extracellular E proteins secreted by cells transfected with DNA expressing the DENV prM-E protein genes may be dependent of the efficiency of C/prM and prM/E protein cleavages by host-derived signal peptidases. Mice immunised with the mutated pVAX-DEN4, which was capable of expressing large amounts of extracellular E proteins in vitro, produced significantly higher concentrations of Th1-type anti-DENV-4 antibodies than mice immunised with the unmodified pVAX-DEN4, but failed to produce detectable levels of anti-DENV-4 neutralising antibodies.    In contrast, increasing the ratio of CpG-S to CpG-N motifs in the pVAX-DEN2 DNA vaccine by incorporating either an additional CpG-S motif, or an antibiotic resistance gene with a high ratio of CpG-S to CpG-N motifs, resulted in a significant increase in both the concentration of Th1-type anti-DENV-2 antibodies and the titres of anti-DENV-2 neutralising antibodies in immunised mice. This result suggested that increasing the amount of CpG-S motifs in DENV DNA vaccines may present an simple and effective approach to increasing the immunogenicity of the DENV DNA vaccines.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">dengue virus</field><field name="subject">dengue vaccine</field><field name="subject">DNA vaccine</field><field name="subject">tetravalent vaccine</field><field name="subject">E protein</field><field name="subject">recombinant subviral particles</field><field name="subject">signal peptide</field><field name="subject">signal peptidases</field><field name="subject">CpG motifs</field><field name="subject">hybrid E proteins</field><field name="identifier">http://eprints.qut.edu.au/16199/</field><field name="validLink">True</field></doc><doc><field name="title">Newborn EEG seizure detection using adaptive time-frequency signal processing</field><field name="creator">Rankine, Luke</field><field name="description">Dysfunction in the central nervous system of the neonate is often first identified through seizures. The diffculty in detecting clinical seizures, which involves the observation of physical manifestations characteristic to newborn seizure, has placed greater emphasis on the detection of newborn electroencephalographic (EEG) seizure. The high incidence of newborn seizure has resulted in considerable mortality and morbidity rates in the neonate. Accurate and rapid diagnosis of neonatal seizure is essential for proper treatment and therapy. This has impelled researchers to investigate possible methods for the automatic detection of newborn EEG seizure. This thesis is focused on the development of algorithms for the automatic detection of newborn EEG seizure using adaptive time-frequency signal processing.  The assessment of newborn EEG seizure detection algorithms requires large datasets of nonseizure and seizure EEG which are not always readily available and often hard to acquire. This has led to the proposition of realistic models of newborn EEG which can be used to create large datasets for the evaluation and comparison of newborn EEG seizure detection algorithms. In this thesis, we develop two simulation methods which produce synthetic newborn EEG background and seizure. The simulation methods use nonlinear and time-frequency signal processing techniques to allow for the demonstrated nonlinear and nonstationary characteristics of the newborn EEG. Atomic decomposition techniques incorporating redundant time-frequency dictionaries are exciting new signal processing methods which deliver adaptive signal representations or approximations. In this thesis we have investigated two prominent atomic decomposition techniques, matching pursuit and basis pursuit, for their possible use in an automatic seizure detection algorithm. In our investigation, it was shown that matching pursuit generally provided the sparsest (i.e. most compact) approximation for various real and synthetic signals over a wide range of signal approximation levels. For this reason, we chose MP as our preferred atomic decomposition technique for this thesis.  A new measure, referred to as structural complexity, which quantifes the level or degree of correlation between signal structures and the decomposition dictionary was proposed. Using the change in structural complexity, a generic method of detecting changes in signal structure was proposed. This detection methodology was then applied to the newborn EEG for the detection of state transition (i.e. nonseizure to seizure state) in the EEG signal.  To optimize the seizure detection process, we developed a time-frequency dictionary that is coherent with the newborn EEG seizure state based on the time-frequency analysis of the newborn EEG seizure. It was shown that using the new coherent time-frequency dictionary and the change in structural complexity, we can detect the transition from nonseizure to seizure states in synthetic and real newborn EEG. Repetitive spiking in the EEG is a classic feature of newborn EEG seizure. Therefore, the automatic detection of spikes can be fundamental in the detection of newborn EEG seizure. The capacity of two adaptive time-frequency signal processing techniques to detect spikes was investigated. It was shown that a relationship between the EEG epoch length and the number of repetitive spikes governs the ability of both matching pursuit and adaptive spectrogram in detecting repetitive spikes. However, it was demonstrated that the law was less restrictive forth eadaptive spectrogram and it was shown to outperform matching pursuit in detecting repetitive spikes.  The method of adapting the window length associated with the adaptive spectrogram used in this thesis was the maximum correlation criterion. It was observed that for the time instants where signal spikes occurred, the optimal window lengths selected by the maximum correlation criterion were small. Therefore, spike detection directly from the adaptive window optimization method was demonstrated and also shown to outperform matching pursuit. An automatic newborn  EEG seizure detection algorithm was proposed based on the detection of repetitive spikes using the adaptive window optimization method. The algorithm shows excellent performance with real EEG data. A comparison of the proposed algorithm with four well documented newborn EEG seizure detection algorithms is provided. The results of the comparison show that the proposed algorithm has significantly better performance than the existing algorithms (i.e. Our proposed algorithm achieved a good detection rate (GDR) of 94% and false detection rate (FDR) of 2.3% compared with the leading algorithm which only produced a GDR of 62% and FDR of 16%). In summary, the novel contribution of this thesis to the fields of time-frequency signal processing and biomedical engineering is the successful development and application of sophisticated algorithms based on adaptive time-frequency signal processing techniques to the solution of automatic newborn EEG seizure detection.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">adaptive</field><field name="subject">atomic decomposition</field><field name="subject">automatic detection</field><field name="subject">electroencephalogram</field><field name="subject">fractal dimension</field><field name="subject">matching pursuit</field><field name="subject">neonate</field><field name="subject">newborn</field><field name="subject">nonlinear</field><field name="subject">nonstationary</field><field name="subject">optimal window scale</field><field name="subject">quadratic time-frequency distribution</field><field name="subject">seizure</field><field name="subject">simulation</field><field name="subject">spike</field><field name="subject">structural complexity</field><field name="subject">time-frequency signal analysis</field><field name="subject">time-frequency signal synthesis</field><field name="identifier">http://eprints.qut.edu.au/16200/</field><field name="validLink">True</field></doc><doc><field name="title">Higher order thinking skills in a science classroom computer simulation</field><field name="creator">Nesbitt-Hawes, Philip John</field><field name="description">Education is rapidly moving away from the instructional models of the 19th century and educationalists are now asserting that not only do students need to be able to learn by rote but also to be able to think in a more profound and complex manner.  Students are required to develop new processes to handle the rapidly changing world that they are expected to take part in as they complete their formal learning.    This change is evident in all the developed nations and Australian students are finding that they are being asked to demonstrate a range of higher order thinking skills in all their school subjects.    Science courses in Queensland require students to be assessed on both complex reasoning and scientific process skills.  Studies have shown that students can develop these skills in a number of ways that include the exposure to appropriate open-ended hands-on tasks.  As higher order thinking skills underlie the development of both complex reasoning and scientific process, it is important that science educators take appropriate steps to facilitate the development of this level of thinking.    This study examined the use of some higher order thinking skills by students using Information Technology in their science classroom.  It investigated the degree to which students used their higher order thinking skills when engaged in a computer simulation of a complex science task.    The study involved two pairs of Year 9 students, one pair each from the upper and lower quartiles of the year level, in a private Years 4 to 12 boys' school in an inner Brisbane suburb.  All students had been immersed in Information Technology in Years 4 to 8 as part of a technology-across-the-curriculum project for all year levels in the school and at the time of the study were at the end of their second semester in Year 9.  Students had worked with a large number of computer applications in all their subjects, averaging about one lesson in the computer room per day across all their subjects for the past year of schooling.  The school also had a policy for learning and teaching that revolved around the development in students of critical thinking and, specifically in Science, complex reasoning, and scientific process skills.    During this study, students engaged in a computer simulation requiring the application of skills and knowledge already learnt in their science course.  The modules of this simulation developed an understanding of the essentials for life and the quantities of a range of items from water to seeds to land areas that would be required for a number of people that would be needed to staff the Lunar Base.  Prompts were given on the way, which assisted students in their decision making.    Students progressed through the various areas and stages of the development of the Lunar Base until they were satisfied that each area supported the others and that there was no imbalance that needed to be corrected.  Once all stages had been completed, students were free to change variables and experiment further as they saw fit in order that they might produce the most self-sufficient Lunar Base possible.    There was some evidence that the simulation did encourage the students in the pairs observed to think in greater depth about the materials and to argue their convictions in an improved manner.    As well as the students appearing to increase in competency in argument over the period of time, the four students in their final interviews, spoke of feeling satisfied with the results of the lessons.  The students also appeared more engrossed in their task and the pedagogy provided in the task was appreciated as it gave meaning to why they were required to learn scientific materials as well also presenting them with ways to find the knowledge for themselves.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Argumentation</field><field name="subject">computer instruction</field><field name="subject">computer simulations</field><field name="subject">critical thinking</field><field name="subject">higher order thinking skills</field><field name="subject">scientific reasoning</field><field name="subject">secondary science</field><field name="subject">senior biology</field><field name="subject">social construction</field><field name="identifier">http://eprints.qut.edu.au/16201/</field><field name="validLink">True</field></doc><doc><field name="title">Development of an optimal spatial decision-making system using approximate reasoning</field><field name="creator">Bailey, David Thomas</field><field name="description">There is a recognised need for the continued improvement of both the techniques and technology for spatial decision support in infrastructure site selection. Many authors have noted that current methodologies are inadequate for real-world site selection decisions carried out by heterogeneous groups of decision-makers under uncertainty. Nevertheless despite numerous limitations inherent in current spatial problem solving methods, spatial decision support systems have been proven to increase decision-maker effectiveness when used. However, due to the real or perceived difficulty of using these systems few applications are actually in use to support decision-makers in siting decisions. The most common difficulties encountered involve standardising criterion ratings, and communicating results. This research has focused on the use of Approximate Reasoning to improve the techniques and technology of spatial decision support, and make them easier to use and understand. The algorithm developed in this research (ARAISS) is based on the use of natural language to describe problem variables such as suitability, certainty, risk and consensus. The algorithm uses a method based on type II fuzzy sets to represent problem variables. ARAISS was subsequently incorporated into a new Spatial Decision Support System (InfraPlanner) and validated by use in a real-world site selection problem at Australia's Brisbane Airport. Results indicate that Approximate Reasoning is a promising method for spatial infrastructure planning decisions. Natural language inputs and outputs, combined with an easily understandable multiple decision-maker framework created an environment conducive to information sharing and consensus building among parties. Future research should focus on the use of Genetic Algorithms and other Artificial Intelligence techniques to broaden the scope of existing work.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">spatial decision-making system</field><field name="subject">approximate reasoning</field><field name="subject">ARAISS</field><field name="subject">Brisbane Airport</field><field name="subject">Artificial Intelligence</field><field name="identifier">http://eprints.qut.edu.au/16202/</field><field name="validLink">True</field></doc><doc><field name="title">Corneal topography and the morphology of the palpebral fissure</field><field name="creator">Read, Scott A.</field><field name="description">The notion that forces from the eyelids can alter the shape of the cornea has been proposed for many years. In recent times, there has been a marked improvement in our ability to measure and define the corneal shape, allowing subtle changes in the cornea to be measured. These improvements have led to the findings that pressure from the eyelids can cause alterations in corneal shape following everyday visual tasks such as reading. There are also theories to suggest that pressure from the eyelids may be involved in the aetiology of corneal astigmatism. In this program of research, a series of experiments were undertaken to investigate the influence of the eyelids on the shape of the cornea.  In the first experiment, an investigation into the diurnal variation of corneal shape was carried out by measuring corneal topography at three different times (approximately 9 am, 1 pm and 5 pm) during the day over three days of the week (Monday, Tuesday and Friday). Highly significant diurnal changes were found to occur in the corneal topography of 15 of the 17 subjects. This change typically consisted of horizontal bands of distortion in the superior, and to a lesser extent, inferior cornea, increasing throughout the day (and returning to baseline the next morning). These changes appeared to be related to forces from the eyelids on the anterior cornea. Some changes were also found in corneal astigmatism. Corneal astigmatism power vector J0 (astigmatism 90/180&#176;) was found to increase slightly over the course of the week. Whilst the changes in astigmatism were small in magnitude, this result leaves open the possibility that pressure from the eyelid may cause changes in corneal astigmatism. If pressure from the eyelids is involved in the aetiology of corneal astigmatism, then one may expect associations to exist between certain characteristics of the eyelids and corneal shape. An experiment was then undertaken to explore these possible associations.  We defined the average morphology of the palpebral fissure in different angles of vertical gaze for 100 young normal subjects. This was achieved through analysis of digital images that were captured in primary gaze, 20&#176; downgaze and 40&#176; downgaze. Parameters defining the size, position, angle and contour of the eyelids were determined. Highly significant changes were found to occur in the palpebral fissure with downward gaze. The palpebral aperture narrows in downward gaze, and the angle of the eyelids changes from being slightly upward slanted in primary gaze, to being slightly downward slanted in downward gaze. The eyelid margin contour also flattens significantly in downward gaze.  The average topography of the central and peripheral cornea was also defined for this same population. A technique was used that allowed the capture and subsequent combination of topography data from both the central and the peripheral cornea. The use of this technique provided a large corneal topography map, with data extending close to the limbus for each subject. Marked flattening was found to occur in the peripheral cornea and a conic section was found to be a poor descriptor of corneal contour in the periphery (i.e. greater than 6 mm diameter). Corneal astigmatism was also found on average to reduce in the periphery. However a number of distinct patterns of peripheral corneal astigmatism were noted in the population. Corneal astigmatism in the peripheral cornea was either found to remain stable (59% of subjects), increase (10% of subjects) or reduce (31% of subjects) in magnitude in comparison to the amount of central corneal astigmatism.  We also investigated associations between the parameters defining the palpebral fissure and parameters describing corneal shape in this population of subjects. A number of highly significant associations were found between the morphology of the palpebral fissure in primary gaze and the shape of the cornea. A general tendency was found for subjects with wider horizontal palpebral fissure widths to exhibit larger corneas and also flatter central corneal powers. There were also highly significant associations found between the angle of the eyelids and the axis of corneal astigmatism, but not the magnitude of corneal astigmatism. The associations found between corneal astigmatism and palpebral fissure morphology is further evidence supporting the hypothesis that pressure from the eyelids is involved in the aetiology of corneal astigmatism.  The results of these investigations have shown that corneal changes as a result of eyelid forces occur in the majority of young subjects tested over the course of a normal working day. The average morphology of the palpebral fissure and topography of the central and peripheral cornea has also been defined in detail for a large population of young subjects. Significant associations were found between corneal astigmatism and the morphology of the palpebral fissure. Whilst these results support a model of corneal astigmatism development based on eyelid morphology, they do not prove causation. Further research including measurement of eyelid pressure and corneal rigidity may aid in understanding the exact aetiology of the magnitude and axis of corneal astigmatism.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">cornea</field><field name="subject">astigmatism</field><field name="subject">aberrations</field><field name="subject">eyelids</field><field name="subject">corneal topography</field><field name="subject">videokeratoscopy</field><field name="subject">digital imaging</field><field name="subject">eyelid morphology</field><field name="identifier">http://eprints.qut.edu.au/16203/</field><field name="validLink">True</field></doc><doc><field name="title">The museum of the personal : souvenirs and nostalgia</field><field name="creator">Benson, Tracey</field><field name="description">This research paper examines the role of the souvenir in terms of social relations and notions of self-identity and/or autobiography. Many types of souvenir objects (commercial and non-commercial) are explored as being agents that participate in the construction of identity.  Commodity fetishism, nostalgia and fetishism are examined as key elements that define the social relations surrounding the souvenir. The notion of home and family is also explored as a fundamental aspect of how identity is constructed.</field><field name="date">2001</field><field name="language" /><field name="relation" /><field name="subject">souvenir</field><field name="subject">keepsake</field><field name="subject">memento</field><field name="subject">nostalgia</field><field name="subject">fetishism</field><field name="subject">commodity fetishism</field><field name="identifier">http://eprints.qut.edu.au/16204/</field><field name="validLink">True</field></doc><doc><field name="title">Estimation of the parameters of stochastic differential equations</field><field name="creator">Jeisman, Joseph Ian</field><field name="description">Stochastic di&#174;erential equations (SDEs) are&#12288;central to much of modern finance theory and have been widely used to model the behaviour of key variables such as the&#12288;instantaneous short-term interest rate, asset prices, asset returns and their volatility.&#12288;The explanatory and/or predictive power of these models depends crucially on the particularisation of the model SDE(s) to real data through the choice of values for their  parameters. In econometrics, optimal parameter estimates are generally considered to&#12288;be those that maximise the likelihood of the sample. In the context of the estimation of the parameters of SDEs, however, a closed-form expression for the likelihood&#12288;function is rarely available and hence exact maximum-likelihood (EML) estimation is  usually infeasible. The key research problem examined in this thesis is the development  of generic, accurate and computationally feasible estimation procedures based on the&#12288;ML principle, that can be implemented in the absence of a closed-form expression for&#12288;the likelihood function. The overall recommendation to come out of the thesis is that&#12288;an estimation procedure based on the finite-element solution of a reformulation of the Fokker-Planck equation in terms of the transitional cumulative distribution function(CDF) provides the best balance across all of the desired characteristics. The recommended approach involves the use of an interpolation technique proposed in this thesis which greatly reduces the required computational effort.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">stochastic differential equations</field><field name="subject">parameter estimation</field><field name="subject">maximum likelihood</field><field name="subject">finite difference</field><field name="subject">finite element</field><field name="subject">cumulative distribution function</field><field name="subject">interpolation</field><field name="identifier">http://eprints.qut.edu.au/16205/</field><field name="validLink">True</field></doc><doc><field name="title">Efficient biomorphic vision for autonomous mobile robots</field><field name="creator">Mikhalsky, Maxim</field><field name="description">Autonomy is the most enabling and the least developed robot capability. A mobile robot is  autonomous if capable of independently attaining its objectives in unpredictable environment.  This requires interaction with the environment by sensing, assessing, and responding to events.  Such interaction has not been achieved. The core problem consists in limited understanding of  robot autonomy and its aspects, and is exacerbated by the limited resources available in a small  autonomous mobile robot such as energy, information, and space.  This thesis describes an efficient biomorphic visual capability that can provide purposeful  interaction with environment for a small autonomous mobile robot. The method used for  achieving this capability comprises synthesis of an integral paradigm of a purposeful autonomous  mobile robot, formulation of requirements for the visual capability, and development of efficient  algorithmic and technological solutions. The paradigm is a product of analysis of fundamental  aspects of the problem, and the insights found in inherently autonomous biological organisms.  Based on this paradigm, analysis of the biological vision and the available technological basis,  and the state-of-the-art in vision algorithms, the requirements were formulated for a biomorphic  visual capability that provides the situation awareness capability for a small autonomous mobile  robot. The developed visual capability is comprised of a sensory and processing architecture, an integral set of motion vision algorithms, and a method for visual ranging of still objects that is based on them. These vision algorithms provide motion detection, fixation, and tracking functionality with low latency and computational complexity. High temporal resolution of CMOS imagers is exploited for reducing the logical complexity of image analysis, and consequently the computational complexity of the algorithms. The structure of the developed algorithms conforms to the arithmetic and memory resources available in a system on a programmable chip (SoPC), which allows complete confinement of the high-bandwidth datapath within a SoPC device and therefore high-speed operation by design. The algorithms proved to be functional, which validates the developed visual capability. The experiments confirm that high temporal resolution  imaging simplifies image motion structure, and ultimately the design of the robot vision system.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">autonomy</field><field name="subject">mobile robot</field><field name="subject">biomorphic vision</field><field name="subject">robot vision system</field><field name="identifier">http://eprints.qut.edu.au/16206/</field><field name="validLink">True</field></doc><doc><field name="title">Overcoming problems with limiting DNA samples in forensics and clinical diagnostics using multiple displacement amplification</field><field name="creator">Muharam, Firman Alamsyah</field><field name="description">The availability of DNA samples that are of adequate quality and quantity is essential for any genetic analysis. The fields of forensic biology and clinical diagnostic pathology testing often suffer from limited samples that yield insufficient DNA material to allow extensive analysis. This study examined the utility of a recently introduced whole genome amplification method termed Multiple Displacement Amplification (MDA) for amplifying a variety of limited sample types that are commonly encountered in the fields of forensic biology and clinical diagnostics. The MDA reaction, which employs the highly processive bacteriophage &#966;29 DNA polymerase, was found to generate high molecular weight template DNA suitable for a variety of downstream applications from low copy number DNA samples down to the single genome level. MDA of single cells yielded sufficient DNA for up to 20,000,000 PCR assays, allowing further confirmatory testing on samples of limited quantities or the archiving of precious DNA material for future work. The amplification of  degraded DNA material using MDA identified a requirement for samples of sufficient quality to allow successful synthesis of product DNA templates. Furthermore, the utility of MDA products in comparative genomic hybridisation  (CGH) assays identified the presence of amplification bias. However, this bias was overcome by introducing a novel modification to the MDA protocol. Future directions for this work include investigations into the utility of MDA products in short tandem repeat (STR) assays for human identifications and application of the modified MDA protocol for testing of single cell samples for genetic abnormalities.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">whole genome amplification</field><field name="subject">multiple displacement amplification</field><field name="subject">&#966;29</field><field name="subject">phi29</field><field name="subject">DNA polymerase</field><field name="subject">single cell</field><field name="subject">low copy number</field><field name="subject">DNA</field><field name="subject">PCR</field><field name="subject">forensic biology</field><field name="subject">forensic science</field><field name="subject">clinical diagnostics</field><field name="subject">comparative genomic hybridisation</field><field name="identifier">http://eprints.qut.edu.au/16207/</field><field name="validLink">True</field></doc><doc><field name="title">Unanticipated evolution of web service provision software using generative object communication</field><field name="creator">Bradford, Lindsay William</field><field name="description">Providing service via theWeb differs from other service provision environments in that it is possible for the unexpected arrival of a massive number of service requests in a small time-frame, a situation commonly referred to as a flash crowd. Events of this nature are beyond the control of the service provider, and have the potential to severely degrade service quality and, in the worst case, to deny service to all clients completely.  The occurrence, severity and sought Web content of a flash crowd is beyond the control of service provision software. How this software reacts to such a flash crowd, however, is not. Given the short-lived nature of flash crowds, it is unreasonable to expect such systems to increase the system resources they can apply to a particular flash crowd event. It is also difficult to predict the particular nature of any flash crowd, and subsequently which system resources will bottleneck. The driving hypothesis of this research is that, if we are to reasonably expect to have software react effectively to flash crowd events, we need to alter that software at runtime to remove system bottlenecks, whilst a flash crowd event is in progress. This is a special case of what is usually known as "unanticipated software evolution". This thesis reports on an investigation into how unanticipated software evolution can be applied to running Web service provision software to remove system bottlenecks.  It does so by introducing automated dynamic Web content degradation to running software currently subject to simulated flash crowd events. The thesis describes and validates appropriate runtime extensions to allow generative object communication architectures (a promising class of architecture for unanticipated software evolution)  to be converted initially into a Web application server, and then later accept further runtime behaviour changes. Such changes could alter system bottlenecks by replacing the key programming logic causing system bottlenecks at runtime.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">unanticipated software evolution</field><field name="subject">generative object communication</field><field name="subject">Web scalability</field><field name="subject">flash crowds</field><field name="subject">dynamic Web content degradation</field><field name="subject">user-perceived quality of service</field><field name="identifier">http://eprints.qut.edu.au/16208/</field><field name="validLink">True</field></doc><doc><field name="title">Responsibility for learning : students' understandings and their self-reported learning attitudes and behaviours</field><field name="creator">Allan, Gary Mitchell</field><field name="description">This study investigated a number of important research questions that were prompted by the existing literature relating to the concept of responsibility for learning. Such literature has highlighted the importance of promoting personal responsibility for learning to not only students as individuals but also to the direction of education and pedagogy in general. The literature has also shown a broad concern over students&#8217; apparent lack of responsibility as well as a lack of consensus over the precise meaning of this concept. The present study addresses gaps in the literature by exploring the following specific issues: firstly, What are students&#8217; understandings of the concept of responsibility for learning?; secondly, How have students reported their own learning related attitudes and behaviours?; and thirdly, What are the associations between students&#8217; understandings and their self-reports? It was also intended that data collected for the first two research questions would enable the investigation of year level and gender differences. 
 
 With a methodology based on a written survey design, this study collected data from a sample of some 286 students from Australian schools in both the Primary and Secondary sectors (comprising Years 5, 7, 9 and 11). The process of data collection involved participants completing one open-ended question and two newly developed Likert-type response questionnaires that incorporated 40 individual descriptive items that were associated with six distinct subscales (i.e., Orientation Towards Schools and Learning; Active Participation in Learning Activities; Autonomy and Personal Control of Learning; Initiative; Management of Learning Resources; and Cooperation and Control of Classroom Behaviour). One scale (the SURLQ), along with the open-ended question, measured students&#8217; understandings of Responsibility For Learning and the other scale (the SRLABQ) measured students&#8217; perceptions of their own learning related attitudes and behaviours.
 
 The data pertaining to the first research question was analysed in two distinct ways. Firstly, students&#8217; responses to the open-ended question were analysed qualitatively by sorting and tallying their original responses according to a determination of the themes and descriptors offered. Secondly, the responses to the SURLQ were analysed quantitatively by calculating the mean and standard deviation scores for all 40 descriptive items and hence the six subscales. Similar quantitative statistical analysis procedures were applied to the data pertaining to students&#8217; self-reported learning attitudes and behaviours (i.e., the SRLABQ). Reliability coefficients for the SURLQ and the SRLABQ were also calculated. Descriptive data for the subscales of these two measures were cross-tabulated by year level and gender to determine whether statistically significant differences were evident. Cohen&#8217;s Effect Size calculations were applied to such differences. Statistically significant interactions between these independent variables were determined by Multivariate analysis of variance techniques. The third research question was investigated by applying correlation analysis to the mean scores of corresponding subscales and by calculating the differences between the same sets of mean scores.
 
 With respect to the first research question, it was found that according to both sets of data, students&#8217; understandings of responsibility for learning generally supported a primarily behavioural perspective that emphasised a high degree of application to learning and relating sociably with others in the classroom. Although the SURLQ data also showed a greater acknowledgement of attitudinal components, it was noted that according to data from the two questionnaires, students did not readily associate responsible learners with being autonomous and having personal control of learning (as does the literature). With respect to the second research question, it was found that students reported themselves to be reasonably responsible learners as evidenced by the moderately high scores collected in all of the six responsibility for learning subscales. This finding led to the conclusion that the concerns expressed in the literature over students&#8217; lack of responsibility in the classroom are not perceived by the students themselves. As the data pertaining to the third research question showed a reasonable correlation between students&#8217; understandings of responsibility for learning and their self-reported learning attitudes and behaviours, it was concluded that students were likely to view themselves as responsible learners in a way that reflects their understandings of the concept. 
 
 It was concluded that this research has important implications for all stakeholders in education. Although this study makes a major contribution to defining and describing responsibility for learning, it is evident that a lack of consensus in understanding between key stakeholders groups (i.e., researchers, educators and students) still exists. The divergence of outlook between students and various elements of the literature reinforces the need for further research to be conducted to determine the relative acceptance of behavioural compliance (and/or prudence) in the classroom versus personal control and accountability with respect to learning. It is also argued that such work would be integral to educators having a clear and unambiguous understanding of responsibility for learning so that the enhancement of this quality in students may take place in classrooms of the future.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">personal responsibility for learning</field><field name="subject">autonomy</field><field name="subject">self-directed learning</field><field name="subject">self-regulated learning</field><field name="subject">choice and personal decision-making</field><field name="subject">intrinsic motivation</field><field name="identifier">http://eprints.qut.edu.au/16209/</field><field name="validLink">True</field></doc><doc><field name="title">A peer-to-peer software framework for cooperative robotic system</field><field name="creator">Zhu, Julie</field><field name="description">Recent developments in embedded systems give robots access to the Internet and make them more flexible and capable of performing more complex applications. However, these robots are still limited in terms of size, CPU power, storage resources and memory. Consequently, these robots have only been manufactured for certain specific applications and cannot be re-used for other applications. This presents us with a challenge to design a software framework - Robot Colony.  The Robot Colony enables robots to be suitable for a wide range of applications, not originally received from manufacturers, to achieve greater functionality, flexibility and utility. This research outlines the architecture and functionality of the Robot Colony to support the collaboration between devices in the P2P community and also analyse the JXTA platform, which was the framework originally proposed.  Lastly we present a customized P2P architecture that specifically addresses the interaction betweensoftware components across the network. We further discuss the following technologies applied in theframework:  * XML-based Directory Service Provider  * HTTP-based publish/describe control commands  * Remote Process Invoke  To fully complete the project, a thorough evaluation of the framework based on either the JXTAplatform or the customized P2P channel has been conducted. This evaluation provides basic statistics data for the proposed framework design and implementation. Further more, we have presented a realtime Demo at the Smart Device lab of the Queensland University of Technology.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">peer-to-peer</field><field name="subject">JXTA</field><field name="subject">JINI</field><field name="subject">XML</field><field name="subject">RPC</field><field name="subject">WWW</field><field name="subject">RMI</field><field name="subject">UPnP</field><field name="subject">salutation</field><field name="subject">SOAP</field><field name="subject">instant messaging</field><field name="subject">filesharing</field><field name="subject">distributed computing</field><field name="subject">MAS</field><field name="subject">agent</field><field name="identifier">http://eprints.qut.edu.au/16210/</field><field name="validLink">True</field></doc><doc><field name="title">Case-only study of interactions between specific genetic polymorphisms and cigarette smoking in the aetiology of Parkinson's disease</field><field name="creator">Deng, Yifu</field><field name="description">The aetiology of Parkinson's disease (PD) is still unclear. Research findings suggest that both environmental and genetic factors may contribute to its development. The interactions between genes and the environment might exist and play a key role. Cigarette smoking was found to be one of the few factors exhibiting a protective effect. If chemical compounds found in cigarette smoke influence PD risk, the difference in the ability of certain individuals in metabolising these substances might alter their susceptibility to the risk of developing PD. Many metabolic enzyme genes exhibit polymorphic traits with alteration of gene function. These might be associated with an altered susceptibility of individuals to PD. Few studies have examined the hypothesis that metabolic enzyme gene polymorphisms might modulate the effect of smoking on PD risk. However, it is crucial to consider these potential interactions when we try to elucidate the aetiology of PD.  Even if each factor only contributes a slight variation and influences a small portion of the whole population, non-linear and unpredictable interactions may account for a high proportion of the aetiological fraction.  Previous studies have not been strictly designed to examine the interactions between smoking and metabolic enzyme genetic polymorphisms. These studies have not been able to elucidate the extent of the interaction. Therefore, this PhD project attempted to examine whether genetic factors, operating in the phase one and phase two metabolic pathways, interact with smoking to influence the development of PD. This is the first genetic epidemiological study of PD specifically addressing this issue. The research aids in further understanding the aetiology of PD and may be useful for identifying people at higher risk. A case-only design was chosen for this project for two reasons:  first, PD is a relatively rare disease and the case-only design is much more efficient at detecting gene-environment interactions; second, the PD cases for the project were recruited over the past few years and represent a prevalence series, for which an appropriate comparison group for the cases is difficult to identify and recruit. In a case-only study, only cases are used to investigate the multiplicative effects of the exposures and susceptible genotypes of interest, while non-case subjects (traditionally controls) are solely used to test the independence between the exposure and the susceptible genotype. Therefore, this approach avoids the challenges of control selection, a major limitation inherent in the case-control approach. This thesis comprised of three independent studies: the first study investigated the interactions between genetic polymorphisms of GSTM1, P1, T1 and Z1 and smoking in PD; the second study examined the interactions between genetic polymorphisms of CYP2E1 and smoking in PD; and the third study examined the interactions between genetic polymorphisms of CYP2D6 and smoking in PD. The first two studies recruited 400 white Caucasian PD cases from both hospital wards and private neurology clinics (230 men and 170 women). The third study further included 142 white Caucasian PD cases newly recruited from the same sources (542 in total, 321 men, and 221 women). The mean age of cases was 67 years with the average onset age at 60 years. GSTM1, GSTP1, GSTT1, GSTZ1 AND CYP2E1 genotyping processes were performed using protocols previously published with minor modification, whereas CYP2D6 genotyping methods were mainly developed by me with assistance from associate supervisor Dr. George Mellick. Reliability and validity of the PCR and RFLP methods were assessed through re-conducting the genotype assays using at least a 10% sample of our DNA samples. The results for all re-assessments were 100% concordant.  Crude bivariate analyses were adjusted for potential confounding effects of the variables, including age at onset, gender, family history of PD and pesticide exposures. Among our unaffected, aged subjects (mean age: 63.9 years, sd: 11.4 years), the genotype frequencies at each locus were similar to those reported in other Caucasian populations. The first study showed that the proportion of carriers of the GSTP1-114Val allele (mutant) increased with increasing smoking dose from 0 to  &gt; 30 pack-years. Homozygotes of the 114Ala allele (wild-type) decreased with increasing smoking dose (trend test: p=0.02). This trend existed both in male and female cases. This dose-effect relationship was most significant in the group of cases with late-onset PD (i.e., age at onset  &gt; 55 years) with the ORicase-only values of 1.88 (95%CI: 0.65-5.48) and 2.63 (95%CI: 1.07-6.49) for  &gt; 0-10 and  &gt; 10 pack-years, respectively. No similar trend was found among our unaffected, aged subjects (p=0.42). Haplotype analyses revealed significant differences for GSTP1 haplotypes between smoking and non-smoking PD cases (ORicase-only for *C haplotype=2.00 (95%CI: 1.11-3.60), p=0.03). In this case, smoking-exposed PD cases were more likely to posses the *C haplotype defined by A to G base-pair transition at nucleotide +313 and C to T base-pair transition at nucleotide +341 (at amino acid level, valine at both positions 105 and 114). The second study found no difference in CYP2E1 genotype frequencies between PD cases who ever smoked compared to those who never smoked (odds ratio for interaction (ORi) = 1.00 (95% CI: 0.39-2.51, p=0.99)). No CYP2E1 gene-smoking interactions were detected in relation to age at onset of PD. The third study found that among cases without regular pesticide exposures, CYP2D6 PMs who smoked more than 5 pack-years had a later mean age at disease onset (68.6 years) than those with extensive metaboliser phenotypes (EMs) (61.1 years, p=0.02) and non-smokers (60.5 years, p=0.01). Analysis of aged subjects without PD confirmed that neither smoking status nor CYP2D6 PM status was associated with age itself.  Our data suggest: 1. smoking exposure is independent of GSTM1, P1, T1, Z1 and CYP2E1 genotypes; 2. smoking may be, to some extent, associated with CYP2D6 genotypes; 3. there are no multiplicative interactive effects linking smoking and GSTM1, T1, Z1 or CYP2E1 genotypes with the risk for PD; 4. there is a multiplicative interactive effect between smoking and GSTP1 haplotype - particularly for genotypes carrying the 114Val allele; and 5. there is a multiplicative interactive effect between smoking and CYP2D6 PMs - particularly for people who ever smoked cigarettes more than 5 pack-years. In general, this thesis provides a model for exploring the gene-smoking interactions in PD. Further studies need to consider the recruitment of a large number of population-based and randomly-selected samples and to pay more attention to measurement of environmental exposures. Further studies also need to examine simultaneously the impact of smoking, pesticide exposures and other potential risk factors on PD. These studies will build evidence for interactions contributing to this common neurological movement disorder.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Parkinson&#146;s disease</field><field name="subject">smoking</field><field name="subject">GSTM1</field><field name="subject">GSTP1</field><field name="subject">GSTT1</field><field name="subject">GSTZ1</field><field name="subject">CYP2D6</field><field name="subject">CYP2E1</field><field name="subject">gene-environment interaction</field><field name="identifier">http://eprints.qut.edu.au/16211/</field><field name="validLink">True</field></doc><doc><field name="title">Experimental studies and modelling of innovative peeling processes for tough-skinned vegetables</field><field name="creator">Emadi, Bagher</field><field name="description">Tough-skinned vegetables such as pumpkin and melon currently are peeled either semi-automatically or automatically. The main limitation of both methods, especially for varieties with an uneven surface, is high peeling losses.    Improvement of current mechanical peeling methods and development of new mechanical methods for tough-skinned vegetables which are close to the "ideal" peeling conditions using mechanical properties of the product were the main objectives of this research.    This research has developed four innovative mechanical peeling methods on the basis of the mechanical properties of tough-skinned vegetables. For the first time, an abrasive-cutter brush has been introduced as the best peeling method of tough-skinned vegetables. This device simultaneously applies abrasive and cutting forces to remove the peel. The same peeling efficiency at concave and convex areas in addition to high productivity are the main advantages of the developed method. The developed peeling method is environmentally friendly, as it minimises water consumption and peeling wastes.    The peeling process using this method has been simulated in a mathematical model and the significant influencing parameters have been determined. The parameters are related to either the product or peeler. Those parameters appeared as the coefficients of a linear regression model. The coefficients have been determined for Jap and Jarrahdale as two varieties of pumpkin. The mathematical model has been verified by experimental results.    The successful implementation of this research has provided essential information for the design and manufacture of a commercial peeler for tough-skinned vegetables. It is anticipated that the abrasive-cutting method and the mathematical model will be put into practical use in the food processing industry, enabling peeling of tough-skinned vegetables to be optimised and potentially saving the food industry millions of dollars in tough-skinned vegetable peeling processes.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">peeling</field><field name="subject">mechanical peeling</field><field name="subject">abrasive peeling</field><field name="subject">mechanical properties</field><field name="subject">tough-skinned vegetables</field><field name="subject">model</field><field name="subject">mathematical model</field><field name="subject">peeling rate</field><field name="subject">peeling efficiency</field><field name="subject">peel losses</field><field name="subject">pumpkin</field><field name="subject">melon</field><field name="identifier">http://eprints.qut.edu.au/16212/</field><field name="validLink">True</field></doc><doc><field name="title">How is leadership understood and enacted within the field of early childhood education and care</field><field name="creator">Hard, Louise</field><field name="description">The field of Early Childhood Education and Care (ECEC) traditionally encompasses care and education for children aged from birth to eight years.  In this study, the focus is specifically on the field that provides services for children in prior to school settings, that being the birth to five sector.  This sector is highly feminised and has emerged over the last century from philanthropic roots.  Despite considerable work into leadership in other areas, until recent times, attention to aspects of leadership has been limited within the ECEC field and much of the research undertaken has focused heavily on centre-based leadership.  This study investigated how personnel, from a range of services, understand and enact leadership.  In terms of data analysis it draws heavily on symbolic interactionism as a methodological tool and engages standpoint feminist theory to inform the analytical process. Data were gathered from semi-structured interviews with twenty-six participants who also identified artefacts, which they considered influenced and supported their understandings of leadership.  In addition, two focus groups were conducted to explore themes emerging from early analysis of the data.  Findings indicate two categories, which emerge as relevant to how leadership is understood and enacted by participants.  The first of these is the concept of interpreted professional identity, which reflects participants' interpretations of who they are as early childhood professionals informed by their own views and the views of others.  How individuals interpret their sense of self (manifest in their professional identity) is influential in the secondary category, which is interpreted leadership capacity.  This category reflects participants' leadership activity or inactivity.  The analysis reflects a complex interplay between how participants interpret their professional sense of self (interpreted professional identity) and their capacity and willingness to enact leadership (interpreted leadership capacity).  Individuals in the formation of their professional identity interpret factors, both internal to the ECEC field and external (through social expectations).  The culture of the ECEC field (internal factors) includes competing elements such as a discourse of niceness juxtaposed against examples of horizontal violence.  Factors external to the field suggest there are lingering social associations between heroic male images and leadership, which make women as leaders problematic.  Within a highly feminised field such as ECEC, this study brings new perspectives to understandings of leadership and its enactment.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">leadership</field><field name="subject">early childhood education and care</field><field name="subject">symbolic interactionism</field><field name="subject">standpoint feminist theory</field><field name="subject">interpreted professional identity</field><field name="subject">agency</field><field name="subject">hesitancy</field><field name="subject">interpreted leadership capacity</field><field name="subject">horizontal violence</field><field name="identifier">http://eprints.qut.edu.au/16213/</field><field name="validLink">True</field></doc><doc><field name="title">A finite element and experimental investigation of the femoral component mechanics in a total hip arthroplasty</field><field name="creator">Bell, Cameron Gordon</field><field name="description">Total hip arthroplasty (THA) is a successful surgical technique that can be used for the effective treatment of fractured neck of femur, osteoarthritis, tumours, avascular necrosis, failed internal fixation, developmental dysplasia and rheumatoid arthritis.  Revision surgery is necessary if loosening allows relative motion between the femoral stem and femur, causing pain and mechanical instability of the THA.  The large number of revision operations undertaken each year as a result of implant failure emphasises the need for better biomechanical understanding of the femoral implant system.  During 2001-02 in Australia 26,689 hip replacement operations were performed, with 3,710 of these being revision operations.  The Exeter stem is the most commonly used cemented stem for primary and revision hip replacement in Australia.  It is therefore very important to understand the mechanics of this clinically successful implant.  Few studies have presented a through investigation into the mechanics of the Exeter stem from a fundamental perspective.  To address these issues, mechanical and finite element (FE) methods were used to conduct experiments and numerical investigations into the mechanics of the Exeter stem.  The femur geometry, for both the experimental and FE studies, was based upon the Sawbones model 3303 medium left third generation femur.  The stem orientation for all specimens of the study was replicated from the orientation achieved by the senior surgeon implanting into the Sawbones femur.  Test rigs were designed specifically to constrain the femur for the purposes of loading and stability measurements.  The experimental investigation was used to investigate the torsional mechanical stability of the stem and to monitor this stability following periods of cyclic loading, using a resultant hip contact force, while monitoring the distal migration of the stem.  The experimental investigation was also able to provide data for the validation of the finite element model.  The resultant hip contact force was represented experimentally by a cyclic load of 1Hz applied to the head of the implant.  The specimen was tested for four days.  The loading regime for the initially implanted specimen involved the application of load for 6 hours a day, allowing the specimen to relax under no load for 18 hours a day.  The mechanical stability of the initially implanted specimen was tested prior to the application of the cyclic load and immediately after the loading periods, prior to relaxation.  Further tests were undertaken to assess the mechanical stability of the stem following the removal and reimplantation of the same stem without the use of additional bone cement (a procedure used surgically when only the acetabular component requires replacement).  The reimplanted specimens were tested for a further two days following reimplantation.  The six hours of loading for the reimplanted specimen was achieved using three, two hour loading periods.  The stability of the reimplaned stem was assessed following each loading period. Initial studies found that the material properties of the Sawbones femurs were highly temperature dependent.  If the temperature of the short glass fibre reinforced (SGFR) epoxy used for the cortical bone analogue was increased from room temperature to body temperature there was a reduction in the Young's modulus of up to 37 percent.  This finding led to further investigation into the strain state of the femur for varus and neutral stem orientations to reduce femur failure during cyclic loading.  The strains of the varus stem orientation were found to be higher than the strains of the neutral stem.  The experiments investigating the mechanical stability under cyclic loading continued using the neutral stem orientation.  For the neutral stem orientation it was found that there was no perceivable variation in the torsional stiffness of the initially implanted system during the cyclic loading period even though distal migration was observed.  Torsional stiffness was observed to be compromised immediately after reimplantation.  However, the torsional stiffness of the reimplanted specimen was recovered within the first two hour loading period.  No perceivable variation in the torsional stiffness was observed between the initially implanted specimens and the reimplanted specimens following the first two hours of loading.  The finite element model (FEM) found good agreement with the experimental investigation in terms of measured strain at two of three rosette positions and failure of the cortical bone.  Trends for the stress-strain state of the stem showed good agreement with the clinical findings of failure and wear of the stem.  The stress-strain state of the cement predicted the expected compressive and hoop stresses once debonding of the stem-cement interface had progressed.  Strain on the surface of the femur was well predicted for pure torsional loading.  The FEM has provided a valuable tool for future investigation of the effect of factors such as implant positioning on femoral component mechanics.    The experimental and finite element models developed within the scope of this project have provided a powerful analysis tool for the investigation of the femoral component mechanics in THA.  Application of the model to clinically relevant problems has given valuable insight into the mechanisms behind the success of this particular implant type.  Models such as this will provide information on implant failure modes that will further lead to an increased implant life expectancy and a reduction in the number of revision operations performed.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">total hip replacement</field><field name="subject">femoral component</field><field name="subject">biomechanics</field><field name="subject">finite element analysis</field><field name="identifier">http://eprints.qut.edu.au/16214/</field><field name="validLink">True</field></doc><doc><field name="title">Inferring biogeography from the evolutionary history of the giant freshwater prawn (macrobrachium rosenbergii)</field><field name="creator">de Bruyn, Mark</field><field name="description">The discipline of historical biogeography seeks to understand the contribution of earth history to the generation of biodiversity. Traditionally, the study of historical biogeography has been approached by examining the distribution of a biota at or above the species level. While this approach has provided important insights into the relationship between biological diversity and earth history, a significant amount of information recorded below the species level (intraspecific variation), regarding the biogeographical history of a region, may be lost. The application of phylogeography - which considers information recorded below the species level - goes some way to addressing this problem. Patterns of intraspecific molecular variation in wide-ranging taxa can be useful for inferring biogeography, and can also be used to test competing biogeographical hypotheses (often based on the dispersal-vicariance debate). Moreover, it is argued here that phylogeographical studies have recently begun to unite these two disparate views, in the recognition that both dispersal and vicariance have played fundamental roles in the generation of biodiversity.  Freshwater dependent taxa are ideal model organisms for the current field of research, as they reflect well the underlying biogeographical history of a given region, due to limited dispersal abilities - their requirement for freshwater restricts them. To this end, this study documented the phylogeographical history of the giant freshwater prawn (Macrobrachium rosenbergii) utilising both mitochondrial (COI &amp; 16S) and nuclear (microsatellite) markers. Samples (n = ~1000) were obtained from across most of the natural distribution of M. rosenbergii [Southern and South East (SE) Asia, New Guinea, northern Australia]. Initial phylogenetic analyses identified two highly divergent forms of this species restricted to either side of Huxley's extension of Wallace's Line; a pattern consistent with ancient vicariance across the Makassar Strait. Subsequent analyses of molecular variation within the two major clades specifically tested a number of biogeographical hypotheses, including that: 1.) a major biogeographical transition zone between the Sundaic and Indochinese biotas, located just north of the Isthmus of Kra in SE Asia, results from Neogene marine transgressions that breached the Isthmus in two locations for prolonged periods of time; 2.) Australia's Lake Carpentaria [circa 80 000 - 8 500 before present (BP)] facilitated genetic interchange among freshwater organisms during the Late Pleistocene; 3.) sea-level fluctuations during the Pleistocene constrained evolutionary diversification of M. rosenbergii within the Indo-Australian Archipelago (IAA); and 4.) New Guinea's Fly River changed course from its current easterly outflow to flow westwards into Lake Carpentaria during the Late Pleistocene. The results support hypotheses 1-3, but not 4. The potential for phylogeography to contribute significantly to the study of historical biogeography is also discussed.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">historical biogeography</field><field name="subject">phylogeography</field><field name="subject">freshwater prawn</field><field name="subject">SE Asia</field><field name="subject">Australia</field><field name="subject">population genetic</field><field name="subject">demography</field><field name="subject">Lake Carpentaria</field><field name="subject">Isthmus of Kra</field><field name="subject">Indo-Australian Archipelago</field><field name="identifier">http://eprints.qut.edu.au/16215/</field><field name="validLink">True</field></doc><doc><field name="title">Molecular characterisation of the intergenic regions of banana bunchy top virus</field><field name="creator">Herrera Valencia, Virginia Aurora</field><field name="description">Banana bunchy top virus (BBTV) is a circular, single-stranded (css) DNA virus that belongs to the genus Babuvirus in the family Nanoviridae. BBTV is responsible for the most devastating virus disease of banana known as "bunchy top", for which conventional control measures are generally ineffective. Genetically engineered resistance appears to be the most promising strategy to generate BBTV-resistant bananas but the success of this strategy is largely dependent upon the molecular characterisation of the target virus and knowledge of the virus life cycle, particularly the replication strategy. This PhD study was aimed at the molecular characterisation of the intergenic regions of BBTV, in order to complement the molecular information currently available and to potentially contribute to the development of transgenic resistance strategies against BBTV in banana.  Three putative iterative sequences (iterons; GGGAC) previously identified in the BBTV intergenic regions were initially characterised. In order to determine their role in the binding of the master BBTV replication initiation protein (M-Rep), the putative iterons (F1 and F2 in the virion sense, and R in the complementary sense) were independently mutated in a BBTV DNA-6 greater-than-genome-length clone (1.1 mer). The DNA-6 1.1 mers (native and mutants) and the M-Rep-encoding component (DNA-1) were co-bombarded into banana (Musa spp. cv."Lady finger") embryogenic suspension cells and transient replication was evaluated by Southern hybridisation. Analysis of the DNA-6 replicative forms showed a significant decrease of approximately 41% for the F1 iteron mutant and 61% for the R iteron mutant in comparison with native levels. However, the mutation in the F2 iteron caused the most dramatic effect, decreasing replication to levels barely detectable by Southern hybridisation. These results suggest that the three iterons all play a role in BBTV replication, most likely as recognition and binding sites for the M-Rep, but that the F2 iteron appears to be the most important in replication.  Following the observation that all BBTV isolates sequenced to date have identical iteron sequences, the extent to which the M-Rep would recognise, bind and initiate replication of heterologous components from geographically diverse BBTV isolates (the South Pacific and the Asian groups) was evaluated. Cross replication assays revealed that heterologous M-Reps from Fiji, Hawaii (South Pacific group) and Vietnam (Asian group) were able to initiate replication of the coat protein-encoding component (DNA-3) from the Australian BBTV isolate (South Pacific group). However, replication of DNA-3 from the Vietnamese isolate was not initiated by heterologous M-Reps from the two South Pacific isolates tested (Australia and Hawaii). These results suggest that a broad-range transgenic resistance strategy based on replication using Australian BBTV intergenic regions may be successful as this region will be recognised by the M-Reps from both Asian and South Pacific BBTV isolates. However, a Rep protein-mediated resistance strategy will more likely be specific to geographical isolates and, therefore, less suitable as a broad-range control strategy.  To further characterise the BBTV intergenic regions and to gain a better understanding of the BBTV transcription process, the 5' untranslated regions (UTRs) of the major open reading frames (ORFs) associated with each of the six BBTV DNA components were mapped. In all cases, the transcription start sites were located 3' of a putative TATA box and the 5' UTRs varied in length from 23 nucleotides (DNA-6) to 5 nucleotides (DNA-3). Two potential transcription start sites (nt 84 and 87) were mapped for DNA-1, but whether these represent the transcription start sites of the two genes associated with DNA-1 remains to be determined. Two start sites were also associated with DNA-2 which is thought to be monocistronic. Whether one of these start sites is an artefact or whether they are due to natural sequence variability of BBTV is unknown. These results now enable us to define the transcribed regions of each BBTV DNA component and accurately predict their promoter regions in an attempt to gain a fundamental understanding of BBTV gene expression patterns.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">banana bunchy top virus</field><field name="subject">BBTV</field><field name="subject">DNA virus</field><field name="subject">molecular characterisation</field><field name="subject">GGGAC</field><field name="identifier">http://eprints.qut.edu.au/16216/</field><field name="validLink">True</field></doc><doc><field name="title">Psychosocial factors contributing to motorcyclists' intended riding style : an application of an extended version of the theory of planned behaviour</field><field name="creator">Tunnicliff, Deborah Josephine</field><field name="description">Motorcycle riding is rapidly increasing in popularity in Australia, attracting a much wider demographic of people than in decades past.  Unfortunately, whilst the overall road toll in Australia has generally been reducing, the proportion of motorcycle-related fatalities has been rising in recent years. Further, the proportion of motorcycle-related fatalities in Australia is unacceptably high compared to other OECD countries.  To reduce motorcycle-related fatalities on Australian roads, there is an urgent need to consider motorcyclists as distinct from other road users.  This program of research facilitates the understanding of safety issues from a motorcyclist perspective and provides important information on factors influencing safe and unsafe rider intentions and behaviour.-----
 
 Study 1 explored what motorcyclists thought about the issues relevant to safety and to risk-taking behaviour on a motorcycle.  The aim of this study was to develop a better understanding of the factors which influence on-road riding behaviour.  Using the theory of planned behaviour (TPB), identity theory, social identity theory, and items based on moral norm and causal attribution theory, a set of questions was developed to guide focus group discussions with riders, police, rider trainers, and an advocacy group for motorcycle safety.  Of the 43 participants in this study, only two were not motorcycle riders. This exploratory process revealed six common behaviours that most motorcyclists agreed were essential to safety or which related directly to riskier riding.-----  
 
 Two behaviours were identified as being essential to rider safety by participants. The first was the necessity of being able to handle the motorcycle proficiently and skilfully.  The second related to the need for riders to maintain a high level of concentration whilst riding and to stay aware of the changing road environment.-----  
 
 The safety or riskiness of two other behaviours mentioned became a matter of debate amongst participants.  First, some riders said that obeying the road rules was essential to their safety, whilst others reported that it was often necessary to break the road rules in order to stay safe.  Second, the definition of what constituted 'riding whilst impaired' differed amongst riders. Most riders agreed that 'drinking and riding' was dangerous.  However, for some, even one alcoholic drink before riding was considered dangerous, whilst others would ride after drinking provided they did not consider themselves to be over the legal BAC limit.  Some riders stated that riding when they were tired was dangerous; however, fatigue was not considered a serious safety issue for many participants.----- 
 
 Two further behaviours identified by participants were often associated with their accounts of crash involvement, yet not seen as intrinsically 'unsafe' by most riders.  The first of these was the concept of 'pushing your limits'.  Most riders interviewed appeared to enjoy pushing the limits of their ability on a motorcycle. Whilst agreeing that pushing the limits too far was dangerous, pushing them to a point that tested a rider's abilities was often reported to facilitate safety as this process developed a rider's skill. The second behaviour that was often mentioned in connection with crashes was extreme riding (e.g., performing stunts and riding at extreme speeds).  The act of perfecting a stunt was often reported to result in the crashing of the motorcycle; although, these crashes were usually accepted as a normal part of the learning process.  Once perfected, performing stunts did not appear to be considered an intrinsically unsafe behaviour; unless performed in traffic or other unpredictable situations.  A sizable minority of both male and female participants reported riding at extreme speeds.  These riders often argued that they could ride extremely fast, safely, on public roads provided certain conditions were met (e.g., good visibility, weather, road, and motorcycle maintenance).-----  
 
 Study 2 [n = 229] operationalised the six behaviours discussed above into three 'safer' behavioural intentions (i.e., handle the motorcycle skilfully, maintain 100% awareness, not ride impaired) and three 'riskier' intentions (i.e., bend road rules, push the limits, perform stunts or ride at extreme speeds).  A seventh item was added to provide a global measure of a rider's intention to ride safely. Multiple regression analyses were then performed to test the predictive utility of the TPB compared with several augmented models. The additional constructs used to augment the TPB included a specific subjective norm and group norm which related to the people a person rides with, self identity, sensation seeking, aggression as well as age, gender and riding exposure.  The multiple regression analysis demonstrated that a greater proportion of variance could be explained in the case of the riskier riding intentions [R2 ranging from 57% - 66%] than the safer riding intentions [R2 ranging from 22% - 36%].  Therefore, this type of theoretical model may be better suited to investigating deliberate risk-taking intentions rather than an overall model of rider behaviour which includes errors and lapses or intentions to ride safely.-----
 
 In the final analyses, perceived behavioural control (PBC) proved to be a significant predictor of all four intentions towards the safer behaviours, and also towards intentions to "push my limits".  Attitude was a significant predictor of the three riskier intentions. Although the standard subjective norm variable performed weakly, as it was only predictive of one intention, the specific subjective norm (i.e., the people that someone rides with) emerged as a significant predictor of four of the seven intention items and group norm was predictive of an additional intention item. This result indicates that the other people a person rides with may have a marked effect on behavioural intentions. Sensation seeking was found to be significantly related to four intentions, self identification as a safe or risky rider related to two intentions and a propensity for aggression was only significantly predictive of one intention.----- 
 
 Study 2 did not find a significant relationship between the seven intentions and past crash history.  However, correlational analyses found that people who had reported being involved in a serious crash in the past two years reported less PBC over their ability to ride as safely as possible and to perform stunts and/or ride at extreme speeds.-----  
 
 In conclusion, this program of research provided insight into the issues riders feel are important to their safety, and has facilitated a greater understanding of the complexity of influences that impact on riding intentions and behaviour. The study also provided support for extending the traditional TPB model to include other measures of social influence, as well as person-related factors such as sensation seeking. The fact that PBC emerged as a predictor of five of the seven intentions suggests that there may be scope to enhance existing training practices to better address both safe and risky riding intentions. The influence of other riders also emerged as a strong influence on intentions, suggesting that strategies to address rider behaviour within the wider social context of riding may be a useful addition to future motorcycle safety or rider training initiatives.  The social dynamics of motorcycle riding, within the context of road safety, is an area that clearly requires more investigation.   Research into this area may provide the key to developing new approaches to promoting motorcycle safety which effectively integrate both the psychological and sociological aspects of riding; therefore, better reflecting the real challenges facing many riders on Australian roads today.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">motorcycle</field><field name="subject">crashes</field><field name="subject">risk</field><field name="subject">behaviour</field><field name="subject">road safety</field><field name="subject">theory of planned behaviour</field><field name="subject">social identity theory</field><field name="subject">identity theory</field><field name="subject">sensation seeking</field><field name="subject">aggression</field><field name="identifier">http://eprints.qut.edu.au/16217/</field><field name="validLink">True</field></doc><doc><field name="title">The visible and the invisible : connecting presence and absence through art, memory and the body</field><field name="creator">Porch, Debra Lynn</field><field name="description">The Visible and the Invisible: Connecting Presence and Absence Through Art, Memory, Mortality and the Body investigates the role that art objects and images used in installation practice have in linking the past to the present. The project's
 
 creative and theoretical research speculatively explore and interpret the potential that
 
 such objects--in my art practice and in the work of a range of noted visual artists--have in evoking ideas, memories or physical ties that are not readily apparent. The studio and theoretical research examines how a range of visual
 
 mechanisms in installation practice can evoke (in present time) past events and experiences previously absent. In the research, memory is revealed as having the capacity to transform the ordinary into the extraordinary, acting as a powerful catalyst that connects a viewer's awareness of a past experience to the visible
 
 objects experienced through a visual installation.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">visible</field><field name="subject">invisible</field><field name="subject">presence</field><field name="subject">absence</field><field name="subject">art</field><field name="subject">memory</field><field name="subject">body</field><field name="subject">mortality</field><field name="identifier">http://eprints.qut.edu.au/16218/</field><field name="validLink">True</field></doc><doc><field name="title">Intuitive interaction with complex artefacts</field><field name="creator">Blackler, Alethea Liane</field><field name="description">This thesis examines the role of intuition in the way that people operate unfamiliar devices, and the importance of this for designers. Intuition is a type of cognitive processing that is often&#12288;non-conscious and utilises stored experiential knowledge. Intuitive interaction involves the use of knowledge gained from other products and/or experiences. Therefore, products that people use intuitively are those with features they have encountered before.  This position has been supported by two initial experimental studies, which revealed that prior exposure to products employing similar features helped participants to complete set tasks more quickly and intuitively, and that familiar&#12288;features were intuitively used more often than unfamiliar ones. Participants who had a higher level of familiarity with similar technologies were able to use significantly more of the&#12288;features intuitively the first time they&#12288;encountered them, and were significantly quicker at doing the tasks. Those who were less familiar with relevant technologies required more&#12288;assistance.  A third experiment was designed to test four different interface designs on a remote control in order to establish which of two variables - a feature's appearance or its location - was more important in making a design intuitive to use. As with the previous experiments, the findings of Experiment 3 suggested that performance is&#12288;affected by a person's level of familiarity with similar technologies. Appearance (shape, size and labelling of buttons) seems to be the variable that most affects time spent on a task and intuitive uses. This suggests that the cues that people store in memory about a product's features depend on how the features look, rather than where on the product they are placed.  Three principles of intuitive interaction have been developed. A conceptual tool has also been devised to guide designers in their planning for intuitive interaction. Designers can work with these in order to make interfaces intuitive to use, and thus help users to adapt more easily to new products and product types.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">design methods</field><field name="subject">ergonomics</field><field name="subject">human centred design</field><field name="subject">human factors</field><field name="subject">industrial design</field><field name="subject">interaction design</field><field name="subject">interface design</field><field name="subject">intuitive interaction</field><field name="subject">intuitive use</field><field name="subject">observational analysis</field><field name="subject">product design</field><field name="subject">usability</field><field name="subject">Talk Aloud Protocol</field><field name="identifier">http://eprints.qut.edu.au/16219/</field><field name="validLink">True</field></doc><doc><field name="title">Stochastic volatility : maximum likelihood estimation and specification testing</field><field name="creator">White, Scott Ian</field><field name="description">Stochastic volatility (SV) models provide a means of tracking and forecasting the variance of financial asset returns. While SV models have a number of theoretical advantages over competing variance modelling procedures they are notoriously difficult to estimate. The distinguishing feature of the SV estimation literature is that those algorithms that provide accurate parameter estimates are conceptually demanding and require a significant amount of computational resources to implement. Furthermore, although a significant number of distinct SV specifications exist, little attention has been paid to how one would choose the appropriate specification for a given data series. Motivated by these facts, a likelihood based joint estimation and specification testing procedure for SV models is introduced that significantly overcomes the operational issues surrounding existing estimators.  The estimation and specification testing procedures in this thesis are made possible by the introduction of a discrete nonlinear filtering (DNF) algorithm. This procedure uses the nonlinear filtering set of equations to provide maximum likelihood estimates for the general class of nonlinear latent variable problems which includes the SV model class. The DNF algorithm provides a fast and accurate implementation of the nonlinear filtering equations by treating the continuously valued state-variable as if it were a discrete Markov variable with a large number of states. When the DNF procedure is applied to the standard SV model, very accurate parameter estimates are obtained. Since the accuracy of the DNF is comparable to other procedures, its advantages are seen as ease and speed of implementation and the provision of online filtering (prediction) of variance. Additionally, the DNF procedure is very flexible and can be used for any dynamic latent variable problem with closed form likelihood and transition functions. Likelihood based specification testing for non-nested SV specifications is undertaken by formulating and estimating an encompassing model that nests two competing SV models. Likelihood ratio statistics are then used to make judgements regarding the optimal SV specification. The proposed framework is applied to SV models that incorporate either extreme returns or asymmetries.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">stochastic volatility</field><field name="subject">variance prediction</field><field name="subject">heavy tailed SV</field><field name="subject">asymmetric SV</field><field name="subject">nonlinear filtering</field><field name="subject">maximum likelihood estimation</field><field name="subject">specification testing</field><field name="subject">encompassing models</field><field name="identifier">http://eprints.qut.edu.au/16220/</field><field name="validLink">True</field></doc><doc><field name="title">For love or money : perceptions and conceptions of the work ethic held by a group of preservice teachers in Queensland</field><field name="creator">Mailler, Emma Cornelia</field><field name="description">The work ethic has been a popular topic for public comment and for research in the social sciences.  The work ethic is usually understood to embody the values, beliefs and principles an individual has in relation to work.  Work is an important dimension of human experience.  Governments and employers are particularly interested in increasing productivity and competitiveness in connection with work and the work ethic is perceived as an important catalyst in achieving these goals.  The main point of reference for discussion about the work ethic in the past century has been Max Weber's Protestant ethic thesis.  Weber's thesis has attracted much criticism over the years and contemporary writers have suggested that alternative conceptions of the work ethic do exist.  Despite widespread agreement that this is the case, consensus has not yet been reached on how such conceptions should be defined or how they may manifest in an individual.  The majority of research on the work ethic has been limited to the collection of quantitative data using one of several survey instruments that are available.  Fewer studies have collected data on the work ethic using a qualitative approach and yet, this is exactly what is required to achieve progress in identifying the range of conceptions that may exist.  This study occurs in the context of teacher education and the work ethic has relevance to teachers and teacher educators for several reasons.  Teachers, through the explicit and hidden curriculum they provide, have some responsibility for inculcating a work ethic in their students.  It follows that it is important to understand the work ethic of teachers on this basis alone.  A most logical starting place for accomplishing this task is during their career preparation.  This study advocates explicit examination of preservice teachers' conceptions of the work ethic and exploration of how this might affect their career and curriculum decision making processes.  This research is primarily intended to inform teacher educators who wish to pay attention to these things in their programs, along with researchers from other disciplines who are interested in the work ethic.  Inspired by a pragmatic philosophy, this study utilised a mixed method research design to investigate the conceptions of the work ethic held by a group of preservice teachers studying in Brisbane, the capital city of the state of Queensland, Australia.  Priority was given to the first phase of the research, which was to identify the qualitative conceptions of the work ethic held by the preservice teachers.  The second quantitative phase was intended to complement and expand those findings by demonstrating that an established instrument in the measurement of work ethic could be used to profile conceptions of the work ethic held by an individual.  The first phase of the research adopted a phenomenographic approach to identify nine conceptions of the work ethic held by a group of 22 preservice teachers.  A courtship metaphor was used to characterise each of the nine conceptions which were labelled as Honeymoon, Monogamist, Serial Monogamist, Arranged Marriage, Celibate, Obsession, One-night Stand, Hedonist and Polyamorist.  The second phase of the research used quantitative techniques involving factor analysis and linear modelling to link anonymous responses from 411 preservice teachers to the Occupational Work Ethic Inventory (OWEI) with the nine conceptions identified in the first phase of the research.  It was found that the OWEI could be used to profile an individual's orientation to the work ethic conceptions that were defined.  This research responded to calls in the literature for a better understanding of the characteristics of the people who choose to become teachers.  It also suggested ways in which teacher education could be improved to prepare preservice teachers better through socialisation practices and the university curriculum.  This study confirms that there are qualitatively different conceptions of the work ethic that may provide an alternative to the traditional Weberian conception.  A technique is proposed to associate OWEI responses with the model of nine work ethic conceptions.  Suggestions are also made with respect to potential improvement of the OWEI.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">conceptions of the work ethic</field><field name="subject">metaphor in phenomenography</field><field name="subject">mixed method research</field><field name="subject">modelling techniques</field><field name="subject">Occupational Work Ethic Inventory (OWEI)</field><field name="subject">phenomenography</field><field name="subject">pragmatism</field><field name="subject">preservice teachers</field><field name="subject">Protestant ethic</field><field name="subject">Protestant work ethic</field><field name="subject">teacher education</field><field name="subject">teacher socialisation</field><field name="subject">work ethic</field><field name="subject">Honeymoon</field><field name="subject">Monogamist</field><field name="subject">Arranged Marriage</field><field name="subject">Celibate</field><field name="subject">Obsession</field><field name="subject">One-night Stand</field><field name="subject">Hedonist</field><field name="subject">Polyamorist</field><field name="subject">Serial Monogamist</field><field name="identifier">http://eprints.qut.edu.au/16221/</field><field name="validLink">False</field></doc><doc><field name="title">The elusive allusive : the use of allusion and quotation as acts of authorship in playwriting</field><field name="creator">Riordan, Michael Patrick</field><field name="description">This project examines the ways in which allusion and quotation may be used by playwrights in the composition of play scripts, principally through the writing of two full length stage plays, String and The Talent, accompanied by a supporting exegesis. This exegesis examines how quotation and allusion are used in these works to support particular meanings intended by the author.
 
 The project also looks at theories that consider the ways allusion functions, particularly focusing on the debate in the field between the advocates of the theories of influence and intertextuality. It does not attempt to provide an historical overview nor an exhaustive investigation of the development of the major theories and their advocates, but rather to consider more summarily - in outline rather than in detail - the manner in which these ideas have set out to explain how allusion functions in texts. 
 
 This project suggests its own theory on the way (particularly literary) allusion works. Transtextuality, although itself only a partial and incomplete means of explaining the allusive transaction, refers to the movement of language between texts. Allusion offers a mechanism by which authors of a new text may underscore intended meaning by reference to established texts based on the assumption that the meaning of the quoted text is already understood (or can easily be accessed), and that therefore that meaning is transferable to the new text and can be absorbed into the different context into which it has been placed. 
 
 The purpose of this study is in part to examine the way allusion works as a practice of intertextuality, transtextuality and the influence of one or more texts upon another. It concludes that allusion to and quotation from one text by another operate as acts of authorship, literary devices employed by the writer as mechanisms for the attempted communication of intended meaning. In doing so, it is hoped that the project may articulate ways in which allusion and quotation can be used by playwrights in the composition of their dramaturgy.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">allusion</field><field name="subject">quotation</field><field name="subject">mimesis</field><field name="subject">playwriting</field><field name="subject">dramaturgy</field><field name="subject">influence</field><field name="subject">intertextuality</field><field name="subject">transtextuality. poststructuralism</field><field name="identifier">http://eprints.qut.edu.au/16222/</field><field name="validLink">True</field></doc><doc><field name="title">Embedding e-learning in universities : analysis and conceptualisation of change processes</field><field name="creator">Rossiter, Darien Elizabeth</field><field name="description">E-learning has acquired the status of a "radical innovation" in higher education over the past decade. This claim is contestable, but certainly as the latest educational innovation, it can be attributed with introducing significant disruption into many facets of university life, reaching well beyond the traditional activities associated with the classroom pedagogies. In Australian universities, there are many now who simply take e-learning for granted as accepted teaching and learning practice (Oliver, 2004). Conversely, there are others who forecast its demise, claiming that, like previous educational technological innovations, it is another passing fad (Noble, 1998b). This thesis does not primarily engage this debate. Instead the purpose of this thesis is to gain insight into how universities can realise sustained benefits from the considerable investments to date that have been made in educational technological innovations. The inquiry seeks to understand better change within contemporary universities, in particular the process of embedding the e-learning innovation effectively. The intention is to produce an analysis useful to university executives, managers, teachers and researchers, as well as to make a more general contribution to knowledge about innovations in organisations.  The research literature on change and innovation in organisations is relevant but is reviewed and assessed as of limited value to the enquiry. This is because:  * the literature mainly focuses on the objective characteristics of an innovative product which cannot encompass the socially constructed value of e-learning  * it fails to differentiate between the concept of "embedding" and other change phases and constructs, mostly examining the precursory and innovation-producing processes  * the context of research into innovation has been primarily industrial, not university-based  * its variable analytic paradigm fails to produce holistic analyses which can be appreciated and enacted on by decision makers and practising managers.  For these reasons and because suitable research on innovation in universities is lacking, an introductory investigation based on grounded theory building was undertaken. To this end, four qualitative, descriptive case studies of contrasting Australian universities embedding e-learning were compiled. The four case universities (their identities protected through use of pseudonyms) assessed were:  * Gamma University - a multi-campus institution, geographically spread across urban and regional locations  * Lambda University - an established university, with the majority of students located at a single urban campus  * Epsilon University - a younger, multi-campus amalgamated university with a strong reputation for distance education  * Delta University - a relatively young multi-campus, urban university, although its parent bodies provide a longer history.  The cases were based on interviews and focus group sessions with 74 participants, and electronic resource and document analyses over two phases; the first conducted in 1998-1999 and the second in 2002-2003. These analyses provided holistic pragmatic accounts that encapsulate a number of issues. One issue was about the importance of creativity in the innovating process. A second set of issues centred on the theme of complexity and the multifarious nature of the e-learning innovation. Other themes included the significance of the innovation context, partnerships and collaborations, and the emerging polarisation of issues such as standardisation versus diversification. These issues provoked three major propositions about the process of embedding and prompted the development of two systems-based analytical frameworks; one focusing on the nature of system relationships and interactions and the second providing a longitudinal perspective of system change. The propositions are:  * the ability of a university to negotiate system intersections and transitions influences the degree to which e-learning can be embedded in that university  * complexity is an integral part of an innovation, therefore cannot be ignored or eliminated without destroying the kernel of the innovation itself, and its longterm viability  * the efficacy of the innovation is related, in some measure, to the ability to sustain partnerships and collaborations.    The analysis suggested that there are number of key influences which affect the embedding process and the ability of an organisation, such as a university, to manage the processes associated with the e-learning innovation. The key system influences which affect embedding include:  * the nature of the interactions and transactions occurring within the system, at the boundaries and between the phases of transition  * the importance of organisational context (cultural, technological, strategic, geographic)  * the pervasive impact of complexity on all dimensions of the research problem (the e-learning innovation, the change process and the university environment)  * the necessity for collaboration.  The implications of this study for university executives, managers and beyond are far reaching, and in some respects contradict accepted contemporary management practice. They include: seeking ways to maximise organisational tensions to achieve positive outcomes; enhancing decision making by allowing more flexibility and personal judgement into the process; developing greater tolerance for system fuzziness and uncertainty; and encouraging better utilisation of previous knowledge gained about innovation practices and processes.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">e-learning</field><field name="subject">higher education</field><field name="subject">university</field><field name="subject">educational technological innovation</field><field name="subject">Australia</field><field name="identifier">http://eprints.qut.edu.au/16223/</field><field name="validLink">True</field></doc><doc><field name="title">Manufacturing dissent</field><field name="creator">Jensen, Rhonda Karen</field><field name="description">There are two distinct but related parts to this exegesis. Firstly there is the production of a fifty-five minute documentary Return of the Trojan Horse, and secondly a written exegesis. The latter advances an academic argument centred around the research question - how to motivate the role of the expository documentary at a time when the documentary field is dominated by the debate between philosophical scepticism and empirical realism, while in aesthetic terms, the documentary mode itself is led by perfomative/interactive documentaries such as Michael Moore's Bowling for Columbine. My response to this question is informed in theoretical terms by the Critical Realist paradigm. The use of Critical Realism enables the exegesis to supply an integrated approach which seeks to transcend both the sceptical and the empirical realist positions. In doing so, the exegesis makes a contribution both to documentary theory and the Critical Realist paradigm itself by applying it to the field of documentary film theory. As such the exegesis addresses an absence of aesthetic theorising within the Critical Realist paradigm.  As part of the process I review, analyse and synthesise the key theoretical arguments of authors Bill Nichols, Michael Renov, Brian Winston, John Corner and Noel Carroll. The documentary sub-genres are then located within the context of these theoretical debates while the emphasis is placed on the expository sub-genre as utilised in my own documentary film, Return of the Trojan Horse. The exegesis then critically discusses Return of the Trojan Horse from a Critical Realist perspective and reflects on the strategies involved in the production of the film. As the topic of the film deals with the negative impacts of economic liberalisation, the mass media is briefly discussed within the context of a deregulated market and right-wing politics, while reviewing Herman and Chomsky's 'A Propaganda Model' in Manufacturing Consent: The Political Economy of the Mass Media, 2002.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">documentary film</field><field name="subject">critical realism</field><field name="subject">economic liberalisation</field><field name="subject">globalisation</field><field name="subject">capitalism</field><field name="subject">media</field><field name="identifier">http://eprints.qut.edu.au/16224/</field><field name="validLink">True</field></doc><doc><field name="title">Cyberdrama and forms of youth engagement</field><field name="creator">Davis, Susan Elizabeth</field><field name="description">What kinds of engagement might be possible for young people through the creation and experience of a cyberdrama?  How do you create a cyberdrama?  These were the questions that underpinned the process for creating the cyberdrama www.cleo-missing.com &#8211; a drama that was created to be experienced through a fully mediated form on the Internet.  The background for this project involved: exploring the context for creating a web-based cyberdrama with young people; defining cyberdrama, the nature of the work and possible processes and forms; and examining the notion of engagement, looking for possible links between aspects of the aesthetic and the immersive. The process of creating the drama utilised aspects of process drama, a form emerging from the field of drama education as one that offers up huge potential for the creation of on-line interactive drama. The project research suggests that the context for experiencing the work through the Internet means that the experience of &#8220;diversion&#8221; needs to be considered and is much more likely for many users than that of &#8220;immersion&#8221;.  This is particularly so in view of the ways many young people use the Internet, with common interactions taking on aspects of Bakhtin&#8217;s &#8220;carnival&#8221; (a subversive or alternative order). The experience for participants in creating the drama was characterised by a number of features, but engagement seemed particularly strong when aspects of control were involved or possible. The framing of this experience through the use of various recording technologies was of key significance to this experience of engagement; the possibility of creating a presence that may affirm a participant&#8217;s sense of existence seems to engage participants solidly in the process.  The research also suggested that for those creating drama on-line the use of a fairly linear narrative structure may still be desirable, and that the more significant experiences of engagement occur when a number of pleasures are experienced in combination.
 
 
 
 The findings of this research may be of relevance to those interesting in exploring the possibilities of creating drama with young people utilising mediated forms.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">cyberdrama</field><field name="subject">youth engagement</field><field name="subject">cleo-missing</field><field name="identifier">http://eprints.qut.edu.au/16225/</field><field name="validLink">True</field></doc><doc><field name="title">Transformative use of copyright material</field><field name="creator">Suzor, Nicolas</field><field name="description">This thesis concerns the ability of individuals to engage in transformative use of copyright expression without the permission of the copyright owner. Transformative use refers to the use of existing expression as an input into the creative process, resulting in the creation of new expression that, while still embodying elements of the original work, is original in its own right. This type of creativity is beneficial for society and should be encouraged. Individuals should have the ability to express themselves, and participate in the interpretation of their culture. My enquiry has shown that Australian law does not facilitate transformative use. Many forms of transformative expression are not currently permissible without the express permission of the copyright owner. Copyright theory, however, is not in accordance with such a prohibition on transformative use. I will suggest some legislative and judicial reforms to Australian copyright law that can have the effect of encouraging transformative expression, while at the same time providing an economic incentive to invest in creative expression and protecting the legitimate interests of creators in their works. The primary modification I suggest is that the definition of 'substantial part' in the Coypright Act 1968 (Cth) should be read, in accordance with the interests served by copyright, to allow a consideration of the context in which copyright material is taken. The seeds of such an approach are present in modern judicial interpretations; the discussion that follows attempts to show how such an approach accords with copyright theory, and why it should be preferred by the judiciary. Firstly, with respect to the economic rights, transformative uses of copyright material which are not substitutable for the original expression should not be found to reproduce a substantial part of the original. Secondly, questions of substantiality in the moral rights should be interpreted to protect authors from unreasonable commodification of their works. To the extent to which it is unclear how the right of integrity applies to the context in which a work is used, as opposed to the modification of the work itself, I submit that it should be interpreted such that authors have a right to object to the commercial association of their work with a position, product, or service against their will. Alternatively, I submit that legislative reform to include an open ended defence to copyright infringement could provide much needed flexibility in the Australian system. Such a defence could draw primarily on the US 'fair use' defence, but certain limitations of the US defence could be overcome in an Australian context. Again, as the theory shows, the primary consideration for infringement of the economic rights in transformative uses should be the degree to which the transformative use is substitutable for the original. Finally, I submit that the reasonableness defence to infringement of the moral right of integrity should be read in such a way as to ensure that the personal interests of authors does not interfere with the legitimate self-expression of future authors. I will show that the theory does not support moral rights to the exclusion of either the ability of future authors to self-actualise. The operation of the reasonableness defence should be clarified to ensure that the legitimate interests of both past and future creators are recognised.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">copyright</field><field name="subject">transformative use</field><field name="subject">re-expression</field><field name="subject">Copyright Act</field><field name="identifier">http://eprints.qut.edu.au/16226/</field><field name="validLink">True</field></doc><doc><field name="title">The concept of self-defending objects and the development of security aware applications</field><field name="creator">Holford, John William</field><field name="description">The self-defending object (SDO) concept is an extension to the object-oriented programming paradigm, whereby those objects that encapsulate the protected resources of a security aware application (SAA), are made aware of, and responsible for, the defence of those resources. That defence takes two forms, the enforcement of mandatory access control on protected resources and the generation of the corresponding portion of the SAA's audit trail. The SDO concept acts as the philosophy that guides the application level mandatory access control within SAAs which ensures that the provided access control is both complete and non bypassable. Although SDOs accept responsibility for controlling access to the protected data and functionality that they encapsulate, an SDO delegates the responsibility for making authorisation decisions to an associated authorisation object. Thus, SDOs fulfill their access control obligations by initiating the authorisation check and then enforcing the decision made on their behalf. A simple, yet effective mechanism for enforcing that access control at the object level involves controlling the ability to invoke those SDO methods that access protected resources. In the absence of previous research on this approach to the enforcement of application level access control, the primary aim of this research was to demonstrate that the SDO concept is a viable paradigm for developing SAAs. That aim was achieved in two stages. The first stage targeted the provision of a 'proof of concept', that demonstrated that the SDO concept could be applied to the development of non-distributed SAAs. The second stage demonstrated its applicability to the development of distributed SAAs. In the second stage, two versions of a distributed prototype were developed, one based on a traditional (proprietary) distributed computing model, (Java RMI), and the second using the currently popular Web services model, to demonstrate the general applicability of the SDO concept. Having already demonstrated that the SDO concept could be applied to SAAs executing on a single machine, the major focus of that research was to devise a mechanism by which SDOs could be transferred between machines.  The research then concentrated on determining what impacts the adoption of the SDO concept would have on SAA development. Experimentation carried out using the distributed prototypes demonstrated that (1) the adoption of the SDO does not restrict the use of inheritance hierarchies that include SDOs, (2) the restriction of the lifetime of SDOs can be supported, (3) usage rights enforcement can be employed, and (4) the use of cryptographic techniques to provide additional security guarantees is not affected. A key feature of the SDO concept, is that no major changes need to be made to current development tools or&#12288;methodologies, so its adoption is not hampered by significant financial or training impediments. This research demonstrated that the SDO concept is practical and constitutes a valuable extension to the object oriented paradigm that will help address the current lack of security in information systems. The SDO approach warrants additional research and adoption.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">mandatory access control</field><field name="subject">authorisation</field><field name="subject">security aware applications</field><field name="subject">information security</field><field name="subject">computer security</field><field name="subject">information technology</field><field name="subject">software engineering</field><field name="subject">object oriented programming</field><field name="subject">programming paradigms</field><field name="identifier">http://eprints.qut.edu.au/16227/</field><field name="validLink">True</field></doc><doc><field name="title">Paul H. Nitze and American Cold War strategy 1949 - 1953</field><field name="creator">Ushay, Joshua Levi</field><field name="description">This study is an intellectual history of Paul H. Nitze's contribution to the evolution of American Cold War strategy from 1949 to 1953. Nitze, a national security advisor and arms control negotiator to a succession of American presidents over fifty years, was almost unrivalled in his breadth and depth of experience in the Cold War national security establishment of the United States. As this study demonstrates, however, the most important and influential phase of his career was during his involvement with the Truman administration, as Deputy Director and then Director of the Department of State's Policy Planning Staff (PPS). It was in this position that Nitze contributed to a profound shift in American strategic thinking that redefined U.S. national security policy both at the time and for the decades to come. He was the principal author of National Security Council directive 68 (NSC 68), the most comprehensive and wide-ranging appraisal of American national security policy of the time. Developed in response to the Soviet Union's first atomic explosion, and approved after the North Korean invasion of South Korea, Nitze's NSC 68 recommended the United States move away from its prevailing strategy of massive nuclear retaliation and towards a forward defence of the' free world', made possible by a vast increase in conventional - or non-nuclear - military capabilities. This shift proved to be the forerunner of 'flexible response', the official defence posture of the Kennedy administration and the formal NATO strategic doctrine for much of the Cold War. Yet crucially, the phase of Nitze's career that produced this fundamental and enduring reorientation of American Cold War strategy has been largely unexplored by historical studies to date.  This thesis addresses this shortcoming. Not only is it the first in-depth study of Nitze's years with the Truman administration, but it also makes use of previously unavailable archival sources, including Nitze's own papers held at the Library of Congress in Washington DC. Given the dearth of literature on his career during this time, and the fact that the critical primary source material used in this study is absent in such literature, this thesis therefore offers a new, original and unprecedented contribution to contemporary understanding of Paul Nitze and the Cold War.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">United States</field><field name="subject">diplomatic history</field><field name="subject">Cold War</field><field name="subject">Soviet Union</field><field name="subject">Paul Nitze</field><field name="identifier">http://eprints.qut.edu.au/16228/</field><field name="validLink">True</field></doc><doc><field name="title">Teachers' understandings of pedagogic connectedness</field><field name="creator">Beutel, Denise</field><field name="description">This thesis explores the nature of pedagogic connectedness and reveals the qualitatively different ways in which teachers in the middle years of schooling experience this phenomenon. The researcher defines pedagogic connectedness as the engagements between teacher and student that impact on student learning. The findings of this phenomenographic-related study are used to provide a framework for changes to pedagogic practices in the middle years of schooling. Twenty teachers of years 7, 8, and 9 boys in an independent college in South-East Queensland participated in this study. Data were obtained through semi-structured interviews with these teachers and the interview transcripts were analysed iteratively. Five qualitatively different ways of experiencing pedagogic connectedness emerged from this study. These categories of description are linked hierarchically and are delimited from each other through six common dimensions of variation.  Teachers' conceptions of pedagogic connectedness range from information providing through instructing, facilitating, guided participation to mentoring. The five different conceptions may be classified broadly as teacher-centred, transitional or student-centred. In the information providing conception, pedagogic connectedness between teachers and students is limited with teachers perceiving themselves as subject experts and providing few opportunities for student-teacher engagements. The most complex conception, mentoring, is characterised by partnerships between teachers and students in which teachers view themselves as more experienced equals. These partnerships extend beyond the confines of the classroom and beyond the years of schooling. In this conception, teachers describe teaching as an emotional activity with teachers demonstrating passion for teaching and learning. The findings of this current study extend earlier understandings of teacher-student mentoring relationships in the middle years of schooling. These expanded understandings may contribute to enthusing middle years students and re-engaging them with schooling during these vital years.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">phenomenography</field><field name="subject">pedagogic connectedness</field><field name="subject">pedagogy</field><field name="subject">teaching</field><field name="subject">mentoring</field><field name="subject">middle years</field><field name="subject">middle years of schooling</field><field name="subject">adolescence</field><field name="identifier">http://eprints.qut.edu.au/16229/</field><field name="validLink">False</field></doc><doc><field name="title">Groundwater flow model for a large sand mass with heterogeneous media, Bribie island, southeast Queensland</field><field name="creator">Spring, Ken</field><field name="description">On the large sand mass of Bribie Island, the sedimentary evolution related to sea level changes has resulted in marked spatial variations of aquifer properties.  The main influence on groundwater behaviour is the induration of layers within the sandy sequences that comprise the island.  The degree of induration controls vertical flows between the perched watertable and the underlying semi-confined regional aquifer.  To identify heterogeneity within the indurated zone, an analysis of bore hydrographs was undertaken. The analysis shows that separate sections of the hydrological profile across the island display distinct unconfined or confined behaviour depending on the degree of  hydrological discontinuity in the sandrock horizon.  A two-dimensional (2-D) hydrogeologic conceptual model of Bribie Island is developed for the numerical modelling process. The two-aquifer system separated by the indurated layer ("coffee rock") is incorporated into the groundwater model.  The indurated layer is spatially variable in thickness, continuity and permeability. An evaluation of the recharge and drainage parameters is conducted for improvement of model accuracy, using MODFLOW software to solve the quasi three-dimensional (3-D) flow model.  The evapotranspiration (ET) parameter is tested due to the important role it has in the water balance of Bribie Island. The groundwater extraction and wastewater infiltration rates are evaluated separately for model input. Average hydraulic conductivities initially used in the numerical model for each aquifer do not match measured heads adequately.  During initial model development, pilot point parameterisation of hydraulic conductivities was conducted providing a more complex distribution of the parameter and a better fit to observed water levels.  Using spatial interpolation techniques, a gradual and realistic distribution of hydraulic properties is achieved rather than sharp changes between facies-related sedimentary sequences.  The resultant visualisation of hydraulic conductivities supports the outcomes of the analysis of water level profiles.  The model interprets and adjusts for the effects of the aquifer heterogeneity in respect to the hydraulic conductivity parameter.  Areas of unconfined aquifer behaviour correspond to zones of higher hydraulic conductivities and are interpreted as regions of higher permeability due to a lesser degree of induration.  Such zones of greater groundwater flow were found in the south of the island, the central swale and the northwest coastline, which act as connections to the basal aquifer enabling preferred recharge to it.  Calibration is conducted in respect of the hydraulic conductivity, drainage and ET parameters.  The calibration of simulated to observed hydraulic heads (objective function of 2.96 and correlation of 0.993) for the two layers achieved a close fit.    The groundwater study demonstrates that both a statistical approach and numerical modelling are important in testing and refining the conceptual model.  The modified conceptual model can be used as a basis for the construction of an improved and more reliable numerical model.  The integration of geological information and spatial variability of aquifer parameters to produce a quasi three-dimensional model based on a two-aquifer conceptual model is a significant innovation of the modelling approach to Bribie Island.  This approach contributes to a clearer understanding of the hydrogeological processes within the island.  The investigation has contributed to a better understanding of the effects of broad and finer scale heterogeneities on groundwater dynamics in large sand mass.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">groundwater</field><field name="subject">sand mass</field><field name="subject">Bribie island</field><field name="subject">southeast Queensland</field><field name="subject">hererogeneity</field><field name="identifier">http://eprints.qut.edu.au/16230/</field><field name="validLink">True</field></doc><doc><field name="title">Morphogenetic evolvable hardware</field><field name="creator">Lee, Justin Alexander</field><field name="description">Evolvable hardware (EHW) uses simulated evolution to generate an electronic circuit with specific characteristics, and is generally implemented on Field Programmable Gate Arrays (FPGAs). EHW has proven to be successful at producing small novel circuits for applications such as robot control and image processing, however, traditional approaches, in which the FPGA configuration is directly encoded on the chromosome, have not scaled well with increases in problem and FPGA architecture complexity. One of the methods proposed to overcome this is the incorporation of a growth process, known as morphogenesis, into the evolutionary process. However, existing approaches have tended to abstract away the underlying architectural details, either to present a simpler virtual FPGA architecture, or a biochemical model that hides the relationship between the cellular state and the underlying hardware. By abstracting away the underlying architectural details, EHW has moved away from one of its key strengths, that being to allow evolution to discover novel solutions free of designer bias. Also, by separating the biological model from the target FPGA architecture, too many assumptions and arbitrary decisions need to be made, which are liable to lead to the growth process failing to produce the desired results. In this thesis a new approach to applying morphogenesis to gate-level FPGA- based EHW is presented, whereby circuit growth is closely tied to the underlying gate-level architecture, with circuit growth being driven largely by the state of gate-level resources of the FPGA. An investigation into the applicability of biological processes, structures and mechanisms to morphogenetic EHW (MGEHW) is conducted, and the resulting design elaborated. The developed MGEHW system is applied to solving a signal routing problem with irregular and severe constraints on routing resources. It is shown that the morphogenetic approach outperforms a traditional EHW approach using a direct encoding, and importantly, is able to scale to larger, more complex, signal routing problems without any significant increase in the number of generations required to find an optimal solution. With the success of the MGEHW system in solving primarily structural prob- lems, it is then applied to solving a combinatorial function problem, specifically a one-bit full adder, with a more complete set of FPGA resources. The results of these experiments, together with the previous experiments, has provided valuable information that when analysed has enabled the identification of the critical factors that determine the likelihood of an EHW problem being solvable. In particular this has highlighted the importance of effective  fitness feedback for guiding evolution towards its desired goal. Results indicate that the gate-level morphogenetic approach is promising. The research presented here is far from complete; many avenues for future research have opened. The MGEHW system that has been developed allows further research in this area to be explored experimentally. Some of the most fruitful directions for future research are described.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">circuit growth</field><field name="subject">evolvable hardware</field><field name="subject">evolutionary computation</field><field name="subject">gene expression</field><field name="subject">morphogenesis</field><field name="subject">reconfigurable hardware</field><field name="identifier">http://eprints.qut.edu.au/16231/</field><field name="validLink">True</field></doc><doc><field name="title">A case study of leadership of kindergarten principals in Hong Kong</field><field name="creator">Wong, Tricia Kwok Sai</field><field name="description">Little attention has been paid to how kindergarten principals in Hong Kong enact their leadership and how their leadership is related to the gender of the principals and to the culture of the society.  This study therefore aimed to document and explore how two kindergarten principals in Hong Kong conducted their leadership in respect of what they did, why they did so, and how they experienced their leadership, with a view to understanding the leadership conduct of these principals and to shedding light on the issues of women and the role of culture in school leadership.  Both participants were female.  One of the leaders was the principal of a non profit-making kindergarten which had joined the government's subsidy scheme, and the other was a principal of a profit-making kindergarten that had not joined the scheme.  A series of in-depth, semi-structured interviews were conducted with the principals along with observations of what they did on specific days as well as an analysis of documents the principals used in their work.  Rich and thick data were obtained regarding what these principals did in leading staff to offer an education to children, and the beliefs, values and motives underlying their leadership.  Both principals exercised strong and direct control over what to teach children, how teachers engaged in their teaching, and the activities designed to promote the kindergartens to the public to recruit children.  They did so because of their beliefs about the importance of these matters for defining the kind of education to offer to children, their determination to lead well, and their perception of staff being insufficiently competent and motivated.  Both exerted much less control on matters perceived as less important to enhancing the survival of the kindergartens.  One of the principals was concerned about adverse effects of how staff viewed her leadership, which arose from the strong control she exercised.  In light of her perception of the propriety of caring behaviour towards others in a kindergarten, she exhibited caring and teamwork behaviour aimed partly at minimising the adverse effects of her strong control.  The other principal was not concerned about negative effects on staff of the strong and direct control she exercised, but still demonstrated a range of behaviour, including caring and teamwork behavior, to motivate staff to perform.  The findings show that these leaders considered a host of factors in enacting their leadership, and thus suggest that current theorizing of women in leadership needs to capture an extended range of complex factors that may influence how female leaders conduct and experience their leadership.  In addition, the findings add to current theorizing about the motives underlying the enactment of leadership, in that control was enacted to conform to cultural expectations and to ensure adequate staff performance, while caring was enacted to minimize the adverse effects on staff of control or as means to motivate staff.  The findings also show that the two leaders made active use of culture to influence staff, and experienced tensions coming from competing cultural values and norms.  These are aspects that have not been addressed by current theorizing of the role of culture in school leadership.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">kindergarten principal</field><field name="subject">leadership</field><field name="subject">Hong Kong</field><field name="subject">gender</field><field name="identifier">http://eprints.qut.edu.au/16232/</field><field name="validLink">True</field></doc><doc><field name="title">Building school connectedness : evidence from the health promoting school approach</field><field name="creator">Rowe, Fiona</field><field name="description">School connectedness, defined as the cohesiveness between diverse groups in the school community, including students, families, school staff and the wider community, is a well-documented protective factor for child and adolescent health. However, strategies for promoting school connectedness are less well known. The Western Gateway Health Promoting Schools Grant Scheme is a program that aims to increase school connectedness by using the health promoting school approach in disadvantaged communities in South-East Queensland, Australia. The scheme provides an opportunity for schools to apply for funding to implement strategies that increase students' sense of school connectedness, using a Health Promoting School approach. Evaluation of the Western Gateway Health Promoting School Grant Scheme provided an opportunity to investigate the influence of the health promoting school approach on school connectedness. The influence of the health promoting school approach on school connectedness was evaluated using a qualitative case study methodology. Three school communities were investigated as single, related case studies to examine the impact of the health promoting school approach on school connectedness. A conceptual framework, based on the theoretical understanding of how the health promoting school approach influences school connectedness, was developed and used as a guide to investigate the relationships within the case study schools. The health promoting school model, which is a 'settings' approach to health promotion, has the potential to promote school connectedness as it is based on the inclusive, participatory, and democratic principles shown to be necessary for the development of social connectedness at the broader community level. The model illustrates this potential through two mechanisms 1) processes that are characterised by the inclusion of a diverse range of members that make up a community; the active participation of community members and equal 'power' relationships, or equal partnerships among community members; and 2) structures such as school policies, school organisation and the school physical environment, that reflect the values of participation, democracy and inclusion andor that promote processes based on these values. These processes and structures, which are located both in the classroom and within the broader school environment, collectively hold the potential to promote connectedness in the school setting. Data on these relationships were collected using in-depth interviews with representatives of groups within the school community such as school staff, parents, students, health service and community agency workers. Additionally, student focus groups and documentary evidence, such as school program reports and observations of health promoting school activities were used in the collection of data. Data sources were triangulated to gain a complete understanding of the impact of the health promoting school approach on school connectedness. Data analysis was conducted by categorising the data into themes and categories based on, but not limited to, the conceptual framework that guided data collection. Data display matrices enabled theoretical relationships between the health promoting school approach and school connectedness to be drawn. The results of the in-depth qualitative evaluation of the program show that the health promoting school approach influences school connectedness through the mechanisms of a 'whole-school approach' that encourage interaction between members of the whole school community. Specific activities that promoted school connectedness were 'whole school' activities that celebrated the school community, for example, the launch of a school cafd and 'whole-class' activities where students and school staff work together towards a shared goal, such as the planning of a school breakfast tuckshop. Activities that encouraged links between classes and school staff in a school community, for example, shared curriculum planning in the co-ordination of a school breakfast tuckshop program also contributed to school connectedness by promoting interaction among school community members. Health promoting school structures and processes help to develop mutual reciprocal relationships characterised by school community members getting to know others better and developing care and support for each other, which in turn develops into other indicators of school connectedness, such as tolerance of diversity, perceptions of being valued, trust, perceptions of safety, and decreased absenteeism. A key element of health promoting school structures and processes that enables the formation of these relationships is the inclusive nature of the approach, which encourages school community members to participate in the school community. This encourages the formation of mutual reciprocal relationships. A number of elements of the health promoting school approach encourage participation in the community. For example, the formation of mutual, reciprocal relationships requires activities that are economically inclusive, and characterised by a social, positive, fun or celebratory element; that are informal and well-managed. Specifically, events characterised by eating food together; real-life activities; activities the school community 'owns' by having a say in them; and activities that involve school community members working together are important for the development of mutual reciprocal relationships. These elements occur at the level of the school and the broader school community interactions, as well as at the level of the class and interactions between classes within the school. In summary, this research provides evidence that the health promoting school approach is an effective model to influence school connectedness, which in effect promotes the health and well-being of children and adolescents.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">school connentedness</field><field name="subject">Health Promoting School</field><field name="subject">school community</field><field name="subject">student</field><field name="subject">famyly</field><field name="subject">school staff</field><field name="subject">child and adlescent health Australia</field><field name="identifier">http://eprints.qut.edu.au/16233/</field><field name="validLink">True</field></doc><doc><field name="title">Building organisational capability</field><field name="creator">Gill, Leanne Margaret</field><field name="description">Much has been written about the benefits to be derived from maximising organisational capability as a means of increasing competitive advantage, establishing human resource functions as a strategic partner and improving stakeholder satisfaction.  However, there is very little in the research on how organisations build their organisational capability (OC).  This thesis explores how developments in our understanding of strategic planning and human resource practices have contributed to a focus in organisations on building their organisational capability.  The emergence of the resource-based theory of the firm, together with changes in human resource practices in job analysis, performance management and staff development has laid the foundation for organisational capability.  A Model of Organisational Capability is proposed that explores how systems and processes can be aligned to maximize core organisational capability.  Three research questions emerge from the literature and the Model:  *How do organisations define their Strategic Intent Domain? *How can organisations define their Core OCs?  *How do organisations embed their OCs into their Job Context, Organisational Systems and Knowledge Networks Enablers? These questions are explored by examining an Australian University utilising a participatory action research methodology.  The study focused on how the organisation engaged senior managers to develop an organisational capability framework and agreed on a strategy to embed the capabilities in HR practice.  As a result, this thesis presents a step-by-step process for organisations seeking to build their Core Organisational Capability.  Practitioners wishing to maximize their organisational capability can draw on the Model of Organisational Capability, step-by-step process and contextual principles, to assist them to engage with the organisation to explore an organisational capability agenda.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">organisational capability</field><field name="subject">strategic human resource management</field><field name="subject">resource-based theory of the firm</field><field name="subject">participatory action research</field><field name="subject">case study</field><field name="subject">university</field><field name="identifier">http://eprints.qut.edu.au/16234/</field><field name="validLink">True</field></doc><doc><field name="title">Public health management at outdoor music festivals</field><field name="creator">Earl, Cameron Phillip</field><field name="description">Background Information: Outdoor music festivals (OMFs) are complex events to organise with many exceeding the population of a small city. Minimising public health impacts at these events is important with improved event planning and management seen as the best method to achieve this. Key players in improving public health outcomes include the environmental health practitioners (EHPs) working within local government authorities (LGAs) that regulate OMFs and volunteer organisations with an investment in volunteer staff working at events. In order to have a positive impact there is a need for more evidence and to date there has been limited research undertaken in this area. The research aim: The aim of this research program was to enhance event planning and management at OMFs and add to the body of knowledge on volunteers, crowd safety and quality event planning for OMFs. This aim was formulated by the following objectives.    1.To investigate the capacity of volunteers working at OMFs to successfully contribute to public health and emergency management; 2.To identify the key factors that can be used to improve public health management at OMFs; and    3.To identify priority concerns and influential factors that are most likely to have an impact on crowd behaviour and safety for patrons attending OMFs.  Methods: This research program has involved a series of five exploratory research studies exploring two main themes within public health management for OMFs, event planning capacity and volunteer capacity. Four studies used a cross-sectional design and survey methodology to collect self-report data from each cohort while the remaining study utilised case methods.  The study participants were recruited from Australian and European OMFs. For volunteer capacity, data have been collected from volunteers at two internationally recognised OMFs. One had formal training for their volunteers and the other did not. For planning capacity, data have been collected on consumer concerns regarding OMFs, priority factors that influence crowd behaviour and safety and leadership in event planning. Results (volunteer capacity): The first studies assessed the public health and emergency management capacity of volunteers working at two OMFs. Volunteer training was provided at one event but not at the other. Comparatively, the participants from the OMF where training was provided reported noticeably better awareness of and involvement in public health and emergency management at that event. Additionally, this awareness was improved with experience volunteering at the study festivals. These studies highlighted the benefits of volunteer training and retention.    Results (event planning capacity): The next three studies focused on event planning capacity with the first being a case study on event planning leadership. The purpose of this study was to demonstrate that the event licensing programs managed by LGAs could improve health outcomes for OMFs. A European OMF, the Glastonbury Festival, was chosen for this study. After problems in 2000, it was highly likely that the event would never be held again unless public health and safety was improved. This study documents the progression from that 2000 event through to the 2004 event that was considered the safest event yet. The LGA EHPs working through the event licensing programs had engineered these changes.  The next study focused on consumer priority concerns associated with attending OMFs. A wide range of public health issues were identified as high concern including access to drinking water, toilets, safe food and personal protection issues such as females being grabbed or losing valuables. Safety in the mosh pit was a particular concern for almost half of the participants in the study. Also mosh pit safety was identified with other concerns such as females being grabbed, needing first aid, being struck by thrown items, crowd sizes, losing valuables and alcohol-related behaviour. Making safety in the mosh pit the most important public health issue for these study participants. The final study focused on identifying the main influences on crowd behaviour and safety at OMFs, particularly mosh pits. This study follows on from the consumer study. The study participants were skilled event security guards, specialising in OMFs and considered the performers, the music and group mentality as the most common motivators for changes in mosh pit behaviour. They also considered that generally (1) crowd composition, (2) drugs and particularly alcohol, (3) the type of performance, (4) venue configuration, and (5) activities of security staff were highly influential on crowd behaviour and safety at OMFs. Conclusion: Results from this research program have added to the body of evidence on public health management for OMFs. Findings support capacity building and retention for volunteer staff working at OMFs. Also this research has provided evidence on quality event planning, crowd behaviour and safety that can support EHPs working with OMFs. All of these studies have been published in peer-reviewed journals in order to communicate these findings to volunteer organisations and EHPs involved with OMFs.    Where to from here? There remains considerable opportunity for research on a variety of topics related to public health management for OMFs. Some specific areas where further work is recommended are: othe development and evaluation of a pilot training program (web-based) for Australian volunteers working at OMFs (this training package is currently under development);  othe development of a national code of practice for the event management industry; oresearch into festival patrons' risk perceptions and the impacts of those choices; oevaluation of the planning and management approaches used by specific OMFs; and oadditional detailed investigations of event characteristics such as crowd mood and its impacts on public health safety at OMFs.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">public health management</field><field name="subject">outdoor music festival</field><field name="subject">OMF</field><field name="subject">volunteer capacity</field><field name="subject">event planning capacity</field><field name="identifier">http://eprints.qut.edu.au/16235/</field><field name="validLink">True</field></doc><doc><field name="title">Structure and ideology : reworking the labour movement</field><field name="creator">Harvey, Donna Maree</field><field name="description">During the 1990s within Australia, a regulated industrial relations system which had fostered the growth of collective bargaining and trade unionism was dismantled and replaced by a neo-liberal approach to labour law.  During this period trade union membership declined dramatically.  Although overall union density has dropped, some unions have managed to arrest membership decline.  The Association of Professional Engineers, Scientists and Managers, Australia and the National Tertiary Education Industry Union have successfully traversed the neo-liberal environment despite having adopted different processes.  Through an analysis of both external and internal contingencies of these two successful but different union types, lessons were drawn as to effective forms of unionism.  A comparative analysis of the empirical information suggest the benefits of a participative structure and collective ideology to enact a range of activities including industrial, political, solidarity and service.  It is through this process that unions have the best possible means to generate alternative methods of social organisation to protect the rights and wellbeing of wage earners within a neo-liberal political economy.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Australia</field><field name="subject">trade unionism</field><field name="subject">industrial relations</field><field name="subject">neo-liberalism</field><field name="identifier">http://eprints.qut.edu.au/16236/</field><field name="validLink">True</field></doc><doc><field name="title">Modelling the cutting process and cutting performance in abrasive waterjet machining with controlled nozzle oscillation</field><field name="creator">Xu, Shunli</field><field name="description">Abrasive waterjet (AWJ) cutting is one of the most recently developed manufacturing technologies. It is superior to many other cutting techniques in processing various materials, particularly in processing difficult-to-cut materials. This technology is being increasingly used in various industries. However, its cutting capability in terms of the depth of jet penetration and kerf quality is the major obstruction limiting its further applications. More work is required to fully understand the cutting process and cutting mechanism, and to optimise cutting performance.  This thesis presents a comprehensive study on the controlled nozzle oscillation technique aiming at increasing the cutting performance in AWJ machining. In order to understand the current state and development in AWJ cutting, an extensive literature review is carried out. It has found that the reported studies on controlled nozzle oscillation cutting are primarily about the use of large oscillation angles of 10 degrees or more. Nozzle oscillation in the cutting plane with such large oscillation angles results in theoretical geometrical errors on the component profile in contouring. No published attempt has been found on the study of oscillation cutting under small angles although it is a common application in practice. Particularly, there is no reported research on the integration of nozzle oscillation technique into AWJ multipass cutting, which is expected to significantly enhance the cutting performance. An experimental investigation is first undertaken to study the major cutting performance measures in AWJ single pass cutting of an 87% alumina ceramic with controlled nozzle oscillation at small angles. The trends and characteristics of cutting performance quantities with respect to the process parameters as well as the science behind which nozzle oscillation affects the cutting performance have been analysed. It has been shown that as with oscillation cutting at large angles, oscillation at small angles can have an equally significant impact on the cutting performance. When the optimum cutting parameters are used for both nozzle oscillation and normal cutting, the former can statistically increase the depth of cut by 23% and smooth depth of cut by 30.8%, and reduce kerf surface roughness by 11.7% and kerf taper by 54%. It has also been found that if the cutting parameters are not selected properly, nozzle oscillation can reduce some major cutting performance measures.  In order to correctly select the process parameters and to optimise the cutting process, the mathematical models for major cutting performance measures have then been developed. The predictive models for the depth of cut in both normal cutting and oscillation cutting are developed by using a dimensional analysis technique. Mathematical models for other major cutting performance measures are also developed with the aid of empirical approach. These mathematical models are verified both qualitatively and quantitatively based on the experimental data. The assessment reveals that the developed models conform well to the experimental results and can provide an effective means for the optimum selection of process variables in AWJ cutting with nozzle oscillation.  A further experimental investigation of AWJ cutting of alumina ceramics is carried out in order to study the application of AWJ oscillation technique in multipass cutting. While high nozzle traverse speed with multipass can achieve overall better cutting performance than low traverse speed with single pass in the same elapsed time, it has been found that the different combination of nozzle traverse speed with the number of passes significantly affects cutting process. Optimum combination of nozzle traverse speed with the number of passes is determined to achieve maximum depth of cut. It has also demonstrated that the multipass cutting with low nozzle traverse speed in the first pass and a comparatively high traverse speed for the following passes is a sensible choice for a small kerf taper requirement. When nozzle oscillation is incorporated into multipass cutting, it can greatly increase the depth of cut and reduce kerf taper. The predictive models for the depth of cut in both multipass normal cutting and multipass oscillation cutting are finally developed. With the help of dimensional analysis, the models of the incremental cutting depth for individual pass are derived based on the developed depth of cut models for single pass cutting. The models of depth of cut for a multipass cutting operation are then established by the sum of the incremental cutting depth from each pass. A numerical analysis has verified the models and demonstrated the adequacy of the models' predictions. The models provide an essential basis for the development of optimization strategies for the effective use of the AWJ cutting technology when the multipass cutting technique is used with controlled nozzle oscillation.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">abrasive waterjet cutting</field><field name="subject">nozzle oscillation</field><field name="subject">experimental design and data analysis</field><field name="subject">cutting performance</field><field name="subject">kerf characteristics</field><field name="subject">mathematical modelling</field><field name="subject">dimensional analysis</field><field name="subject">model verification</field><field name="identifier">http://eprints.qut.edu.au/16237/</field><field name="validLink">True</field></doc><doc><field name="title">Understanding teacher commitment in times of change</field><field name="creator">Crosswell, Leanne</field><field name="description">Teacher commitment is one of the key elements in education and is arguably becoming an increasingly important factor.  The work teachers engage in on a daily basis is complex and demanding and requires a level of personal engagement and commitment. With the escalating demands and new challenges inherent in the current educational climate, what it means to be a committed teacher is also changing.  It has become imperative to gain further insight into teacher commitment due to its close association with concepts such as quality of teaching, teacher adaptability, teacher attendance, teacher burnout, teacher retention, organisational "health" of the school, and student attitudes and learning outcomes.  This multi-method study examined the phenomenon of teacher commitment as it is perceived by the teachers themselves.  The research used a multi-method enquiry approach that employed two rarely connected qualitative methods of phenomenography and case study.  It combined the two methods in an effort to extrapolate and enhance the results from one method (phenomenography) with the results from another method (case study).  The combined methodology was considered to be appropriate to investigate the complex phenomenon of teacher commitment, specifically the multi-dimensional nature of teacher commitment, which is an area that had not previously been fully explored.    In the phenomenographic investigation of this study, 30 experienced classroom teachers were interviewed.  Participants worked in schools that represent the diverse education settings and contexts of Queensland.  Geographically the range included teachers from suburban (Brisbane), regional (Rockhampton) and remote (Longreach) settings.  Schools that participated in the research included special schools, primary schools, high schools and schools of distance education. This interview data were analysed to identify categories of description and develop a conceptual "map" of teacher commitment.    The school site of Willowbark State School, a small inner city school was then investigated as a case study.  The case study elaborated on the phenomenographic categories of teacher commitment identified by this study.  Case study data were collected from a range of sources that included the school website, school documents, anecdotal evidence collected from observations and informal discussions and formal interviews with five educators with extended teaching experience.    One of the significant outcomes of the study was an informed conceptualised Model of Contemporary Teacher Commitment that illustrates the relationship between the key categories of description and as such demonstrates the "collective mind" of the teachers in the study. The study identified six categories of description of teacher commitment. These categories included teacher commitment as a passion, investment of "extra" time, a focus on the students, maintaining professional knowledge, engagement with the school community and transmitting knowledge and values.  These categories are integrated into the model by the use of two summarising dimensions, a "personal dimension" and a professional "enactment dimension."    Another key finding that emerges from the study was the centrality of passion within teacher commitment. This finding challenges the position that teacher commitment can be discussed merely in terms of external factors such as students and subject areas.  What the findings of this study do indicate is that a passionate connection to teaching is fundamental to any discussion about teacher commitment and this has implications for school and system leaders.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">teacher commitment</field><field name="subject">passion</field><field name="subject">values and beliefs</field><field name="subject">mixed-method approach</field><field name="subject">phenomenography</field><field name="subject">case study</field><field name="identifier">http://eprints.qut.edu.au/16238/</field><field name="validLink">True</field></doc><doc><field name="title">Development of predictive force models for classical orthogonal and oblique cutting and turning operations incorporating tool flank wear effects</field><field name="creator">Song, Wenge</field><field name="description">Classical orthogonal and oblique cutting are the fundamental material removal or machining processes to which other practical machining processes can be related in the study and modelling of the machining processes. In the last century, a large amount of research and development work has been done to study and understand the various machining processes with a view to improving the processes for further economic (cost and productivity) gains. However, many aspects of the cutting processes and cutting performance remains to be fully understood in order to increase the cutting capability and optimize the cutting processes; in particular, there is little study to understand the effects of the inevitable tool wear on the machining processes. This thesis includes an extensive literature review on the mechanics of cutting analysis. Considerable work has been carried out in past decades on the fundamental analysis of 'sharp' tool cutting. Although some work has been reported on the effects of tool flank wear on the cutting performance, there is a general lack of the fundamental study of the effects of the flank wear on the basic cutting or chip formation process. It has been well documented that tool flank wear results in an increase in the cutting forces. However, it was not known if this force increase is a result of the change in the chip formation process, and/or the rubbing or ploughing forces between the tool flank and the workpiece. In work carried out since the early 1980s, the effects of the so-called edge forces have been considered when the tool is not absolutely sharp. Little has been reported to further develop fundamental cutting theories to understand applications to more relevant the practical situation, i.e. to consider the tool wear effects. Based on the findings of the literature review, an experimental investigation is presented in the first part of the thesis to study the effects of tool flank wear on the basic cutting or chip formation process by examining the basic cutting variables and performance in the orthogonal cutting process with tool flank wear. The effects of tool flank wear on the basic cutting variables are discussed by a comprehensive analysis of the experimental data. It has been found that tool flank wear does not affect the basic cutting variables (i.e. shear angle, friction angle and shear stress). It is therefore deduced that the flank wear does not affect the basic chip formation process in the shear zone and in the tool-chip interface. The study also finds that tool flank wear causes an increase in the total cutting forces, as can be expected and such an increase is entirely a result of the rubbing or ploughing forces on the tool wearland. The significance of this finding is that the well-developed machining theories for 'sharp' tools can be used in modelling the machining processes when tool flank wear is present, rather than study the machining process and develop machining theories from scratch. The ploughing forces can be modelled for incorporation into the overall cutting force prediction. The experimental study also allows for the forces on the wearland (or wearland force) and edge forces to be separated from the total measured forces. The wearland force and edge force models are developed in empirical form for force prediction purpose. In addition, a database for the basic cutting variables or quantities is established for use in modelling the cutting forces. The orthogonal cutting force model allowing for the effects of flank wear is developed and verified by the experimental data. A comprehensive analysis of the mechanics of cutting in the oblique cutting process is then carried out. Based on this analysis, predictive cutting force models for oblique cutting allowing for the effects of flank wear are proposed. The wearland force and edge force are re-considered by analysing the oblique cutting process and the geometrical relation. The predictive force models are qualitatively and quantitatively assessed by oblique cutting tests. It shows that the model predictions are in excellent agreement with the experimental data. The modelling approach is then used to develop the cutting force models for a more general machining process, turning operation. By using the concept of an equivalent cutting edge, the tool nose radius is allowed for under both orthogonal and oblique cutting conditions. The wearland forces and edge forces are taken into consideration by the integration of elemental forces on the tool flank and the cutting edge, respectively. The cutting forces in turning operations are successfully predicted by using the basic cutting quantity database established in the orthogonal cutting analysis. The models are verified by turning operation tests. It shows that the model predictions are in excellent agreement with the experimental results both qualitatively and quantitatively. The major findings, research impacts and practical implications of the research are finally highlighted in the conclusion. The modelling approach considering the flank wear effects in the classical orthogonal and oblique cutting and turning operations can be readily extended to other machining operations, such as drilling and milling.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">orthogonal cutting</field><field name="subject">oblique cutting</field><field name="subject">turning operations</field><field name="subject">flank wear</field><field name="subject">wearland force</field><field name="subject">cutting force model</field><field name="subject">mechanics of cutting</field><field name="subject">chip formation</field><field name="subject">equivalent cutting edge</field><field name="identifier">http://eprints.qut.edu.au/16239/</field><field name="validLink">True</field></doc><doc><field name="title">Expression variation in lysosomal storage disorder genes</field><field name="creator">Mason, Lyndel Ann</field><field name="description">Metachromatic leukodystrophy (MLD) and Gaucher disease (GD) are caused by a deficiency of arylsulphatase A (ASA) and b-glucocerebrosidase (GBA), respectively. They are lysosomal storage disorders with a heterogeneous clinical spectrum encompassing visceral, skeletal and neurologic involvement resulting in high morbidity and mortality. The overall aim of this study is to elucidate the genetic component/s of high ASA and GBA enzyme activity in normal healthy individuals with the ultimate goal of using this information to produce greater protein activity from a recombinant protein. A wide variation in ASA and GBA enzyme activity levels has been observed in the normal population. The first objective of this project was to identify and characterise single nucleotide polymorphisms (SNPs) in the arylsulphatase A (ARSA) and glucocerebrosidase (GBA) genes that are responsible for determining the levels of expressed enzyme activity in the normal population. The second objective was to assess the contribution of transcriptional regulation and TCP80 mediated translational control to normal enzyme variation. TCP80, a translational control protein that interacts with the GBA coding region, is a splice variant of the interleukin binding factor 3 (ILF3) gene. Ten samples from individuals with high ASA activity and twenty samples from individuals with high GBA activity were screened for polymorphisms via denaturing high pressure liquid chromatography (dHPLC) and sequencing. The frequency of these polymorphisms in the normal population was determined using dot-blot hybridisation. Fifteen ARSA polymorphisms (4 promoter, 5 coding, 5 intronic and 1 poly(A) signal) and two GBA polymorphisms (1 intronic and 1 in 3&#162;-UTR) were identified. Two low frequency ASA polymorphisms (2723A &gt; G, W193C) were found to be correlated with low activity, while another low frequency ASA polymorphism (1101+123C &gt; T) was found to be correlated with high activity in a population of 113 individuals. Real time PCR was used to measure mRNA levels of GBA, ASA and LF3 along with enzyme activity levels of GBA and ASA in two cell types (leucocytes and skin fibroblasts) from four healthy individuals and seven cell lines (HL60, THP1, Huh7, U118, SW1353, Hep G2, and B-cells). Transcriptional control was evident for all three genes with GBA mRNA levels varying over 30 fold, ASA mRNA levels varying over seven fold and ILF3 levels varying more than 24 fold. The 5&#162;-flanking region of GBA was investigated for the cis-elements responsible for tissue-specific expression. However, it was not possible to demonstrate that the cis-element region was influencing GBA expression. Translational efficiency was measured using the magnitude of the mRNA:enzyme activity ratio as an indicator. GBA translational inefficiency was most pronounced in B cells which require four times more mRNA molecules than hepatocytes (Hep G2) and over 25 times more mRNA molecules than chondrocytes (SW1353) to produce one unit of GBA enzyme activity. Except in B-cells, GBA translational efficiency appears to increase as ILF3 mRNA levels decrease. The tissue-specific variation observed in the protein levels of the ILF3 splice variants, TCP80 and DRBP76, may play a role. The correlation of several low frequency SNPs with low ASA enzyme activity or high ASA activity indicates a role in determining the distribution of enzyme activity levels in the normal population. However, there do not appear to be any common high activity polymorphisms. Knowledge of the exact mechanisms responsible for the observed transcriptional and translational control of these lysosomal genes will greatly enhance the understanding of genotype-phenotype correlation and the contribution of genetic variants to natural variation.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">gaucher disease</field><field name="subject">GD</field><field name="subject">glucocerebrosidase gene</field><field name="subject">GBA</field><field name="subject">glucocerebrosidase</field><field name="subject">GBA</field><field name="subject">metachromatic leucodystrophy</field><field name="subject">MLD</field><field name="subject">arylsulphatase A gene</field><field name="subject">ARSA</field><field name="subject">arylsulphatase A</field><field name="subject">ASA</field><field name="subject">single nucleotide polymorphism</field><field name="subject">SNP</field><field name="subject">polymerase chain reaction</field><field name="subject">PCR</field><field name="subject">promoter</field><field name="subject">transcriptional regulation</field><field name="subject">translational regulation</field><field name="subject">lysosomal storage disorders</field><field name="subject">LSDs</field><field name="identifier">http://eprints.qut.edu.au/16240/</field><field name="validLink">True</field></doc><doc><field name="title">Design, experimentation and fabrication of a low cost controller board for robotic applications</field><field name="creator">Singh, Rajendra</field><field name="description">This thesis presents the design, construction and experiments done on a microcontroller board called 'SMARTY BOARD' targeted at small mobile robot applications. The primary motivation for this work was the lack of commercially available and cheap controller boards that would have all their components including interfaces on a single board. Having a single board simplifies the construction of programmable robots that can be used as platforms for teaching and learning robotics. Reducing the cost of the board as much as possible was one of the main design objectives. The target user groups for this device are the secondary and tertiary students, and hobbyists. Previous studies have shown that equipment cost is one of the major obstacles for teaching robotics in Australia. The other design objectives were robustness, reliability and functionality of the board. Most of the early technological learners such as high school students lack experience and expert knowledge for interfacing a controller board with other components. To prevent the learners from making errors, connectors on our board have been made foolproof (the user cannot damage the components of the board by plugging cables in the wrong sockets). Commercially available designs lack these essential features. After reviewing the commercially available micro-controller boards with respect to their suitability as teaching tools, we concluded that none of the existing microcontroller boards met our requirements. We then designed a new controller board based on previous boards. The main advantage of this new controller board is that it is a single board whereas the other controller boards are multi-board. Moreover, it is more foolproof. The new controller board was demonstrated at high-school seminars. In these demonstrations the new controller board was used for controlling two robots that we built. These robots are available as kits. The response from the high school teachers was very positive. The board has been selected as the platform for a robotic competition.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">low cost controller board</field><field name="subject">robotic application</field><field name="subject">software</field><field name="subject">programming</field><field name="identifier">http://eprints.qut.edu.au/16241/</field><field name="validLink">True</field></doc><doc><field name="title">An adaptive framework for Internet-based distributed genetic algorithms</field><field name="creator">Berntsson, Lars Johan</field><field name="description">Genetic Algorithms (GAs) are search algorithms inspired by genetics and natural selection, and have been used to solve difficult problems in many disciplines, including modelling, control systems and automation. GAs are generally able to find good solutions in reasonable time, however as they are applied to larger and harder problems they are very demanding in terms of computation time and memory. The Internet is the most powerful parallel and distributed computation environment in the world, and the idle cycles and memories of computers on the Internet have been increasingly recognized as a huge untapped source of computation power. By combining Internet computing and GAs, this dissertation provides a framework for Internet-based parallel and distributed GAs that gives scientists and engineers an easy and affordable way to solve hard real world problems. Developing parallel computation applications on the Internet is quite unlike developing applications in traditional parallel computation environments, such as multiprocessor systems and clusters. This is because the Internet is different in many respects, such as communication overhead, heterogeneity and volatility. To develop an Internet-based GA, we need to understand the implication of these differences. For this purpose, a convergence model for heterogenous and volatile networks is presented and used in experiments that study GA performance and robustness in Internet-like scenarios. The main outcome of this research is an Internet-based distributed GA framework called G2DGA. G2DGA is an island model distributed GA, which can provide support for big populations needed to solve many real world problems. G2DGA uses a novel hybrid peer-to-peer (P2P) design with island node activity coordinated by supervisor nodes that offer a global overview of the GA search state. Compared to client/server approaches, the P2P architecture improves scalability and fault tolerance by allowing direct communication between the islands and avoiding single-point-of-failure situations. One of the defining characteristics of Internet computing is the dynamics and volatility of the environment, and a parallel and distributed GA that does not adapt to its environment cannot use the available resources efficiently. Two novel adaptive methods are investigated. The first method is migration topology adaptation, which uses clustering on elite individuals from each island to rebuild the migration topology. Experiments with the migration topology adapter show that it gives G2DGA better performance than a GA with static migration topology of a similar or larger connectivity level. The second method is population size adaptation, which automatically finds the number of islands and island population sizes needed to solve a given problem efficiently. Experiments on the population size adapter show that it is robust, and compares favourably with the traditional trial-and-error approach in terms of computational effort and solution quality. The scalability and robustness of G2DGA has been extensively tested in network scenarios of varying volatility and heterogeneity. Experiments with up to 60 computers were conducted in computer laboratories, while more complex network scenarios have been studied in an Internet simulator. In the experiments, G2DGA consistently performs as well as, and usually significantly better than, static distributed GAs and the difference grows larger with increased network instability. The results show that G2DGA, by continuously adjusting the migration policy and the population size, can detect and make efficient use of idle cycles donated over volatile Internet connections. To demonstrate that G2DGA can be used to implement and solve real world problems, a challenging application in VLSI design was developed and used in the testing of the framework. The application is a multi-layer floorplanner, which uses a novel GA representation and operators based on a slicing structure approach. Its packing quality compares favourably with other multi-layer floorplanners found in the literature. Internet-based distributed GA research is exciting and important since it enables GAs to be applied to problem areas where resource limitations make traditional approaches unworkable. G2DGA provides a scalable and robust Internet-based distributed GA framework that can serve as a foundation for future work in the field.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">genetic algorithms</field><field name="subject">distributed genetic algorithms</field><field name="subject">Internet computing</field><field name="subject">floorplanning</field><field name="subject">adaptation</field><field name="subject">VLSI</field><field name="identifier">http://eprints.qut.edu.au/16242/</field><field name="validLink">True</field></doc><doc><field name="title">A preliminary formalism for variable coupling in agile systems</field><field name="creator">Redding, Guy Matthew</field><field name="description">It is generally the case that corporate information systems consist of heterogeneous software subsystems that interact using many various processes and protocols. Applications that execute within such subsystems tend to be designed in isolation with little or no thought given to the requirements for future interaction. To provide bridges between these heterogeneous subsystems, one-off "hacked" solutions are usually introduced which rely upon maintenance of the status quo for all aspects of the execution environment and are thus inherently "brittle". Such a situation is inappropriate for large-scale and highly decentralised system deployments.  In order to make such systems more robust and exhibit scalable performance characteristics, it is preferable to construct them with the ability to react to changes in the environment that they operate within. This research seeks to provide a method of how to engender "agility" into system components to improve their ability to deal with unpredictable environments. Our approach is to view systems and components from an interactive perspective and provide a middleware mechanism that enables a "variable" degree of coupling between system components. To achieve this we introduce three high-level "dimensions" of coupling, namely mediation, adaptation and crystallisation. Each dimension is characterised by the location of behaviour required for interaction and patterns of behaviour movement. The coordination characteristics of these dimensions of coupling are specified to establish a separation of coordination and application functionalities in endogenous distributed systems. The outcomes of this research project are: a definition for the dimensions of coupling that have been identified, a protocol to perform transitions between dimensions and a preliminary framework for the development of more agile applications.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">information system</field><field name="subject">heterogeneous software</field><field name="subject">agility</field><field name="identifier">http://eprints.qut.edu.au/16243/</field><field name="validLink">True</field></doc><doc><field name="title">Multiliteracies : a critical ethnography : pedagogy, power, discourse and access to multiliteracies</field><field name="creator">Mills, Kathy Ann</field><field name="description">The multiliteracies pedagogy of the New London Group is a response to the emergence of new literacies and changing forms of meaning-making in contemporary contexts of increased cultural and linguistic diversity. This critical ethnographic research investigates the interactions between pedagogy, power, discourses, and differential access to multiliteracies, among a group of culturally and linguistically diverse learners in a mainstream Australian classroom. The study documents the way in which a teacher enacted the multiliteracies pedagogy through a series of mediabased lessons with her year six (aged 11-12 years) class. The reporting of this research is timely because the multiliteracies pedagogy has become a key feature of Australian educational policy initiatives and syllabus requirements. The methodology of this study was based on Carspecken's critical ethnography. This method includes five stages: Stage One involved eighteen days of observational data collection over the course of ten weeks in the classroom. The multiliteracies lessons aimed to enable learners to collaboratively design a claymation movie. Stage Two was the initial analysis of data, including verbatim transcribing, coding, and applying analytic tools to the data. Stage Three involved semi-structured, forty-five minute interviews with the principal, teacher, and four culturally and linguistically diverse students. In Stages Four and Five, the results of micro-level data analysis were compared with macro-level phenomena using structuration theory and extant literature about access to multiliteracies. The key finding was that students' access to multiliteracies differed among the culturally and linguistically diverse group. Existing degrees of access were reproduced, based on the learners' relation to the dominant culture. In the context of the media-based lessons in which students designed claymation movies, students from Anglo-Australian, middle-class backgrounds had greater access to transformed designing than those who were culturally marginalised. These experiences were mediated by pedagogy, power, and discourses in the classroom, which were in turn influenced by the agency of individuals. The individuals were both enabled and constrained by structures of power within the school and the wider educational and social systems. Recommendations arising from the study were provided for teachers, principals, policy makers and researchers who seek to monitor and facilitate the success of the multiliteracies pedagogy in culturally and linguistically diverse educational contexts.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">multiliteracies</field><field name="subject">access</field><field name="subject">critical ethnography</field><field name="subject">critical sociology</field><field name="subject">sociocultural theory</field><field name="subject">multiliteracies pedagogy</field><field name="subject">structuration theory</field><field name="subject">pedagogy</field><field name="subject">power</field><field name="subject">discourse</field><field name="subject">diversity</field><field name="subject">culture</field><field name="subject">multimodal</field><field name="subject">monomodal</field><field name="subject">literacy</field><field name="subject">linguistics</field><field name="subject">semiotics</field><field name="subject">design</field><field name="subject">digital texts</field><field name="subject">Learning by Design</field><field name="subject">overt instruction</field><field name="subject">situated practice</field><field name="subject">critical framing</field><field name="subject">transformed practice</field><field name="subject">intertextuality</field><field name="subject">lifeworld</field><field name="subject">situated learning</field><field name="subject">marginalisation</field><field name="subject">domination</field><field name="identifier">http://eprints.qut.edu.au/16244/</field><field name="validLink">True</field></doc><doc><field name="title">Local moorings, international visions : fabricating internationalised practices in Australian higher education</field><field name="creator">O'Regan, Justine Mary</field><field name="description">Over the last two decades, Australian higher education has undergone dramatic changes in purpose and orientation.  Changes in public funding arrangements and concomitant policy statements have contributed to the reconceptualisation of Australian higher education, and internationalisation has become a core goal for Australian universities.  In light of these dynamics, this study examined understandings of internationalisation within two Australian universities.    The study examined the ways in which internationalisation was understood by university staff working in either a teaching capacity and/or a managerial position. Situated within the broad field of critical sociology, the study drew on critical realism (Bhaskar, 1979, 1989), critical epistemology (Carspecken, 1996) and reflexive sociology (Bourdieu, 1972, 1990) to analyse how the universities and their staff positioned themselves in relation to the goal of internationalisation.  Furthermore, the study examined how this goal served to reposition the institution and/or various forms of university work.  The insights of critical social theory were used to examine the contested power relations associated with the growing importance attributed to the goal of internationalisation in Australian higher education.    The significance of the study resides in its recognition of the ways in which academic and non-academic subcultures within the university contribute to the goal of internationalisation.  Whereas previous research viewed divergence of understandings as weakening the commitment given to internationalisation as an institutional goal, this study has shown that such diversity stems from the differential encounters with and experiences of internationalisation.  Moreover, in previous research, the pre-determined objectives for internationalisation resulted in the compartmentalisation of this goal, as in economic objectives and academic objectives. In contrast, this study focused on the dynamic and evolving nature of internationalisation in higher education.  Consequently, the study's contribution lies in its explanation of the long term benefits to be derived from viewing internationalisation as a dynamic and generative phenomenon, rather than simply as a pre-determined goal. A case study approach was used in this research with two contrasting onshore Australian universities selected as the case sites.  One institution had a reputation as an elite, research intensive university.  The other was a post-Dawkins university with a strong vocational orientation.  At each site, semi-structured interviews were conducted with staff from across the university's hierarchy.  Interviewees included the Pro Vice-Chancellor for the Office of Internationalisation, the Chair of the Academic Board, the Director of the Teaching and Learning Support Unit, Faculty Deans, Heads of Departments, as well as departmental staff concerned with first year teaching. Departmental staff were drawn from two disciplinary areas, Australian History and Marketing.  Interviews engaged participants in discussion about the processes by which internationalisation was enacted.  Furthermore, university documents, such as the Strategic Plan, were analysed in terms of how the given institution constructed the need for internationalisation and the means by which this goal was to be achieved. The study found that internationalisation involves and promotes constant adaptability.  The two institutions used whatever resources they had to develop and promote their international aspirations. The international visions of the institutions were influenced by both their historical and intended relationship with the broader higher education world.  The elite, research intensive institution viewed internationalisation with becoming a university of international standing.  This institution used its bureaucratic and hierarchical nature to advance its objectives for internationalisation.  The vocationally oriented university had developed an internationalisation policy with a view to maximising the revenue to be derived from its diverse international activities and to gaining greater prestige within the higher education field. Staff involved with managerial and/or teaching work were found to develop their ideas about internationalisation through a combination of personal and professional experiences. The study confirmed the growing trend for academics to assume managerial roles in addition to their teaching and research. Consequently, accounts of internationalisation were not necessarily confined to a purely managerial or an academic perspective. Furthermore, the accounts of internationalisation differed between and within the two selected disciplines. On the one hand, specific disciplinary attributes could be seen by the academics interviewed as inherently international, even though they may not assist in realising institutional objectives for internationalisation. On the other, academics spoke of the perceived need for the frames of reference used in undergraduate education to be broadened, given the globalised nature of contemporary society and/or the increasing international enrolments.  The study concluded that internationalisation is an important means by which the localised priorities of an institution, an academic department, and/or of individuals can engage with forms of global mobility.  Moreover, the study argued the need for all staff and students in Australian higher education to see themselves as part of the processes of internationalisation.  This latter point raises questions about the personal and professional attributes required of academics when working within internationalised Australian universities.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">academic work</field><field name="subject">critical epistemology</field><field name="subject">critical realism</field><field name="subject">critical sociology</field><field name="subject">globalisation</field><field name="subject">higher education</field><field name="subject">intercultural connectedness</field><field name="subject">internationalisation</field><field name="subject">internationalisation at home</field><field name="subject">international/overseas students</field><field name="subject">local-global dynamics</field><field name="subject">reflexive sociology</field><field name="subject">undergraduate education</field><field name="identifier">http://eprints.qut.edu.au/16245/</field><field name="validLink">True</field></doc><doc><field name="title">Phytoestrogen status in relation to sociodemographic factors and biomarkers of bone health in older Brisbane women</field><field name="creator">Hanna, Katherine Lavina</field><field name="description">Background:  Phytoestrogens are diphenolic compounds found in plants with a structure and molecular weight similar to oestradiol which enables them to bind to the oestrogen receptor.  Isoflavonoids occur mainly within the legume family with highest concentration in soybeans.  Lignans are found in a range of plant foods and the richest known source is linseed.  Few studies have been published on intake of isoflavonoids and none were located on intake of lignans in Australian women.    The validity of methods designed to estimate intake can be assessed using urinary excretion of isoflavonoids and lignans as studies have found an association between intake and excretion of isoflavonoids and lignans.  It has been proposed that, through their ability to act like oestrogen, phytoestrogens could decrease bone turnover and attenuate the loss of bone mineral density (BMD) at menopause.  The aims of this research were to determine the pattern of intake of isoflavonoids and lignans in 500 women from food and supplements and to assess a questionnaire used to estimate intake using excretion in a sub-sample of 141 women.  Associations between usual intake or excretion of isoflavonoids and lignans and biomarkers of bone health were also examined.    Methods:  A cross-sectional study was conducted involving 500 women aged 40-80 years participating in the Longitudinal Assessment of Ageing in Women (LAW), a 5 year study being conducted in the Betty Byrne Henderson Centre at the Royal Brisbane and Women's Hospital.   Subjects were randomly selected from the electoral role and stratified into ten year age groups. Intake of isoflavonoids and lignans from food and supplements was assessed using a specially designed questionnaire containing 110 items.  Values for individual items were obtained from published literature and summed to provide average daily intakes of isoflavonoids and lignans (mg/d). A sub-sample of 141 women was recruited to take part in the assessment of the association between phytoestrogen intake and excretion.  Participants collected three 24-h urine samples spaced over one week.  Samples were analysed using high performance liquid chromatography MS/MS for seven isoflavonoids and four lignans.  Bone mineral densities (BMD) of the femur neck, total hip and lumbar spine were measured by dual energy x-ray absorptiometry.  Bone formation was assessed using serum bone alkaline phosphatase (bone ALP) and osteocalcin (OC) and bone resorption was assessed using deoxypyridinoline (DPD) and urinary excretion of N-terminal cross-linking telopeptide of type-I collagen (NTX).  Potential confounding factors were also evaluated.  Statistical analyses were conducted using SPSS for windows (version 10). Participants were defined as consumers if they reported intake of one or more serves of soy or linseed in the prior month.  Differences in socio-demographic and lifestyle characteristics between groups were assessed using ANOVA and Chi Square tests. Associations between intake and excretion of phytoestrogens were assessed using Spearman's rank-order correlations (&#61554;) for non-normal data.  Phytoestrogen intake was categorised into four groups for the assessment of the association with markers of bone health.  Associations between phytoestrogen excretion and markers of bone health were assessed using Pearson's product moment correlations for normal data (r) and Spearman's rank-order correlations for non-normal data. A value of P &lt; 0.05 was taken as statistically significant.    Results:  Consumption of soy food was reported by 40% and consumption of linseed by 34% of women.  Median (range) intakes among soy/linseed consumers for isoflavonoids, 3.87 (0-173) mg/d, and lignans, 2.40 (0.1-33) mg/d, were significantly higher than corresponding intakes among non consumers of 0.005 (0-2.6) and 1.57 (0.4-4.7) mg/d, respectively (P &lt; 0.001). Soy/linseed consumers reported higher intakes of energy (P=0.043), dietary fibre (P=0.003) and polyunsaturated fat (P=0.004); and a higher level of physical activity (P=0.006), SEP (P &lt; 0.001), education (P &lt; 0.001) and supplement use (P &lt; 0.001). Use of non-prescription supplements for menopause in the previous month was reported by 13% of women.  A review of supplements available for treatment of menopause indicated that use of soy, red clover, black cohosh and sage could have a role in treatment of menopause symptoms.  Evidence supporting the presence of oestrogenic components was available for soy and red clover isoflavonoids only.  There was a significant association between intake and excretion of isoflavonoids within the total group (r=0.207, P &lt; 0.05), with a stronger association in soy consumers (r=0.364, P &lt; 0.01).  Excretion of isoflavonoids was detected in women who did not report known intake of soy foods, suggesting isoflavonoids could be derived in small amounts from other plant foods or use of soy as an ingredient in processed foods. There was no significant association between intake and excretion of lignans, however both intake and excretion were associated with dietary fibre (r=0.303 and r=0.230, respectively, P &lt; 0.01 for both).  Bone ALP was higher among the very low isoflavonoid intake group (P=0.005) for the total sample (P=0.005) and women with BMI&#8804;25 kg/m2 (P=0.002).  Data also demonstrated an inverse association between excretion of isoflavonoids and NTX within women with BMI&#8804;25 kg/m2 (r=-0.33, P &lt; 0.05).  There was a positive association between lignan excretion and bone ALP in the total sample (r=0.21, P &lt; 0.05) which was strengthened in women with osteoporosis/osteopenia (r=0.41, P &lt; 0.05) and a positive association between lignan excretion and DPD among women with BMI&#8804;25 kg/m2 (&#961;=0.28, P &lt; 0.05) All associations remained significant after adjustment for confounding.  Conclusions:  Few women who chose phytoestrogen-rich foods consumed amounts similar to women with traditional soy-based diets although some achieved high intakes with supplements. Women who consumed soy or linseed foods differed in lifestyle and sociodemographic characteristics that could influence the association with disease in epidemiological studies.   Results indicated that the phytoestrogen questionnaire was useful for assessment of isoflavonoids but was not acceptably precise for measurement of lignans. Findings suggest that there is an inverse association between isoflavonoid status and bone ALP and NTX although the precise mechanism of action has not been clarified.  The association between lignan intake and bone is less well understood; however findings of a positive association with bone ALP indicate that further research on the lignan content of foods and the inclusion of lignans in studies is warranted.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">phytoestrogens</field><field name="subject">isoflavonoids</field><field name="subject">lignans</field><field name="subject">soy</field><field name="subject">linseed</field><field name="subject">food intake</field><field name="subject">dietary supplements</field><field name="subject">urine</field><field name="subject">bone mineral density</field><field name="subject">bone remodelling</field><field name="subject">menopause</field><field name="subject">osteoporosis</field><field name="identifier">http://eprints.qut.edu.au/16246/</field><field name="validLink">True</field></doc><doc><field name="title">The Role of Bacterial GTPases in Chlamydial Development</field><field name="creator">Polkinghorne, Adam</field><field name="description">Members of the important disease causing bacterial generas, Chlamydia and Chlamydophila, are characterised by a complex developmental cycle which is comprehensively described by microscopy. The inability to use standard genetic techniques for this obligate intracellular bacterium, however, means that significant gaps in our understanding of the molecular mechanisms used to control growth and development of Chlamydia still exist. The current study investigated the function of bacterial guanosine triphosphatases (GTPases), components of the organism's limited signal transduction arsenal, in regulatory control of the chlamydial development cycle. Initial analysis of the gene transcription of chlamydial GTPases and other predicted signal transduction genes using real time RT-PCR, in a Chlamydophila pneumoniae A-03 tryptophan depletion model of persistence, revealed significant differential expression of genes in response to the addition of interferon gamma (IFN-&#947;). Predicted chlamydial GTPase encoding genes, ychF, yhbZ and yphC, associated with ribosome function amongst other processes were strongly up-regulated, while hflX was down-regulated in the persistent cultures. Analysis of an additional model of Cp. pneumoniae persistence, induced by limitation of host cell iron, revealed that ychF, yhbZ and yphC were also up-regulated in the persistent cultures. This study provided the most comprehensive analysis of Cp. pneumoniae gene transcription to date and suggest that chlamydial GTPases serve a role in generation of the persistent chlamydial phenotype. Cloning and expression of Cp. pneumoniae and Cp. abortus yhbZ, including demonstration of in vitro GTPase activity, indicates that this chlamydial gene encodes a member of the universally conserved and essential bacterial Obg subfamily of GTPases. Evidence is building that members of this latter family of bacterial GTPases are important regulators of bacterial growth and morphological differentiation in developmentally complex bacteria. Over-expression of chlamydial YhbZ subfamily GTPases in Escherichia coli revealed inhibition of bacterial growth and disruption of cell division and chromosome functions leading to the generation of elongated cells with limited chromosome segregation, as described for Obg subfamily members from E. coli and other bacteria. Although more analysis is required, we suggest a novel mechanism of chlamydial Obg GTPase regulation involving sensing of host cell GTP/GDP pools to control secondary differentiation of reticulate bodies (RBs) back to elementary bodies (EBs). Analysis of the chlamydial complement of bacterial GTPases was extended to HflX, a previously uncharacterised and only predicted GTPase conserved in bacteria. HflX sequence analysis revealed conservation of G motifs responsible for nucleotide binding and hydrolysis (G1, G3, G4) and protein interaction (G2), although the latter was unique to HflX subfamily GTPases. Recombinant Cp. pneumoniae HflX displays GTPase activity with nucleotide specificity for GTP. We tested Cp. pneumoniae HflX function by over-expression in E. coli which led to inhibition of growth in E. coli and elongation of cells with normal chromosome partitioning. This phenotype was the probable result of disruption of a stage in cell division subsequent to chromosome segregation. This present study provides the first evidence to show that bacterial HflX is a GTPase and suggests a regulatory role in bacterial cell cycle control.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">chlamydophila pneumoniae</field><field name="subject">signal transduction</field><field name="subject">persistence</field><field name="subject">gamma interferon</field><field name="subject">real-time PCR</field><field name="subject">RT-PCR</field><field name="subject">differential gene expression</field><field name="subject">GTPase</field><field name="subject">ribosome</field><field name="subject">cell cycle</field><field name="subject">chromosome partitioning</field><field name="identifier">http://eprints.qut.edu.au/16247/</field><field name="validLink">True</field></doc><doc><field name="title">The dynamics of learning partnerships : case studies from Queensland</field><field name="creator">Peirce, Heather Jean</field><field name="description">This study examines the emerging notion of learning partnerships. As the study of such partnerships is a nascent research field, no single definition has yet emerged in the literature. However, within an uncertain and rapidly changing global context, two strategic initiatives have been identified which will support individuals, communities and organisations in their transition to a knowledge-based economy whilst building capacity for change and renewal. These two strategies are fostering learning communities/regions/towns and developing learning partnerships between multiple stakeholders. The term "learning partnership" has appeared in a wide variety of literatures including those of adult learning, management, social science and education. Working papers and emerging case reports identify a diversity of applications and a range of operational models or configurations that link multiple stakeholders. Learning partnerships have been associated with vocational education and training, innovation and research, lifelong learning, organisational learning and knowledge cultivation. These literatures reveal a paucity of Australian research to explain how multiple stakeholders form and develop these configurations, particularly in the Queensland context. The purpose of this study is to build deeper understanding of the meaning of a learning partnership in the Australian and (more precisely) the Queensland context. A working definition of a learning partnership, adopted as the basis for the research, indicates a strategy designed to foster continuous learning, collaboration, innovation and renewal in response to the demands of the knowledge-based economy and knowledge and learning societies. The research focuses on organisational arrangements in order for the researcher to gain deeper understanding from the key stakeholders in their work environments. Three diverse situations were selected for detailed exploration of their issues, relationships, activities, processes and working knowledge. With a view to contributing to emerging theory, an organisational case study methodology  was adopted to identify and explore the nature of the relationships and issues confronting the key stakeholders in three Queensland-based learning partnerships. An interpretive theoretical framework draws on the social theory of symbolic interactionism and the "systems thinking" of General Systems Theory. An interpretivist perspective influenced the case study research strategy and guided data collection, analysis and reporting. Within the case studies, data collection methods included observations, informal meetings, synergetic focus groups, semi-structured interviews, diary notes, researcher memos and documents. From these multiple data sources, the researcher was able to assemble three case files. The inductive process for within-case analysis for the case reports, and later, cross-case analysis, integrated as a form of constant comparison technique, was used as a basis for presenting findings. These findings are reported as three separate "in progress" models to address three interrelated research questions. The case reports explain complex and interconnected organisational arrangements - evolving, adapting and responding to internal and external tensions. While there is considerable activity which could be regarded as representing learning partnerships, there is no cohesive policy framework to support such partnerships, and much ambiguity, "muddy" definitions and unclear terminology. It appears that a "new breed" of knowledge-worker is emerging - linking, networking, interacting, exchanging - to work across organisational intersections. The study shows that like "herding cats", co-ordinating and managing the inter relationships at the organisational intersection take time, resources, vision, processes for interaction, individual willingness and "in-kind" support. Whilst there is opportunity for linking disparate groups to cross-fertilise ideas, working knowledge, and information, and there is the potential to cultivate a knowledge and learning ecosystem (a fertile compost heap for knowledge generation and an innovative learning system) - "intellectual horsepower" - such configurations may also derail, realign or stagnate. It is individual stakeholders who form the relationships, interact, share ideas, and build networks, and it is the individual who maintains the relationships, engages in the process and learns from the experience. Therein lies a paradox between the strength of diversity of the collective (synergies) and their weakness as the relationships may be compromised by a single individual who withdraws or transfers. Drawing on a computing analogy, this could be akin to "corruption" in a system which may not be sufficiently robust to tolerate ambiguity, or a system that is too inflexible to survive threats while maintaining the momentum to adapt and renew. On the basis of this research it would appear that a more robust or resilient paradigm is emerging with interconnected, blurred boundaries and much "talking and thinking" about more sustainable futures. The study identifies these as indicative of wider social and economic changes. The thesis proposes three conceptual models as particularly useful in interpreting these "shifting systems and shifting paradigms": the concentric, the centripetal, and the plutonic.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">learning partnerships</field><field name="subject">shifting paradigms</field><field name="subject">shifting systems</field><field name="subject">complex adaptive systems</field><field name="subject">innovation</field><field name="subject">lifelong learning</field><field name="subject">knowledge economy</field><field name="subject">knowledge and learning age</field><field name="subject">knowledge and learning ecosystems</field><field name="subject">systems thinking</field><field name="subject">interpretive theoretical framework</field><field name="subject">plutonic knowledge</field><field name="subject">knowledge octopus</field><field name="subject">sustainable economic development</field><field name="identifier">http://eprints.qut.edu.au/16248/</field><field name="validLink">True</field></doc><doc><field name="title">Students' lived experience of transition into high school : a phenomenological study</field><field name="creator">Ganeson, Krishnaveni</field><field name="description">There is a need to understand the transition of students from primary to secondary schooling outside the confines of practitioners' and academics' viewpoints. This thesis explores that transition from the perspectives of the students themselves. It argues that they experience the transition into secondary schooling as challenging. This issue is significant because transition into high school coincides with adolescent  developmental changes - social, physical, emotional, cognitive and psychological - as well as the move from the relative stability of one teacher a year to different teachers for each subject, and the shift in status from being the most senior to the most junior students in their school. These students also face challenges such as friendship and identity issues as well as problems locating places in the new environment, for example, subject classrooms, play areas, teachers' rooms.    This study's theoretical framework is constructed from a phenomenological psychological stance. A phenomenological methodology guides this study, allowing students' experiences to speak for themselves. Other methodologies were not appropriate as the researcher wanted to hear the students' voices while they were experiencing transition. Few studies in the past have attempted to study transition into high school as it is lived and experienced by students themselves. This empirical study addresses that gap in the literature. Its findings could provide the necessary information needed to further assist educationalists in developing appropriate programs and activities to support this group.  	Sixteen adolescents participated in the study. Of two common methods of collecting data in phenomenological studies - interviews and journal writing - journal writing was chosen. This data collection technique enabled the researcher to learn about transition from students' perspectives.  The data were collected in the first ten weeks of high school from Year 7 students (first year of high school in New South Wales). Drawing on the work of Giorgi (1985a, 1985b), who translated aspects of phenomenological philosophy into a concrete method of research (Ehrich, 1997), a phenomenological psychological approach was used to analyse the data in a step-by-step process. There were four steps to the analysis of the data. The first step involved reading through the entire description of the participants' experience to get a sense of the meaning of the experience as a whole. In the second step, the description was read to identify meaning units, i.e. words/phrases that clearly express meanings of the experience of transition. In the third step, the analysis involved transformation of the meaning units from participants' concrete descriptions into more general categories. The fourth step involved two aspects: a situated structural description of the experience was written, and finally the researcher produced a general structural description that represented the whole experience of the phenomenon. 	Because of the small sample selected, the study does not claim generalisability across other populations of adolescents. However, what the study does is to highlight seven essential themes of transition. First peers can play a significant role in enabling a smooth transition to high school. Second, schools support transition through a number of programs and activities to help students adapt to the new environment. Third, students need to learn new procedures, location of rooms and other new routines in this environment. Fourth, learning occurs through the academic, practical and extracurricular activities and some learning is more challenging than other types of learning. Fifth, high school transition is enhanced when students are confident and feel a sense of achievement and success in their new environment. Sixth, homework and assignments are a part of the high school curriculum. Finally, teachers' attitudes/abilities can affect student integration into high school and make learning fun or boring.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">student</field><field name="subject">school transition</field><field name="subject">phenomenological study</field><field name="subject">learning</field><field name="subject">study environment</field><field name="identifier">http://eprints.qut.edu.au/16249/</field><field name="validLink">True</field></doc><doc><field name="title">The masquerade of the feminine</field><field name="creator">Boyes, Emma Louise</field><field name="description">This project investigates the apparent contradiction of a female artist who prioritises embodied presence in her art works, but produces Minimalist installations. It does this by describing in detail and analysing, and thus re-evaluating the significance of, the full range of actions and processes that are performed to produce the work. It further proposes that, in the actions of crafting the individual elements and in designing, planning and installing the work in Modernist gallery spaces, conditions are set up for viewers of the finished work to experience a physical awareness that echoes that of the artist in those actions and processes.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">visual arts</field><field name="subject">practice led research</field><field name="subject">phenomenology</field><field name="subject">feminism and minimal art</field><field name="identifier">http://eprints.qut.edu.au/16250/</field><field name="validLink">True</field></doc><doc><field name="title">Unifying abstractions and code with concern maps</field><field name="creator">Cooney, Patrick</field><field name="description">People trying to understand, develop and maintain software have faced greater challenges as the complexity of software systems has increased. These challenges include the difficulty of cleanly separating different intertwined parts of a system, or relating parts of the system spread across many modules. This makes it difficult to neatly identify an area of interest, which in turn makes it difficult to understand or edit that area. The ability to separate these areas of interest, called concerns, into their own modules has been shown to improve the situation.    Several approaches have been developed to enable this separation: aspect-oriented programming allows program code to be divided into smaller modules that better match areas of interest; reverse engineering tools help programmers extract information from an existing system; requirements traceability tools track individual requirements through the development process. This thesis describes a technique that works in a wide variety of circumstances.  This technique allows users to create simple diagrams that describe the concern and then annotate this diagram with query expressions which link the diagram to related development artefacts like source code or documents. This research has used the tool in a set of common scenarios and compared the results to those achieved using other approaches.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">separation of concerns and feature interaction</field><field name="subject">software engineering tools and environments</field><field name="subject">software evolution and change management</field><field name="subject">software architectures and design</field><field name="identifier">http://eprints.qut.edu.au/16251/</field><field name="validLink">True</field></doc><doc><field name="title">The relationship between strength, power and speed measures and playing ability in premier level competition rugby forwards</field><field name="creator">Bramley, Wesley Joel</field><field name="description">Physical tasks such as scrummaging, rucking and mauling are highly specific to rugby and also place unique physiological demands on the different playing positions within the forwards. Traditionally, the recruitment and development of talented rugby union players has focused on the assessment of motor skills and game intelligence aspects of performance, with less emphasis placed on the specific physiological requirements of playing positions in rugby. The purpose of this investigation was to measure the position-specific strength, speed and power characteristics of Premier rugby forwards in order (1) to determine whether any differences existed in the physiological characteristics of the different forward playing positions (prop, lock and loose forwards) and (2) to investigate the relationship between these physiological characteristics and coaches evaluations of football playing ability. Twenty-two male Premier level competition rugby forwards, consisting of eight prop forwards, five lock forwards and nine loose-forwards participated in the study. The Grunt 3000, a rugby specific force testing device was utilised to measure the static and dynamic horizontal strength during simulated scrummaging and rucking/mauling movements.  Sprint times relating to acceleration ability (0 -10m, 0-20m) and maximum running speed (20 - 40m) were measured during a 40m sprint running test. In addition, force, power and displacement characteristics of a countermovement vertical jump were calculated from trials performed on a force plate. Also, player performance skill and physical capacity scores were determined independently by experienced coaches who assessed them based on their performances during the season. One-way analysis of variance and effect size statistics evaluated differences in the measured variables between forward playing positions and linear regression analysis evaluated the relationship between the coaches' scores of player performance skill and physical capacity and game specific measures of strength speed and power.    Since there were no statistical significant differences between forward groups for horizontal force and countermovement jump variables and these analyses lacked statistical power, an effect size statistic was used to establish trends for differences in force and CMJ variables between the groups. There were moderate effect size differences between groups for horizontal impact force with prop and lock forwards producing 17.7% and 12.8% more force than the loose forwards respectively. No clear differences were apparent between forward positional groups for mean dynamic horizontal force and countermovement jump displacement of the centre of gravity. A significant difference (p =0.049) was shown between forward positional groups over the 0-40m sprint distance. Also, moderate effect size differences between pairs of groups were evident in 0-10m, 0-20m, 20-40m sprint times with both loose forwards and lock forwards on average, 6% faster than the prop forwards. A backward linear regression analysis revealed that the single best predictor of coaches' physical capacity and performance skill scores was the 20 - 40m sprint performance, accounting for 28% of the variance in player's physical capacity scores and 29% of the variance in player's performance skill scores.    Whole-body horizontal static strength and impact strength in prop forwards and dynamic horizontal strength (relative to body mass) and sprint acceleration ability in loose forwards represent key factors for consideration when selecting forward players to these positions in the Premier rugby competition. The vertical jumping ability of all forward positional groups needs to be confirmed in a future study utilising a line-out specific countermovement jump test (free use of arm swing and line-out lifters in the jump) on a force plate. Monitoring of performance in rugby forwards should include an acceleration sprint test (0-10m) as this is specific to the sprinting patterns of forward players during a game, and maximum sprinting speed test (20-40m) as this test has the ability to discriminate between skilled and less-skilled rugby union forwards.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">rugby</field><field name="subject">performance</field><field name="subject">forward players</field><field name="subject">playing position</field><field name="subject">horizontal force</field><field name="subject">sprint times</field><field name="subject">power</field><field name="subject">countermovement jump</field><field name="subject">physical capacity</field><field name="subject">relationship</field><field name="subject">coach</field><field name="subject">physical capacity score</field><field name="subject">performance skill score</field><field name="subject">dynamic</field><field name="subject">static</field><field name="subject">measures</field><field name="subject">football playing ability</field><field name="subject">ruck</field><field name="subject">maul</field><field name="subject">scrum</field><field name="subject">line-out</field><field name="identifier">http://eprints.qut.edu.au/16252/</field><field name="validLink">True</field></doc><doc><field name="title">What happens next?  " Telling " the Japanese in contemporary Australian screen stories</field><field name="creator">Taylor, Cory Jane</field><field name="description">This study investigates the challenges facing screenwriters in Australia who set out to represent the Japanese on screen. The study is presented in two parts; an exegesis and a creative practice component consisting of two full length feature film screenplays. The exegesis explores how certain screenwriting conventions have constrained recent screen images of the Japanese within the bounds of the cliched and stereotypical, and argues for a greater resistance to these conventions in the future. The two screenplays experiment with new ways of representing the Japanese in mainstream Australian film and aim to expand the repertoire of Asian images in the national film culture.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Japanese</field><field name="subject">Australian</field><field name="subject">screenwriting</field><field name="subject">representation</field><field name="subject">stereotypes</field><field name="subject">Orientalism</field><field name="subject">film</field><field name="subject">cinema</field><field name="subject">narrative</field><field name="subject">whiteness</field><field name="subject">multiculturalism</field><field name="subject">identity</field><field name="subject">ethnicity</field><field name="subject">Clara Law</field><field name="subject">John Doyle</field><field name="subject">Mike Leigh</field><field name="subject">Changi</field><field name="subject">Heaven&#146;s Burning</field><field name="subject">The Goddess of 1967</field><field name="subject">Japanese Story</field><field name="subject">Secrets and Lies</field><field name="identifier">http://eprints.qut.edu.au/16253/</field><field name="validLink">True</field></doc><doc><field name="title">Government funded public broadcasting : a United States ethical necessity</field><field name="creator">Ballou, Nicole Arielle</field><field name="description">While journalistic ethics exists in the Untied States today, it works primarily to address dilemmas in the profession, as opposed to working to comprehensively understand journalism in relation to its public duties. This role in United States journalism is not only misunderstood by the majority of journalists working in the media industry, it is also misunderstood by the public. This misinterpretation is directly linked to the concepts of cultural separation between the 'natural' laws that run the market place and those things in society that influence everything else. In this sense, journalism has become an industry working in the market place. Essentially, the product of completely corporatising the media industry has created a gap between the role of journalism in a democratic society and the current state of journalism in the United States.  That said, the relationship between the media and democracy can be traced back through the history of United States democracy and the subsequent history of journalism as a profession that was an essential part to keeping the public sphere of democratic debate healthy. A section of journalists, public journalists, currently attempt to heed the public responsibility needed to create this space for democratic debate. However, these journalists, though earnest in their pursuit to rebuild the type of journalism needed to create this democratic sphere, cannot reach the masses effectively without more funding and more autonomy. Likewise, the public broadcast station (PBS) in the United States could be enhanced in many ways with more funding and more autonomy. Such funding and autonomy for media in the United States could come from a tax-payer funded public broadcast station. And though not all media need to bear the responsibility of journalism focused on public life and politics, a section of the mass media should commit itself to creating a sphere to enhance democratic debate.  This thesis explores the necessity of a government funded mass media source in the United States. Given that United States media and democracy are inherently linked, as I will aim to show through the development of democratic history and the development of liberal democracy in the United States today, the ethical need for a media source that can fulfil its democratic duties.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">media</field><field name="subject">journalism</field><field name="subject">democracy</field><field name="subject">liberal democracy</field><field name="subject">media ethics</field><field name="subject">applied ethics</field><field name="subject">journalism ethics</field><field name="subject">journalistic codes</field><field name="subject">globalisation</field><field name="subject">broadcasting</field><field name="subject">pubic broadcasting</field><field name="subject">professional journalism</field><field name="subject">corporate journalism</field><field name="subject">public journalism</field><field name="subject">democratic media</field><field name="subject">journalism business</field><field name="subject">propaganda</field><field name="subject">censorship</field><field name="identifier">http://eprints.qut.edu.au/16254/</field><field name="validLink">True</field></doc><doc><field name="title">Levels and Patterns of Genetic Diversity in Wild Populations and Cultured Stocks of Cherax Quadricarinatus (von Martens, 1868) (Decapoda: Parastacidae)</field><field name="creator">Baker, Natalie</field><field name="description">Studying species at the molecular level can provide insights into how ecological and biological processes interrelate resulting in the diversity we see today. This information can be applied to conserve species at risk of extinction, or to better manage genetic diversity in species of economic importance. Species that inhabit freshwater riverine systems commonly exhibit population structures that are related to their relative dispersal capability, contemporary stream structure and/or historical stream structure. This thesis examined the populations genetic structure of wild and cultured stocks of the commercially farmed freshwater crayfish, C. quadricarinatus (von Martens), using genetic markers characterized by different modes of inheritance.  C. quadricarinatus is distributed naturally in riverine systems in northern Australia, and southern Paupa New Guinea (PNG) and inhabits a variety of freshwater ecosystems ranging from ephemeral to permanent. Life history characteristics of C. quadricarinatus suggest a high level of genetic structuring among wild stocks might exist. However, seasonal flooding coupled with low topography across its distribution in northern Australia may promote sufficient gene flow among rivers to produce genetic homogeneity. Historical gene flow may also influence modern genetic structure as many distinct riverine catchments that C. quadricarinatus inhabits, were once connected at times of lower sea level. Insight into genetic relationships among C. quadricarinatus populations will allow for better management practices of wild populations in the future.    The study investigated phylogenetic relationships among C. quadricarinatus representing 17 discrete natural drainages across the natural range in Australia and PNG, using 16s and COI gene sequences. Sequence analysis of both genes resolved two distinct genealogical lineages in Australia and three in PNG.  The two divergent Australian lineages concur with original taxonomic descriptions of Reik (1969) based on external morphological differences. The three C. quadricarinatus populations sampled in PNG were all genetically distinct from each other, with one exhibiting a close association with an Australia lineage. The immense physical barriers (rugged mountain ranges) to gene flow in PNG will almost certainly have reduced dispersal capabilities for C. quadricarinatus. During times of lowered sea levels in the past, Australia and southern PNG were a single landmass with terrestrial and freshwater organisms theoretically able to disperse over associated land and via freshwater connections. The close genetic relationship between PNG and Australian C. quadricarinatus support a recent freshwater connection and hence gene flow between northern Australia and PNG C. quadricarinatus populations. Genetic differentiation among some C. quadricarinatus lineages exhibit as much genetic divergence at 16s RNA sequences as taxonomically recognised sub-species in the Cherax genus. Since C. quadricarinatus was originally described as different species based on external morphological differences (Reik, 1969), it is recommended that the taxonomy of C. quadricarinatus in Australia and PNG be re-evaluated.    C. quadricarinatus specific microsatellite markers were developed for this study. Five variable loci were employed to investigate the extent of contemporary gene flow among fourteen C. quadricarinatus wild river populations in northern Australia. High FST and genetic distance estimates observed among pair wise comparisons of C. quadricarinatus populations are consistent with limited or no gene flow occurring among drainages. Speculation that C. quadricarinatus may disperse between adjacent or nearby drainages at times of flood, either across floodplains, or via flood plumes therefore seems highly unlikely among the populations examined in the current study. No significant correlation was observed between geographic distance and genetic distance among C. quadricarinatus populations here. C. quadricarinatus populations most closely resemble an island-like model, where gene flow is independent of geographic distance among populations and where genetic divergence occurs to a greater or lesser extent as a result of genetic drift within otherwise isolated populations.    A significant number of C. quadricarinatus populations showed deviations from expected Hardy-Weinberg equilibrium (HWE). Samples sizes may not have been sufficiently large to reflect a true representation of genotypic proportions present in the sampled populations due to the highly variable nature of microsatellite loci. Deviations from HWE equilibrium, however, can also result from null alleles. Null allele estimates suggested a large proportion of null alleles were present in the C. quadricarinatus populations analysed. This may be a result of C. quadricarinatus populations confined to discrete drainages experiencing independent evolution, resulting in mutations in primer binding sites.    The growing economic potential of C. quadricarinatus culture, both domestically and internationally, prompted expanding the current study to examine genetic diversity levels in commercial C. quadricarinatus stocks. The study employed five microsatellite markers to quantify genetic diversity in four Australian and three C. quadricarinatus culture stocks from overseas. Many C. quadricarinatus culture stocks also showed deviations from HWE expectations. This was not a surprising result given that the wild populations also deviated and domestication can also influence HWE. Relatively high levels of genetic diversity were observed. This probably results from intentional mixing of discrete river strains for production of the first commercial stock. Genetic differentiation estimates among culture stocks and assignment tests indicated that overseas culture stocks are most likely derived from the first commercial culture stock developed in Australia and then disseminated widely (the Hutchings stock). Robin Hutchings was a known supplier of live C. quadricarinatus to many international culture initiatives. Assignment of culture stocks back to their wild origins indicated that all C. quadricarinatus culture stocks sampled possess alleles that originate from the Flinders River (proportions ranged from 33-94%).    Domestication of C. quadricarinatus to date has not resulted in significant reductions in levels of genetic diversity (heterozygosity or alleles richness) when compared to wild populations sampled in this study. Comparing culture stocks to wild populations to gauge their 'genetic health' may not be a suitable scale for evaluating genetic diversity in culture stocks. Wild populations are essentially evolving independently, are subjected to harsh seasonal environmental fluctuations resulting in periodic population crashes (genetic bottlenecks), with little or no recruitment from neighbouring drainages (gene flow). This study does however indicate that there is a large amount of genetic diversity distributed among wild populations that has yet to be exploited in culture. Genetic diversity in wild populations provides a resource for future stock improvement programs for C. quadricarinatus culture and thus requires careful conservation and appropriate management.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">cherax quadricarinatus</field><field name="subject">mitochondrial DNA</field><field name="subject">microsatellites</field><field name="subject">population genetics</field><field name="subject">phylogeography</field><field name="subject">aquaculture</field><field name="identifier">http://eprints.qut.edu.au/16255/</field><field name="validLink">True</field></doc><doc><field name="title">Issues of co-ordinate collection technologies for rural property boundary surveys in Queensland</field><field name="creator">Webb, Robert M.</field><field name="description">The use of co-ordinates as a description of land boundaries and their limitations has been investigated given recent advances in GPS measurement technology and its proliferation in the surveying and mapping industry. While the use of coordinate information is in essence a representation of reality at a given point in time, it is shown that they can be used within a well-defined framework for summary purposes. 
 
 
 
 The conceptual and operational elements of a measurement-based spatial information system are developed in order to determine if it could aid in the organisation of land boundary information. The fundamental concepts of this information system are that measurements are the primary carriers of metric information. The investigation reveals that measurement-based concepts can serve as the foundation of a multi-purpose spatial information system. Increasing instrument precisions available to surveyors are providing quality measurements with decreasing uncertainties from standard daily operations. Much of this measurement information is in digital form and can provide useful additions of new information as and when they become available to the system. Control measurements are integrated into the system in the same manner as cadastral measurements. The addition of measurements increases the accuracy of the information system over time.
 
 
 
 The concept of a local controlled area and surface movement indicators are briefly covered relating to geo-movements of cadastral evidence. Some issues surrounding the historical foundations of geodetic datums are studied as they provides a basis of knowledge of where future spatial information developments may occur given current understandings and technological ability. A review of International and Australian measurement systems is presented. In this context,  issues surrounding GPS traceability are explored as a means of demonstrating conformance with suitably recognised quantities of length and time. Discussion is held on the legal acceptance of measurements and reviews rules of evidence questioning the term geographical position used in Australian courts.
 
 
 
 An investigative study into rural property boundary surveys for subdivision purposes has been undertaken to provide comparative discussion on issues of changing methods and evolving technology approaches to the measurement challenges using GPS techniques.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Queensland</field><field name="subject">GPS measurement technology</field><field name="subject">rural property boundary survey</field><field name="subject">geographical information</field><field name="identifier">http://eprints.qut.edu.au/16256/</field><field name="validLink">True</field></doc><doc><field name="title">Investigation of radiation sensitive normoxic polymer gels for radiotherapy dosimetry</field><field name="creator">Venning, Anthony James</field><field name="description">The overall objective of this study was to develop and characterise new normoxic polymer gel formulations for evaluation of complex 3-D treatment volumes for application in radiotherapy dosimetry. Throughout this thesis, the essential characteristics of normoxic polymer gels have been extensively investigated. Studies were performed on the chemical components of the MAGIC gel and an improved formulation was proposed. Various anti-oxidants were studied and different versions of the MAGIC gel with fewer chemicals were developed and named MAGAS and MAGAT gel dosimeters. The ascorbic acid anti-oxidant was found to have a slow oxygen scavenging rate and therefore a delay period between manufacture and irradiation of the MAGAS gel was necessary before the gel became radiation sensitive. Vacuum pumping on the MAGAS gel solution to remove dissolved oxygen was shown to initially increase the R2-dose response and sensitivity of the dosimeter, reducing the time between manufacture and irradiation. Studies of the MAGAS gel for measurement of depth dose showed that MAGAS gel has potential as a clinical radiotherapy dosimetry tool. The radiological properties of MAGIC, MAGAS and MAGAT gels were investigated. Due to their high gelatine and monomer concentration, differences with water were observed for the cross-section ratios for attenuation, energy absorption and collision stopping power coefficient ratios through the therapeutic energy range. It was determined that when using and developing normoxic polymer gels the most important consideration for radiological water equivalence are the mass and relative electron densities. A preliminary study was performed with the hypoxic PAG gel dosimeter combined with tetrakis (hydroxymethyl) phosphonium chloride anti-oxidant to form a normoxic PAG gel dosimeter named PAGAT gel. It was found PAGAT gel compared favourably with previous studies of the hypoxic PAG gel. An extensive study was subsequently undertaken in which PAGAT gel was investigated for a number of essential characteristics. The PAGAT gel formulation showed potential as a normoxic polymer gel for clinical radiotherapy dosimetry, which has a significantly reduced manufacturing time and procedure compared with the hypoxic PAG gel dosimeter. The radiological attenuation properties of the PAGAT and MAGAT gels were investigated as a feasibility study for using x-ray computerised tomography (CT) as an evaluation technique of normoxic polymer gels. CT was shown to have potential as an evaluation tool for measuring the dose response of normoxic polymer gel dosimeters. An investigation was performed on the CT diagnostic dose response of normoxic polymer gels. Normoxic polymer gels were found to have potential for use as a specialised tool in measuring computerised tomography dose index (CTDI) for acceptance testing and quality assurance of CT scanners in diagnostic radiology. These findings provide a significant contribution toward the development and successful implementation of normoxic polymer gel dosimetry to clinical radiotherapy.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Polymer gel dosimetry</field><field name="subject">normoxic</field><field name="subject">radiotherapy</field><field name="subject">MAGIC</field><field name="subject">MAGAS</field><field name="subject">MAGAT</field><field name="subject">PAGAT</field><field name="subject">MRI</field><field name="subject">x-ray CT</field><field name="subject">anti-oxidant</field><field name="subject">Monte Carlo</field><field name="subject">R2-dose response</field><field name="subject">sensitivity</field><field name="subject">stability</field><field name="identifier">http://eprints.qut.edu.au/16257/</field><field name="validLink">True</field></doc><doc><field name="title">The relative contribution of psychological, social, and environmental variables to explain variation in leisure-time physical activity among adults at a population level</field><field name="creator">Burton, Nicola Winship</field><field name="description">Background Information: There is substantial evidence demonstrating the significant benefits of regular physical activity (PA) and the burden of morbidity and mortality associated with inactivity. In Australia however, approximately 40% of the adult population is not meeting recommended levels of PA, the rates of inactivity may be increasing, and improving population levels of PA has been identified as a public health priority. Research is needed therefore, to develop a better understanding of the variables that limit and facilitate PA levels within the population, so as to guide the development of population-based PA promotion. Although a range of psychological, social and environmental variables have been associated with PA, few studies have integrated correlates across these domains and compared their relative contribution. The current evidence base is also limited by too few population-based studies, insufficient assessment of the measurement properties of correlate scales, minimal information on PA item non-response, and a lack of specificity among PA domains. Aims: This research program aimed to develop measures and examine the relative contributions of self-reported psychological, social, and environmental variables to explain variation in leisure-time PA (LTPA) among adults in the general population. Methods: This research program comprised three studies that utilised a crosssectional design and a mail survey methodology with a population-based random sample drawn from Brisbane, Australia (N=5000). Study one involved development and assessment of the measurement properties of a battery of scales to measure correlates of LTPA, using principal components and internal reliability analyses. Study two assessed the magnitude of and sociodemographic variables associated with LTPA item non-response on the mail survey, using logistic regression. Study three examined the independent contributions of self-reported psychological, social, and environmental variables to variation in walking, moderate- and vigorousintensity LTPA, using logistic regression adjusted for sociodemographic covariates.  Results: Study one produced a battery of 28 scales to assess self-reported psychological, social and environmental correlates of LTPA. The scales used a total of 123 items to measure activity history (habit, mastery, exposure), health (physical, psychological), activity-related cognitions (self schemata, activity schemata, demand, need, knowledge), self-efficacy, anticipated benefits (psychological, health, challenge, improved appearance, social, weight management), perceived barriers (expense/low access, poor skill, poor personal functioning, time organization, disinterest, family obligations), social support (encouragement, discouragement) and neighborhood environment (available facilities, physical characteristics, aesthetic features, traffic). Of the 28 scales that were factorially derived, 25 had acceptable or marginal levels of internal consistency with Cronbach's alpha values ranging from 0.65 to 0.89. Study two indicated that 28% of the mail survey respondents had incomplete LTPA data with 8% of respondents missing the walking item, and 18% and 23% missing the vigorous-intensity and moderate-intensity LTPA items respectively. Respondents who missed all three LTPA items were more likely than those with complete LTPA data to be female, less educated, from low-income households, in poor health, and a current smoker. Respondents who missed the walking item were significantly more likely to be a current smoker, and to have limited education and low household income. Incomplete moderate-intensity LTPA data was associated with single parenthood and vocational education. Those who missed the vigorousintensity LTPA item were more likely to be 35-54 years old, in fair or poor health, and obese. Respondents with incomplete LTPA data were also more likely to miss sociodemographic items assessing education, household composition, and household income. In study three, the sociodemographic and correlate variables collectively accounted for 43% of the variation in total LTPA, 45% of vigorous-intensity LTPA, 26%of walking, and 22% of moderate-intensity LTPA (Nagelkerke R square). The individual correlates accounted for 0.0 - 4.0% of unique variation across the different domains of LTPA. Habit, self-efficacy, and social encouragement tended to contribute more unique variation for each LTPA domain. Physical health, discouragement, competition, and time management barriers contributed more unique variation to vigorous-intensity LTPA. Anticipated benefits of social interactions and weight management contributed more unique variation to moderate-intensity LTPA. Neighbourhood aesthetics contributed more unique variation to walking variation.  Conclusions. This research program demonstrates the importance of integrating psychological, social, and environmental variables to explain PA, and that the relative importance of these correlates is likely to differ among PA domains. More research is needed to enhance the conceptualisation and measurement of correlate variables, in particular PA opportunities across the lifecourse, the anticipated benefit of a balanced lifestyle, the barriers of an unpredictable lifestyle and family obligations, social discouragement, and environmental variables. Population-based mail surveys of LTPA may under-represent population subgroups that are insufficiently active for health, and proactive strategies are needed to maximise their full participation in research and obtain complete survey data, in particular among individuals of low socioeconomic position and for the assessment of moderateintensity LTPA. Generic promotion to increase overall levels of LTPA in the population could focus on promoting self-efficacy for PA and habitual LTPA, as well as enhancing social encouragement. Tailored promotion for vigorous-intensity LTPA could reduce barriers associated with physical health, discouragement, competitiveness, and time management. Tailored promotion for moderate-intensity LTPA and walking should focus on supportive local neighbourhoods and promote the benefits of weight management and social interactions. In time, the successful implementation of such policy and promotion may arrest the decline of PA levels in the population, reduce preventable morbidity and mortality and economic burden associated with inactivity, and facilitate improved health for all Australians.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">physical activity</field><field name="subject">exercise</field><field name="subject">determinants</field><field name="subject">correlates</field><field name="subject">measurement development</field><field name="identifier">http://eprints.qut.edu.au/16258/</field><field name="validLink">True</field></doc><doc><field name="title">Teaching girls a lesson : the fashion model as pedagogue</field><field name="creator">Dwyer, Angela Ellen</field><field name="description">There appears to be little doubt about the nature of the relationship between the fashion model and the young girl in contemporary Western culture.  Dominant literature, emerging from medico-psychological and feminist research, situates the model as a disorderly influence, imbued with the capacity to infect and, hence, distort the healthy minds and bodies of 'suggestible' young girls.  Opposing these perspectives is a smaller, more recent body of literature, emerging from post-feminist work that argues that the model-girl relationship is a delightful influence.  Thus, the contemporary field of scholarship reveals an increasingly dichotomous way of thinking about fashion model influence: the model influences young girls in ways that are disorderly or delightful, never both.
 
 
 
 This thesis argues that to assume that the model-girl encounter is 'neatly' disorderly or delightful is shifty at best.  It suggests that, in their rush to judge the fashion model as either pernicious or pleasurable, existing literature fails to account for the precision with which young girls know the fashion model.  Using poststructuralist theory, the thesis argues that 'influence' may be more usefully thought of as a discursive effect, which may produce a range of effects for better and worse.  Following Foucault (1972), fashion model influence is interrogated as a regime of truth about the model-girl encounter, constituted discursively under specific social, cultural and historical conditions.  In so doing, the thesis makes different sense of fashion model influence, and questions influence as an independently-existing 'force' that bears down on vulnerable young girls.
 
 
 
 Drawing on a poststructural conceptual architecture, this thesis re-conceptualises the model-girl encounter as a pedagogical relationship focused on the (ideal) female body.  It suggests that the fashion model, as an authoritative embodied pedagogue, transmits knowledge about 'ideal' feminine bodily conduct to the young girl, as attentive gazing apprentice.  Fashion model influence is re-interrogated as the product of certain forms of disciplinary training (Foucault, 1977a), with young girls learning a discursive knowledge about how to discipline the body in ways that are properly feminine.  Such a perspective departs from the notion that fashion model influence is necessarily disorderly or delightful, and makes possible a re-reading of influence in terms of learning outcomes.
 
 
 
 A problematic arises conceptualising the fashion model in this way.  To consider the model as a 'good' teacher breaches a number of discursive rules for best pedagogical practice in postmodern times: She is not a pedagogue of the mind; she is not student-centred, facilitative, asexual, interpersonally engaged, relational, or authentic.  To create a space for thinking differently about the model as a teacher, then, the thesis looks to ancient historical times and places in which female-to-female and body-to-body pedagogies were practised and understood.
 
 
 
 The first phase of the research project embedded in this thesis defamiliarises pedagogical work using historical texts from ancient Greece.  It examines in particular the erotically embodied pedagogical relationships conducted between older, authoritative elite prostitutes known as hetairae, and their younger female apprentices.  The discursive rules governing these pedagogical relationships are examined with a view to diagnosing the model-girl encounter in terms of these rules.  These rules are then used to interrogate ethnographic data generated through observation of the model-girl encounter in situ in a modelling course, and through focus group interviews with groups of young girls.
 
 
 
 Working through notions of corporeal embodiment, self as art, desire, discipline, stillness, spectacle, the gaze and the conduct of conduct, the study interrogates the model-girl encounter as a contemporary pedagogical encounter.  To avoid reaffirming more traditional binaries, the reading of data is ironic, working within and between binaries such as disorder/delight.  Three ironic categories of femininity are produced out of the analysis: unnaturally natural, stompy grace and beautifully grotesque.  These categories 'speak' the fragmentation, fissure, contradiction, inconsistency and absurdity that permeate the talk of young girls and model-girl pedagogy in the modelling classroom.  Thus, the thesis offers up an analysis of the model-girl encounter that refuses the neatness and uni-dimensionality that characterises existing literature.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Ancient Greece</field><field name="subject">conduct of conduct</field><field name="subject">corporeality</field><field name="subject">discourse</field><field name="subject">effective history</field><field name="subject">embodiment</field><field name="subject">fashion model</field><field name="subject">Foucault</field><field name="subject">gaze</field><field name="subject">hetairai</field><field name="subject">historiography</field><field name="subject">ideal femininity</field><field name="subject">influence</field><field name="subject">ironic category</field><field name="subject">pedagogy</field><field name="subject">performance</field><field name="subject">poststructuralism</field><field name="subject">posture</field><field name="subject">self as art</field><field name="subject">sexual conduct</field><field name="subject">spectacle</field><field name="subject">young girl</field><field name="subject">Angela Draper</field><field name="subject">Fashion model</field><field name="subject">Relationship</field><field name="subject">Discourse</field><field name="subject">Teaching</field><field name="identifier">http://eprints.qut.edu.au/16259/</field><field name="validLink">True</field></doc><doc><field name="title">An Investigation into the role of the ghrelin axis in hormone-dependent cancer and characterisation of a novel Exon 3-deleted preproghrelin isoform and its murine homologue</field><field name="creator">Jeffery, Penelope Lorrelle</field><field name="description">Ghrelin is a 28 amino acid peptide hormone with a unique octanoic acid modification that has an extensive range of physiological effects, including stimulation of growth hormone (GH) release, appetite regulation, and modulation of reproductive functions.  The cognate receptor for ghrelin is the growth hormone secretagogue receptor (GHS-R), a G protein-coupled receptor with two documented isoforms, the functional GHS-R type 1a and the C-terminally truncated GHS-R type 1b.  Several ghrelin variants have also been identified in addition to the n-octanoylated form of ghrelin.  In our laboratory, we have identified a novel exon 3-deleted preproghrelin variant that retains sequence for the mature ghrelin hormone and also encodes a novel C-terminal peptide (designated as C-terminal &#61554;3 peptide). There is emerging evidence to suggest that the ghrelin axis, encompassing ghrelin, several ghrelin variants and both forms of the GHS-R, is implicated in tumour growth.  The objective of this project is to investigate the role of the ghrelin axis in hormone-dependent cancer and to further characterise the expression and function of the novel exon 3-deleted preproghrelin isoform.    Hormone-dependent cancers, including prostate and breast cancers, are significant causes of morbidity and mortality in the Western world.  Improved diagnoses and treatments earlier in the progression of the disease are urgently required to improve patient outcomes.  Growth factors play an integral role in prostate and breast cancer, particularly in the emergence of aggressive, hormone-refractory disease that is resistant to standard therapies.  We have previously identified ghrelin as being a novel growth factor for prostate cancer cells in vitro and have hypothesised that this may be extended to other hormone-dependent cancer types including breast cancer.  In the current study, techniques including real-time quantitative RT-PCR, Western blot analysis and immunohistochemistry have been used to determine and quantitate ghrelin, exon 3-deleted preproghrelin and GHS-R expression in prostate and breast cancer. Ghrelin and exon 3-deleted preproghrelin are highly expressed in prostate cancer tissues compared to expression levels in normal prostate glands. Similarly, breast carcinoma specimens display greater immunoreactivity for ghrelin and exon 3-deleted preproghrelin than normal breast tissues.  Expression of the exon 3-deleted preproghrelin mRNA isoform is upregulated in the oestrogen-independent, highly malignant MDA-MB-435 breast cancer cell line compared to the non-tumourigenic MCF-10A breast epithelial cell line, suggesting that augmented transcription of the isoform is associated with an increased malignant potential in breast cancer. The functional GHS-R type 1a is expressed in normal breast tissue and breast cancer specimens and cell lines. In contrast, the truncated GHS-R type 1b isoform is exclusively expressed in breast carcinoma. These data suggest that GHS-R type 1b, ghrelin and exon 3-deleted preproghrelin display potential as novel diagnostic markers for prostate and breast cancer.   These studies have been the first to demonstrate that ghrelin may have an important role in cell proliferation in breast and prostate cancer. Functional assays demonstrated that (10nM) ghrelin stimulated proliferation in the LNCaP prostate cancer cell lines (45.0 &#177; 1.7% above control, P &amp;lt0.01) and rapidly activated the ERK 1/2 mitogen-activated kinase (MAPK) pathway in both PC3 and LNCaP cell lines. It does not, however, protect these cells from chemically-induced apoptosis. The MAPK inhibitors PD98059 and U0126 blocked ghrelin-induced MAPK activation, as well as cell proliferation, in both cell lines.  Prostate cancer cells secrete mature ghrelin in vitro, and may therefore stimulate MAPK pathways in an autocrine manner.  Ghrelin also appears to act as a growth factor in breast cancer cell proliferation, as the growth of MDA-MB-435 and MDA-MB-231 breast cancer cell lines is significantly increased by ghrelin treatment. Our findings suggest that the ghrelin axis could provide an important new target for adjunctive therapies for both breast and prostate cancer. 	The C-terminal &#61554;3 peptide derived from exon 3-deleted preproghrelin may be an important new component of the ghrelin axis and studies into its function are currently in progress. Although it did not induce MAPK cascades or stimulate proliferation in prostate or breast cancer cell lines, the discovery of a murine counterpart, exon 4-deleted preproghrelin, indicates that it is highly conserved. Exon 4-deleted preproghrelin is expressed in all mouse tissues examined, with stomach being the predominant site of synthesis.  Other components of the ghrelin axis were also found to be present in a wide-range of mouse tissues including brain, ovary and prostate.  This comprehensive report has paved the way for future work with in vivo mouse models of cancer.    This study has provided a substantial basis for the further evaluation of ghrelin, exon 3-deleted preproghrelin and the GHS-R type 1b as novel diagnostic/prognostic markers for prostate and breast cancer and supports the rationale for targeting the ghrelin axis for treatment of these tumours.    Keywords: Ghrelin, exon 3-deleted preproghrelin, GHS-R, growth factors, MAPK, ERK 1/2, hormone-dependent cancer, prostate, breast, diagnostic/prognostic marker, therapeutic targets.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">ghrelin axis</field><field name="subject">preproghrelin isoform</field><field name="subject">hormones</field><field name="subject">cancer</field><field name="identifier">http://eprints.qut.edu.au/16260/</field><field name="validLink">True</field></doc><doc><field name="title">An Evaluation of Health-Related Quality of Life and Cost-Effectiveness of Two Rehabilitation Programs For Breast Cancer Survivors</field><field name="creator">Collins, Louisa Gaye</field><field name="description">Breast cancer is a common disease in Australia and exerts a sizable burden to individuals, families, and health care resources. Studies that assess healthrelated quality-of-life (HRQoL) are particularly relevant as survivors must learn to live with breast cancer, undergo prolonged treatment, use new pharmacological agents, monitor and adjust to a serious condition. Relatively little published evidence exists on the effects of rehabilitation programs for breast cancer survivors but those published demonstrate positive health benefits that alleviate both physical and psychological problems. This study aimed to partly fill this gap and had the objectives of: a) estimating the effectiveness of two rehabilitation interventions for breast cancer survivors over time compared to a non-intervention comparison group; and b) ascertaining which option was cost-effective when taking a societal perspective. Effectiveness was described in terms of HRQoL and functional status and there was a particular focus on upperbody morbidity since the two interventions primarily addressed this aspect of rehabilitation. The study participants comprised three groups: one group received a physiotherapy home-visits service (DAART), the second attended a gentleexercise group program (STRETCH), while the third represented a nonintervention comparison group for later analyses only. Data collection was primarily by way of postal questionnaires while medical and cost data abstraction was also necessary. Reliable and validated instruments were used to collect HRQoL and utility data. The Functional Assessment of Cancer Therapy - Breast Cancer plus the Arm Morbidity module (FACT-B+4), Disabilities of the Arm, Shoulder and Hand (DASH), and the Subjective Health Estimation (SHE) instruments were chosen for their high psychometric performance with various populations, their brevity, quick administration and relevance to a breast cancer sample. Missing data was a small concern overall, however, baseline differences were present and mixed across the three participant groups indicating selection bias was present. DAART showed poorer demographic indicators of socioeconomic status and were older, STRETCH participants had poorer disease and treatment profile, while the non-intervention women had poorer general health characteristics. Based on bivariate analyses, age, presence of comorbidities, chemotherapy, high blood pressure, work status (unpaid/paid), hormone therapy were determined to be factors requiring control for in the multivariate analyses. Benefits were found for multiple dimensions of HRQoL for the DAART intervention. On average, HRQoL levels were fairly high across the three alternative participant groups and no significant group differences were found. However, approximately one-third of the women experienced declining HRQoL between 6- to 12-months and their scores were significantly poorer than other participants. STRETCH incurred higher overall costs per participant (on average) than DAART and the non-intervention groups. This was driven by higher leisure time forgone, travel and higher community costs. DAART experienced the highest program costs (or health system costs). Therefore, by taking a societal perspective, and incorporating the estimated value of more intangible or indirect costs (e.g., volunteers, travel costs etc.) the STRETCH program was more costly. The greatest influence on higher costs incurred by the STRETCH participants was the average out-of-pocket expenses for health care services purchased during the previous 12 months for breast cancer-related problems. Although an exploratory finding, the DAART group emerged as the cost-effective option, that is, the incremental cost per QALY gained was $1,344 compared to STRETCH $14,478. The key drivers in the cost-effectiveness modelling were utility values and health service expenditure. When uncertainty was quantified by way of Monte Carlo modelling, DAART remained the cost-effective choice. This project has highlighted that while many women seem to breeze through their breast cancer diagnosis and treatment, there are a substantial number of women who do not. Therefore, it is quite mistaken to generalise the favourable levels of HRQoL and expect that all women will get back to 'normal'. Given that HRQoL is a very complex concept, it was important to use validated tools that had undergone extensive testing with sound psychometric properties. Health care activities observed in their natural 'real world' setting are preferable to minimise biases that may cause more favourable results than truly occur and allow a better assessment on the impact of the service. The project findings have been interpreted while respecting a number of limitations. These have included potential selection and response bias, missing data, and small numbers of intervention women and defined socio-demographic profiles. Taken together, these are likely to overestimate the true outcomes. Arguably, selection bias and the timing of the interventions are likely to be the strongest factors affecting the generalisability of these findings. Given the caveats of this research, the following recommendations were made: 1. Greater awareness and/or screening of adjustment problems among survivors needs to be considered during recovery from breast cancer surgery. 2. Early physiotherapy should be given to all breast cancer survivors after surgery due to the potential functional, physical and overall HRQoL benefits that may arise. 3. Professionally-led group exercise therapy with psychosocial care appears to have a neutral effect on upper-body recovery and improving HRQoL. However, it provides advantages for attendees in the form of peersupport, education, a holistic focus and the potential for addressing previously unrecognised psychological problems in a caring and acceptable environment. This program, with large community resources (provided voluntarily), represents a very low-cost outlay for health services and should be given support and consideration during follow-up care after breast surgery. 4. From a societal perspective, a home-visiting physiotherapy service represents a cost-effective means to provide rehabilitative care for breast cancer patients and represents an excellent public health investment. Several topics for further research are likely to be important in the future including, among others, other modes and settings of rehabilitation service delivery, barriers to psychosocial care and the indirect financial and work consequences of having breast cancer.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">breast cancer</field><field name="subject">health-related quality of life</field><field name="subject">longitudinal</field><field name="subject">rehabilitation</field><field name="subject">recovery</field><field name="subject">cost-effectiveness</field><field name="subject">cost-utility</field><field name="subject">economic evaluation</field><field name="subject">public health</field><field name="subject">physiotherapy</field><field name="subject">psychosocial support</field><field name="identifier">http://eprints.qut.edu.au/16261/</field><field name="validLink">True</field></doc><doc><field name="title">Key establishment : proofs and refutations</field><field name="creator">Choo, Kim-Kwang Raymond</field><field name="description">We study the problem of secure key establishment. We critically examine the security models of Bellare and Rogaway (1993) and Canetti and Krawczyk (2001) in the computational complexity approach, as these models are central in the understanding of the provable security paradigm. We show that the partnership definition used in the three-party key distribution (3PKD) protocol of Bellare and Rogaway (1995) is flawed, which invalidates the proof for the 3PKD protocol. We present an improved protocol with a new proof of security. We identify several variants of the key sharing requirement (i.e., two entities who have completed matching sessions, partners, are required to accept the same session key). We then present a brief discussion about the key sharing requirement. We identify several variants of the Bellare and Rogaway (1993) model. We present a comparative study of the relative strengths of security notions between the several variants of the Bellare-Rogaway model and the Canetti-Krawczyk model. In our comparative study, we reveal a drawback in the Bellare, Pointcheval, and Rogaway (2000) model with the protocol of Abdalla and Pointcheval (2005) as a case study.  We prove a revised protocol of Boyd (1996) secure in the Bellare-Rogaway model. We then extend the model in order to allow more realistic adversary capabilities by incorporating the notion of resetting the long-term compromised key of some entity. This allows us to detect a known weakness of the protocol that cannot be captured in the original model. We also present an alternative protocol that is efficient in both messages and rounds. We prove the protocol secure in the extended model. We point out previously unknown flaws in several published protocols and a message authenticator of Bellare, Canetti, and Krawczyk (1998) by refuting claimed proofs of security. We also point out corresponding flaws in their existing proofs. We propose fixes to these protocols and their proofs. In some cases, we present new protocols with full proofs of security. We examine the role of session key construction in key establishment protocols, and demonstrate that a small change to the way that session keys are constructed can have significant benefits. Protocols that were proven secure in a restricted Bellare-Rogaway model can then be proven secure in the full model. We present a brief discussion on ways to construct session keys in key establishment protocols and also prove the protocol of Chen and Kudla (2003) secure in a less restrictive Bellare-Rogaway model. To complement the computational complexity approach, we provide a formal specification and machine analysis of the Bellare-Pointcheval-Rogaway model using an automated model checker, Simple Homomorphism Verification Tool (SHVT). We demonstrate that structural flaws in protocols can be revealed using our framework. We reveal previously unknown flaws in the unpublished preproceedings version of the protocol due to Jakobsson and Pointcheval (2001) and several published protocols with only heuristic security arguments. We conclude this thesis with a listing of some open problems that were encountered in the study.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">authentication</field><field name="subject">communications security</field><field name="subject">computational complexity</field><field name="subject">computer</field><field name="subject">security</field><field name="subject">cryptographic protocols</field><field name="subject">cryptography</field><field name="subject">Diffie&#150;Hellman-based protocols</field><field name="subject">formal methods</field><field name="subject">formal specification and verification</field><field name="subject">identity-based protocols</field><field name="subject">key agreement protocols</field><field name="subject">key distribution</field><field name="subject">key establishment protocols</field><field name="subject">key exchange protocols</field><field name="subject">key transport protocols</field><field name="subject">password-based protocols</field><field name="subject">proofs of security</field><field name="subject">provable security</field><field name="subject">provably-secure protocols</field><field name="subject">security proofs</field><field name="identifier">http://eprints.qut.edu.au/16262/</field><field name="validLink">True</field></doc><doc><field name="title">Creativity in consulting engineering: how civil engineers talk about design</field><field name="creator">Hayes, Marion</field><field name="description">An appropriate civil infrastructure is vital to the wealth and wellbeing of cultures. Appropriateness is increasingly defined in terms of sustainability, aesthetics, innovation and cultural suitability. These expectations pose challenges for engineers to use their creativity, aesthetic appreciation, knowledge and character to predict and respond creatively with their designs. However, a treadmill of cost innovation in construction projects makes improved design challenging. This tends to reinforce the misconception that engineers are dull and uncreative, even though historically they have displayed considerable imagination and ingenuity. This thesis is based on an in-depth study conducted at the Brisbane office of Kellogg Brown &amp; Root P/L (a large consulting engineering firm). A contemporary qualitative approach is used to explore how creativity is manifested in an engineering design context, and how it relates to phenomena such as knowledge, innovation, project culture and organizational environment. In-depth interviews reveal the authentic meaning of design and creativity for engineers and other company staff. The study highlights an important distinction between design-based and cost-driven innovation and unveils multiple influences that can stifle or nurture personal and group creativity.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Creativity</field><field name="subject">innovation</field><field name="subject">engineering design</field><field name="subject">aesthetics</field><field name="subject">sustainable building</field><field name="subject">organizational culture</field><field name="subject">project alliance</field><field name="subject">research and development (R&amp;D)</field><field name="subject">sustainability</field><field name="subject">eureka innovation</field><field name="subject">case study</field><field name="subject">qualitative research</field><field name="subject">tacit knowledge</field><field name="identifier">http://eprints.qut.edu.au/16263/</field><field name="validLink">True</field></doc><doc><field name="title">The influence of management on runoff and water quality in a coastal lowland PINUS plantation, Southeast Queensland</field><field name="creator">Forsyth, Adam</field><field name="description">The exotic Pinus plantations of southeast Queensland occupy approximately 130 000 ha and are prominent in catchments which drain to estuarine and marine waters that are economically, socially, and environmentally important.  Recently, the deterioration of estuarine and marine water quality has raised concerns about the possible off-site impacts from the intensive management of the Pinus estate in southeast Queensland.  Additionally, forest managers have raised questions over the effects of the currently adopted management practices on soil, water, and nutrient resources within plantations.  A paucity of information regarding the impacts of these plantations in the humid sub-tropics of southeast Queensland initiated the research presented here.  The objectives of this study were to:  (i)	determine the influence specific Pinus management techniques (harvesting, site-preparation, prescribed burning and forest roads) have on runoff generation;  (ii)	quantify fluxes of some nutrients (nitrogen (N), phosphorus (P), dissolved organic carbon (DOC) and iron (Fe)) and suspended solids (SS) in runoff from these management treatments; and,  (iii)	assess the overall effectiveness of the currently adopted Best Management Practices (BMP's) in protecting on-site soil, water and nutrient resources, as well as protecting off-site waters from pollution.  The study site was located in an intensively managed sub-catchment within the Beerburrum State Forest Pinus plantation on the coastal plain of the Pumicestone region, southeast Queensland.  This study was established in October 2001 and consisted of a 141 ha catchment based investigation into water quality and hydrology, which received a 50 ha harvest treatment in February and March 2002.  Water was monitored for two water years (October 2001 - September 2003), and incorporated site-preparation and the establishment of the subsequent rotation.  The influence of a forest road stream crossing was also monitored in this component of the investigation.  Two discrete forest road plots were monitored for the same period to measure the response of runoff, nutrient and sediment fluxes to different road surface materials (gravelled and ungravelled), road maintenance and traffic intensity.  Rainfall simulation was used on small plots covering specific management treatments (clearfall harvest, cultivation, fertilised cultivation, prescribed fire and established trees) within the general plantation area to determine their influence on water, sediment and nutrient fluxes.  The investigation in the catchment receiving inter-rotation management revealed that that there was very little difference in water quality indices up and downstream of the forest road stream crossing, which suggests that road borne runoff contributed only minor amounts of N, P, Fe and SS to the stream.  Perched groundwater quality within the general plantation area was similar to that observed in the adjacent stream.  Water quality monitoring within the Coochin-Mellum and Coonowrin Creek catchments showed that the mean annual concentrations of N and P in surface waters were highest from catchments hosting agriculture and residential areas, respectively.  Mean annual DOC and Fe concentrations were highest from the catchment hosting native Wallum vegetation.  The mean annual concentration of SS was highest from an unmanaged native forest catchment.    The rainfall simulation on specific management treatments revealed that mean losses of N and P from unfertilised and unburnt treatments were comparable to loads reported from catchment scale studies in the Pinus plantations of south-east Queensland.  Mean SS loads from all treatments were considerably higher than stream loads reported in the literature from catchment scale investigations, and suggest that the currently adopted mitigation practices between the general plantation area and streams are effective in promoting the deposition of entrained solids.  The investigation into gravelled and ungravelled forest roads revealed that the mean runoff coefficient (runoff depth / rainfall depth) was consistently higher from the gravelled road plot with 0.57, as compared to the ungravelled road with 0.38.  Total sediment loss over the two year period was greatest from the gravelled road plot.  Suspended solids contributed 86% of the total sediment loss from the gravelled road and 72% from the ungravelled road over the two years.  When road and drain maintenance (grading) was performed runoff and sediment loss was increased from both road types.  It should be noted that the results presented herein were based on only two water years, and both years experienced below average rainfall.  As such it is important that future research in a catchment prone to waterlogging be conducted over a longer term so as to increase the chance of quantifying water, nutrient and sediment fluxes in response to average and above average rainfall years.  It is likely that in above average rainfall years the results for nutrient and sediment fluxes from the general plantation area would be significantly different as runoff would be more readily generated and sustained for longer periods.    Overall, the research presented suggests that the management of an exotic Pinus plantation during the inter-rotation period results in relatively low fluxes of N, P, SS Fe and DOC in stream water and vindicates the use of the current practices in protecting on-site water, soil and nutrient resources.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Pinus</field><field name="subject">inter-rotation management</field><field name="subject">nutrients</field><field name="subject">sediment</field><field name="subject">runoff</field><field name="subject">harvest</field><field name="subject">roads</field><field name="subject">prescribed burn</field><field name="subject">site-preparation</field><field name="identifier">http://eprints.qut.edu.au/16264/</field><field name="validLink">True</field></doc><doc><field name="title">Discourse on primary school physical education curriculum in Papua New Guinea</field><field name="creator">Doecke, Philip John</field><field name="description">The Problem  Physical Education in Papua New Guinea (PNG) schools did not appear to be widespread nor progressing effectively. Its place in education appeared uncertain. Therefore the study's key question was, "What is the status of physical education in PNG, and the implications of this status?" The focus was narrowed to the history of the development of physical education curriculum, and considered decisions made by curriculum officers about what ought to be taught.  Purposes The study's purposes, in answering the key question, were to:  &#167; evaluate the existing physical education curriculum  &#167; generate recommendations for physical education programs.  The Research  Postmodern ethnography was chosen to undertake the evaluation, through the analysis of historical records and personal narratives. As there was little available literature on physical education curriculum development in PNG, the narratives and opinions of a variety of policymakers, policydevelopers, policyimplementers, and clients of this curriculum development were recorded. The curriculum itself was analysed, as well as related articles and official documentation. The collective data were evaluated, to provide an overall view of physical education curriculum development.  Methodology  Following the search for literature in libraries, data were collected from Curriculum Development Division records. As many curriculum documents (such as syllabi and advisory memos) as possible were collected. Key personnel were identified and personally interviewed by the researcher. For a wider group (school principals) an interview guideline was used, while for the oneonone interviews, an unstructured interview format was adopted, allowing respondents considerable control, as they recounted their histories, experiences, and opinions. Further data were collected from correspondence from teachers' colleges, and the former director of the National Sports Institute. The data were analysed by viewing through seven key concepts central in postmodern literature: knowledge, power, culture, postcolonialism, hegemony, globalism, and apathy. The analysis was constructed upon the historical background information, issues that arose during the research activities and the collection of the raw data and, additionally, upon the researcher's own evaluative feelings.  Outcomes  During the analysis of the literature, the narratives, the curriculum, and related documents, four recurrent issues emerged:  &#167; physical education's low status  &#167; problems in understanding the concept of physical education  &#167; apathy towards physical education  &#167; PNG knowledge versus global knowledge  The analysis of the data was therefore undertaken around these issues, as viewed through the key concept's lenses. It was found that there was a lack of usefulness in the existing physical education documents, and that there was a lack of availability of existing physical education documents. Key Education authorities were unfamiliar with physical education curriculum. Its history, both in colonial and postcolonial times, was weak. It continued to receive little attention by curriculum administrators, or schools. The National attitude of apathy towards physical education had been established by the colonial administrators and educators, and reproduced. CDD administration had little time for physical education. Consequently, there was little physical education taught in PNG schools, even though it was in the national curriculum. The only physical activity which had some place in schools was the commercial modified rules sport program, Pikinini Sport. Global activities dominated any thought of local input and activities.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Papua New Guinea</field><field name="subject">education</field><field name="subject">physical education</field><field name="subject">curriculum</field><field name="subject">history</field><field name="subject">society</field><field name="subject">knowledge</field><field name="subject">power</field><field name="subject">culture</field><field name="subject">postcolonialism</field><field name="subject">colonialism</field><field name="subject">hegemony</field><field name="subject">globalism</field><field name="subject">apathy</field><field name="subject">school sports</field><field name="subject">contextuality</field><field name="identifier">http://eprints.qut.edu.au/16265/</field><field name="validLink">True</field></doc><doc><field name="title">Design of a hip screw for injection of bone cement</field><field name="creator">Grant, Caroline Ann</field><field name="description">Fracture to the neck of femur is frequently stabilised with a hip screw system, however the host bone is often weak or osteoporotic.  This causes premature failure of the system, commonly by cut-out of the lag screw through the head of the femur.  While augmentation of the fixation with bone cement improves the holding power and decreases failure rate, current methods of administering the cement are messy and inaccurate.  This project proposes a lag screw design which allows for direct injection of the cement, via the lag screw itself, after the screw has been inserted and correctly positioned in the femur.  A method is also suggested to reduce the risk of cement leakage into the joint space when the guide wire has punctured the head of the femur.    The design uses a system of holes in the threaded section of a cannulated screw to allow delivery of cement to the desired area; the modified screw was also tested with and without the tip of the screw closed.  These design and implantation techniques were compared to the standard design lag screw both with and without bone cement augmentation by traditional methods.    Initial testing in a synthetic bone analogue looked promising. The modified screw with closed end performed better in push out tests than the standard screw alone and comparably with the standard screw with cement augmentation.  A second phase of testing with the synthetic material was then conducted to more closely represent physiological loading conditions.  In this case again the closed ended modified screw with cement augmentation outperformed the original screw and was comparable with the augmented original screw.    However, during this phase of testing problems were observed with the synthetic testing material and it was decided to conduct further testing in paired porcine cadaveric femurs.  Several further problems occurred in this phase of testing, including the bending of the test screws.  It was concluded that the modified screw showed potential in being a more accurate and consistent method of cement augmentation, however neither the synthetic bone analogue or the porcine material was an adequate model of an osteoporotic human femur.  If a suitable testing material could be found, continued study of this prototype may prove beneficial.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">bone cement</field><field name="subject">cement augmentation</field><field name="subject">compression hip screw</field><field name="subject">fracture fixation</field><field name="subject">head of femur</field><field name="subject">lag screw</field><field name="subject">modified hip screw</field><field name="subject">modified lag screw</field><field name="subject">sliding hip screw</field><field name="identifier">http://eprints.qut.edu.au/16266/</field><field name="validLink">True</field></doc><doc><field name="title">Service quality evaluation in internal healthcare service chains</field><field name="creator">Hollis, Charles</field><field name="description">Measurement of quality is an important area within the services sector. To date, most attempts at measurement have focussed on how external clients perceive the quality of services provided by organisations. Although recognising that relationships between providers within a service environment are important, little research has been conducted into the identification and measurement of internal service quality. This research focuses on the measurement of internal service quality dimensions in the complex service environment of an internal healthcare service chain.
 
 
 
 The concept of quality in healthcare continues to develop as various provider, patient and client, governmental, and insurance groups maintain an interest in how to 'improve' the quality of healthcare service management and delivery. This research is based in healthcare as a major area within the service sector. The service environment in a large hospital is complex, with multiple interactions occurring internally; health is a significant field of study from both technical and organisational perspectives providing specific prior research that may be used as a basis for, and extension into service quality; and the implications of not getting service delivery right in healthcare in terms of costs to patients, families, community, and the government are significant. 
 
 
 
 There has been considerable debate into the nature, dimensionality, and measurement of service quality. The five dimensions of SERVQUAL (tangibles, assurance, reliability, responsiveness, and empathy) have become a standard for evaluations of service quality in external service encounters, although these have been challenged in the literature. As interest in internal service quality has grown, a number of researchers have suggested that external service quality dimensions apply to internal service quality value chains irrespective of industry. However, this transferability has not been proven empirically.
 
 
 
 This research examines the nature of service quality dimensions in an internal healthcare service network, how these dimensions differ from those used in external service quality evaluations, and how different groups within the internal service network evaluate service quality, using both qualitative and quantitative research. Two studies were undertaken. In the first of these, interviews with staff from four groups within an internal service chain were conducted. Using dimensions established through qualitative analysis of this data, Study Two then tested these dimensions through data collected in a survey of staff in a major hospital. 
 
 
 
 This research confirms the hierarchical, multidirectional, and multidimensional nature of internal service quality. The direct transferability of external quality dimensions to internal service quality evaluations is only partially supported. Although dimension labels are similar to those used in external studies of service quality, the cross-dimensional nature of a number of these attributes and their interrelationships needs to be considered before adopting external dimensions to measure internal service quality. Unlike in previous studies, equity has also been identified as an important factor in internal service quality evaluations.
 
 
 
 Differences in service expectations between groups in the internal service chain, and differentiation of perceptions of dimensions used to evaluate others from those perceived used in evaluations by others were found. This has implications on formulation of future internal service quality instruments. For example, the expectations model of service quality is currently the dominant approach to conceptualising and developing service quality instruments. This study identifies a number of problems in developing instruments that consider differences in expectations between internal groups. Difficulty in evaluating the technical quality of services provided in internal service chains is also confirmed. 
 
 
 
 The triadic nature of internal service quality evaluations in internal healthcare service chains and the problems associated with transferring the traditional dyadic measures of service quality are identified. The relationships amongst internal service workers and patients form these triads, with patient outcomes a significant factor in determining overall internal service quality, independent of technical quality.
 
 
 
 This thesis assists in supporting the development of measurement tools more suited to internal service chains, and will provide a stronger and clearer focus on overall determinants of internal service quality, with resultant managerial implications for managerial effectiveness.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">internal service quality</field><field name="subject">equity</field><field name="identifier">http://eprints.qut.edu.au/16267/</field><field name="validLink">True</field></doc><doc><field name="title">Early adolescent boys' descriptions of nonparental adults who are significant to them and the influence these adults may have on the boys' identity development</field><field name="creator">Lake, Stephen James</field><field name="description">Parents and peers play an important role in the lives of early adolescent boys but others may also be influential. This study considers the descriptions given by boys in their early adolescence, of their chosen, very important, nonparental adults and the interactions they have with these significant people. Primarily utilising a phenomenological approach, individual interviews and small group discussions were conducted with 11 and 14 year old boys. Four essences of the nature of the interactions between the boys and their chosen adults were identified within the boys' descriptions: fun and humour; care and encouragement; learning and teaching; and doing, being, becoming. Implications for parents, grandparents, teachers and others who care about, and work with, early adolescent boys are discussed.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">early adlescent boy</field><field name="subject">nonparental adults</field><field name="subject">identity development</field><field name="identifier">http://eprints.qut.edu.au/16268/</field><field name="validLink">True</field></doc><doc><field name="title">Enterprise systems success: a measurement model</field><field name="creator">Sedera, Darshana</field><field name="description">Organizations make large investments in Information Systems (IS) expecting positive impacts to the organisation and its functions. Yet, there exists much controversy surrounding the 'potential' impacts of these systems, with some studies reporting broadly positive impacts of IS across organizations (Barua, Kriebel and Mukhopadhyay 1995; Barua and Lee 1997; Brynjolfsson and Hitt 1996; Lehr and Lichtenberg 1999; Mukherjee, Ray and Miller 2001), while others have shown nil or detrimental impacts (Attewell and Rule 1984; Brynjolfsson and Yang 1996; Cameron and Quinn 1988; Wilson 1993). Various authors have suggested that these conflicting results may be due to poor measurement - E.g. incomplete or inappropriate measures of success (DeLone and McLean 1992; Gable 1996; Melone 1990), lack of theoretical grounding and hence agreement on appropriate measures of success (Bonner 1995; Myers, Kappelman and Prybutok 1998), myopic focus on financial performance indicators (Ballantine, Bonner, Levy, Martin, Munro and Powell 1996; Kaplan and Norton 1996), weaknesses in survey instruments employed (Gable, Sedera and Chan 2003) (e.g., constructs lacking in validity), or (5) inappropriate data collection approach (Seddon, Staples, Patnayakuni and Bowtell 1999; Sedera and Gable 2004) (e.g., asking the wrong people, unrepresentative sample). Enterprise Systems (ES) have over the past decade emerged to be one of the most important developments in the corporate use of information technology. Anecdotal evidence reveals discontent with these large application software packages. Yet Enterprise System investments are seldom systematically evaluated post-implementation; the review process and measures typically being idiosyncratic and lacking credibility. Impacts resulting from 'Enterprise Systems' are particularly difficult to measure, with an Enterprise System entailing many users ranging from top executives to data entry operators; many applications that span the organization; and a diversity of capabilities and functionality. Despite the substantial investments made by organizations and the anecdotal evidence of discontent, systematic attempts to measure their success have been few. The primary objective of this research is to develop and test a standardized instrument for measuring ES-Success. Other related objectives of this research include: (1) to identify the dimensions and measures of ES-Success, (2) to validate a maximally generalizable measurement model and survey instrument for gauging ES-Success; (3) to develop an understanding of the state of Enterprise Systems using descriptive/comparative statistics, and (4) to identify and test an antecedent of ES-Success. With the above objectives, and in attention to the weaknesses identified in past IS-success research, this study follows and extends the 'research cycle' guidelines of Mackenzie and House (1979) and McGrath (1979). The research cycle entails two main phases: (1) an exploratory phase to develop the hypothesized measurement model, and (2) a confirmatory phase, to test the hypothesized measurement model against new data. The two surveys (termed as identification-survey and specification-survey) conducted in the exploratory phase of this research go beyond the activities recommended by Mackenzie and House (1979) and McGrath (1979). A third "confirmation-survey" was completed in the confirmatory phase of the research cycle. The three surveys gathered and analyzed data from six hundred (600) respondents.    The purpose of the identification-survey was to discover the salient ES-Success dimensions and measures to include in an a-priori ES-Success model. Data from 137 respondents representing 27 Australian State Government Agencies that had implemented SAP R/3 in the late 1990s were analyzed. The analysis of identification-survey data yielded an a-priori model with 41 measures of 5 dimensions of ES-Success that provide a holistic view across the organization from strategic to operational levels. The specification-survey was employed to validate the a-priori ES-Success measurement model derived in the preceding identification-survey. Employing 310 responses from the same 27 public sector organizations, exploratory data analysis validated 27 measures of success pertaining to the 4 dimensions: information quality, system quality, individual impact and organizational impact. Data for testing the influence of an antecedent of ES-Success was simultaneously gathered during the specification-survey. This analysis, based on the Adaptive Structuration Theory (AST), investigated the influence of Knowledge Management Structures Adequacy (KMSA) on ES-Success. Preliminary results indicate a strong relationship between the Knowledge Management Structures Adequacy and ES-Success. The purpose of the confirmation-survey was to further validate the dimensions and measures of the ES-Success model, using new data, employing confirmatory statistical techniques. Data was gathered from 153 respondents across a large University that had implemented the Oracle Enterprise System, which facilitated further construct validity of the ES-Success measurement instrument was further established using Structural Equation Modeling (SEM).</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">enterprise systems</field><field name="subject">information systems</field><field name="subject">enterprise systems success</field><field name="subject">knowledge management</field><field name="subject">adaptive structuration theory</field><field name="subject">IT impact</field><field name="subject">information quality</field><field name="subject">system quality</field><field name="subject">individual impact</field><field name="subject">organizational impact</field><field name="subject">use</field><field name="subject">satisfaction</field><field name="identifier">http://eprints.qut.edu.au/16269/</field><field name="validLink">True</field></doc><doc><field name="title">Mathematical modelling of dye-sensitised solar cells</field><field name="creator">Penny, Melissa</field><field name="description">This thesis presents a mathematical model of the nanoporous anode within a dyesensitised solar cell (DSC). The main purpose of this work is to investigate interfacial charge transfer and charge transport within the porous anode of the DSC under both illuminated and non-illuminated conditions. Within the porous anode we consider many of the charge transfer reactions associated with the electrolyte species, adsorbed dye molecules and semiconductor electrons at the semiconductor-dye- electrolyte interface. Each reaction at this interface is modelled explicitly via an electrochemical equation, resulting in an interfacial model that consists of a coupled system of non-linear algebraic equations. We develop a general model framework for charge transfer at the semiconductor-dye-electrolyte interface and simplify this framework to produce a model based on the available interfacial kinetic data. We account for the charge transport mechanisms within the porous semiconductor and the electrolyte filled pores that constitute the anode of the DSC, through a one- dimensional model developed under steady-state conditions. The governing transport equations account for the diffusion and migration of charge species within the porous anode. The transport model consists of a coupled system of non-linear differential equations, and is coupled to the interfacial model via reaction terms within the mass-flux balance equations. An equivalent circuit model is developed to account for those components of the DSC not explicitly included in the mathematical  model of the anode. To obtain solutions for our DSC mathematical model we develop code in FORTRAN for the numerical simulation of the governing equations. We additionally employ regular perturbation analysis to obtain analytic approximations to the solutions of the interfacial charge transfer model. These approximations facilitate a reduction in computation time for the coupled mathematical model with no significant loss of accuracy. To obtain predictions of the current generated by the cell we source kinetic and transport parameter values from the literature and from experimental measurements associated with the DSC commissioned for this study. The model solutions we obtain with these values correspond very favourably with experimental data measured from standard DSC configurations consisting of titanium dioxide porous films with iodide/triiodide redox couples within the electrolyte. The mathematical model within this thesis enables thorough investigation of the interfacial reactions and charge transport within the DSC.We investigate the effects of modified cell configurations on the efficiency of the cell by varying associated parameter values in our model. We find, given our model and the DSC configuration investigated, that the efficiency of the DSC is improved with increasing electron diffusion, decreasing internal resistances and with decreasing dark current. We conclude that transport within the electrolyte, as described by the model, appears to have no limiting effect on the current predicted by the model until large positive voltages. Additionally, we observe that the ultrafast injection from the excited dye molecules limits the interfacial reactions that affect the DSC current.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">anode</field><field name="subject">asymptotic analysis</field><field name="subject">charge injection</field><field name="subject">charge transfer</field><field name="subject">charge transport</field><field name="subject">differential equations</field><field name="subject">diffusion</field><field name="subject">dye&#150;sensitised solar cell</field><field name="subject">electrochemistry</field><field name="subject">electrolyte</field><field name="subject">electron injection</field><field name="subject">equivalent circuit</field><field name="subject">interfacial charge transfer</field><field name="subject">interfacial kinetics</field><field name="subject">iodide</field><field name="subject">lithium</field><field name="subject">mathematical modelling</field><field name="subject">migration</field><field name="subject">model</field><field name="subject">nanoporous</field><field name="subject">nonlinear equations</field><field name="subject">perturbation analysis</field><field name="subject">porous</field><field name="subject">porous film</field><field name="subject">reaction</field><field name="subject">recombination</field><field name="subject">semiconductor</field><field name="subject">semiconductor&#150;dye&#150;electrolyte interface</field><field name="subject">semiconductor&#150;electrolyte interface</field><field name="subject">sensitised</field><field name="subject">titanium dioxide</field><field name="subject">triiodide</field><field name="identifier">http://eprints.qut.edu.au/16270/</field><field name="validLink">True</field></doc><doc><field name="title">Pleistocene palaeoecology of the eastern Darling Downs</field><field name="creator">Price, Gilbert J.</field><field name="description">Several late Pleistocene fossil localities in the Kings Creek catchment, Darling Downs, southeastern Queensland, Australia, were examined in detail to establish an accurate, dated palaeoecological record for the region, and to test human versus climate change megafauna extinction hypotheses. Accelerator Mass Spectrometry (AMS 14C) and U/Th dating confirm that the deposits are late Pleistocene in age, but the dates obtained from the two methods are not in agreement. Fluvial depositional accumulation processes in the catchment reflect both high-energy channel and low-energy episodic overbank deposition. The most striking taphonomic observations for vertebrates in the deposits include: 1) low representation of post-cranial elements; 2) high degree of bone breakage; 3) variable abrasion but most identifiable bone elements with low to moderate degree of abrasion; 4) low rates of bone weathering; 5) low degree of carnivore bone modification; and 6) low degree of articulated or associated specimens. Collectively, those data suggest that the material was transported into the deposit from the surrounding proximal floodplain and that the assemblages reflect hydraulic sorting. A multifaceted palaeoecological investigation revealed significant habitat change between superposed assemblages of site QML796. The basal fossiliferous unit contained species that indicate the presence of a mosaic of habitats including riparian vegetation, vine thickets, scrubland, open and closed woodlands, and open grasslands during the late Pleistocene. Those woody and scrubby habitats contracted over the period of deposition so that by the time of deposition of the youngest horizon, the creek sampled a more open type environment. Sequential faunal horizons show a step-wise decrease in taxonomic diversity that cannot be explained by sampling or taphonomic bias. The decreasing diversity includes loss of some, but not all, megafauna and is consistent with a progressive local loss of megafauna in the catchment over an extended interval of time. Collectively, those data are consistent with a climatic cause of megafauna extinction, and no specific evidence was found to support human involvement in the local extinctions. Better dating of the deposits is critically important, as a secure chronology would have significant implications regarding the continent-wide extinction of the Australian megafauna.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">fluvial sedimentology</field><field name="subject">taphonomy</field><field name="subject">megafauna extinction</field><field name="subject">climate change</field><field name="subject">Pleistocene</field><field name="subject">Darling Downs</field><field name="subject">Australia</field><field name="identifier">http://eprints.qut.edu.au/16271/</field><field name="validLink">True</field></doc><doc><field name="title">The synthesis and application of near infrared absorbing dyes in photoelectrochemical cells</field><field name="creator">Goddard, Victoria H. M.</field><field name="description">Research into dye sensitised solar cells has increased in recent years as the search for a viable low cost, renewable energy source continues.    The synthesis and characterisation of an array of symmetrical and asymmetrical zinc and ruthenium centred phthalocyanines and naphthalocyanines are presented in this work. Certain compounds were designed so that they would possess a carboxylic acid group which could be utilised to chemisorb the compound to a titanium dioxide surface. The dye sensitised titania electrodes were studied as potential photoanodes in dye sensitised solar cells. The use of symmetrical and asymmetrical compounds in the solar cells enabled conclusions to be drawn about the effects on electron injection of the HOMO energy level and the number and position of binding groups.    The highest incident photon-to-current conversion efficiency (IPCE) of 4 % and overall conversion efficiency (&#951;) of 0.09 % were obtained when 2,3:9,10-(22,92-carboxyl)benzo(b,k)-15,18,22,25-tetrakis(octyl)phthalocyaninatozinc(II) (63) was utilised as a sensitiser. This response was concluded to be due to the molecule possessing two binding groups and phthalocyanine like energy levels.    When the ruthenium centred and zinc centred compounds were compared as sensitisers in DSCs, an increase in photovoltage and photocurrent was observed with the use of the ruthenium centred compounds. This is due to the binding group being attached to the axial ligand and therefore being situated closer to the LUMO electron density which is found at the centre of the molecule. As the binding group is closer there is less hindrance to electron injection into the TiO2 conduction band.    Aggregation studies were also conducted on the acid and ester substituted zinc naphthalocyanine with and without the use of additives. It was found that the ester existed primarily as a dimer whose formation is concentration dependent. The acid also existed as a dimer but produced a "fake" monomer peak due to the formation of J aggregates. It was found that upon dilution the angle of the J aggregates shifted so that they formed face-to-face aggregates. It was found that the peripherally binding additive cetyltrimethylammonium bromide (CTAB) prevented aggregation at a concentration 20 times that of the compound but upon dilution rearranged itself so that aggregation was no longer inhibited.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">near infrared absorbing dye</field><field name="subject">photoelectrochemical cell</field><field name="identifier">http://eprints.qut.edu.au/16272/</field><field name="validLink">True</field></doc><doc><field name="title">Reliability prediction of complex repairable systems : an engineering approach</field><field name="creator">Sun, Yong</field><field name="description">This research has developed several models and methodologies with the aim of improving the accuracy and applicability of reliability predictions for complex repairable systems. A repairable system is usually defined as one that will be repaired to recover its functions after each failure. Physical assets such as machines, buildings, vehicles are often repairable. Optimal maintenance strategies require the prediction of the reliability of complex repairable systems accurately. Numerous models and methods have been developed for predicting system reliability. After an extensive literature review, several limitations in the existing research and needs for future research have been identified. These include the follows: the need for an effective method to predict the reliability of an asset with multiple preventive maintenance intervals during its entire life span; the need for considering interactions among failures of components in a system; and the need for an effective method for predicting reliability with sparse or zero failure data. In this research, the Split System Approach (SSA), an Analytical Model for Interactive Failures (AMIF), the Extended SSA (ESSA) and the Proportional Covariate Model (PCM), were developed by the candidate to meet the needs identified previously, in an effective manner. These new methodologies/models are expected to rectify the identified limitations of current models and significantly improve the accuracy of the reliability prediction of existing models for repairable systems. The characteristics of the reliability of a system will alter after regular preventive maintenance. This alternation makes prediction of the reliability of complex repairable systems difficult, especially when the prediction covers a number of imperfect preventive maintenance actions over multiple intervals during the asset's lifetime. The SSA uses a new concept to address this issue effectively and splits a system into repaired and unrepaired parts virtually. SSA has been used to analyse system reliability at the component level and to address different states of a repairable system after single or multiple preventive maintenance activities over multiple intervals. The results obtained from this investigation demonstrate that SSA has an excellent ability to support the making of optimal asset preventive maintenance decisions over its whole life. It is noted that SSA, like most existing models, is based on the assumption that failures are independent of each other. This assumption is often unrealistic in industrial circumstances and may lead to unacceptable prediction errors. To ensure the accuracy of reliability prediction, interactive failures were considered. The concept of interactive failure presented in this thesis is a new variant of the definition of failure. The candidate has made several original contributions such as introducing and defining related concepts and terminologies, developing a model to analyse interactive failures quantitatively and revealing that interactive failure can be either stable or unstable. The research results effectively assist in avoiding unstable interactive relationship in machinery during its design phase. This research on interactive failures pioneers a new area of reliability prediction and enables the estimation of failure probabilities more precisely. ESSA was developed through an integration of SSA and AMIF. ESSA is the first effective method to address the reliability prediction of systems with interactive failures and with multiple preventive maintenance actions over multiple intervals. It enhances the capability of SSA and AMIF. PCM was developed to further enhance the capability of the above methodologies/models. It addresses the issue of reliability prediction using both failure data and condition data. The philosophy and procedure of PCM are different from existing models such as the Proportional Hazard Model (PHM). PCM has been used successfully to investigate the hazard of gearboxes and truck engines. The candidate demonstrated that PCM had several unique features: 1) it automatically tracks the changing characteristics of the hazard of a system using symptom indicators; 2) it estimates the hazard of a system using symptom indicators without historical failure data; 3) it reduces the influence of fluctuations in condition monitoring data on hazard estimation. These newly developed methodologies/models have been verified using simulations, industrial case studies and laboratory experiments. The research outcomes of this research are expected to enrich the body of knowledge in reliability prediction through effectively addressing some limitations of existing models and exploring the area of interactive failures.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">reliability prediction</field><field name="subject">failure distribution functions</field><field name="subject">hazard</field><field name="subject">interactive failure</field><field name="subject">dependent failure</field><field name="subject">complex system</field><field name="subject">repairable system</field><field name="subject">condition monitoring</field><field name="subject">preventive maintenance</field><field name="subject">imperfect repairs</field><field name="subject">split system approach</field><field name="subject">Taylor&#146;s expansion approach</field><field name="subject">proportional covariate model</field><field name="identifier">http://eprints.qut.edu.au/16273/</field><field name="validLink">True</field></doc><doc><field name="title">Evolution and function of cellulase genes in Australian freshwater crayfish</field><field name="creator">Crawford, Allison Clare</field><field name="description">The most abundant organic compound produced by plants is cellulose, however it has long been accepted that animals do not secrete the hydrolytic enzymes required for its degradation, but rely instead on cellulases produced by symbiotic microbes.  The recent discovery of an endogenous cDNA transcript encoding a putative GHF9 endoglucanase in the parastacid crayfish Cherax quadricarinatus (Byrne et al., 1999) suggests that similar cellulase genes may have been inherited by a range of crustacean taxa.  In this study, the evolutionary history of the C. quadricarinatus endoglucanase gene and the presence of additional GHF9 genes in other decapod species were investigated.  The activity of endoglucanase and endoxylanase enzymes within several cultured decapod species were also compared.    The evolutionary history of the C. quadricarinatus endoglucanase gene was assessed by comparing intron/exon structure with that of other invertebrate and plant GHF9 genes.  The coding region of the gene was found to be interrupted by eleven introns ranging in size from 102-902 bp, the position of which was largely conserved in both termite and abalone GHF9 genes.  These structural similarities suggest GHF9 genes in crustaceans and other invertebrate taxa share a common ancestry.  In addition, two introns were observed to share similar positions in plant GHF9 genes, which indicates this enzyme class may have been present in ancient eukaryote organisms.    The presence of GHF9 genes in C. quadricarinatus and various other decapod species was then explored via degenerate primer PCR.  Two distinct GHF9 gene fragments were determined for C. quadricarinatus and several other Cherax and Euastacus parastacid freshwater crayfish species, and a single GHF9 gene fragment was also determined for the palaemonid freshwater prawn Macrobrachium lar.  Phylogenetic analyses of these fragments confirmed the presence of two endoglucanase genes within the Parastacidae, termed EG-1 and EG-2.  The duplication event that produced these two genes appears to have occurred prior to the evolution of freshwater crayfish.  In addition, EG-2 genes appear to have duplicated more recently within the Cherax lineage.  The presence of multiple GHF9 endoglucanase enzymes within the digestive tract of some decapod species may enable more efficient processing of cellulose substrates present in dietary plant material.    Endoglucanase and endoxylanase enzyme activities were compared in several parastacid crayfish and penaeid prawn species using dye-linked substrates.  Endoglucanase activity levels were higher in crayfish compared with prawn species, which corresponds with the known dietary preferences of these taxa.  Endoglucanase temperature and pH profiles were found to be very similar for all species examined, with optimum activity occurring at 60&#176;C and pH 5.0.  These results suggest endoglucanase activity in penaeid prawns may also be derived from endogenous sources.  Additional in vitro studies further demonstrated crayfish and prawn species liberate comparable amounts of glucose from carboxymethyl-cellulose, which indicates both taxa may utilise cellulose substrates as a source of energy.  Endoxylanase temperature and pH profiles were also similar for all crayfish species examined, with optimal activity occurring at 50&#176;C and pH 5.0.  These results suggest xylanase activity in crayfish may originate from endogenous enzymes, although it is unclear whether this activity is derived from GHF9 enzymes or a different xylanase enzyme class.  In contrast, no endoxylanase activity was detected in the three prawn species examined.    Together, these findings suggest a wide range of decapod crustacean species may possess endogenous GHF9 endoglucanase genes and enzymes.  Endoglucanases may be secreted by various decapod species in order to digest soluble or amorphous cellulose substrates present in consumed plant material.  Further biochemical studies may confirm the presence and functional attributes of additional endoglucanase genes and enzymes in decapods, which may ultimately assist in the design of optimal plant based crustacean aquaculture feeds.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">aquaculture</field><field name="subject">aquafeed</field><field name="subject">cellulase</field><field name="subject">cellulose digestion</field><field name="subject">cherax</field><field name="subject">crayfish</field><field name="subject">crustacean nutrition</field><field name="subject">decapoda</field><field name="subject">duplication</field><field name="subject">endoglucanase</field><field name="subject">euastacus</field><field name="subject">eukaryote</field><field name="subject">evolution</field><field name="subject">gene structure</field><field name="subject">GHF9</field><field name="subject">glucose</field><field name="subject">intron position</field><field name="subject">macrobrachium</field><field name="subject">multigene family</field><field name="subject">NSP</field><field name="subject">palaemonidae</field><field name="subject">parastacidae</field><field name="subject">penaeus</field><field name="subject">phylogeny</field><field name="subject">plant material</field><field name="subject">protein evolution</field><field name="subject">structural polysaccharide</field><field name="subject">xylanase</field><field name="identifier">http://eprints.qut.edu.au/16274/</field><field name="validLink">True</field></doc><doc><field name="title">Word-of-mouth information gathering : an exploratory study of Asian international students searching for Australian higher education services</field><field name="creator">Chen, Chia-Hung</field><field name="description">Word-of-mouth communication (WOMC) has been recognized as a powerful marketing communication medium that many consider beyond marketers' control and yet is a reliable, creditable, trustworthy information-gathering tool, especially in credence-based services (CBS). To date, the various types of WOMC messages have not yet been adequately studied in the context of CBS. Using the individual face-toface convergence interview (CI) technique as the primary data collection method of exploratory research, this study attempts to fill this gap by describing the types, the characteristics, and the significance of WOMC messages involved in a CBS information gathering process (e.g. selection of an Australian higher education service). Marketers in the higher education sector feel WOMC advertising is unfamiliar and less manageable, but powerful in practice, especially in recruiting overseas Asian students.  This study took the strengths of computer-assisted qualitative data analysis software (CAQDAS), N*Vivo 2, to manage qualitative transcriptions and enhance the data analysis process in organizing, linking, coding categorizing, organizing, summarizing behaviour patterns in order to explore the insightful findings and answer research questions. The study summarizes participants' motivation items and the specific information gathering steps as the foundation to discover the three types of WOMC messages (service information gathering, subjective personal experience, and personal advice) the characteristics of WOMC messages and the significance of WOMC messages in the CBS information gathering process. In theoretical terms, the findings on the role of types of WOMC messages have extended Beltramini model in the information gathering stage. In terms of the management implications, this research advances the current understanding of the types of WOMC messages, insightful WOMC characteristics and significances in behaviour patterns in the CBS information gathering process. As a result, university marketers are able to effectively cultivate various types of WOMC messages in promotion campaigns.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">market communication</field><field name="subject">word-of-mouth adverting</field><field name="subject">information search</field><field name="subject">service marketing</field><field name="subject">promotion management</field><field name="subject">credence-based service</field><field name="subject">higher education services</field><field name="subject">international students / foreign students</field><field name="identifier">http://eprints.qut.edu.au/16275/</field><field name="validLink">True</field></doc><doc><field name="title">Localisation of kallikreins in the prostate and association with prostate cancer progression</field><field name="creator">Bui, Loan Thuy</field><field name="description">At present, prostate cancer is a significant public health issue throughout the world and is the second leading cause of cancer deaths in older men.  The prostate specific antigen or PSA (which is encoded by the kallikrein 3/KLK3 gene) test is the current most valuable tool for the diagnosis and management of prostate cancer.  However, it is insufficiently sensitive and specific for early diagnosis, for staging of prostate cancer or for discriminating between benign prostatic hyperplasia (BPH) and prostate cancer.  Recent research has revealed another potential tumour marker, glandular kallikrein 2 (KLK2 gene/hK2 protein), which may be used alone or in conjunction with PSA to overcome some of the limitations of the PSA test.  Twelve new kallikrein gene family members have been recently identified and, like hK2 and PSA, many of these genes have been suggested to be involved in carcinogenesis.  In this study, the cellular localisation and level of expression of several of these newer kallikreins (KLK4, KLK5, KLK7, KLK8 and KLK11) was examined in prostate tissue, to provide an understanding of the association of their expression with prostatic diseases and their potential as additional biomarkers. Like PSA and hK2, the present observation indicated that each of these proteins, hK4, hK5, hK7, hK8 and hK11, was detected within the cytoplasm of the secretory cells of the prostate glands.  For the first time, all of these newly-identified proteins were shown to be expressed in prostatic intraepithelial neoplasia (PIN) lesions, in comparison to normal glands and cancer lesions.  In addition to cytoplasmic secretory cell expression, the localisation of hK4 to the basal cells and nuclei in prostatic lesions was intriguing.  The intensity of hK4 staining in prostate tissue was strongest in comparison to the other newly-identified kallikrein proteins (hK5, hK7, hK8 and hK11).  Therefore, KLK4/hK4 expression was characterised further to define this cellular localisation and examined in non-prostatic tissue and also in a larger number of prostate tissues in an attempt to determine its potential value as a biomarker for prostate disease.    Three hK4 antipeptide polyclonal antibodies, derived against N-terminal, mid-region and C-terminal hK4 amino acid sequences, were used.  The hK4 N-terminal antipeptide antibody was used to demonstrate the cellular localisation of hK4 in kidney, salivary glands, liver, testis, colon carcinoma, heart, endometrium and ovarian cancer, for the first time.  The presence of hK4 in these non-prostate tissues was consistent with the previous reports using RT-PCR.  The dual cytoplasmic and nuclear localisation of hK4 observed in the prostate above was also seen in these tissues.    Although hK4 was found widely expressed in many human tissue types, indicating that it is not prostate specific in its expression, the highest expression level of hK4 was seen in the prostate.  Therefore, detailed expression patterns and levels of KLK4 mRNA and hK4 protein in the normal prostate and prostatic diseases and histopathological lesions were investigated and reported for the first time in this study.  Twelve benign prostatic hyperplasia (BPH), 19 adenocarcinoma (Gleason grade 2-5) and 34 bone metastases from prostate cancer were analysed.  Using in situ hybridisation, the expression of KLK4 mRNA was detected in the cytoplasm of the secretory cells of both normal and diseased prostate tissue.  KLK4 mRNA was also noted in both secretory and basal cells of PIN lesions, but the basal cells of normal glands were negative.  Using the hK4 N-terminal and mid-region antipeptide antibodies, hK4 was predominantly localised in the cytoplasm of the secretory cells.  The intensity of hK4 staining appeared lowest in normal and BPH, and increased in PIN lesions, high Gleason grade prostate cancer and bone metastases indicating the potential of hK4 as a histopathological marker for prostatic neoplasias.  Further studies are required with a larger cohort to determine its utility as a clinical biomarker.  Small foci of atypical cells, which were found within normal glands, were also intensely stained.  Surprisingly, hK4 protein was found in the nucleus of the secretory cells (but not the basal cells) of high grade PIN and Gleason grade 3 prostate cancer.  The detection of KLK4 mRNA and hK4 protein in PIN lesions and small foci of atypical cells suggests that up-regulation of KLK4 expression occurs early in the pathology of prostate carcinogenesis.  The finding of basal cell expression is not typical for the kallikreins and it is not clear what role hK4 would play in this cell type.  With the use of the hK4 C-terminal antipeptide antibody, the staining was mainly localised in the nuclei of the secretory cells of the prostate glands.  Although the nuclear localisation was readily noted in more than 90% of epithelial cells of the prostate gland with the C-terminal antibody, no difference in staining intensity was observed among the histopathological lesions of the prostate.  The prominent nuclear localisation with the C-terminal antipeptide antibody was also shown to be distributed throughout the nucleus by using confocal microscopy.  Further, by using gold-labelled particles for electron microscopy, the intracellular localisation of these hK4 antipeptide antibodies was reported here for the first time.  Similar to the immunohistochemical results, the cytoplasm was the major site of localisation with the N-terminal and mid-region antipeptide antibodies.    To further characterise the involvement of KLK4/hK4 in human prostate cancer progression, the transgenic adenocarcinoma mouse prostate (TRAMP) model was used in this study.  In this study, mouse KLK4 (also known as enamel matrix serine protease -1, EMSP-1) was shown to be expressed in the TRAMP prostate for the first time.  Previous studies had only shown the developing tooth as a site of expression for EMSP-1.  The level of EMSP-1 mRNA expression was increased in PIN and prostate cancer lesions of the TRAMP model, while negative or low levels of EMSP-1 mRNA were seen in normal glands or in control mouse prostate tissue.  The normal mouse prostate did not stain with any the three hK4 antipeptide antibodies.  hK4 N-terminal and mid-region antipeptide antibodies showed positive staining in the cytoplasm of the epithelial cells of PIN and cancer lesions of the mouse prostate.  The C-terminal antipeptide antibody showed distinctively nuclear staining and was predominantly localised in the nuclei of the glandular cells of PIN and cancer lesions of the mouse prostate.  The expression patterns of both the mRNA and protein level for mouse KLK4 strongly supported the observations of KLK4/hK4 expression in the human prostate and further support the utility of the TRAMP model.  Overall, the findings in this thesis indicate a clear association of KLK4/hK4 expression with prostate cancer progression.  In addition, several intriguing findings were made in terms of cellular localisation (basal as well as secretory cells; nuclear and cytoplasmic) and high expression in atypical glandular cells and PIN, perhaps indicating an early involvement in prostate disease progression and, additionally, utility as basal cell and PIN histological markers.  These findings provide the basis for future studies to confirm the utility of hK4 as a biomarker for prostate cancer progression and identify functional roles in the different cellular compartments.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Prostate cancer</field><field name="subject">Prostate cancer progression</field><field name="subject">Gleason grade</field><field name="subject">Benign prostatic hyperplasia (BPH)</field><field name="subject">Prostatic intraepithelial neoplasia (PIN)</field><field name="subject">Bone metastases from prostate cancer</field><field name="subject">Transgenic adenocarcinoma mouse prostate (TRAMP)</field><field name="subject">Kallikreins</field><field name="subject">KLK4/hK4 (prostase</field><field name="subject">KLK-L1 protein</field><field name="subject">EMSP-1)</field><field name="subject">Prostate specific antigen (PSA</field><field name="subject">KLK3)</field><field name="subject">Human glandular kallikrein (KLK2/hK2)</field><field name="subject">KLK5/hK5 (KLK-L2</field><field name="subject">HSCTE)</field><field name="subject">KLK7/hK7 (PRSS6</field><field name="subject">HSCCE)</field><field name="subject">KLK8/hK8 (PRSS19</field><field name="subject">Neuropsin</field><field name="subject">Ovasin)</field><field name="subject">KLK11/hK11 (PRSS20</field><field name="subject">TLSP</field><field name="subject">Hippostasin)</field><field name="subject">Immunohistochemistry</field><field name="subject">In situ hybridisation</field><field name="subject">Secretory cells</field><field name="subject">Basal cells</field><field name="subject">Nuclear staining</field><field name="subject">Cellular localisation</field><field name="identifier">http://eprints.qut.edu.au/16276/</field><field name="validLink">True</field></doc><doc><field name="title">Some kind of beautiful : the grotesque body in contemporary art</field><field name="creator">Cross, David Anthony</field><field name="description">This thesis investigates, through a body of interdisciplinary artwork, the representation of the grotesque body. It examines how it might be possible to manipulate the iconography of attraction and repulsion in contemporary art with the aim of confusing the binary opposition of what signifies pleasure and disgust. Each of the three artworks function to draw the audience into a powerful and affective relationship with representations that are simultaneously appealing and revolting. Using a number of modes and techniques to disrupt the dyad, including audience interaction and the use of seductive visual forms, the work focuses on my body as a site for the development of new knowledge about the representation of the non-preferred body. By bringing together otherwise unrelated discourses such as horror and formalist abstract painting, the artwork in this study attempts to call into doubt received wisdom about the nature of beauty and ugliness. There are a lexicon of different artistic mediums explored in this project including performance, installation, video and photography. The engagement with these disciplines represents an attempt to speculate on how we know and experience the body in an increasingly mediatised world. This research is also a key means of highlighting how our understanding of the body is informed by the differing effects of timebased, photographic and performative media. By creating a series of dialogues between the live and the virtual, timebased and static imagery, and the fragmentary body and its relationship to the holistic body, this project seeks to activate in the viewer/participant, a critical self-reflexivity. I ask how it is possible to know and experience corporeality in a virtual world of digitally manipulated bodies.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">grotesque</field><field name="subject">contemporary art</field><field name="subject">fragmentary body</field><field name="subject">beauty and ugliness</field><field name="identifier">http://eprints.qut.edu.au/16277/</field><field name="validLink">True</field></doc><doc><field name="title">Determination of aquifer properties and heterogeneity in a large coastal sand mass : Bribie Island, Southeast Queensland</field><field name="creator">Armstrong, Timothy James</field><field name="description">Aquifer heterogeneity within the large coastal sand island of Bribie Island, Queensland, Australia, has an affect on groundwater occurrence and migration. The stratigraphy of Bribie Island is complicated by the presence of low permeability humate-cemented indurated sand layers. Occurrences of indurated sand layers have previously been identified within many unconsolidated profiles along the east coast of Australia and around the world. Indurated sand layers are often discontinuous resulting in localised aquifer heterogeneity. However, their regional significance is commonly underestimated. The groundwater resource of Bribie Island is of commercial and environmental significance to the surrounding bay area. Recent development proposals for the groundwater resource necessitate an investigation into the nature of the water bearing properties of the island aquifer and in particular the presence of aquifer heterogeneity. Investigation of a "reference" transect across Bribie Island has involved the drilling and development of monitoring wells and the performance of hydraulic tests. This study demonstrates how detailed measurement of stratigraphy, groundwater levels, rainfall, barometric pressure and hydraulic testing can be used in conjunction to identify and assess aquifer heterogeneity within a sand island environment. Drill logs confirm the position of a palaeochannel within the sandstone bedrock that extends from the mainland continuing under Bribie Island. The overlying sediment profile is thickest within the palaeochannel. The Pleistocene and Holocene unconsolidated profile reflects a prograding barrier island/strandplain formation. The vertical sequence of sediments consists of units that range from offshore sandy silts to foreshore and beach medium-fine grained sands. An extensive indurated sand layer exists throughout the centre of the island. The greatest thickness of indurated sand is located centrally on the island beneath the main beach ridge system. The indurated layer at its thickest is approximately 5-8 m thick, but over much of the island the thickness is 1-3 m. The top of indurated sand layer is generally 1-3 m above mean sea level. Hydrographs from a network of groundwater monitoring wells illustrate that the groundwater resources across the reference transect can be divided into a shallow unconfined water table aquifer and basal confined aquifers. These upper and lower aquifers are characterised by different hydrological processes, physico-chemical properties, and water chemistry. The stratification of water levels across the reference transect and the relatively flat piezometric surface are in contrast with the classical "domed" water table aquifer expected of a barrier island. Stratified head gradients through the Bribie Island aquifers suggest groundwater migration to depth is impeded by the indurated sand layer. An elevated shallow water table results from the mounding of water above the indurated sand layer. The indurated sand layer is extensive across the reference transect. The elevated unconfined groundwater is usually stained with organic matter ("black water"), where as groundwater sourced from beneath the indurated sand layer is colourless ("white water"). The unconfined groundwater is also distinguished by low pH, low bicarbonate concentrations and high concentrations of organic carbon. Interaction between unconfined groundwater and surface water are also evident. Hydraulic tests indicate that each of the unconsolidated units across the reference transect has distinctive hydraulic characteristics. Estimates of vertical and horizontal hydraulic conductivity of the unconfined aquifer are two to three orders of magnitude greater than estimates for the indurated sand layer. Beneath the indurated sand layer hydraulic conductivities of the basal aquifers are also greater by two to three orders of magnitude than estimates for the indurated sand layer. The lower hydraulic conductivity within the indurated sand layer is responsible for the local semiconfinement of the basal aquifers.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Briebie Island</field><field name="subject">Queensland</field><field name="subject">Australia</field><field name="subject">groundwater</field><field name="subject">sand island</field><field name="subject">hydraulic conductivity</field><field name="identifier">http://eprints.qut.edu.au/16278/</field><field name="validLink">True</field></doc><doc><field name="title">The systematic improvement of advice given by public sector call centres</field><field name="creator">Schefe, Neville Lindsay</field><field name="description">The persistent demand for increased accountability and value for money in the public sector from both the public and governments raises the issue of quality of service in advice-giving by governmental agencies. The goal of this study is to develop a model to validate frameworks able to contribute to improved advice-giving through the application of knowledge management principles.  Zack's (2001) Four Knowledge Problem Model, Brogowicz, Delene, and Lyth's (1990) Synthesised Service Quality Model, and Markus's (2001) Theory of Knowledge Reuse are used to examine knowledge strategies in advice-giving through the application of a case study methodology.  Two Queensland public-sector call centres are investigated.  This study confirms that although the studied call centres operate under differing business drivers, agents have developed strategies generally consistent with those suggested by Zack (2001) to deal with uncertain, complex, and ambiguous problem types. No equivocal problems were encountered in the study. The solution of the former problem pair of uncertainty and complexity relies on knowledge that is codified and stored in databases, while the latter equivocality and ambiguity, seeks out experts who apply both technical and functional knowledge to the problem resolution. Roles performed by call-centre agents predominantly align with those described by Markus (2001), with the opportunity to enhance performance through contribution by shared-work producers to knowledge repositories. The problem-solving strategies employed by agents and the technical capabilities of the call centres combine to deliver a level of service quality which, although meeting client expectations, has been able to be improved through the application of knowledge strategies targeting efficient problem resolution through knowledge reuse.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">knowledge management; call centre</field><field name="subject">information systems</field><field name="subject">problem types</field><field name="subject">quality of service</field><field name="identifier">http://eprints.qut.edu.au/16279/</field><field name="validLink">True</field></doc><doc><field name="title">How Information Retrieval Systems Impact on Designers' Searching Strategies Within the Early Stages of the Design Process</field><field name="creator">Francis, Caroline M.</field><field name="description">The purpose of this research is to investigate the influences that Information Retrieval Systems such as online Search Engines and Databases have on designers' early searching strategies. The study involves the observation of designers transforming early design language into query 'keyword' language for the operation of Information Retrieval Systems and how this transition causes a shift in early design exploration. This transformation is referred to in this research as the CLASS activity; Converting Language from Abstract Searching to Specific. Findings show a common pattern across the activity of both professional and advanced student designers. Information Retrieval Systems are seen to drive the searching process into specific, explored domains rather than stimulate an 'abstract' broad investigation. The IR systems are built upon categories that are created to manage the information content. It is these categories that require a person to use defined keywords and query sentences to operate the Information Retrieval Systems. The findings suggest that using Information Retrieval Systems prior to defining the scope of a design problem causes designers to prematurely focus on specific searching.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">design activity</field><field name="subject">industrial design</field><field name="subject">searching strategies</field><field name="subject">searching practices</field><field name="subject">information retrieval systems</field><field name="subject">design language</field><field name="subject">classification</field><field name="subject">abstract searching</field><field name="subject">specific searching</field><field name="subject">online databases</field><field name="subject">design research</field><field name="identifier">http://eprints.qut.edu.au/16280/</field><field name="validLink">True</field></doc><doc><field name="title">Creative industries development in regional Queensland</field><field name="creator">Doneman, Michael</field><field name="description">Creative industries have significance in considerations of regional development because of their potential for both social-cultural and political-economic benefit. This is especially the case in Indigenous communities, given the potential of traditional and contemporary cultural expression for industry development and employment. This research set out to explore and evaluate an action research approach to creative industries development in regional contexts, stimulated by a research initiative of&#12288;Queensland's Department of State Development in cooperation with Queensland University of Technology's Creative Industries Research and Applications Centre. It is based on an analysis of seven pilot projects undertaken between 2002 and 2004, most of which involved Indigenous&#12288;participation and which gave rise to consideration of the additional value of Indigenist research perspectives. The research found that an action research methodology, informed by Indigenist research values, can assist creative enterprise development in a regional context through the development of new businesses or by value-adding to existing businesses, and the consequent generation and exploitation of new intellectual property. In this process, it found that there is an emerging role for the creative entrepreneur, such a role arising from the practices of community cultural development and social-cultural animation.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">creative industries</field><field name="subject">action research</field><field name="subject">commercialisation</field><field name="subject">regional queensland</field><field name="subject">entrepreneurship</field><field name="subject">business</field><field name="subject">indigenist</field><field name="subject">social-cultural animation</field><field name="subject">animateur</field><field name="identifier">http://eprints.qut.edu.au/16281/</field><field name="validLink">True</field></doc><doc><field name="title">Using risk analysis to prioritise road-based intelligent transport systems (ITS) in Queensland</field><field name="creator">Johnston, Katherine Amelia</field><field name="description">With perpetual strains on resources, road agencies need to develop network-level decision-making frameworks to ensure optimum resource allocation. This is especially true for incident management services and in particular variable message signs (VMS), which are relatively immature disciplines compared to traditional road engineering. The objective of incident management and VMS is to minimise the safety, efficiency, reliability and environmental impacts of incidents on the operations of the transport system. This may be achieved by informing travellers of the incidents so they can adapt their behaviour in a manner that reduces community impacts, such as lateness and the associated vehicle emissions, unreliability of travel times, as well as secondary accidents due to incidents.
 
 
 
 Generally, road authorities do carry out needs assessments, but qualitatively in many cases. Therefore, this masters research presents a framework that is systematic, quantitative and relatively easy to implement. In order to prioritise VMS infrastructure deployment, a risk management approach was taken that focuses on minimising the impacts on, and costs to the community. In the framework and case study conducted, safety, efficiency and reliability, and environmental impacts are quantified using an economic risk management approach to determine an overall risk score. This score can be used to rank road sections within the network, indicating the roads with the highest risk of incident network impacts and therefore the roads with the highest need for intervention. A cost-effectiveness based risk-reduction ranking can then be determined for each incident management treatment type, comparing the net risk with treatment to that without treatment, and dividing by the net present value of deployment. The two types of ranking, pure risk and cost-effectiveness based risk reduction, will help to minimise the network impacts on the community and optimise resource allocation.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Intelligent Transport Systems</field><field name="subject">evaluation</field><field name="subject">incident management</field><field name="subject">variable message signs</field><field name="subject">prioritisation</field><field name="subject">risk analysis</field><field name="subject">decision-making</field><field name="identifier">http://eprints.qut.edu.au/16282/</field><field name="validLink">True</field></doc><doc><field name="title">Influences of organisational image on applicant attraction in the recruitment process</field><field name="creator">Rose, Natalie Emma</field><field name="description">In the present investigation, factors related to prospective applicants impressions of an organisation at the pre-interview stage of the recruitment process, and how these perceptions influence decisions to pursue an organisation for possible employment were explored. A heightened understanding of these factors is of relevance to organisations in the current labour market environment, and is of critical importance when considering that recruitment in the pre-interview stages remains under-researched and lacking in a strong theoretical foundation. To address this weakness in the recruitment research the present investigation will integrate two disparate areas of literature - recruitment and marketing - within the theoretical context of Fishbein and Ajzen's (1975) theory of reasoned action. The theory of reasoned action is well tested in the social psychology arena and provides a sound theoretical platform to underpin the relationships applicable to this investigation. In applying the marketing literature to the recruitment context, the concept of brand image is specifically utilised. Additionally, a problem that plagues much of the recruitment research is the heavy reliance on college and university students as a source of research data. The present study responds to this issue by sourcing data from a population of active job seekers submitting applications for advertised job vacancies at a large, Queensland-based higher education institution. A total of three hundred and fifty-one survey responses were obtained. The measures included perceptions of organisational image, attraction, and application intentions. The results indicated that there is support for the assertion that positive image perceptions held by applicants towards an employing organisation will lead to attraction to the organisation and active pursuit behaviour. Within this framework, it is evident that the 'impression management' capability of organisations in the contemporary business environment may hold the key to sustained competitive advantage in the critical search for qualified talent.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">recruitment</field><field name="subject">organisation image</field><field name="subject">brand image</field><field name="subject">labour market</field><field name="identifier">http://eprints.qut.edu.au/16283/</field><field name="validLink">True</field></doc><doc><field name="title">Computerised methods for selecting a small number of single nucleotide polymorphisms that enable bacterial strain discrimination</field><field name="creator">Robertson, Gail Alexandra</field><field name="description">The possibility of identifying single nucleotide polymorphisms (SNPs) that would be useful for rapid bacterial typing was investigated.  Neisseria meningitidis was the organism chosen for modelling the approach since informative SNPs could be found amongst the sequence data available for multi-locus sequence typing (MLST) at http://www.mlst.net.    The hypothesis tested was that a small number of SNPs located within the seven gene fragments sequenced for MLST provide information equivalent to MLST.  Preliminary investigations revealed that a small number of SNPs could be utilised to highly discriminate sequence types (STs) of clinical interest.  Laboratory procedures demonstrated that SNP fingerprinting of N. meningitidis isolates is achievable.  Further tests showed that laboratory identification of a defining SNP in the genome of isolates was to be a practical method of obtaining relevant typing information.    Identification of the most discriminating SNPs amongst the ever-increasing amount of MLST sequence data summoned the need for computer-based assistance.  Two methods of SNP selection devised by the author of this thesis were translated into computer-based algorithms by contributing team members.  Software for two computer programs was produced.  The algorithms facilitate the optimal selection of SNPs useful for (1) distinguishing specific STs and (2) differentiating non-specific STs.  Current input information can be obtained from the MLST database and consequently the programs can be applied to any bacterial species for which MLST data have been entered.    The two algorithms for the selection of SNPs were designed to serve contrasting purposes.  The first of these was to determine the ST identity of isolates from an outbreak of disease.  In this case, isolates would be tested for their membership to any of the STs known to be associated with disease.  It was shown that one SNP per ST could distinguish each of four hyperinvasive STs of N. meningitidis from between 92.5% and 97.5% of all other STs.  With two SNPs per ST, between 96.7% and 99.0% discrimination is achieved.  The SNPs were selected from MLST loci with the assistance of the first algorithm which scores SNPs according to the number of base mismatches in a sequence alignment between an allele of an ST of interest and alleles belonging to all other STs at a specified locus.  The second purpose was to determine whether or not isolates from different sources belong to the same ST, regardless of their actual ST identity.  It was shown that with seven SNPs, four sample STs of N. meningitidis could, on average, be discriminated from 97.1% of all other STs.  The SNPs were selected with the aid of the second algorithm which scores SNPs at MLST loci for the relative frequency of each nucleotide base in a sequence alignment as a measure of the extent of their polymorphism.    A third algorithm for selecting SNPs has been discussed.  By altering the method of scoring SNPs, it is possible to overcome the limitations inherent in the two algorithms that were utilised for finding SNPs.  In addition, the third approach caters for finding SNPs that distinguish members of a complex from non-members.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">bacterial typing</field><field name="subject">single nucleotide polymorphism (SNP)</field><field name="subject">multilocus sequence typing (MLST)</field><field name="subject">sequence type (ST)</field><field name="subject">neisseria meningitidis</field><field name="subject">discrimination</field><field name="subject">Simpson&#146;s index of diversity</field><field name="identifier">http://eprints.qut.edu.au/16284/</field><field name="validLink">True</field></doc><doc><field name="title">Mechanical and electrical environments to stimulate bone cell development</field><field name="creator">Hannay, Gwynne George</field><field name="description">Healthy bone is bombarded with many different mechanical strain derived signals during normal daily activities. One of these signals is present as a direct connective tissue strain on the cells. However, there is also the presence of an electrically charged streaming potential during this straining. The electrical potential is created from the movement of charged fluid through the small bone porosities. To date, little focus has been applied to elucidating the possible synergistic effects of these two stimulants.  The aim of this project was to evaluate the effects of mechanical strain and indirect electrical stimulation upon the development of bone forming osteoblast cells and any possible synergistic effects of the two stimulants. This aim was achieved by using a novel device, designed and developed with the capability of creating a cell substrate surface strain along with an exogenous electrical stimulant individually or at the same time. Proliferation and differentiation were determined as a measure of cellular development.  The indirect electrical stimulation was achieved through the use of a pulsed electromagnetic field (PEMF) while the mechanical strain was produced from dynamic stretching of a deformable cell substrate. Strain and strain rate were modelled from recent studies proposing that relatively high frequency, low strain osteogenic mechanical stimulants are more indicative of what healthy bone would be experiencing during normal activities. The PEMF signal mimicked a clinically available bone growth stimulator signal.  Results showed a PEMF stimulus on monolayers of SaOS-2 and MG-63 osteoblast-like cells leads to a depression in proliferation. A concomitant increase in alkaline phosphatase production was also observed for the SaOS-2 cultures, but not for the MG-63 cell line. It was hypothesised that this was due to the MG-63's lack of phenotypic maturity compared to the SaOS-2 cells. Mechanical strain of the cell substrate alone, at a relatively high frequency (5Hz) but small strain, did not significantly effect either cell proliferation or differentiation for the MG-63 cells.  However, when the electrical and mechanical stimulants were combined a significant increase in cellular differentiation occurred with MG-63 cultures, revealing a possible synergistic effect of these two stimulants on the development of bone cells.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">PEMF</field><field name="subject">pulsed electromagnetic fields</field><field name="subject">electrical stimulation</field><field name="subject">mechanical stimulation</field><field name="subject">mechanical strain</field><field name="subject">cell substrate stretch</field><field name="subject">biophysical stimuli</field><field name="subject">dual stimuli</field><field name="subject">osteoblast</field><field name="subject">bone healing</field><field name="subject">electrical currents in bone</field><field name="subject">cell proliferation</field><field name="subject">cell differentiation</field><field name="subject">cell adhesion</field><field name="subject">surface characteristics</field><field name="identifier">http://eprints.qut.edu.au/16285/</field><field name="validLink">True</field></doc><doc><field name="title">Material properties of bilaminar polymethylmethacrylate cement mantles in revision hip arthroplasty</field><field name="creator">Weinrauch, Patrick Connor</field><field name="description">Cement - within - Cement (C-C) revision techniques have been demonstrated to reduce the complications associated with removal of secure cement from the femoral canal during revision hip joint arthroplasty. Material failure at the interface between new and old cement mantles represents a theoretical limitation of this technique. The objectives of this thesis are to describe the variability in material properties of uniform and bilaminar polymethylmethacrylate (PMMA) cement mantles in shear with respect to duration of post-cure and the influence of commercial inclusion of antibiotics on bilaminar cement mantle interfacial shear strength.  Uniform mantles of Surgical Simplex P and Antibiotic Simplex PMMA cements demonstrated variability in ultimate shear stress to failure with respect to duration of post-cure (p &lt; 0.001), however the variations were quantitatively small and unlikely to be of clinical relevance. Bilaminar cement mantles were 15 - 20 percent weaker than uniform mantles (p &lt; 0.001) and demonstrated similar time dependant material property variations in shear (p &lt; 0.001). Bilaminar PMMA test specimens manufactured using Antibiotic Simplex cement demonstrated equivalent ultimate shear stress to failure as bilaminar specimens manufactured from Surgical Simplex (p=0.52). High C-C interfacial strengths are demonstrated as early as one hour after cement application. Interfacial adhesion by mechanisms other than mechanical interlock significantly influence the bond formed between layered PMMA cements, with an important contribution by diffusion based molecular interdigitation.  In the presence of a secure cement-bone interface, C-C femoral revision can be recommended as a viable technique on the basis of the strong interfacial bond formed between new and old cement mantles. The use of Antibiotic Simplex in C-C revision is recommended as detrimental effects on the interfacial shear properties have not been demonstrated with the commercial addition of Tobramycin.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">hip</field><field name="subject">arthroplasty</field><field name="subject">revision</field><field name="subject">cement</field><field name="subject">polymethylmethacrylate</field><field name="subject">adhesion</field><field name="identifier">http://eprints.qut.edu.au/16286/</field><field name="validLink">True</field></doc><doc><field name="title">Elucidating the role of silicone in the treatment of burn scars : an essential step in the development of improved treatment products</field><field name="creator">Sanchez, Washington H.</field><field name="description">Hypertrophic scarring is a common occurrence for severe burn victims leading to major functional, physiological, and aesthetic effects to the patients.  Limiting the hypertrophic scarring of the patients alleviates the functional, physiological, and aesthetic effects.  Silicone gels, over the past decade, have been widely used to remediate and limit hypertrophic scarring but the mechanism of action is yet to be determined.  One explanation has been that hydration of the outermost area of the burn is induced by the silicone gel .  However, non-silicone polymers which increase hydration could not mimic the effect.  An alternative interpretation is that there may be silicone species that migrate from the silicone gel into the viable tissue to mediate reactions in the extra-cellular matrix that result in a decreased deposition of excessive amounts of collagen - a central feature of the hypertrophic scar.  A novel and informative technique to study these species is MALDI-TOF/MS (Matrix Assisted Laser Desorption Ionisation-Time of Flight Mass Spectrometry) in conjunction with gel permeation chromatography.  MALDI-TOF/MS, which has allowed the detection of intact molecular species that were not possible with more established mass spectrometric techniques.  The mobile species that may migrate from polydimethylsiloxane medical gel sheeting into skin have been identified by MALDI-MS.  The bulk gel contains predominantly cyclic oligomers with a mass distribution peaking at n = 19 (number of repeating siloxane units), but in an aqueous environment the species at the surface of the silicone medical gel are predominantly methyl/methylol-terminated linear siloxanes. By using a gelatine matrix as a model substrate, the distribution of silicon after application of the silicone gel for 16 weeks was determined by Energy-dispersive X-Ray mapping of the sectioned gelatine. The association of the linear and cyclic oligomers with proteins relevant in hypertrophic scarring are considered.  The mobility of silicone species across stratum corneum was confirmed by Attenuated Total Reflectance Fourier Transform Infrared spectroscopy (ATR-FT/IR).  This method confirms our hypothesis that not only are the low molecular weight silicone species mobile, but also that they do traverse the natural barrier, the stratum corneum, to levels that are detectable by ATR after a continuous application over approximately 11 days.  Invitro studies of the effects of LMWS on primary line fibroblast cells indicate a response that down regulates the proliferation of fibroblast cells and protein production. Preliminary results indicate that a family of pendant functional LMWS are effective in down regulating hypertrophic-derived fibroblast primary cells.  Studies on hypertrophic scar tissue treated with silicone medical gel indicate that LMWS permeate across the stratum corneum into viable scar tissue.  In some areas, the LMWS tend to pool as detected by SEM/EDX elemental silicon analysis.  These areas of LMWS pooling tend to be composed of highly disorganised collagen nodules.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">MALDI-TOF/MS</field><field name="subject">stratum corneum</field><field name="subject">tissue</field><field name="subject">mass spectrum</field><field name="subject">mapping</field><field name="subject">hypertrophic scar</field><field name="subject">chromatography</field><field name="subject">scan</field><field name="subject">imaging</field><field name="subject">software</field><field name="subject">fibroblast</field><field name="subject">maturation</field><field name="subject">resolution</field><field name="subject">surgical revision</field><field name="subject">polymers</field><field name="identifier">http://eprints.qut.edu.au/16287/</field><field name="validLink">True</field></doc><doc><field name="title">In Search of a Childhood Landscape : Historical Narratives From a Queensland Kindergarten 1940-1965</field><field name="creator">Gahan, Deborah</field><field name="description">This dissertation details the study of the influences of historical discourses of early childhood on the recalled experiences of children, parents and teachers in a Queensland kindergarten between 1940 and 1965. The study investigates the interweaving of discourses  of childhood and recounted experiences of kindergarten, drawing on the view that "different discursive practices produce different childhoods, each and all of which are 'real' within their own regime of truth" (James &amp; Prout, 1997, p.26). The study builds a case for using an interpretive/constructionist historical approach to reframe the recounted narratives of those present in an historical kindergarten landscape, particularly the narratives of those who were children in that landscape.    To date, historical studies of early childhood education in Australia have largely focused on "big picture" issues of policy, practice and training, rather than on investigating and documenting the lived experiences of children and adults in particular early childhood contexts and historical eras. In contrast, this study takes a micro-history approach, focusing on one early childhood setting in a way that Mills &amp; Mills (2000, p.165) argue enables the "complexity and richness of the big picture to be understood".  Reiger (1993) suggests that growing interest in the social construction of childhood has increased awareness of "the agency of children as contributors to interpretations ... of their development" (p.4).While participants in my study look back on childhoods lived in a past era, their interpretations and feelings about events and practices that they observed and experienced as children at kindergarten provide a valuable perspective on the discourses which framed their childhoods. Findings from this study have the potential to broaden understandings of the impact on children of pedagogical approaches to early childhood education, and deepen awareness of the meaning of childhood at particular points in time.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">historical discourse</field><field name="subject">Queensland</field><field name="subject">Queensland kindergarten</field><field name="subject">between 1940 and 1965</field><field name="subject">early childhood education</field><field name="subject">micro-history approach</field><field name="identifier">http://eprints.qut.edu.au/16288/</field><field name="validLink">True</field></doc><doc><field name="title">Fractal techniques for face recognition</field><field name="creator">Ebrahimpour-Komleh, Hossein</field><field name="description">Fractals are popular because of their ability to create complex images using only several simple codes. This is possible by capturing image redundancy and presenting the image in compressed form using the self similarity feature. For many years fractals were used for image compression. In the last few years they have also been used for face recognition. In this research we present new fractal methods for recognition, especially human face recognition.    
 
 This research introduces three new methods for using fractals for face recognition, the use of fractal codes directly as features, Fractal image-set coding and Subfractals.  In the first part, the mathematical principle behind the application of fractal image codes for recognition is investigated. An image Xf can be represented as Xf = A x Xf + B which A and B are fractal parameters of image Xf . Different fractal codes can be presented for any arbitrary image. With the defnition of a fractal transformation, T(X) = A(X - Xf ) + Xf , we can define the relationship between any image produced in the fractal decoding process starting with any arbitrary image X0 as Xn = Tn(X) = An(X - Xf ) + Xf . We show that some choices for A or B lead to faster convergence to the final image.    
 
 Fractal image-set coding is based on the fact that a fractal code of an arbitrary gray-scale image can be divided in two parts - geometrical parameters and luminance parameters. Because the fractal codes for an image are not unique, we can change the set of fractal parameters without significant change in the quality of the reconstructed image. Fractal image-set coding keeps geometrical parameters 
 
 
 the same for all images in the database. Differences between images are captured in the non-geometrical or luminance parameters - which are faster to compute.  For recognition purposes, the fractal code of a query image is applied to all the images in the training set for one iteration. The distance between an image and the result after one iteration is used to define a similarity measure between this image and the query image.    
 
 The fractal code of an image is a set of contractive mappings each of which transfer a domain block to its corresponding range block. The distribution of selected domain blocks for range blocks in an image depends on the content of image and the fractal encoding algorithm used for coding. A small variation in a part of the input image may change the contents of the range and domain blocks in the fractal encoding process, resulting in a change in the transformation parameters in the same part or even other parts of the image. A subfractal is a set of fractal codes related to range blocks of a part of the image. These codes are calculated to be independent of other codes of the other parts of the same image. In this case the domain blocks nominated for each range block must be located in the same part of the image which the range blocks come from.    
 
 The proposed fractal techniques were applied to face recognition using the MIT and XM2VTS face databases. Accuracies of 95% were obtained with up to 156 images.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">fractals</field><field name="subject">subfractals</field><field name="subject">fractal image-set coding</field><field name="subject">image coding</field><field name="subject">face recognition</field><field name="subject">image processing</field><field name="subject">computer vision</field><field name="identifier">http://eprints.qut.edu.au/16289/</field><field name="validLink">True</field></doc><doc><field name="title">Photocatalysis with a Heterosupramolecular Assembly</field><field name="creator">Wilson, Gregory J.</field><field name="description">Supramolecular chemistry has asserted itself as a significant multidisciplinary field concerned with molecular effects afforded through non-covalent molecular interactions. The increased interest in the literature towards nanoscale devices, through modulation of molecular function, has seen the renaissance of supramolecular chemistry as function progresses from solution to surface. Heterosupramolecular chemistry follows the architectural principles of supramolecular chemistry and embraces both covalent and non-covalent interactions of condensed phase surfaces and molecular components.    A modular approach to device architecture was applied as a novel method of performing photocatalysis under visible light illumination. The application of heterosupramolecular assembly to the design of photoelectrochemical cells capable of visible light induced charge separation allowed the study of interfacial processes by means of electrochemical observations.    Preparation of a series of supramolecular components was undertaken as specific molecular species within a photochemical system. Starting from a synthesised bidentate ligand that incorporated an acidic functional group, 4,4'-bis(methyl)phosphonate-2,2'-bipyridine (dmpbpy) as its ethyl ester, was chelated to give the surface sensitisers, bis-(2,2'-bipyridine)-(4,4'-bis(methyl)phosphonato-2,2'-bipyridine)ruthenium(II) dichloride ([Ru(bpy)2(dmpbpy)]Cl2) and cis-bis-(4,4'-bis-(methyl)phosphonato-2,2'-bipyridine)(2,2'-bipyridine)ruthenium(II) dichloride ([Ru(dmpbpy)2(bpy)]Cl2). An electron relay moiety with an acidic functional group, 1-ethyl-1'-(2-phosphonoethyl)-4,4'-bipyridinium dichloride (EVP), was also prepared using a procedure developed by the candidate.    The electronic properties of the prepared photosensitisers were examined by theoretical quantum chemical TD-DFT calculations on the molecular structures and singlet excitations were discussed in relation to experimental data. This identified that the lowest lying LUMO states were consistently occupied by 2,2'-bipyridine (bpy) and this was speculated to be a factor affecting quantum injection yields.    The effect of microwave modification of colloidal TiO2 suspensions under extended periods of treatment was investigated. Nanoparticles of TiO2 were compared and contrast to similar convection hydrothermally treated TiO2 and a commercial titania product, namely Degussa P25, both of which are utilised in device fabrication. The investigation identified that extended periods of microwave hydrothermal treatment do not greatly enhance the crystallinity and primary grain size of TiO2.    The heterosupramolecular assembly of a multi-component photochemical system was constructed from prepared molecular and condensed phase components. It was demonstrated that this device was capable of inducing a photochemical reaction in H2O under irradiation with &#61548; &gt; 420 nm in the absence of an organic electron donor. Interpretation of the photocurrents obtained from this assembly provided understanding of photochemical reactions under low light intensities. Optimised conditions for the photochemical reaction was determined to be pH = 5 and illumination yielded &#61544;&#61472;= 0.0036% with an apparent quantum yield (AQY) = 1.6%.    Photocatalytic decomposition of organic compounds in a dye-sensitised photoelectrocatalytic cell was investigated for the complete mineralisation of EDTA into CO2, H2 and simple amines and interpreted through photocurrent observations. This was extended to a broad range of organic compounds of various solution concentrations as a simulated industrial waste stream. Photooxidation gave unique photocurrent-time profiles which identified two distinct interfacial processes by mathematical treatment of photocurrent transients with a kinetic model. Kinetic parameters were proposed as a factor for qualitative discrimination of the organic compounds.    The implications of these results for heterogeneous catalysis were discussed and the formation of Host-Guest complexes as a method of molecular sensing and as specific photocatalytic receptors was proposed.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Alternative energy storage</field><field name="subject">coordination complex</field><field name="subject">dye-sensitised</field><field name="subject">grey-water</field><field name="subject">heterosupramolecular</field><field name="subject">hydrogen gas</field><field name="subject">kinetic model</field><field name="subject">organic pollutants</field><field name="subject">photocatalysis</field><field name="subject">photo-degradation</field><field name="subject">photooxidation</field><field name="subject">titania</field><field name="subject">titanium dioxide</field><field name="subject">TiO2</field><field name="subject">ruthenium</field><field name="subject">visible-light</field><field name="identifier">http://eprints.qut.edu.au/16290/</field><field name="validLink">True</field></doc><doc><field name="title">Measurement of 222Rn Exhalation Rates and 210Pb Deposition Rates in a Tropical Environment</field><field name="creator">Lawrence, Cameron Eoin</field><field name="description">This thesis provides the measurements of 222Rn exhalation rates, 210Pb deposition rates and excess 210Pb inventories for locations in and around Ranger Uranium Mine and Jabiru located within Kakadu National Park, Australia. Radon-222 is part of the natural 238U series decay chain and the only gas to be found in the series under normal conditions. Part of the natural redistribution of 222Rn in the environment is a portion exhales from the ground and disperses into the atmosphere. Here it decays via a series of short-lived progeny, that attach themselves to aerosol particles, to the long lived isotope 210Pb (T1/2 = 22.3 y). Attached and unattached 210Pb is removed from the atmosphere through wet and dry deposition and deposited on the surface of the earth, the fraction deposited on soils is gradually transported through the soil and can create a depth profile of 210Pb. Here it decays to the stable isotope 206Pb completing the 238U series.    Measurements of 222Rn exhalation rates and 210Pb deposition rates were performed over complete seasonal cycles, August 2002 - July 2003 and May 2003 - May 2004 respectively. The area is categorised as wet and dry tropics and it experiences two distinct seasonal patterns, a dry season (May-October) with little or no precipitation events and a wet season (December-March) with almost daily precipitation and monsoonal troughs. November and April are regarded as transitional months. As the natural processes of 222Rn exhalation and 210Pb deposition are heavily influenced by soil moisture and precipitation respectively, seasonal variations in the exhalation and deposition rates were expected. It was observed that 222Rn exhalation rates decreased throughout the wet season when the increase in soil moisture retarded exhalation. Lead-210 deposition peaked throughout the wet season as precipitation is the major scavenging process of this isotope from the atmosphere.    Radon-222 is influenced by other parameters such as 226Ra activity concentration and distribution, soil porosity and grain size. With the removal of the influence of soil moisture during the dry season it was possible to examine the effect of these other variables in a more comprehensive manner. This resulted in categorisation of geomorphic landscapes from which the 222Rn exhalation rate to 226Ra activity concentration ratios were similar during the dry season. These results can be extended to estimate dry season 222Rn exhalation rates from tropical locations from a measurement of 226Ra activity concentration.    Through modelling the 210Pb budget on local and regional scales it was observed that there is a net loss of 210Pb from the region, the majority of which occurs during the dry season. This has been attributed to the fact that 210Pb attached to aerosols is transported great distance with the prevailing trade winds created by a Hadley Circulation cell predominant during the dry season (winter) months. By including the influence of factors such as water inundation and natural 210Pb redistribution in the soil wet season budgeting of 210Pb on local and regional scales gave very good results.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Radon</field><field name="subject">exhalation</field><field name="subject">emission</field><field name="subject">Lead-210</field><field name="subject">deposition</field><field name="subject">excess</field><field name="subject">redistribution</field><field name="subject">budget</field><field name="subject">Kakadu</field><field name="subject">Ranger</field><field name="subject">uranium</field><field name="subject">mining</field><field name="subject">radionuclides</field><field name="subject">isotopes</field><field name="subject">soil moisture</field><field name="subject">radium</field><field name="subject">activity concentration</field><field name="subject">land application</field><field name="subject">soil erosion</field><field name="subject">atmospheric transport</field><field name="subject">geomorphic landscapes</field><field name="subject">tropics</field><field name="subject">Alligator Rivers Region</field><field name="subject">environmental radioactivity</field><field name="subject">Jabiru</field><field name="subject">atmospheric dispersion</field><field name="subject">soil profile</field><field name="subject">diurnal</field><field name="subject">seasonality</field><field name="subject">wet season</field><field name="subject">dry season</field><field name="subject">precipitation scavenging</field><field name="subject">aerosol transport</field><field name="subject">aerosol removal</field><field name="subject">Hadley circulation</field><field name="subject">water inundation</field><field name="identifier">http://eprints.qut.edu.au/16291/</field><field name="validLink">True</field></doc><doc><field name="title">The behaviour of rollover protective structures subjected to static and dynamic loading conditions</field><field name="creator">Clark, Brian</field><field name="description">The Rollover of heavy vehicles operating in the construction, mining and agricultural sectors is a common occurrence that may result in death or severe injury for the vehicle occupants. Safety frames called ROPS (Rollover Protective Structures) that enclose the vehicle cabin, have been used by heavy vehicle manufacturers to provide protection to vehicle occupants during rollover accidents. The design of a ROPS requires that a dual criteria be fulfilled that ensures that the ROPS has sufficient stiffness to offer protection, whilst possessing an appropriate level of flexibility to absorb some or most of the impact energy during a roll. Over the last four decades significant research has been performed on these types of safety devices which has resulted in the generation of performance standards that may be used to assess the adequacy of a ROPS design for a particular vehicle type. At present these performance standards require that destructive full scale testing methods be used to assess the adequacy of a ROPS. This method of ROPS certification can be extremely expensive given the size and weight of many vehicles that operate in these sectors. The use of analytical methods to assess the performance of a ROPS is currently prohibited by these standards. Reasons for this are attributed to a lack of available fundamental research information on the nonlinear inelastic response of safety frame structures such as this. The main aim of this project was to therefore generate fundamental research information on the nonlinear response behaviour of ROPS subjected to both static and dynamic loading conditions that could be used to contribute towards the development of an efficient analytical design procedure that may lessen the need for destructive full scale testing. In addition to this, the project also aspired to develop methods for promoting increased levels of operator safety during vehicle rollover through enhancing the level of energy absorbed by the ROPS. The methods used to fulfil these aims involved the implementation of an extensive analytical modelling program using Finite Element Analysis (FEA) in association with a detailed experimental testing program. From these studies comprehensive research information was developed on both the dynamic impact response and energy absorption capabilities of these types of structures. The established finite element models were then used to extend the investigation further and to carry out parametric studies. Important parameters such as ROPS post stiffness, rollslope inclination and impact duration were identified and their effects quantified. The final stage of the project examined the enhancement of the energy absorption capabilities of a ROPS through the incorporation of a supplementary energy absorbing device within the frame work of the ROPS. The device that was chosen for numerical evaluation was a thin walled tapered tube known as frusta that was designed to crush under a sidewards rollover and hence lessen the energy absorption demand placed upon the ROPS. The inclusion of this device was found to be beneficial in absorbing energy and enhancing the level of safety afforded to the vehicle occupants.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Rollover Protective Structures</field><field name="subject">ROPS</field><field name="subject">Safety</field><field name="subject">Occupant protection</field><field name="subject">Impact</field><field name="subject">Energy absorption</field><field name="subject">Destructive testing</field><field name="subject">Dynamic loading</field><field name="subject">Impulse loads</field><field name="subject">Finite Element Analysis (FEA)</field><field name="subject">Energy Absorption Enhancement</field><field name="identifier">http://eprints.qut.edu.au/16292/</field><field name="validLink">True</field></doc><doc><field name="title">Improving Indonesian nursing students' self-directed learning readiness</field><field name="creator">Saha, Djenta</field><field name="description">Introduction  The purpose of this study was to improve Indonesian nursing students' self-directed learning readiness. An educational intervention program (EIP) was developed, implemented and evaluated.    Background to the study  Many studies have documented the need for nursing students to be prepared for the rapidly changing and complex health care environment. Lifelong, self-directed learning (SDL) has been identified as an important ability for nursing graduates. However, no study has documented the needs of, or preparation required for, nursing students to function effectively in the rapidly changing health care system in Indonesia. The Indonesian diploma nursing schools still use a teacher-centred approach with little emphasis on a student-centred approach.    Method  The study used a mixed method involving both quantitative and qualitative design. Simple random sampling was used to select an intervention school and control school. The sample was 2nd year nursing students with 47 in the intervention group and 54 in the control group. A pre-post test questionnaire, using the Self-Directed Learning Readiness Scale (Guglielmino, 1978), was used to collect quantitative data and focus group discussions (FGD) were used to collect qualitative data regarding students' perceptions of SDL prior to and at the completion of study. The intervention group received an EIP. The Staged Self-Directed Learning Model (Grow, 1991) and the Teacher Student Control Continuum (D'A Slevin &amp; Lavery, 1991) were used as the organising framework. A self-learning module and learning plans were used as learning strategies to operationalise SDL concepts alongside teacher-centred methods. The control group received the existing teacher-centred methods. At the completion of the intervention, clinical instructors from both the intervention and control groups participated in FGD to explore their perceptions of students' activities during the EIP.    Results  For the majority of students, readiness for SDL was 'below average'. The mean for the Indonesian nursing students was significantly lower than established norms (Guglielmino, 1978). The introduction of SDL concepts through an EIP improved the level of readiness for SDL in the intervention group from 'below average' to 'average' compared to the control group who remained in the 'below average' range. Higher SDL readiness was reported by female students and students who completed the educational intervention.  The FGD before the intervention revealed that students perceived SDL as a 'self-activity'. Perceptions of students in the intervention group changed during the EIP compared to students in the control group. Students in the intervention group viewed SDL as a 'process of learning'. Increased self-confidence, incremental learning, and having direction in learning were identified as benefits of SDL. Knowledge and skills in SDL, learning materials and communication were identified as important issues that needed to be improved. Clinical Instructors' perceptions of students' clinical activities confirmed that students in the intervention group were 'more active' compared to the control group who were 'still inactive'.    Conclusion  The study confirmed the expected effect of the EIP on students' SDL readiness. The EIP improved nursing students' readiness for SDL and had a positive impact on students' perceptions of SDL. Introducing the concept of SDL through the EIP was found acceptable by the sample and was deemed feasible to implement within the Indonesian nursing education system. The study has potential to make a significant contribution to nursing education in Indonesia by promoting lifelong learning and SDL in nursing students and in curricula through the development of innovative curricula and teaching and learning practices. The study also has potential wider benefit to nursing practice and global health practice.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Educational intervention program</field><field name="subject">Indonesia</field><field name="subject">Lifelong learning</field><field name="subject">Nursing education</field><field name="subject">Nursing students</field><field name="subject">Self-directed learning readiness</field><field name="identifier">http://eprints.qut.edu.au/16293/</field><field name="validLink">True</field></doc><doc><field name="title">Reculturing a school as a learning organisation: investigative narratives in two Queensland schools</field><field name="creator">Martoo, Gladys Vivian</field><field name="description">The focus of this study has been to connect the idea of developing schools as learning organisations with the notion of developing learning leaders and building school capacity for our knowledge economy.  Therefore, this action-inquiry self-study has examined the issues of curriculum reform in the context of more general organisational reform. It has explored the notion of schools being recultured or reconstructed to work as learning organisations in a climate that focuses on the improved social and academic learning outcomes of their students.    This self-study represents two significant chapters in my professional life and captures approximately four years of professional snapshots. It has allowed me to examine my practice of partnering, conversing, arranging and developing shared vision across two schools. This study recognized these as powerful reculturing mechanisms and affirmed that conversations about learning, shared beliefs mission and vision, enabling leadership that reflects parallel learning relationships and enabling organisational arrangements are critical for sustainable reform. Consequently the exploration of the relationship between teacher learning, teacher leadership and a professional learning culture has been the main focus for this research.    Analytical processes for this study first explored the relationship between teacher learning, teacher leadership and a professional learning culture through an examination of current curriculum reforms. This is followed by a layered analysis of the two narratives based on my leadership in two different school settings. A rigorous mapping and scanning process then assisted the analysis of these narratives. This process was supported by a number of specific conceptual frameworks that underpin the school reculturing process and reflect key qualities of schools that work as learning organisations.    Six significant snapshots emerged from the analysis of the two narratives. The deeper analysis of these snapshots, which have been referred to as close-ups, formed a number of my first tentative propositions. These layers of investigation were also supported by the responses of several key snapshot participants and reader respondents, before the final propositions were made. These responses recognised that an organisation that works together, learns together; and that there is strength and powerful learning when leadership can assist practitioners to work as a learning community.  These qualities were found to be directly related to this study's proposed reconstructed model for developing schools as learning organisations.    The reconstructed model recognised a number of other less visible elements that can be seen in a school working as a learning organisation. These elements relate directly to enabling/capacity building leadership and the associated relationship skills of leaders. They were found to be necessary elements for effective collaboration and for creating spaces for conversation, reflection, spontaneity and risk-taking.    This study also recognised that any deconstruction and reconstruction of a school as a learning organisation is first a reconstruction of core beliefs and values. These beliefs and values are reflected in a school's culture and are inclusive of the visible and less visible elements. The constant examination of one's assumptions, ideas, values and beliefs has been considered to be essential to the analysis process, as well as to the process of reform and achieving organisational change. The study revealed, therefore, that enabling/capacity-building leadership is a key to the process of reculturing a school as a learning organisation. The data from respondents also indicates that this notion of leadership as being enabling/capacity building has also been a primary focus for answering the second of the key research questions: 'How does a process of deconstruction and reconstruction take place?'    The additional points of difference/interest that emerged from the various respondents suggest that the process of deconstruction and reconstruction of a school as a learning organisation would be assisted by realising that energy and passion are needed for enabling/capacity building leadership. This form of leadership requires moving from being top-down and become more parallel with renewed learning relationships. This study affirmed that this focus on establishing parallel learning relationships assists in the development of parallel learning leadership and parallel learning partnerships.    Enabling/capacity building leaders working in parallel with their teachers can also play an important role in developing/supporting flexible and imaginative school organisation. In this way enabling/capacity building leaders can work as learning leaders and brokers to assist the development of other learning partnerships/alliances. This community building strategy can consequently develop opportunities for teachers to work and learn collaboratively as learning leaders.    Enabling/capacity building leadership is correctly placed as the key to considering how the deconstruction and reconstruction process takes place. Further, the reconstruction process taking place reflect a culture of dynamic inquiry. This is made possible when enabling/capacity building leaders share and commit to similar notions of schools working as learning organisations and teachers are assisted/brokered to work collaboratively for professional alliances and professional growth.    Consequently this study proposes that teachers cope better with the ever-increasing demands of curriculum reforms if: * schools can work as learning organisations * schools allow teachers to work as learning leaders * administrative leaders support/enable and model risk-taking, spontaneous and collaborative practices * there are shared beliefs, mission and vision; organisational arrangements/support; conversations for learning; shared approaches to pedagogy, and parallel relationships * enabling/capacity-building leadership for learning alliances allows for a professional culture of dynamic inquiry that can evolve with a renewed focus on conversations for learning.    The findings of this study have theoretical, methodological and practical significance. In the first instance it presents as theoretical significance, the reconstruction of a theoretical framework for schools working as learning organisations. The methodological significance is reflected in this study's emphasis on theorising through layers.  The methodological contribution acknowledges a legitimate and rigorous form of practitioner research, revealing self-study methodology at a level that is more then mere self-indulgence. In presenting its final contribution, the thesis acknowledges the practical contribution of the study by emphasising the process involved in creating a culture of dynamic inquiry. The transformative nature of this action- inquiry self-study is therefore confirmed in this study. The layered analysis reflects a process of making sense of the messiness of practitioner research, and consequently provides a true sense of this established form of practical theorising in the teaching profession. These characteristics should be seen not as limitations, but rather as authentic strengths.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Curriculum leadership</field><field name="subject">Curriculum reform</field><field name="subject">Organisational reform</field><field name="subject">School reform</field><field name="subject">School reculturing</field><field name="subject">Teacher learning</field><field name="subject">Learning organisations</field><field name="subject">Professional learning communities</field><field name="subject">Learning communities</field><field name="subject">Learning alliances</field><field name="subject">Communities of practice</field><field name="subject">Professional learning culture</field><field name="subject">Learning leadership</field><field name="subject">Parallel leadership</field><field name="subject">Relational leadership</field><field name="subject">Teacher leadership</field><field name="subject">Educational leadership</field><field name="subject">Action-inquiry self-study</field><field name="subject">Practitioner research</field><field name="subject">Reflective practice</field><field name="subject">Reflection-in-action</field><field name="identifier">http://eprints.qut.edu.au/16294/</field><field name="validLink">True</field></doc><doc><field name="title">Approaches to learning and learning values: an investigation of adult learners in Malaysia</field><field name="creator">Tan, Po Li</field><field name="description">This research was inspired by a pressing question which formed the main aim of the current study--What factors contribute to the differential academic performance of adult learners in the formal setting in Malaysia? It is hoped that by addressing this question, insights obtained may be useful for the Malaysian policy makers in attempting to implement the government's initiative--Malaysia Vision 2020. The current literature informs that in order to achieve the desired goals, Malaysian adult learners, must now more than ever be conscious of the effect of learning values and approaches to learning. Hence, there is a need to develop a more holistic understanding of the interrelated dynamics between learning values and approaches to learning. The current study adopts a transdisciplinary, etic/emic approach, using two culturally sensitive questionnaires, Revised Study Process Questionnaires-2 Factors Malaysia (RSPQ- 2FM) and Learning Values Survey (LVS) on 858 Malay and Chinese adult learners in Malaysia. The study found the significant others can have substantial influence on the 'face value' for both Malay and Chinese adult learners generally, but was more pronounced for the Malay adult learners. This in turn may encourage Malay adult learners to submit to pressure from others in influencing how they perceive the importance of learning and motivation in learning. Because Malay adult learners are constantly driven by external factors to compete with other cultural groups in education or economic achievement, they may tend to avoid challenging tasks such as deeper approaches to learning in order to rapidly achieve their immediate learning goals. Engaging with deep approaches and meaningful learning are effortful and the pressure to save face may result in the likelihood of adopting surface approaches. This coupled with the finding that they do not appreciate the middle way principles as much as the Chinese adult learners suggest that they may be less flexible and/or pragmatic learners. The findings suggest that practice of middle way principles (such as 'Willing to compromise one's own values to suit the situation/issues when I learn') can indeed enhance certain positive learning approaches which implies that Malay adult learners may be disadvantaged in the learning settings due to their lack of appreciation of the middle way principles. It is also interesting to find that Malay adult learners appreciate time factor more than their Chinese counterparts when engaging with Deep Approaches to learning. In contrast, the middle way principle practiced as a way of life by the Chinese culture has made Chinese adult learners more malleable, resulting in a relatively less face conscious cultural group. Being less externally driven and less restrictive, Chinese adult learners are more likely to adopt deep approaches to enhance meaningful learning. In addition, the Chinese culturally ingrained learning approach, Understand and Memorization was found to be more likely to produce positive learning outcome. Unlike their Malay counterparts, Chinese adult learners view work experiences more essential in helping them to engage with Deep Approaches to learning. The above findings are novel and add to previous studies on approaches to learning by introducing the effect of learning values. While previous research has referred to cultural variable in learning, they have not sufficiently explored the effect of culture. Learning values is one significant cultural variable that is considered in the study. The findings underpin the different emphasis placed by the two cultural groups as they engage with professional development activities. It is hoped that by identifying values pertinent to learning in this competitive globalized economy, the study has provided insights for Malaysian policy makers to develop holistic future education plans to assist in achieving Malaysian Vision 2020. Insights gained can also support plans where Malay can be encouraged to become competent global leaders and workers, capable of competing in this knowledge economy.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">adult learning</field><field name="subject">professional development</field><field name="subject">Aapproaches to learning</field><field name="subject">cultural values</field><field name="subject">asian values</field><field name="subject">cross-cultural studies</field><field name="subject">cross-cultural methodology</field><field name="subject">cultural awareness and training</field><field name="identifier">http://eprints.qut.edu.au/16295/</field><field name="validLink">True</field></doc><doc><field name="title">Creative work: Onward bound: The first fifty years of Outward Bound Australia and Exegesis written component: Creatively writing historical non fiction</field><field name="creator">Klaebe, Helen Grace</field><field name="description">Onward Bound: -- the first 50 years of Outward Bound Australia traces the founding and development of this unique, Australian, non-profit, non-government organisation from its earnest beginnings to its formidable position today where it attracts some 5,000 participants a year to its courses.
 
 The project included interviewing hundreds of people and scouring archives and public records to piece together a picture of how and why Outward Bound Australia (OBA) developed -- recording its challenges and achievements along the way. 
 
 A mediated oral history approach was used among past and present OBA founders, staff and participants, to gather stories about their history. This use of oral history (in a historical book) was a way of cementing the known recorded facts and adding colour to the formal historical outline, while also giving credence to the text through the use of 'real' people's stories.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Outward Bound</field><field name="subject">Outward Bound Australia</field><field name="subject">Australian history</field><field name="subject">Australian war history</field><field name="subject">biography</field><field name="subject">creative non fiction</field><field name="subject">creative writing</field><field name="subject">non fiction</field><field name="subject">oral history</field><field name="subject">organisational history</field><field name="subject">post World War 2 history</field><field name="subject">social history</field><field name="subject">writing processes</field><field name="identifier">http://eprints.qut.edu.au/16296/</field><field name="validLink">True</field></doc><doc><field name="title">Role of soil physical and chemical characteristics and landscape factors in defining soil behaviour under long term wastewater dispersal</field><field name="creator">Dawes, Les A.</field><field name="description">The use of on-site wastewater treatment systems for the treatment and dispersal of domestic effluent is common in urban fringe areas which are not serviced by centralised wastewater collection systems. However, due to inappropriate siting and inadequate evaluation of soil characteristics, the failure of these systems has become a common scenario. The current standards and guidelines adopted by many local authorities for assessing suitable site and soil conditions for on-site dispersal areas are coming under increasing scrutiny due to the public health and environmental impacts caused by poorly performing systems, in particular septic tank-soil adsorption systems. In order to achieve sustainable on-site wastewater treatment with minimal impacts on the environment and public health, more appropriate means of assessment of long term performance of on-site dispersal areas are required.
 
 
 
 The research described in the thesis details the investigations undertaken for the development of robust assessment criteria for on-site dispersal area siting and design and assessment of the long term performance of soil dispersal areas. The research undertaken focused on three key research areas; (i) assessment of site and soil suitability for providing adequate treatment and dispersal of domestic wastewater; (ii) understanding sorption, purification and transport processes influencing retention and release of pollutants and the natural controls governing these processes and (iii) the development of assessment criteria for long term behaviour of soils under effluent dispersal. 
 
 
 
 The research conducted was multidisciplinary in nature, with detailed investigations of the physical and chemical processes involved in on-site wastewater treatment and dispersal. This involved extensive field investigations, sampling and monitoring, laboratory and soil column testing and detailed data analysis across the fields of soil science, groundwater quality, subsurface hydrology, chemical contamination, and contaminant fate and transport processes. The interactions between these different disciplines can be complex which resulted in substantial amounts of data being generated from the numerous field and laboratory investigations and sampling undertaken. In order to understand the complex relationships that can occur, multivariate statistical techniques were utilised. The use of these techniques was extremely beneficial. These techniques not only allowed not only the respective relationships between investigated parameters to be identified, but also adequate decisions based on the correlations were able to be formulated. This allowed a more appropriate assessment of the influential factors, and the prediction of ongoing changes to soil properties due to effluent disposal.
 
 
 
 The primary outcomes for this research were disseminated through a series of peer reviewed scientific papers centred on these key disciplines. The assessment of site and soil suitability was achieved through extensive soil sampling throughout the study areas and detailed laboratory testing and data analysis. The study identified and investigated the role of influential site and soil characteristics in the treatment performance of subsurface effluent dispersal areas. The extent of effluent travel and the ability of the soil to remove pollutants contained in the effluent by adsorption and/or nutrient uptake were investigated. A framework for assessing the renovation ability of the major soil groups located throughout Southeast Queensland was also developed. The outcomes provide a more rigorous scientific basis for assessing the ability of soil and evaluating site factors to develop more reliable methods for siting effluent dispersal areas. The resulting assessment criteria developed was compared with soil column studies to determine the robustness and validity of the outcomes. This allowed refinement of the assessment criteria in developing a more reliable approach to predicting long term behaviour of soils under sewage effluent dispersal. Multivariate techniques assisted in characterising appropriate soils and to determine their long-term suitability for effluent treatment and dispersal. 
 
 
 
 The assessment criteria developed included physical, chemical and sub-surface hydrological properties of a site and soil which can be used to predict suitability for long term effluent treatment and dispersal. These include:
 
 &#61607;	Moderate to slow drainage (permeability) to assist the movement of effluent (percolation) through the soil profile and allow adequate time for treatment and dispersal to occur. With longer percolation times, the opportunity for exchange and transport processes increase.
 
 &#61607;	Significant soil cation exchange capacity and dominance of exchangeable Ca2+ or exchangeable Mg2+ over exchangeable Na+. Although a soil dominated by Mg2+ is found to promote dispersion of soil particles to some extent, its impact is far less than that of Na+. A stable soil would have a Ca: Mg ratio &gt; 0.5.
 
 &#61607;	Low exchangeable Na+ content to maintain soil stability.
 
 &#61607;	Minimum depth of 400mm of potentially unsaturated soil before encountering a restrictive horizon, to permit adequate purification to take place.
 
 &#61607;	Clay type with Illite and mixed mineralogy soils being the most sensitive to Na+. In general, significant increases in ESP occur in soils with 30 to 40% clay and in the presence of illite clay. Small amounts of smectite clays enhance treatment potential of a soil. 
 
 
 
 The research outcomes have significantly contributed to the knowledge base on best practice in on-site dispersal area siting and design. The developed predictive site and soil suitability assessment criteria allows more appropriate evaluation of site and soil characteristics for providing long term effluent renovation. This is generally not done in the current assessment techniques for on-site dispersal areas. The processes and techniques used in the site and soil suitability assessment, although based on the common soil types typical of South East Queensland, can be implemented in other regions, provided appropriate soil information is collected or available.
 
 
 
 The predictive assessment criteria have been developed at a generic level, allowing easy implementation into most assessment processes. This gives the framework the flexibility to be developed for other areas specifically targeting the most influential on-site dispersal area siting and design factors, and assessment of long term performance under wastewater application.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">on-site wastewater treatment systems</field><field name="subject">soil dispersal areas</field><field name="subject">soil chemistry</field><field name="subject">multivariate analysis</field><field name="subject">physical and chemical soil parameters</field><field name="identifier">http://eprints.qut.edu.au/16297/</field><field name="validLink">True</field></doc><doc><field name="title">'&#129;Eor China's benefit' : the evolution and devolution of German influence on Chinese military affairs, 1919 - 1938</field><field name="creator">Berleb, Stefan</field><field name="description">In the years between 1919 and 1938, Germany and China, two nations each plagued in its own way by the foreign political fall-out of World War I, by internal unrest and by the disastrous global economic situation of the inter-war era, established extraordinarily close military and military economic ties. German military advisers helped in the organisation and training of the troops of several Chinese warlords and, after the re-establishment of the Chinese Republic under Chiang Kaishek, of the Nationalist government's armed forces. At the same time, German arms manufacturers and German trading companies delivered weapons and other war materials to arm and equip China's soldiers, who fought first against each other and later against Mao Zedong's Communist guerillas and Japanese invaders. Still, despite outward appearances, any kind of German military support for China was never official. Successive Weimar German governments tried everything in their power to stop the widely-condemned Sino-German military cooperation, while Adolf Hitler's National Socialists only tolerated it for as long as it did not interfere with their long-term political agenda. In the end, however, the German influence on Chinese military affairs was only minimal. German military advisers and German arms shipments, contrary to repeated world-wide accusations throughout the years, were too few in number and too small in amount to have any real impact on war-ravaged China. The breakdown of Sino-German relations due to National Socialist Germany's alliance with Japan and the Sino-Japanese War eradicated every trace China's informal military supporters had left behind after their withdrawal in 1938.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">China</field><field name="subject">Germany</field><field name="subject">Chinese Military</field><field name="subject">war</field><field name="identifier">http://eprints.qut.edu.au/16298/</field><field name="validLink">True</field></doc><doc><field name="title">An IMRT class solution for patients with skin lesions of the temple region that have spread to the parotid gland</field><field name="creator">O'Rourke, Amy Louise</field><field name="description">Patients with skin lesions of the temple region that have spread to the parotid gland are  commonly treated with three-dimensional conformal radiation therapy (3DCRT). 3DCRT has associated limitations when treating this disease. 3DCRT requires this disease site to be treated with two junction regions, resulting in poor dose conformity to the tumour target. Proximity of critical structures to the target volume can make dosimetry difficult, "especially for concave-shaped targets in close proximity to sensitive normal structures" (Saw.C et al., 2002, p76). Intensity modulated radiation therapy (IMRT) is a relatively new treatment technology that has potential to overcome limitations associated with 3DCRT (Garden.A et al., 2004). IMRT has been reported to have significant advantages over conventional 3DCRT treatment, by improving dose to the tumour and lowering doses to critical structures (Adams.E et al., 2001). Research has been conducted into the optimal IMRT treatment for specific head and neck carcinomas. They are identified as class solutions. "A class solution can be defined as the historical experience in designing RT plans for a particular site" (Intensity Modulated Radiation Therapy Collaborative Working, 2001, p913). This study was performed to establish an optimal IMRT class solution for patients with skin lesions of the temple region that have spread to the parotid gland, and to determine if it is the superior treatment option over 3DCRT treatment. Dosimetry planning was performed on computerised tomography data sets of nine patients with this disease site. One optimised 3DCRT dosimetry plan and eight optimised IMRT plans with specific beam arrangements were calculated. Clinical and statistical analysis was performed on; critical structures, conformity indices (CI) and dose volume histogram (DVH) range analysis of the planning target volume (PTV). Analysis of IMRT plans revealed that the 7-beam arrangement and 4-beam ipsilateral arrangement produced significantly lower doses to the majority of critical structures (P &lt; 0.05). The 7-beam IMRT arrangement produced the best and second best CI and DVH PTV results, but these were not significantly different to the majority of other beam arrangements. This indicates that the 7-beam arrangement with defined beam angles of; 40&#176;,120&#176;,160&#176;,200&#176;,240&#176;,300&#176;,0&#176;, is the superior IMRT treatment plan, and thus class solution for this disease site. Clinical analysis confirmed results. Analysis was performed on IMRT class solution results compared with 3DCRT results. CI was significance higher and DVH PTV range was significantly lower for the IMRT class solution (P &lt; 0.05). The class solution delivered significantly higher doses to the majority of critical structures in comparison to the 3DCRT plan (P &lt; 0.05). This indicates that the IMRT class solution is superior to 3DCRT in terms of PTV conformity and homogeneity, but not in terms of doses to critical structures. Skin lesions of the temple region with tumour extension to the parotid gland, is a complicated disease site. Investigations into current and potential radiation therapy treatments will guide treatment options and facilitate outcomes for patients with this disease.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">3DCRT</field><field name="subject">IMRT</field><field name="subject">DVH</field><field name="subject">PTV</field><field name="subject">skin lesion of the temple region</field><field name="identifier">http://eprints.qut.edu.au/16299/</field><field name="validLink">True</field></doc><doc><field name="title">A mathematical model of wound healing and subsequent scarring</field><field name="creator">Cumming, Benjamin Donald</field><field name="description">Wound healing is governed by a complex cascade of related processes, involving cells, extracellular matrix and cytokines. In adults this always results in a scar whilst embryonic wound healing is scarless and extensive research worldwide is aimed at reducing scarring in adults.  A mathematical framework for problems in dermal wound healing is developed that incorporates models of the individual processes involved. Cells are modelled as discrete individuals. Cytokines and other biologically active factors are modelled as continua. A novel tensorial approach is taken to modelling the extracellular matrix.  The numeric and computational challenges associated with combining models for the individual processes are identified and investigated. These include the development of data structures and numeric methods for the continuous and discrete species. Effective visualisation methods for the large amounts of data generated by the model are also discussed. The possibilities offered by high performance computing in mathematical biology are highlighted in this work.  The final part of this thesis gives an example of a combined model of the inflammatory and proliferative phases of dermal wound healing using the new computational framework. Both quantitative and qualitative methods are used to analyse the information-rich data sets generated by the model, offering insight into the dynamic systems that can be modelled using the new approach.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">wound healing</field><field name="subject">collagen</field><field name="subject">fibrin</field><field name="subject">extracellular matrix</field><field name="subject">cytokine</field><field name="subject">macrophage</field><field name="subject">fibroblast</field><field name="subject">dermal</field><field name="subject">clot</field><field name="subject">finite volume</field><field name="subject">stochastic</field><field name="subject">tensor</field><field name="subject">fibre</field><field name="identifier">http://eprints.qut.edu.au/16300/</field><field name="validLink">True</field></doc><doc><field name="title">Towards Globo Sapiens : using reflective journals to prepare engineering students able to engage with sustainable futures</field><field name="creator">Kelly, Patricia</field><field name="description">How do we help students to integrate their tertiary education with their development as " wise" global citizens and professionals? The study engages with this question through exploring the use of Reflective Journals as a central and integrating strategy for learning and assessment for a socially and culturally diverse group of students in a large, compulsory, first year, one-semester Engineering unit [BNB007: Professional Studies] between 2000 and 2004.  The study supports the hypothesis that Reflective Journals can be an effective strategy for improving the often-criticised poor communication skills of domestic and international students in technical fields. For many students, the process of reflection also became a means of learning about their learning. Attitude surveys administered to students pre and post the teaching intervention in the years 2000-2002 showed positive changes in anticipated directions that encouraged further research. If attitude change was occurring in BNB007, what was the nature of the change? The research showed that at a deeper, longer term and more complex level, this new self-awareness supported many students to develop the kind of futures thinking and social learning " that will be necessary to navigate the transition to sustainable futures" (Raskin et al., 2002). The study contributes to the literature and to methodology through the first complementary use of two new methodologies, Sense-Making and Causal Layered Analysis. Thirty in-depth Sense-Making based interviews, including four with staff, indicate that 'meta-reflection' and transformative learning did take place.  Expressing these qualities in the discourse of internationalisation as  " global portability" or even " global competence" is unsatisfactory because these popular terms do not embody the qualities graduates need to create sustainable futures. As currently used, they mainly serve a market-dominated version of globalisation and its allied internationalisation-as-profit discourse. Raskin et al proposed a more appropriate term,  " sustainability professionals", emerging from a preferred, valuesbased globalisation inspired by a vision of humane, sustainable futures that see  " rights assured, nature treasured, culture rich and the human spirit animate" (p.70). This more challenging concept of a graduate for the 21st century is expressed here through the term Globo sapiens, whose qualities are identified in this study. Such professionals are willing to think critically and to assume responsibility for their impact on communities and the planet. This is the critical-futures oriented, transformative and therefore radical notion connoted by the title Towards Globo sapiens.  This research identified some of the terrain and challenges of a post-development vision in a vocational area of teaching in Higher Education. It explained how particular students resisted or reconstructed their worlds when challenged at fundamental levels, but within a supportive atmosphere. Thus the study contributes to what educators might need to know, be and do, in order to teach effectively for the transformations urged by Sustainability Scientists, among others, and upon which any sustainable alternative futures depend. The study is underpinned by transdisciplinary syntheses that help to illuminate each area in new and fruitful ways.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Causal Layered Analysis</field><field name="subject">Critical Futures Thinking</field><field name="subject">Engineering Education</field><field name="subject">Internationalisation of the Curriculum</field><field name="subject">Learning Society</field><field name="subject">Sense-Making</field><field name="subject">Sustainability Education</field><field name="subject">Reflective Journals</field><field name="subject">Transdisciplinarity</field><field name="subject">Transformation</field><field name="subject">Writing in the Curriculum</field><field name="identifier">http://eprints.qut.edu.au/16301/</field><field name="validLink">True</field></doc><doc><field name="title">The production of cultural difference and cultural sameness in online internationalised education</field><field name="creator">Doherty, Catherine Ann</field><field name="description">This research investigates the cultural politics of 'borderless' education. In Australia, online internationalised education has recently emerged as a market innovation borne from the intersection of two agendas in the higher education sector: an enthusiasm for technological means of delivery; and the quest for international full-fee paying enrolments. The empirical study analyses how both cultural difference and cultural sameness were produced in a case study of borderless education and were made to matter in both the design and the conduct of online interaction. A core MBA unit offered online by an Australian university was selected for the study because its enrolments included a group enrolled through a partner institution in Malaysia. The study is framed in the broad context of the changing cultural processes of globalisation, and in educational markets where knowledge is business. In this more fluid and complicated cultural landscape, the technologies and social practices supporting online education were understood to offer new cultural resources for identity processes.  Pedagogy, rather than providing an inert stage for cultural identities to interact, was understood to play an active role in invoking and legitimating possible orientations for student identities.  The framework thus builds on a metaculture, or understandings of culture and cultural identity, more appropriate for the cultural conditions of globalising times. The study was conducted as a virtual ethnography of the case study unit drawing on: the observation and recording of all virtual interaction in the unit's website; interviews and dialogues with the lecturer and designer involved; email interviews with some students; and the collection of course artefacts and related documentation. The methodological arguments and design addressed the complexity of grasping how culture is lived in globalised times, and how it is invoked, performed and marked in virtual interactions. Using layered textual analyses synthesising Bernstein's theory of pedagogic discourse and Systemic Functional Linguistics, a description of the unit drew out contradictory aspects in its macrogenre design. On one hand, the design aimed for cultural saming in terms of delivering undifferentiated curriculum and pedagogy for the diverse cohort of students.  On the other hand, it also aimed for cultural differencing in the 'student subsidy'of the curriculum. The analysis showed how cultural difference was thus produced as both a curricular asset, and as a series of pedagogical problems in the case study unit.    The 'student subsidy' design involved allocating students to purposefully mixed groups for assessable small group discussions in order to enrich the curricular treatment of cultural diversity as a topic of interest. This design invoked expressions of a range of cultural identities and knowledge claims about cultural differences. These claims were analysed with reference to how they were legitimated, and who invoked what culture on behalf of which groups. Despite the design of an undifferentiated process, the conduct of the unit displayed a number of pedagogical problems or 'regulative flares' in which groups of students complained about being overly or insufficiently differentiated. The analysis focused on three such flares: troubles with naming protocols; troubles around genre expectations for assessment tasks; and trouble over 'local' markers for the Malaysia students. These were summarised as trouble with the unit's 'default settings' and presumptuous assumptions about whose cultural terms applied in this educational setting.    The study makes a contribution to the sociology of education, in particular with regard to internationalisation and online modes of delivery. The empirical study also contributes to the sociology of the cultural processes of globalisation. More practically, it is suggested that such programs could profitably embrace a version of culture more in line with the entangled routes and global flows that have brought the students and provider together, one that can accommodate and celebrate glocalised identities.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">globalisation</field><field name="subject">internationalisation</field><field name="subject">pedagogy</field><field name="subject">pedagogic discourse</field><field name="subject">cultural difference</field><field name="subject">cultural identity</field><field name="subject">online education</field><field name="subject">ethnography</field><field name="identifier">http://eprints.qut.edu.au/16302/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation of a finite volume method incorporating radial basis functions for simulating nonlinear transport</field><field name="creator">Moroney, Timothy John</field><field name="description">The objective of this PhD research programme is to investigate the effectiveness of a finite volume method incorporating radial basis functions for simulating nonlinear transport processes. The finite volume method is the favoured numerical technique for solving the advection-diffusion equations that arise in transport simulation. The method transforms the original problem into a system of nonlinear, algebraic equations through the process of discretisation. The accuracy of this discretisation determines to a large extent the accuracy of the final solution.    A new method of discretisation is presented that employs radial basis functions (rbfs) as a means of local interpolation. When combined with Gaussian quadrature integration methods, the resulting finite volume discretisation leads to accurate numerical solutions without the need for very fine meshes, and the additional overheads they entail.    The resulting nonlinear, algebraic system is solved efficiently using a Jacobian-free Newton-Krylov method. By employing the new method as an  extension of existing shape function-based approaches, the number of nonlinear iterations required to obtain convergence can be reduced. Furthermore, information obtained from these iterations can be used to increase the efficiency  of subsequent rbf-based iterations, as well as to construct an effective parallel reconditioner to further reduce the number of nonlinear iterations required.    Results are presented that demonstrate the improved accuracy offered by the new method when applied to several test problems. By successively  refining the meshes, it is also possible to demonstrate the increased order of the new method, when compared to a traditional shape function basedmethod.  Comparing the resources required for both methods reveals that the new approach can be many times more efficient at producing a solution of a given accuracy.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Finite volume method</field><field name="subject">Diffusion</field><field name="subject">Advection</field><field name="subject">Radial basis functions</field><field name="subject">Gaussian quadrature</field><field name="subject">Control volume-finite element</field><field name="subject">Jacobian-free</field><field name="subject">Newton-Krylov</field><field name="subject">Unstructured mesh</field><field name="subject">Triangular mesh</field><field name="subject">Tetrahedral mesh</field><field name="subject">Parallelb preconditioner</field><field name="identifier">http://eprints.qut.edu.au/16303/</field><field name="validLink">True</field></doc><doc><field name="title">Citizen tourist: newspaper travel journalism's responsibility to its audience</field><field name="creator">Hill-James, Candeeda Rennie</field><field name="description">Travel is the stuff of dreams. But its facilitation or impediment is the reality of commerce and governments and their manipulation by marketing and political considerations. This thesis examines how travel journalism can maintain responsibility to a 'private' tourist audience in the 'public' tourism sphere.    Travel journalism is not only an under-researched area, but provides an important site to study the role of public interest information for a consumer audience participating in a sometimes culturally and politically dangerous activity. The reporting of travel by mainstream newspapers concentrates on the travel dream, while the tourism industry, described as the largest in the world, receives little scrutiny by society's guardians of democracy.    This thesis examines literature from the fields of journalism, sociology and marketing to highlight the private tourist audience desires and the measures that commercial and government travel enterprises employ to reach consumers through public relations influence over journalism entities and practitioners. This study also emphasises the public nature of tourism and the risks it presents to tourists to examine how travel journalism, as a responsible moral practice, should address its audience.    A content analysis was conducted on a sample of Australian newspaper travel journalism to provide a description of international travel coverage. More specifically it revealed the characteristics of travel articles that provide public interest information to move the private tourist audience to engage in the public tourism sphere as an active citizenship.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Travel journalism</field><field name="subject">Newspapers</field><field name="subject">Journalistic responsibility</field><field name="subject">Public interest</field><field name="subject">Tourist citizenship</field><field name="subject">Travel</field><field name="subject">Tourism</field><field name="subject">Cultural studies</field><field name="subject">Content analysis</field><field name="identifier">http://eprints.qut.edu.au/16304/</field><field name="validLink">True</field></doc><doc><field name="title">A conceptual framework for information management : formation of a discipline</field><field name="creator">Middleton, Michael Robert</field><field name="description">The aim of the research was to investigate the formation of the information management discipline, propose a framework by which it is presently understood, and test that framework within a particular area of application, namely the provision of scientific and technological information (STI) services. 
 
 The work is presented as a PhD by Publication which comprises a narrative that encompasses the series of published papers, and includes excerpts from the book written to illustrate the province of the discipline.
 
 In thee book the disciplinary context is detailed and exemplified based upon information management domains. The book consolidates information management principles within a framework defined by these operational, analytical and administrative domains. It was created by a redaction of prior epistemological proposals; an analysis of the understanding of practice that has been shaped by professional, institutional and information science influences; and demonstration of practice within the domain framework.
 
 The disciplinary framework was then used in a series of STI case studies where it was found to provide an effective description of information management. Together, the book and subsequent case studies provided illustration of the principles utilised in information management and the way that they are practiced within different domains, along with an explanation of the manner in which the information management discipline has been formed. These should assist with direction of future research and scholarship particularly with respect to factors relevant to information services and indicators for their successful application in future.
 
 It is anticipated that this generalised description of the practices across the range of interpretations of information management should enable practicing information professionals to appreciate the relationship of their own work to disciplines that are converging towards similar purpose, such as through a clearer indication of the extent to which technical and management standards may be applied, and performance analysis undertaken.
 
 Complementary outcomes that were achieved during the course of the work were: a comparative analysis of thesauri in the information field which shows that in this field, the ways that information professionals represent themselves remains unreconciled; an historical examination of Australian STI services that provides pointers to their effective continuation; and a reconsideration of the relationship between librarianship and information management.
 
 The work is presented as a compilation of papers that comprise firstly extracts from the book to exemplify its consolidation of information management principles, then a number of published and submitted papers that examine how principles have been applied in practice. This is in the context of six case studies of Australian STI services including interviews with creators and developers, and analysis of historical information.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Information management</field><field name="subject">discipline formation</field><field name="subject">information services</field><field name="subject">case studies</field><field name="subject">bibliographic databases</field><field name="subject">Australia</field><field name="identifier">http://eprints.qut.edu.au/16305/</field><field name="validLink">True</field></doc><doc><field name="title">La Boite Theatre 1925 to 2003: an historical survey of its transformation from an amateur repertory society to an established professional company</field><field name="creator">Comans, Christine Anne Wilmington</field><field name="description">This study addresses the central question of how Brisbane's La Boite Theatre negotiated its transformation from an amateur repertory society to an established professional company and, despite set-backs and crises, survived, changed and developed in an unbroken line of theatrical activity from its genesis in1925 to 2003. To answer the question, La Boite's history is surveyed within its three status modes of amateur, 'pro-am', and professional. Effective artistic and organizational leadership and a set of key manifestations of effective leadership are identified as crucial to the company's successful transformational journey. Such a transformation is a distinctive achievement in Australian repertory theatre history and, in exploring it, this study makes an original and important contribution to the history of Australian theatre organizations, very few of which have been the subject of scholarly research.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Australian theatre history</field><field name="subject">Brisbane Repertory Theatre</field><field name="subject">Brisbane theatre history</field><field name="subject">La Boite Theatre Company</field><field name="identifier">http://eprints.qut.edu.au/16306/</field><field name="validLink">True</field></doc><doc><field name="title">Enabling ad hoc interaction with electronic services</field><field name="creator">Oaks, Phillipa Jane</field><field name="description">Web services are a new breed of Web application. They are self-contained, self-describing, modular applications that can be published, located, and invoked across the Web [154]    Web services are a promising technology for ad hoc machine to machine interaction across application, enterprise and web boundaries. Self describing web services is a catchy phrase but it should mean more than having an interface description written in XML syntax.    This research is motivated by the vision of web services in the future as loosely coupled applications operating on different platforms inter-operating without prior agreements in place and without direct human intervention at runtime.    The main obstacle to advancing the vision of ad hoc runtime interaction is complexity. The complexity of ad hoc interaction for web services is related to 1) the information the service requires and provides and the nuances of the domain or context the service operates on and in. 2) The specific nature of the operations the service provides and the constraints related to those operations and 3) the necessary ordering of operations to achieve the desired result.    There are three problems that must be addressed before the vision for web services can become a reality. These problems are aligned with the three aspects of service complexity identified above. The three inter-related elements of this research address each of these problems.    The first part of the research deals with what web services "talk" about and how the data required or provided by services can be described to enable mutual understanding. An extension to traditional conceptual models, called outsourced type descriptions, allows the description of shared data in terms of publicly available information, including standards, specifications, ontologies and definitions from dictionaries and thesauri.    The second part is concerned with describing why services interact and the capabilities (actions or information) services can provide. A structured format for the description, advertisement and discovery of services based on what they actually do is presented. The structured format is based on previous work in the description of actions and the context in which they are performed.    The last part of the research addresses how previously unknown services can talk to one another to supply and use the advertised capabilities. Interaction is based on providers having "plans" for the delivery of capabilities. The flow of interaction is directed by the service providers' data requirements and is responsive to the resources of the client. A small language for information gathering based on well known interaction primitives is defined. An example implementation of a capability plan interpreter demonstrates how messages are generated, managed and interpreted at runtime in order to satisfy the client's goals.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Web services</field><field name="subject">service description</field><field name="subject">ad hoc interaction</field><field name="subject">capabilities</field><field name="subject">outsourced type descriptions</field><field name="identifier">http://eprints.qut.edu.au/16307/</field><field name="validLink">True</field></doc><doc><field name="title">A sense of control : a model of a virtual community for people with mobility impairments</field><field name="creator">Tilley, Christine Margaret</field><field name="description">This qualitative study develops a model of a virtual community for people with longterm, severe physical or mobility disabilities. The model also has implications for the wider community of people with disabilities. The study uses the Strauss and Corbin grounded theory methodology to inform the investigation from which a systematic theory has been developed. On the basis of this theory, the study proposes strategies for implementing the virtual community model.    In-depth interviews were conducted with twelve Queenslanders with paraplegia, quadriplegia or other severe, long-term physical or mobility disabilities and with six health care professionals, service providers, information personnel and policy advisers involved in their well-being. The methodology used one interview question to determine their experiences and perceptions regarding virtual communities and the use of Information and Communications Technology (ICT). Each interview explored in detail the elements, enablers and barriers behind the usage of ICT and/or assistive technology.    The personal responses and narratives of the people with disabilities who use the technology and their allied health care professionals were analysed and interpreted for meaning before the transcripts were returned to these participants for validation. Rich explanations were derived. Details of the various response categories of these interviews were analysed as part of the grounded theory, constant comparison methodology, and the relationship to the literature was considered. These de-constructed meanings were compared and contrasted with those in the current literature.    The central theme to emerge from these narratives is that people with long-term disabilities regain a sense of control and independence in their lives through the use of ICT, as they move towards an on-line community. Other major themes that emerged from being on-line indicated that being on-line tended to break down people's isolation, while potentially changing the work paradigm (both vexed issues for people with disabilities). Information and communications technology and on-line communities offer ways to enhance every person's inclusion, participation and empowerment in our society.    The primary outcome of the study is a theory regarding the character of virtual communities for people with long-term, severe mobility impairments that stakeholders may consider whenever such a virtual community is proposed. The theory is represented as a virtual community model.    The model identifies the need for "a sense of control" as the foundational element of virtual communities for the disabled, and distinguishes the key domains in which disabled people participate in virtual communities. The barriers and enablers to their participation are specified within it. The model also provides a framework within which virtual communities can be facilitated. It melds six types of e-communities or sets of well-developed discrete categories (for example, themes, concepts) that the data from this study revealed: education-oriented, fantasy-oriented, information-oriented, interestoriented, relationship-oriented and transaction-oriented, depending on the type(s) of consumer need(s) to be met.    The study concludes that although the technology itself provides strategies for independence and thus facilitates self-empowerment, it is also capable of being disempowering. Many interviewees referred to this aspect as a "double-edged sword". Empowerment and dis-empowerment are intersecting processes because of digital divide and information literacy issues and this "double-edged sword", which virtual reality presents for people with physical disabilities. Based on the new knowledge and the model as the outcomes of this study, a range of recommendations are discussed that have application in the community for persons with mobility impairments.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Access</field><field name="subject">assistive technology</field><field name="subject">barriers</field><field name="subject">control</field><field name="subject">digital divide</field><field name="subject">disability</field><field name="subject">e-commerce</field><field name="subject">empowerment</field><field name="subject">grounded theory methodology</field><field name="subject">ICT usage</field><field name="subject">information</field><field name="subject">information and communications technology</field><field name="subject">information literacy</field><field name="subject">people with mobility impairments</field><field name="subject">portals for people with physical disabilities</field><field name="subject">technological literacy</field><field name="subject">telecommunications</field><field name="subject">tele-working</field><field name="subject">well-being</field><field name="subject">and virtual community.</field><field name="identifier">http://eprints.qut.edu.au/16308/</field><field name="validLink">True</field></doc><doc><field name="title">Visual homing for a car-like vehicle</field><field name="creator">Usher, Kane</field><field name="description">This thesis addresses the pose stabilization of a car-like vehicle using omnidirectional visual feedback. The presented method allows a vehicle to servo to a pre-learnt target pose based on feature bearing angle and range discrepancies between the vehicle's current view of the environment and that seen at the learnt location. The best example of such a task is the use of visual feedback for autonomous parallel-parking of an automobile.    Much of the existing work in pose stabilization is highly theoretical in nature with few examples of implementations on 'real' vehicles, let alone vehicles representative of those found in industry. The work in this thesis develops a suitable test platform and implements vision-based pose stabilization techniques. Many of the existing techniques were found to fail due to vehicle steering and velocity loop dynamics, and more significantly, with steering input saturation. A technique which does cope with the characteristics of 'real' vehicles is to divide the task into predefined stages, essentially dividing the state space into sub-manifolds. For a car-like vehicle, the strategy used is to stabilize the vehicle to the line which has the correct orientation and contains the target location. Once on the line, the vehicle then servos to the desired pose. This strategy can accommodate velocity and steering loop dynamics, and input saturation. It can also allow the use of linear control techniques for system analysis and tuning of control gains.    To perform pose stabilization, good estimates of vehicle pose are required. A simple, yet robust, method derived from the visual homing literature is to sum the range vectors to all the landmarks in the workspace and divide by the total number of landmarks--the Improved Average Landmark Vector. By subtracting the IALV at the target location from the currently calculated IALV, an estimate of vehicle pose is obtained. In this work, views of the world are provided by an omnidirectional camera, while a magnetic compass provides a reference direction. The landmarks used are red road cones which are segmented from the omnidirectional colour images using a pre-learnt, two-dimensional lookup table of their colour profile. Range to each landmark is estimated using a model of the optics of the system, based on a flat-Earth assumption. A linked-list based method is used to filter the landmarks over time. Complementary filtering techniques, which combine the vision data with vehicle odometry, are used to improve the quality of the measurements.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Mobile robots</field><field name="subject">nonholonomic systems</field><field name="subject">control of nonholonomic systems</field><field name="subject">control of carlike vehicles</field><field name="subject">pose stabilization</field><field name="subject">non-linear control</field><field name="subject">switching control</field><field name="subject">computer vision</field><field name="subject">omnidirectional vision</field><field name="subject">panoramic vision</field><field name="subject">colour segmentation</field><field name="subject">object tracking</field><field name="subject">visual homing</field><field name="identifier">http://eprints.qut.edu.au/16309/</field><field name="validLink">True</field></doc><doc><field name="title">Production structure models and applications within a Statistical Activity Cost Theory (SACT) Framework</field><field name="creator">Turner, Lyle Robert</field><field name="description">Statistical Activity Cost Theory (SACT) is an axiomatic and statistical theory of basic accounting measurement practice. The aim of the SACT analysis, among others, is to determine the statistical nature of both the physical production system of an accounting entity and its related costs, which can then be examined  and applied to various decision-making problems. A central proposition of SACT is that the physical system of the entity, and the costs related to this system, are separate structures which can be modelled as such. To date, however, mini- mal progress has been made in describing production process structures within the SACT framework, and nor have there been any advances made in applying common statistical techniques to such an analysis. This thesis, therefore, moves to extend the basic theory that has already been developed, presenting a novel  method for representing and examining the physical processes that make up an entity's production system. It also examines the costing of these physical models, such that transactional data can be examined and related back to the underlying production processes. The thesis concludes by giving an example of such an application in a case study. The analysis developed in this thesis has been applied in a larger project which aims to produce generic modelling and decision tools, based upon SACT, to support return and risk management.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Statistical Activity Cost Theory (SACT)</field><field name="subject">Production Theory</field><field name="subject">Task</field><field name="subject">Production Process</field><field name="subject">Project Evaluation and Review Technique (PERT)</field><field name="subject">Critical Path Method (CPM)</field><field name="subject">Activity Network</field><field name="subject">Uncertainty</field><field name="subject">Project Simlation</field><field name="identifier">http://eprints.qut.edu.au/16310/</field><field name="validLink">True</field></doc><doc><field name="title">One man's vision : a play in two acts and an accompanying exegesis</field><field name="creator">Bavinton, George M.</field><field name="description">The play One Man's Vision covers the period 1963 to 1966 when Jorn Utzon, the Danish architect of the Sydney Opera House, resided in Sydney until his resignation or dismissal in February 1966. The play draws on the tensions and hostility towards Utzon, which builds in the government of the day, cultural groups, press, and also with some senior architects. Rowdy scenes in the N.S.W. Legislative Assembly paint a broad canvas of construction, funding, and political problems. These further escalate with a change of government. Utzon's daily work features interaction between his assistant, consulting engineers, and Public Works Department inspectors, as pressures develop to overcome operational and financial problems. His forced dismissal, resulting in a public rally and march, puts in doubt the completion of the opera house. The exegesis takes Arthur Miller's argument for the playwright as an interpreter of history as its starting point, in order to examine the issues of balancing history with drama in the writing of my play, One Man's Vision. To bring unity to existing reports and to construct a play capable of holding an audience, a playwright must make many choices shaped by the conventions of the theatre and of the genre of the work being attempted. A historical play based on existing records will also draw on the imagination of the playwright. The playwright, therefore, makes decisions as to the blend of history and imagination which will be used to serve the story and represent ideas and concepts through dialogue. In making these artistic decisions history becomes just one component rather than the predominant one.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">history</field><field name="subject">playwriting</field><field name="subject">Sydney Opera House</field><field name="subject">Jorn Utzon</field><field name="identifier">http://eprints.qut.edu.au/16311/</field><field name="validLink">True</field></doc><doc><field name="title">Estimating the parameters of polynomial phase signals</field><field name="creator">Farquharson, Maree Louise</field><field name="description">Nonstationary signals are common in many environments such as radar, sonar, bioengineering and power systems. The nonstationary nature of the signals found in these environments means that classicalspectralanalysis techniques are notappropriate for estimating the parameters of these signals. Therefore it is important to develop techniques that can accommodate nonstationary signals. This thesis seeks to achieve this by firstly, modelling each component of the signal as having a polynomial phase and by secondly, developing techniques for estimating the parameters of these components. Several approaches can be used for estimating the parameters of polynomial phase signals, eachwithvarying degrees ofsuccess.Criteria to consider in potential estimation algorithms are (i) the signal-to-noise (SNR) ratio threshold of the algorithm, (ii) the amount of computation required for running the algorithm, and (iii) the closeness of the resulting estimates' mean-square errors to the minimum theoretical bound. These criteria will be used to compare the new techniques developed in this thesis with existing techniques. The literature on polynomial phase signal estimation highlights the recurring trade-off between the accuracy of the estimates and the amount of computation required. For example, the Maximum Likelihood (ML) method provides near-optimal estimates above threshold, but also incurs a heavy computational cost for higher order phase signals. On the other hand, multi-linear techniques such as the high-order ambiguity function (HAF) method require little computation, but have a significantly higher SNR threshold than the ML method. Of the existing techniques, the cubic phase (CP) function method is a promising technique because it provides an attractive SNR threshold and computational complexity trade-off. For this reason, the analysis techniques developed in this thesis will be derived from the CP function. A limitation of the CP function is its inability to accurately process phase orders greater than three. Therefore, the first novel contribution to this thesis develops a broadened class of discrete-time higher order phase (HP)functions to address this limitation.This broadened class is achieved by providing a multi-linear extension of the CP function. Monte Carlo simulations are performed to demonstrate the statistical advantage of the HP functions compared to the HAFs. A first order statistical analysis of the HP functions is presented. This analysis verifies the simulation results. The next novel contribution is a technique called the lower SNR cubic phase function (LCPF)method. It is an extension of the CP function, with the extension enabling performance at lower signal-to-noise ratios (SNRs). The improvement of the SNR threshold's performance is achieved by coherently integrating the CP function over a compact interval in the two-dimensional CP function space. The computation of the new algorithm is quite moderate, especially when compared to the ML method. Above threshold, the LCPF method's parameter estimates are asymptotically efficient. Monte Carlo simulation results are presented and a threshold analysis of the algorithm closely predicts the thresholds observed in these results. The next original contribution to this research involves extending the LCPF method so that it is able to process multicomponent cubic phase signals and higher order phase signals. The LCPF method is extended to higher orders by applying a windowing technique as opposed to adjusting the order of the kernel as implemented in the HP function method. To demonstrate the extension of the LCPF method for processing higher order phase signals and multicomponent cubic phase signals, some Monte Carlo simulations are presented. Finally, these estimation techniques are applied to real-worldscenarios in the fields of Power Systems Analysis, Neuroethology and Speech Analysis.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">parameter estimation</field><field name="subject">signal-to-noise ratio</field><field name="subject">higher order phase signals</field><field name="subject">multicomponent phase signals</field><field name="subject">cubic phase function</field><field name="subject">higher order phase function</field><field name="subject">lower signal-to-noise ratio cubic phase function</field><field name="subject">computational complexity</field><field name="subject">signal-to-noise ratio threshold</field><field name="subject">mean square error</field><field name="subject">Cramer-Rao lower bound</field><field name="subject">Monte Carlo simulations</field><field name="subject">applications</field><field name="identifier">http://eprints.qut.edu.au/16312/</field><field name="validLink">True</field></doc><doc><field name="title">Dwelling at the margins : an exegesis of the film Boundaries</field><field name="creator">Pullen, Naomi Margaret</field><field name="description">" Dwelling at the Margins" is an exegesis of the short film Boundaries. Boundaries is a journey into the world of marginalised young people in inner urban Brisbane seen through the eyes of a the female main character with an eye for gentle beauty. The film forms the first part of the research and in the exegesis the ideas unfold that were behind the making of the film and that emerged further through its production and audience reception. The exegesis discussion centres on the major aspects of the film which are visual representations, female narratives and the themes of home and dwelling. Boundaries is a political film that looks from the edges of society. The exegesis seeks to explain the ideas behind this intention.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">dwelling</field><field name="subject">female gaze</field><field name="subject">male gaze</field><field name="subject">boundaries</field><field name="subject">home</field><field name="subject">community</field><field name="subject">soap opera</field><field name="subject">narrative</field><field name="subject">female narratives</field><field name="subject">representation</field><field name="subject">marginalised</field><field name="subject">protective state</field><field name="subject">incarceration</field><field name="subject">prison</field><field name="subject">short film</field><field name="subject">inner-city</field><field name="subject">share house</field><field name="subject">eviction</field><field name="subject">women &amp; cinematography</field><field name="subject">Brisbane</field><field name="identifier">http://eprints.qut.edu.au/16313/</field><field name="validLink">True</field></doc><doc><field name="title">High performance HR systems as drivers of star performance : exploring the intervening mechanisms of work context and perceptions of justice</field><field name="creator">Bish, Adelle Jayne</field><field name="description">Attracting and engaging talented people, the 'star performers', is an on-going  challenge for organisations. Our theoretical understanding of the nature of star  performance and the way in which HR systems facilitate such performance is  limited. Drawing from theories of human resource management, leadership,  performance, job characteristics and organisational justice, this research develops  and tests a model of the role of High Performance HR systems in facilitating task and  contextual performance. This model proposes that the way in which organisational  systems influence individual levels of performance is via two intervening  mechanisms - perceptions of work processes and organisational justice.    The program of research is comprised of two studies. In Study 1, I explored the  utility of the task and contextual performance framework for understanding stars  using supervisor-employee dyads (N = 174) from a large Australian government  agency. The results of this study provide support for the central hypothesis of this  thesis. Task and contextual performance are key components of star ratings, and  other elements such as being self-directed, having a big picture viewpoint, and a  willingness to lead, also contribute.    In Study 2, I employed two well-established frameworks of employee responses  to situational factors and psychological perceptions to examine the role of HR  systems and practices in facilitating star performance. Specifically, the study used  substitutes for leadership theory (Kerr &amp; Jermier, 1978) and the formation of  psychological contracts (Robinson, Kraatz &amp; Rousseau, 1994) to examine the way in  which HR practices are connected with task and contextual performance.    It was proposed that HR practices are positively associated with task and  contextual performance, and that this relationship is moderated by job characteristics  and teamwork. It was also proposed that the relationship between HR practices and  performance is mediated by perceptions of justice. The results of this study indicate  that complex relationships exist. Specifically the findings provide support for one of  the core propositions. Job characteristics and teamwork can moderate the  relationship between HR practices and performance. The patterns of moderation  indicate that HR practices provide marginal gains where jobs are perceived by  employees as being enriched, but are able to make a more substantial contribution  under conditions of less enrichment. Under these conditions HR practices are able to  make a greater contribution to performance by providing performance cues and  establishing expectations and clarifying roles. The relationship between HR  practices and performance was not found to be mediated by perceptions of justice.    In this thesis I provide evidence of the relevance of the task and contextual  performance framework to conceptualising star performance. Furthermore, I  examine the conditions under which High Performance HR systems facilitate star  performance. Both of these aspects are necessary for designing appropriate HR  strategies and interventions for managing talent.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">human resources</field><field name="subject">employees</field><field name="subject">supervisors</field><field name="subject">teamwork</field><field name="subject">performance</field><field name="identifier">http://eprints.qut.edu.au/16314/</field><field name="validLink">True</field></doc><doc><field name="title">Ethical behaviours in e-commerce based construction procurement process</field><field name="creator">Li, Vera</field><field name="description">Electronic commerce is increasingly applied in commercial fields, no exception to construction procurement process. But coming with it, also creates many problems, many of them remain as hot issues for both researchers and stakeholders in industries and have not been solved, though enormous efforts have been offered from different parties involved, among which, ethics in e-commerce enabled construction procurement process stays on top of all. This thesis investigates ethical issues related to the e-commerce application in the construction industry.    Research methods used in this study include a thorough literature review, a questionnaire survey, interviews and a case study. These studies were conducted in August 2004. The samples studied in my thesis included a group of 30 experienced construction professionals who were attending a MBA distance learning programme offered by The Hong Kong Polytechnic University in Beijing.    Through these studies, various construction ethical issues such as computer ethics and corruption in the e-commerce enabled construction procurement process are thoroughly discussed and patterns of ethical behaviors were identified. Specifically, through the questionnaire and interviews, it was identified that the majority of the respondents (70%) agreed that ethical atmosphere is almost nonexistent in the China construction industry.  The majority (78%) also agreed that there was only a little ethical awareness. However, the majority of respondents (51%) believed that there is a positive relationship between ethical behavior and long-term profitability of the company. On the other hand, the respondents' views were divided when judging the relationship between ethical behaviour and short-term profitability as 40% believed the relationship between ethical behaviour and short-term profitability of the company was uncritical, while 43% believed there was a strong relationship between them. The majority of respondents (63%) also confirmed that ethics was never discussed with companies. When asked on the difficulties encountered in developing a strong ethical awareness in the company, respondents cited various reasons including the lack of support from senior management; prevailing trend in the industry, negative impact on long-term and short-term profitability. The majority of respondents (90%) also chose "keep silent" when asked if they spotted unethical behaviors. Finally, the majority of respondents (90%) believed that unethical behaviors increase the cost of procurement by at least 10%.    The interviews and case study reinforced the findings and revealed reasons for the ethical behaviors in China construction industry. Based on these findings, this study has proposed several remedial measures in order to prevent unethical behaviors. In addition, scope for further research is also identified.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">ethical behaviours</field><field name="subject">construction procurment</field><field name="subject">e-commerce</field><field name="subject">questionnaire survey</field><field name="identifier">http://eprints.qut.edu.au/16315/</field><field name="validLink">True</field></doc><doc><field name="title">Multilevel organisational structure in the management of fleet safety</field><field name="creator">Newnam, Sharon</field><field name="description">This thesis presents a program of research exploring the multilevel organisational structure of fleet safety management. The aim of this research was to investigate three current fleet safety initiatives, and individual and contextual factors influencing safe driving behaviour in a work vehicle. Three studies were conducted to achieve this aim. This research utilised a sample of employees from a range of Queensland Government agencies.----- 
 
 Study one evaluated three current fleet safety initiatives within the Queensland Government. From a sample of fleet co-ordinators (N=24) and drivers (N=88), this study established the extent to which specific psychological processes underlying the fleet safety initiatives were adopted, and the attitude change associated with their use. This study found mixed support for the Hypotheses, with the influence of the fleet safety initiatives on fleet co-ordinators' and drivers' attitude change being consistent with processes associated with the persuasive communication framework, and behaviour management. However, the study found no support for the behavioural management processes hypothesised to underlie the incentive scheme (CPP). The findings of the study suggested that while fleet safety initiatives can have an influence on fleet co-ordinator and driver attitude change, their impact depends on the extent to which safety issues are viewed as relevant, and the extent to which there is reinforcement within the organisational environment to support these safety initiatives. Therefore, the findings from this study, combined with existing research into the impact of safety climate, suggest the workplace context needs to be taken into account. For this reason, study two investigated the role of perceptions of the safety climate, in addition to individual attributes, as predictors of self-reported crash involvement.----- 
 
 
 
 Study two applied a framework incorporating driver attributes, including attitudes towards traffic safety and self-efficacy, and drivers' perceptions of the safety climate, as predictors of self-reported crashes in a work vehicle. Within this framework, drivers' perception of the safety climate, and their individual attributes were conceptualised as antecedents of driving performance, and driver safety motivation and knowledge mediated the relationship between these factors and self-reported crashes. A total of 385 drivers participated in this study, which found motivation to drive safely mediated the relationship between driver attributes and self-reported crashes. The initial analysis did not find a significant relationship between safety climate and safety motivation. However, posthoc analyses exploring this non-significant relationship found managerial safety values could be distinguished from other facets of the safety climate construct. Subsequently, the results indicated managerial safety values predicted safety motivation, when drivers perceived a strong safety climate. This study provided a more thorough understanding of the variables predicting driver behaviour at an individual level of analysis. However, a shortcoming is the study did not consider the various influences impacting on drivers' safety perceptions, and individual attributes within the context of the work environment.----- 
 
 Study three extended on the framework established in study two, and investigated the contribution of leader attributes to the prediction of drivers' safety perceptions, and individual attributes. The leader attribute measures, specifically, perceptions of the safety climate, motivation, knowledge, and work overload were collected from a sample of fleet co-ordinators (N=52) and supervisors (N=88). Through multi-level analyses, both supervisors and fleet co-ordinators were shown to influence the safety perceptions and individual attributes of individuals who drive work vehicles. Support was found for positive relationships between supervisor safety knowledge, and the individual attributes. However, there was a large amount of variation due to group membership unaccounted for by supervisor safety knowledge and the safety performance factors investigated within the supervisor groups. These findings suggested supervisors may not be interacting with drivers in relation to fleet safety matters, but that other factors associated with work group membership are having an impact on drivers' safety perceptions.  In comparison, there was a small amount of variation accounted for by fleet co-ordinator group membership. However, the results suggested the fleet co-ordinator leader attributes accounted for a high percentage of this variation in group membership. Support was found for a positive relationship between fleet co-ordinator safety perceptions, and driver safety perceptions. Other results found fleet co-ordinators were engaging in higher workloads to enhance the safety perceptions, and attitudes towards traffic safety of drivers within their groups.----- 
 
 Overall, these studies establish a multilevel organisational process of effect, whereby individual and leader attributes, and organisational initiatives all play a role in influencing the safety performance of work-related drivers. The results also indicated an unclear structure in the management of fleet safety, as perceived by drivers, and through the roles and responsibilities of supervisors and fleet co-ordinators. The implications of these results for the management of fleet safety are discussed.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">fleet safety</field><field name="subject">work-related driving</field><field name="subject">fleet safety initiatives</field><field name="subject">safety climate</field><field name="subject">attitudes</field><field name="subject">self-efficacy</field><field name="subject">work overload</field><field name="subject">multilevel analysis</field><field name="subject">structural equation modeling</field><field name="identifier">http://eprints.qut.edu.au/16316/</field><field name="validLink">True</field></doc><doc><field name="title">Purple poppies in/and fields of green: young lesbians speak out</field><field name="creator">Burnett, Lynn Patricia</field><field name="description">Non-heterosexually identified young people, particularly those with a lesbian identity, have always experienced a marginalised position within Australian culture (Burnett, 1997; Gamson, 2000; Signorile, 1995; Thonneman, 1999). There is very little empirical research available which explores the experiences of lesbian, gay, bisexual and transgender lives (Brown, 1995; Burnett, 1997; Gamson, 2000). Hence myths, stereotypes, invisibility, lack of understanding and marginalisation of non-heterosexual identified people continue to be perpetuated in mainstream Australian society (Baird, 2005; Burnett, 1997; MacBride-Steward, 2004).    The anthropological study presented in this dissertation was designed to explore and theorise the lived experiences of young lesbians post-initial coming-out within an Australian context using Memory Work methodology (Haug, 1987). The first goal of this project was to describe and provide details of the under researched and misunderstood lives of young lesbians between the ages of 23 and 33 years of age who had identified as lesbian for between two and ten years; what is termed here as post-initial coming-out.    The second goal of the study was to gain insight into how young lesbians, post-initial coming-out, make sense of their lives, selves and identities, and positioning within society given the negative myths and stereotypes which currently exist within the general population in relation to people with non-heterosexual identities. The literature and data presented throughout the dissertation highlight the issues of invisibility, marginalisation, and homophobia experienced by each of the participants within a predominately heterosexual society. They also emphasised the inner strength and resilience developed by each of the participants in the face of adversity as they attempted to construct and make sense of their self narrative and positioning as defined by themselves and the positioning and identity imposed upon them by significant others. The data have been organised into four main focus areas; negotiating the family, work, heterosexual and lesbian landscapes.    Lastly, the study sought to further develop and refine the Memory Work methodology (Haug, 1987), particularly as it pertains to a doctoral research program. This study has been able, via the use of Memory Work methodology, to provide richly descriptive and in-depth snap-shots of the lives of young lesbians post-initial coming-out in an Australian context which represents a unique contribution to the research literature. The study concludes with reflections on the methodology as it pertains to a doctoral research program and recommendations for further research which have developed as a result of this investigation.    The five participants in this study were strong, independent, brave young wimmin searching for acceptance and an understanding of their post-initial coming-out lesbian identities in an Australian context. While there were only a small number of participants, their memories and experiences yield rich new insights into the everyday lives and experiences of young lesbians.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">lesbian</field><field name="subject">post-initial coming-out</field><field name="subject">memory work</field><field name="subject">identity</field><field name="subject">Australian lesbian communities</field><field name="identifier">http://eprints.qut.edu.au/16317/</field><field name="validLink">True</field></doc><doc><field name="title">Influence of damping systems on building structures subject to seismic effects</field><field name="creator">Marko, Julius</field><field name="description">In order to control the vibration response of high rise buildings during seismic events, energy absorbing passive damping devices are most commonly used for energy absorption. Today there are a number of types of manufactured dampers available in the market, which use a variety of materials and designs to obtain various levels of stiffness and damping. Some of these include friction, yielding, viscoelastic and viscous dampers. These dampers are usually installed between two load bearing elements (walls or columns) in new buildings. In existing buildings, which require retrofitting, they could be installed in cut-outs of shear walls, as evidenced from recent investigations. An effective damping system can result in higher levels of safety and comfort, and can also lead to considerable savings in the total cost of a building.  This thesis treats seismic mitigation of multistorey buildings using embedded dampers. Three types of damping mechanisms, viz, friction, viscoelastic, and combined friction-viscoelastic were investigated. Finite element methods were employed in the analysis using the program ABAQUS version 6.3. A direct integration dynamic analysis was carried out to obtain the damped and undamped responses of the structure in terms of deflections and accelerations at all storeys in order to evaluate the effectiveness of the damping system in mitigating the seismic response. The damping mechanisms have been modelled as (i) a linear spring and dash-pot in parallel for the viscoelastic damper, (ii) a contact pair with friction parameter for a friction damper and (iii) a hybrid damper consisting of both a viscoelastic and a friction damper. The earthquake events used in this study have been applied as acceleration time-histories at the base of the structure in the horizontal plane. Concrete material properties were chosen to represent the model as many high-rise buildings are constructed by using reinforced concrete.  Several medium and high-rise building structures with embedded dampers in different configurations and placed in various locations throughout the structure were subjected to different earthquake loadings. Influence of damper type and properties, configuration and location were investigated. Results for the reduction in tip deflection and acceleration for a number of cases demonstrate the feasibility of the technique for seismic mitigation of these structures for a range of excitations, even when the dominant seismic frequencies match the natural frequency of the structure. Results also provide information which can be used for optimal damper placement for seismic mitigation.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">seismic response</field><field name="subject">friction damper</field><field name="subject">viscoelastic damper</field><field name="subject">damping</field><field name="subject">configuration</field><field name="identifier">http://eprints.qut.edu.au/16318/</field><field name="validLink">True</field></doc><doc><field name="title">A coordination-based framework for reconfigurable mobile applications</field><field name="creator">Fjellheim, Tore</field><field name="description">Mobile applications are deployed in highly dynamic environments. Devices have limited resources available and the user context changes frequently. This introduces new requirements for applications, and requires that applications are able to adapt during runtime. In addition, developers must be able to incrementally add new behaviour to applications as required by unanticipated situations. Current approaches to mobile application development and architectures do not properly address these requirements of mobile applications. This work proposes a framework, based on coordination principles, which is able to facilitate the required methods of adaptation. The framework incorporates a methodology and an architecture. The architecture provides significant advantages over previous work in terms of adaptation support. The methodology provides developers with a development process and guidelines whereby adaptive applications may be specified. As new requirements of existing applications emerge, developers can build and deploy additions to applications during runtime. The research has been evaluated through the design of application prototypes. These were built through the use of an implemented toolkit for application development, which is based on the specified methodology. The architecture, methodology and toolkit provide a unifying framework for mobile applications. The work presented in this thesis closes a gap in existing knowledge in the design and execution of distributed mobile applications.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">mobile computing</field><field name="subject">mobile architectures</field><field name="subject">context awareness</field><field name="subject">coordination</field><field name="subject">tuple spaces</field><field name="subject">object spaces</field><field name="subject">software development methodology</field><field name="identifier">http://eprints.qut.edu.au/16319/</field><field name="validLink">True</field></doc><doc><field name="title">A programming model and performance model for cycle stealing</field><field name="creator">Sumitomo, Jiro</field><field name="description">This work describes a programming model and performance model for cycle stealing on the Internet.    Cycle stealing is the use of otherwise idle computers to perform work, and promises high performance computing at relatively low cost. The Internet, being the largest pool of potentially idle computers, is an obvious target for cycle stealing. However, computers connected to the Internet are often protected by firewalls, preventing point-to-point communication between them. The fluctuating avail-ability of computers for cycle stealing as they move in and out of an idle state, combined with the restricted communication of the Internet environment, means that programming models and abstractions suitable for programming supercom-puters and clusters are not ideal. Therefore, I have created a programming model for cycle stealing which reflects the types of parallel applications that are suitable for execution using idle computers connected to the Internet. The model is de-signed for use by non-expert parallel programmers, and I will show how it simpli-fies the development of cycle stealing applications, enabling rapid application de-velopment, and straightforward porting of existing sequential applications. This simple to use programming model, combined with the low cost of cycle stealing, improves the accessibility of high performance computing to non-traditional us-ers of supercomputers and clusters. Deployment on the Internet, and the need to navigate through firewalls, suggests a web based framework using common web protocols, web servers and web browsers. Part of this work investigates the feasibility of web based approaches to cycle stealing, from the setup of a cycle stealing system, application development and deployment, and connection of potentially idle computers. I designed and implemented a cycle stealing framework, deployable on the web, to meet expec-tations of performance, reliability, ease of use and safety. Existing cycle stealing frameworks emphasise the need for applications to be de-composed into a set of jobs that execute for a long period, that is, a job should have a computation time sufficient to justify its communication cost. However, there are no tools available for users to determine what an appropriate computa-tion time might be, given a job's data communication requirements. To date, de-ciding the granularity of jobs has been a matter of intuition. Therefore, a user may experience uncertainty as to the benefit of cycle stealing for their particular application, especially if the applications will have relatively short-lived jobs. Based on performance analysis of my framework, I have developed an analytical model and simulator, which can be used to predict, and help to optimise, the per-formance of user applications, and show the feasibility of executing a particular application using the cycle stealing framework.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">cycle stealing</field><field name="subject">cycle scavenging</field><field name="subject">volunteer computing</field><field name="subject">programming model</field><field name="subject">performance model</field><field name="subject">performance analysis</field><field name="subject">simulation</field><field name="subject">distributed computing</field><field name="identifier">http://eprints.qut.edu.au/16320/</field><field name="validLink">True</field></doc><doc><field name="title">Resonances of difference : creative diplomacy in the multidimensional and transcultural aesthetics of an indigenous photomedia practice</field><field name="creator">King-Smith, Leah</field><field name="description">Multidimensional aesthetics in photomedia practice shift the emphasis away from the culturally dominating singularity of the camera's eye-piece towards a supple interplay of semi-transparent image planes and shifting positions. Using various image-capture devices that can produce digital, film, still or moving pictures, I create bodies of work that invite the viewer to see many perspectives simultaneously. The challenge is to implement the effectiveness of the technologies and simultaneously dislodge those principles and values fundamental to their imperialist cultural backgrounds. My practice investigates a diplomatic negotiability of aesthetic language to accommodate conceptual and cultural difference/s.  Located on the print surface or in animated sequences are symbolic representations that disclose histories, cultures, times and places in subtle and ambiguous ways. The interplay of allure and resistance, repetition and change, are strategies that reveal the delicate and paradoxical nature of the multidimensional psyche.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">multiverse</field><field name="subject">multidimensional aesthetics</field><field name="subject">transcultural aesthetics</field><field name="subject">multidimensional psyche</field><field name="subject">indigenous photomedia</field><field name="subject">creative diplomacy</field><field name="subject">transpersonal</field><field name="subject">quantum model</field><field name="subject">practice-led research</field><field name="subject">digital media</field><field name="subject">photography</field><field name="subject">animation</field><field name="identifier">http://eprints.qut.edu.au/16321/</field><field name="validLink">True</field></doc><doc><field name="title">An analysis of parental engagement in contemporary Queensland schooling</field><field name="creator">Macfarlane, Kym Majella</field><field name="description">This thesis examines an instance of the failure of a parent-led bid for a new local school in Queensland at the end of the last millennium. This parent-led and school-endorsed initiative failed despite a policy climate that appeared actively to encourage such initiatives from government funded school communities. The work shows that the parents of Sunnyvale College, (a pseudonym), were both encouraged by the policy environment and discouraged by the response given to their new schooling initiative, from being full educational partners in the process of the schooling of their children. The unanticipated failure is investigated as a case study of parent engagement set against a background of relationships between government and particular educational stakeholders in that time and place. It examines how these relationships are played out in this context and what the implications of this are for contemporary relationships of this type.  Because the approach to the case study is not based on any assumption that the " failure" was the outcome of a pernicious state, the investigation acknowledges the discontinuous nature of such educational relationships and thus, refuses notions of linearity and continuity.  The case study approach draws on poststructuralist scholarship, in particular the work of Michel Foucault (1979-84), who is the key theorist informing the investigation. Foucault's theories relating to truth, power and governmentality, are of particular interest and are used as a basis for argument and analysis.    The case study is conducted in three key parts. First, the study brings together an overarching framework of interpretive and theoretical bricolage, which works to allow multiple theoretical perspectives and understandings to inform the process of investigation. Second, there is an acknowledgement of the importance of history and also, of historical contingency, in the production of events such as this failure. Thus, there is an historical account of the establishment of schools in Queensland, particularly in the 1990s, and an exploration of the differences in the establishment process across this decade. This exploration is undertaken by working backwards through relevant archival documents and other data in order to highlight the discontinuous nature of such processes. This means that parent/school relationships are historicised, using a macro and micro analysis to understand how such relationships have been produced over time. The case in question is situated within this historicising, allowing for an exploration of its nature and setting, its historical background, the roles of particular individuals, and the processes and procedures that were important in the development of the case. The third part of the study involves re-theorising parent/school relationships in contemporary contexts.  The main argument of the case study is that there was a shift in the discursive constitution of schooling that was taking place at the very time that the initiative was undertaken in 1997. It is argued that the school community in question was working out of a set of assumptions about school partnerships, which had already been substantially reinscribed by a new discursive system. This new system reframed " choice" and " community" in terms of the " performative" rather than the " democratic" school.    The main arguments and findings in the case study are then used to re-theorise parent/school relationships in post-millennial Queensland, particularly in relation to policy reform. This re-theorising is conducted in the form of a discourse analysis of current federal and state government policy and other types of data, which are relevant to schooling in contemporary contexts. Various interpretive and theoretical perspectives are used in this process of re-theorising, including notions of performativity (Ball, 2003a, 2003b, 2004), responsibilisation (Rose, 1990, 1999, 2000) and pedagogicalisation (Popkewitz, 2003). Such notions are employed to build on the lines of inquiry that develop as a consequence of the use of Foucauldian theory in the earlier part of the study. These concepts are also used to develop new epistemological understanding of parent/school relationships in contemporary contexts. The work of Pierre Bourdieu (1984, 2001) further assists in the conceptualisation of parent engagement in schooling as a game played on the field of schooling.    As a consequence of this re-theorising, it is argued that parent engagement in schooling is a focus of increased attention on the part of educational stakeholders and is increasingly demanded by way of increased levels of responsibilised participation. This trend raises questions about the levels of fatigue and anxiety that could result for parents as a consequence of such demanding levels of performance. Additionally, an argument is presented that " performative" parenting is a prescribed set of activities, not an open invitation to leadership and high-level decision-making. Thus, as previously mentioned, choice is always already framed, as " proper" parents make " informed" choices with regard to their children's schooling. This thesis concludes that " performative" schools offer new and problematic subject positions for " performative" parents, which are inviting more engagement but constraining the type of partnership that is possible between parents and schools.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">case study</field><field name="subject">genealogy</field><field name="subject">bricolage</field><field name="subject">discourse</field><field name="subject">truth</field><field name="subject">power</field><field name="subject">governmentality</field><field name="subject">discourse analysis</field><field name="subject">performativity</field><field name="subject">propriety</field><field name="subject">pedagogicalisation</field><field name="subject">responsibilisation</field><field name="subject">Foucault</field><field name="subject">Foucauldian theory</field><field name="subject">poststructuralism</field><field name="subject">Bourdieu</field><field name="subject">habitus</field><field name="subject">capital</field><field name="subject">field</field><field name="subject">game</field><field name="identifier">http://eprints.qut.edu.au/16322/</field><field name="validLink">True</field></doc><doc><field name="title">Journeys and border crossings : emerging issues facing the expatriate teacher : an " Ang Moh" art teacher in Singapore</field><field name="creator">Vial, David G.</field><field name="description">This qualitative research study analyses the causal conditions of educational, cultural and ideological issues that emerged as a result of Expatriate teaching experiences in secondary schools in Singapore. The study also examines how the foreign educational environment affects the performance of the Expatriate Teacher (ExT). Specifically, the results provide insight into how Expatriate Teachers (ExTs) conceive of notions of work, teaching and learning and how they come to terms with, and adjust to employment within a foreign teaching environment.    Seven teacher-participants were selected on the basis of their individual experiences as an ExT or experiences working alongside ExTs. Semi-structured interviews were conducted in the UK, Singapore and Australia to explore teacher-participants' teaching conceptions and experiences. Two Pilot interviews were conducted prior to the Interview Schedules being made available to the participants. One pilot interview was subsequently included in the analysis. Aspects of Grounded Theory methodology, in particular the Constant Comparison method, were utilised to categorise and analyse data. Analysis of the data was also facilitated using the computer software programme NUD*IST 6.    The findings identified three related and interwoven themes which categorised the issues as experienced by the seven teacher-participants. One is the Conditional Variables of the physical, structural and organizational setting. The second is the resident Proficiencies and Attributes of the ExT, which includes ideologies, values and expectations. The third includes Configurations of Culture such as work culture, subject culture and cultural adaptations. The study outlines how Incongruity and Dissonance can operate within and between these three themes and indicates implications for improving the experiences of ExTs and other stakeholders.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">expatriate teaching</field><field name="subject">expatriate teacher</field><field name="subject">secondary schools</field><field name="subject">Singapore</field><field name="identifier">http://eprints.qut.edu.au/16323/</field><field name="validLink">True</field></doc><doc><field name="title">Semantics, verification, and implementation of workflows with cancellation regions and OR-joins</field><field name="creator">Wynn, Moe Thandar</field><field name="description">Workflow systems aim to provide automated support for the conduct of certain business processes. Workflow systems are driven by workflow specifications which among others, capture the execution interdependencies between various activities. These interdependencies are modelled by means of different control flow constructors, e.g., sequence, choice, parallelism and synchronisation. It has been shown in the research on workflow patterns that the support for and the interpretation of various control flow constructs varies substantially across workflow systems. Two of the most problematic patterns relate to the OR-join and to cancellation.    An OR-join is used in situations when we need to model " wait and see" behaviour for synchronisation. Different approaches assign a different (often only intuitive) semantics to this type of join, though they do share the common theme that synchronisation is only to be performed for active paths. Depending on context assumptions this behaviour may be relatively easy to deal with, though in general its semantics is complicated, both from a definition point of view (in terms of formally capturing a desired intuitive semantics) and from a computational point of view (how does one determine whether an OR-join is enabled?). Many systems and languages struggle with the semantics and implementation of the OR-join because its non-local semantics require a synchronisation depending on an analysis of future execution paths. This may require some non-trivial reasoning. The presence of cancellation features and other OR-joins in a workflow further complicates the formal semantics of the OR-join. The cancellation feature is commonly used to model external events that can change the behaviour of a running workflow. It can be used to either disable activities in certain parts of a workflow or to stop currently running activities. Even though it is possible to cancel activities in workflow systems using some sort of abort function, many workflow systems do not provide direct support for this feature in the workflow language. Sometimes, cancellation affects only a selected part of a workflow and other activities can continue after performing a cancellation action. As cancellation occurs naturally in business scenarios, comprehensive support in a workflow language is desirable. We take on the challenge of providing formal semantics, verification techniques as well as an implementation for workflows with those features.    This thesis addresses three interrelated issues for workflows with cancellation regions and OR-joins. The concept of the OR-join is examined in detail in the context of the workflow language YAWL, a powerful workflow language designed to support a collection of workflow patterns and inspired by Petri nets. The OR-join semantics has been redesigned to represent a general, formal, and decidable approach for workflows in the presence of cancellation regions and other OR-joins. This approach exploits a link that is proposed between YAWL and reset nets, a variant of Petri nets with a special type of arc that can remove all tokens from a place. Next, we explore verification techniques for workflows with cancellation regions and OR-joins. Four structural properties have been identified and a verification approach that exploits coverability and reachability notions from reset nets has been proposed. The work on verification techniques has highlighted potential problems with calculating state spaces for large workflows. Applying reduction rules before carrying out verification can decrease the size of the problem by cutting down the size of the workflow that needs to be examined while preserving some essential properties. Therefore, we have extended the work on verification by proposing reduction rules for reset nets and for YAWL nets with and without OR-joins. The proposed OR-join semantics as well as the proposed verification approach have been implemented in the YAWL environment.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">workflow management</field><field name="subject">Business process modelling</field><field name="subject">workflow patterns</field><field name="subject">synchronising merge</field><field name="subject">OR-join</field><field name="subject">cancellation</field><field name="subject">petri nets</field><field name="subject">reset nets</field><field name="subject">verification</field><field name="subject">formal semantics</field><field name="subject">reduction rules</field><field name="subject">yet another workflow language (YAWL)</field><field name="identifier">http://eprints.qut.edu.au/16324/</field><field name="validLink">True</field></doc><doc><field name="title">An empirical study of implied volatility in Australian index option markets</field><field name="creator">Yang, Qianqian</field><field name="description">With the rapid development of option markets throughout the world, option pricing has become an important field in financial engineering. Among a variety of option pricing models, volatility of underlying asset is associated with risk and uncertainty, and hence is treated as one of the key factors affecting the price of an option. In particular, in the framework of the Black-Scholes option pricing model, volatility of the underlying stock is the only unobservable variable, and has attracted a large amount of attention of both academics and practitioners. This thesis is concerned with the implied volatility in the Australian index option market. Two interesting problems are examined.    First, the relation between implied volatility and subsequently realized volatility is investigated by using the S&amp;P/ASX 200 (XJO) index options over a five-year period from April 2001 to March 2006. Unlike the S&amp;P 100 index options in the US market, the XJO index options are traded infrequently, in low volumes, and with a long maturity cycle. This implies that the errors-in-variable problem for the measurement of implied volatility is more likely to exist. After accounting for this problem by the instrumental variable method, it is found that both call and put options implied volatilities are nearly unbiased and superior to historical volatility in forecasting future realized volatility.    Second, the volatility structure implied by the XJO index options is examined during the period from April 2001 to June 2005. The volatility structure with respect to moneyness and time to maturity are investigated for both call and put option price series. It is found that the volatility smile largely exists, with call (put) option implied volatilities decreasing monotonically as the call (put) goes deeper out of the money (in the money). This result is consistent with the welldocumented evidence of volatility smile on other index options since the stock market crash of 1987.    In summary, this thesis presents some important findings on the volatility inferred from the XJO index options traded on the ASX.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">option markets</field><field name="subject">option pricing</field><field name="subject">volatility</field><field name="identifier">http://eprints.qut.edu.au/16325/</field><field name="validLink">True</field></doc><doc><field name="title">An evaluation of the capital gains tax concessions for small business</field><field name="creator">Marriage, Wayne Wilson</field><field name="description">The small business Capital Gains Tax (CGT) concessions were introduced by the Federal Treasurer on 21 September 1999. The provisions are based on the landmark Review of Business Taxation.  The Federal Government's intention was to remove impediments to efficient asset management, improve capital mobility, reduce complexity and compliance costs and generally, make Australia's CGT regime internationally competitive.    Division 152 contains four separate small business concessions. In order to qualify for the four CGT concessions, the small business must satisfy stringent tests (basic conditions). It is possible that the small business will receive significant concessional treatment if these basic conditions are satisfied.    Commentary by academics and tax practitioners indicate that the small business CGT concessions are excessively complex. There is concern that the provisions are not achieving their desired outcomes. This thesis involves a critical evaluation of Division 152 against the traditional criteria for a good tax system, using a legal research methodology designed by Wade.  Within Wade's framework, the research includes a comparative analysis of the Australian and United Kingdom legislative provisions for small business CGT concessions. This comparison is undertaken with a view to highlighting strengths and weaknesses in the respective legislation to better meet the goals of equity, efficiency and simplicity. The culmination of this thesis will be the proposal of policy recommendations to Subdivision 152-A.    This thesis states the law available as at 30 April 2006. In the light of this, an appendix is inserted to cover changes since this date.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">capital gains tax</field><field name="subject">small business</field><field name="subject">taxation</field><field name="subject">tax system</field><field name="identifier">http://eprints.qut.edu.au/16326/</field><field name="validLink">True</field></doc><doc><field name="title">Antecedents of commitment to an import supplier</field><field name="creator">Saleh, Md. Abu</field><field name="description">The concept of commitment has emerged recently in international business literature especially in explaining importer behaviour as a counterpart of the process of internationalisation. Importer commitment often plays a dominant role as one of the major factors influencing relationships in the exporter-importer dyad and facilitates the process of internationalisation by imparting access to the international market. This critical importer and supplier relationship and its animating factors are, however, overlooked and largely neglected in the literature. Accordingly, it is inconclusive as to which factors influence importer commitment and how they influence it. Drawing on the literature, this study strived to investigate the spectrum of importer commitment and has explicitly examined eight factors influencing importer commitment to a foreign supplier by integrating the factors in a comprehensive model. Cultural similarity between importer and overseas supplier, knowledge and experience of the importer, the supplier's competencies, communication between importer and supplier, the supplier's opportunism, the importer's trust, importer transaction-specific investment, and environmental volatility of the import market have been identified as possible antecedents of importer commitment. Theoretical foundations are drawn basically from transaction cost economics, internationalisation process theory and resource-based theory of the firm to design a basic framework for quantitative investigation. Further, the study endeavors to gain important insights into the phenomena related to the trust and commitment building process through qualitative in-depth interviews. In addition, to validate the qualitative reasoning, a competing quantitative model is developed where trust plays a mediating role for some of the predictor variables in the model.    Primary data were collected from a sample of 232 industrial and commercial importers in a developing country for empirical verification of the quantitative models using Structural Equation Modeling. As reported in this thesis, the proposed model with minor modifications fit better with the data compared to the competing model, and it explained 56% of the variance of importer commitment. However, the analysis of the modified proposed structural model revealed that ten out of fourteen hypotheses are significant including five direct paths as antecedents of importer commitment. The mediating role of trust and opportunism in the model is also supported.    Twelve interviews were conducted to add in-depth richer insights into the study for further verification of the knowledge development, and trust and commitment building process in the importer-supplier relationship. The findings support most conceptual links in the qualitative model and lend support to most of the hypothesised relationships in the modified competing quantitative model. These findings extend the application of the underpinned theories and their tenets in explaining the importersupplier commitment relationship and contribute to the body of knowledge. Implications of the findings are discussed and future research directions are recommended.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">antecedents of commitment</field><field name="subject">importer's commitment</field><field name="subject">importer supplier relationship</field><field name="subject">mediating role of trust</field><field name="subject">cultural similarity</field><field name="subject">communication</field><field name="subject">knowledge and experience</field><field name="subject">supplier's opportunism</field><field name="subject">environmental volatility</field><field name="subject">transaction-specific investment</field><field name="subject">supplier's competencies</field><field name="identifier">http://eprints.qut.edu.au/16327/</field><field name="validLink">True</field></doc><doc><field name="title">Studies of electronic and structural properties of molecular clusters of prebiotic importance</field><field name="creator">Aylward, Nigel Nunn</field><field name="description">This thesis  applies the ab initio techniques of  computational chemistry to studies of  molecular clusters containing covalent (strong) or van der Waals (weak) bonds formed in chemistry and biochemistry in the temperature range 10-300 K. Van derWaals complexes with an enthalpy of  formation from reactants of less than 25 kJ mol-1 and covalent clusters are described in this thesis.    The first group of van der Waals complexes involved the molecule carbon monoxide that possesses a small permanent dipole that could lead to dipole - induced dipole interaction and dipole - dipole interaction with another reactant in addition to dispersion.  The substrates investigated were methanimine and cyanogen where  endergonic unstable molecules were formed, and the clustering of carbon monoxideon a porphin surface leading to the formation of carbon - carbon fragments. TheFaraday effect was invoked to suggest that this was the original method by which thechirality of the D-sugars was selected.  Coordination of  imino-compounds on thesame surface involving induction and electrostatic interactions could lead to the preferential formation of L-aziridones, hydrolysable to L-amino-acids.The preferred formation of  D-ribose, and the more stable D-2-deoxyribose, andnucleotides polymerisable to deoxyribonucleic acids was described.    The second group of van der Waals complexes involved the polymerisation of acetylene molecules, to di- and tri-acetylene complexes where the exchange interaction involved the quadrupole moment of the acetylene radical reacting with acetylene or diacetylene.  The reaction of carbon monoxide was extended to include its interaction with diacetylene.  The entire potential energy surface for the interaction with diacetylene was investigated. The reaction was shown to be endergonic to produce a reactive species, here postulated to rearrange with a reasonable activation energy toform an aldehyde.  The energetics of the formation of diacetylene, triacetylene andhigher polymers was briefly investigated.  The reactivity of the acetylene polymeraldehydes with other substrates was briefly investigated.    This work has apparently laid a firm basis both, qualitative and quantitative, tounderstand some of the weakest interactions in nature involving the simplest ofreactions that have been important in atmospheric chemistry.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">carbon monoxide</field><field name="subject">azirine-2one</field><field name="subject">aziridine-2one</field><field name="subject">2</field><field name="subject">2&#146;-bi(cycloazirine-3one)</field><field name="subject">nicotinamide</field><field name="subject">flavin</field><field name="subject">folic acid D-ribose</field><field name="subject">D-2deoxyribose</field><field name="subject">L-amino-acids</field><field name="subject">nucleotides</field><field name="subject">deoxyribonucleic acid 2-methylene-2H-pyrrole</field><field name="subject">porphin</field><field name="identifier">http://eprints.qut.edu.au/16328/</field><field name="validLink">True</field></doc><doc><field name="title">The implication of global warming on the energy performance and indoor thermal environment of air-conditioned office buildings in Australia</field><field name="creator">Guan, Li-Shan</field><field name="description">Global warming induced by the emissions of greenhouse gases is one of the most important global environmental issues facing the world today. Using the building simulation techniques, this research investigates the interaction and relationship between global warming and built environment, particularly for the air-conditioned office buildings. The adaptation potential of various building designs is also evaluated. Based on the descriptive statistics method, the Pearson Product Moment Correlation and the regression analysis method, ten years of historical hourly climatic data for Australia are first analyzed. The distribution patterns of key weather parameters between a Test Reference Year (TRY) and multiple years (MYs), and between relatively cold and hot years are also compared. The possible cross-correlation between several different weather variables are then assessed and established. These findings form a useful basis and provide insights for the development of future weather models under "hot" global warming conditions and the explanation of building performance at different locations. Based on a review of the existing weather data generation models and findings from historic climatic data analysis, an effective method to generate approximate future hourly weather data suitable for the study of the impact of global warming is presented. This is achieved by imposing the future temperature projection from the global climate model on top of the historically observed weather data. Depending on the level of information available for the prediction of future weather conditions, this method allows either the method of retaining to current level, constant offset method or diurnal modelling method to be used. Therefore it represents a more comprehensive and holistic approach than previous one that have been used to convert the available weather data and climatic information to a format suitable for building simulation study. An example of the application of this method to the different global warming scenarios in Australia is also presented. The performance of a representative office building is then examined in details under the five weather scenarios (present, 2030 Low, 2030 High, 2070 Low and 2070 High) and over all eight capital cities in Australia. The sample building used for this study is an air conditioned, square shape, ten storey office tower with a basement carpark, which is recommended by the Australian Building Codes Board to represent the typical office building found in the central business district (CBD) of the capital cities or major regional centres in Australia. Through building computer simulations, the increased cooling loads imposed by potential global warming is quantified. The probable indoor temperature increases and overheating problems due to heat load exceeding the capacity of installed air-conditioning systems are also presented. It is shown that in terms of the whole building indoor thermal environment, existing buildings would generally be able to adapt to the increasing warming of the 2030 year Low and High scenarios projections and the 2070 year Low scenario projection. For the 2070 year High scenario, the study indicates that the existing office buildings in all capital cities will suffer from the overheating problem. To improve the building thermal comfort to an acceptable standard (ie, less than 5% of occupied hours having indoor temperature over 25&#176;), a further increase of 4-10% of building cooling load is required. The sensitivity of different office building zoning (i.e. zone at different floors and/or with different window orientation) to the potential global warming is also investigated. It is shown that for most cities, the ground floor, and the South or Core zone would be most sensitive to the external temperature change and has the highest tendency to having the overheating problem. By linking building energy use to CO2 emissions, the possible increase of CO2 emissions due to increased building energy use is also estimated. The adaptation potential of different designs of building physical properties to global warming is then examined and compared. The parametric factors studied include the building insulation levels, window to wall ratio, window glass types, and internal load density. It is found that overall, an office building with a lower insulation level, smaller window to wall ratio and/or a glass type with lower shading coefficient, and lower internal load density will have the effect of lowering building cooling load and total energy use, and therefore have a better potential to adapt to the warming external climate. This phenomenon can be linked to the nature of internal-load dominated office-building  characteristics. Based on these findings, a series of design and adaptation strategies have been proposed and evaluated.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">adaptation strategies</field><field name="subject">climate change</field><field name="subject">global warming</field><field name="subject">buildings</field><field name="subject">building performance</field><field name="subject">energy efficiency</field><field name="subject">indoor comfort</field><field name="subject">sustainable built environment</field><field name="identifier">http://eprints.qut.edu.au/16329/</field><field name="validLink">True</field></doc><doc><field name="title">Mathematical and statistical modelling of infectious diseases in hospitals</field><field name="creator">McBryde, Emma Sue</field><field name="description">Antibiotic resistant pathogens, such as methicillin-resistant Staphylococcus aureus (MRSA), and vancomycin-resistant enterococci (VRE), are an increasing burden on healthcare systems. Hospital acquired infections with these organisms leads to higher morbidity and mortality compared with the sensitive strains of the same species and both VRE and MRSA are on the rise worldwide including in Australian hospitals. Emerging community infectious diseases are also having an impact on hospitals. The Severe Acute Respiratory Syndrome virus (SARS Co-V) was noted for its propensity to spread throughout hospitals, and was contained largely through social distancing interventions including hospital isolation. A detailed understanding of the transmission of these and other emerging pathogens is crucial for their containment. The statistical inference and mathematical models used in this thesis aim to improve understanding of pathogen transmission by estimating the transmission rates of contagions and predicting the impact of interventions. Datasets used for these studies come from the Princess Alexandra Hospital in Brisbane, Australia and Shanxi province, mainland China. Epidemiological data on infection outbreaks are challenging to analyse due to the censored nature of infection transmission events. Most datasets record the time on symptom onset, but the transmission time is not observable. There are many ways of managing censored data, in this study we use Bayesian inference, with transmission times incorporated into the augmented dataset as latent variables. Hospital infection surveillance data is often much less detailed that data collected for epidemiological studies, often consisting of serial incidence or prevalence of patient colonisation with a resistant pathogen without individual patient event histories. Despite the lack of detailed data, transmission characteristics can be inferred from such a dataset using structured HiddenMarkovModels (HMMs). Each new transmission in an epidemic increases the infection pressure on those remaining susceptible, hence infection outbreak data are serially dependent. Statistical methods that assume independence of infection events are misleading and prone to over-estimating the impact of infection control interventions. Structured mathematical models that include transmission pressure are essential. Mathematical models can also give insights into the potential impact of interventions. The complex interaction of different infection control strategies, and their likely impact on transmission can be predicted using mathematical models. This dissertation uses modified or novel mathematical models that are specific to the pathogen and dataset being analysed. The first study estimates MRSA transmission in an Intensive Care Unit, using a structured four compartment model, Bayesian inference and a piecewise hazard methods. The model predicts the impact of interventions, such as changes to staff/patient ratios, ward size and decolonisation. A comparison of results of the stochastic and deterministic model is made and reason for differences given. The second study constructs a Hidden Markov Model to describe longitudinal data on weekly VRE prevalence. Transmission is assumed to be either from patient to patient cross-transmission or sporadic (independent of cross-transmission) and parameters for each mode of acquisition are estimated from the data. The third study develops a new model with a compartment representing an environmental reservoir. Parameters for the model are gathered from literature sources and the implications of the environmental reservoir are explored. The fourth study uses a modified Susceptible-Exposed-Infectious-Removed (SEIR) model to analyse data from a SARS outbreak in Shanxi province, China. Infectivity is determined before and after interventions as well as separately for hospitalised and community symptomatic SARS cases. Model diagnostics including sensitivity analysis, model comparison and bootstrapping are implemented.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Bayesian inference</field><field name="subject">epidemic modelling</field><field name="subject">environmental reservoir</field><field name="subject">hiddenMarkov models</field><field name="subject">infectious diseases</field><field name="subject">mathematical modelling</field><field name="subject">methicillin resistant Staphylococcus aureus (MRSA)</field><field name="subject">severe acute respiratory syndrome (SARS)</field><field name="subject">statistical modelling</field><field name="subject">stochastic processes</field><field name="subject">vancomycin resistant enterococci (VRE)</field><field name="subject">epidemiology</field><field name="subject">public health</field><field name="subject">infectious disease</field><field name="identifier">http://eprints.qut.edu.au/16330/</field><field name="validLink">True</field></doc><doc><field name="title">Child maltreatment in Vietnam : prevalence and associated mental and physical health problems</field><field name="creator">Nguyen, Huong Thanh</field><field name="description">Child maltreatment is not a new issue. It has existed in various forms in every society since the early days in history. However, it is only in the past four decades that abuse and neglect of children has attracted widespread interest among health professionals and the general public. There is now a large body of evidence that identifies four main maltreatment forms: physical, sexual, emotional maltreatment and neglect. Child maltreatment is a substantial public health problem, as it is associated with immediate and long-term health problems.    Most research into child maltreatment has been conducted in English-speaking, developed countries. Although there has been a small but steady increase in the number of studies from less developed countries over the past decade, there remains a relative dearth of research in these populations, especially in Asia. Over the years, most research projects around the world tend to be focused on only one type of child maltreatment (usually either child sexual abuse or child physical maltreatment), and many studies do not examine risk factors in depth, or address the possible outcomes of various forms of maltreatment.    Children have always held a very important place in the culture and traditions in Vietnam. In 1989, Vietnam was the first Asian country and the second country in the world to sign and ratify the United Nations Convention on the Rights of the Child. Since then Vietnam has adopted various measures to promote children's rights and particularly children's rights to be protected from abuse and exploitation. Despite strong political support for the rights of children, there is little formal research into child maltreatment. From the small amount of available evidence and media reports, it appears that children in Vietnam are vulnerable to maltreatment, just as they are all over the world. It is clear that information about the extent and health consequences of different forms of child maltreatment from scientifically sound studies is still far from sufficient. Thus, more research is essential to ensure effective and culturally appropriate responses to protect children from maltreatment.    The primary aim of this research was to examine the nature and co-occurrence of four forms of child maltreatment including sexual, physical, emotional maltreatment and neglect among Vietnamese secondary and high school adolescents in both urban and rural settings, and determine the extent to which such adverse experiences impact on self-reported health risk behaviours and physical and mental health.    A mixed methods design including qualitative interviews and focus group discussions, and a cross-sectional survey was employed in this study. Incorporation of qualitative inquiry added a cultural dimension on child maltreatment and informed to develop appropriate quantitative measures.    Following 8 focus group discussions and 16 in-depth interviews as well as a pilot study of 299 adolescents in Vietnamese schools, a cross-sectional survey of 2,591 adolescents randomly selected from eight secondary and high schools in one urban district and one rural district was undertaken between 2004 and 2005. Data were collected by self-administered questionnaires in class rooms. Key information included demographics, family characteristics and environment, and four scales measuring sexual abuse, emotional and physical maltreatment and neglect as well as standard brief assessments of health related risk behaviours, mental and general physical health.  The study clearly revealed that experiences of different forms and co-occurrence of child maltreatment among school adolescents were prevalent in Vietnam. The prevalence estimates of at least one type of physical and emotional maltreatment, neglect and sexual abuse were 47.5%, 39.5%, 29.3% and 19.7% respectively. A significant proportion of respondents (41.6%) was exposed to more than one form of child maltreatment, of which 14.5% and 6.3% experienced three or four maltreatment forms.    Results from multivariate logistic regression analyses showed that the prevalence of child physical and emotional maltreatment and neglect among adolescents was not statistically different between urban and rural districts. However, children from rural schools were more likely to report unwanted sexual experiences than their counterparts in urban schools. There was no significant gender difference in reports of adverse sexual experiences. In contrast, girls were more likely to report emotional maltreatment and neglect whereas boys were more likely to experience physical maltreatment. Furthermore, family environment assessed by parental quarrelling, fighting, perceived quality of parental relationship and emotional support appeared to be the most consistent factors significantly predicting each form of child maltreatment.    After controlling for a wide range of potential confounding factors, many significant correlates between each type of maltreatment, each level of maltreatment co-occurrence and each health risk behaviour were found. In general, the pattern of correlations between child maltreatment and health risk behaviours was similar for females and males. Emotional maltreatment significantly correlated with most behaviours examined. Physical maltreatment seems more likely to be associated with involvement in physical fights and being threatened. Sexual abuse was significantly related to smoking, drinking, being drunk, and involvement in fighting. Statistically significant associations between neglect and self-harm such as involvement in fighting, feeling sad and hopeless, suicidal thoughts and attempts were found. Clearly, co-occurrence of child maltreatment was significantly associated with almost all examined health risk behaviours and a dose-response relationship was observed in most of the dependent variables.    Regarding continuous measures of mental and physical health, multivariate regression analyses revealed that presence of four types of child maltreatment explained a small but significant proportion of variance (from 5% to 9%), controlling for a wide range of background variables. Additionally, while each form of child maltreatment had independent effects on depression, anxiety problems, low self-esteem and poor physical health emotional maltreatment appeared to be the strongest influence on mental and physical health of both female and male adolescents. Analysis of variance also clearly suggested that exposure to increasing numbers of maltreatment forms significantly increased the risk of mental and physical health problems in a dose-response fashion.    The present study extends a small body of previous research examining poly-victimization in developed nations to an Asian country. The data contribute new knowledge on cross-cultural child maltreatment problems. Considerable commonalities as well as some differences in the findings in Vietnam compared with earlier research were found. One important conclusion concerns the significant independent associations between various types of child maltreatment, as well as the cumulative effects of poly-victimization on a wide range of health risk behaviours, depression, anxiety, self-esteem, and general physical health. This pioneering research in Vietnam provides timely and substantial evidence that can be used to raise public awareness of the nature of child maltreatment and the harmful effects of not only sexual and physical abuse but also other forms of emotional maltreatment and neglect which have not received attention before. These results from a community-based sample have demonstrated the urgent need for prevention programs. The current study provides an impetus for more comprehensive research in this sensitive area in the near future so that culturally and politically relevant evidence-based responses to child maltreatment can be developed in Vietnam.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">child abuse/maltreatment1</field><field name="subject">poly-victimization2</field><field name="subject">child sexual abuse/maltreatment</field><field name="subject">community-based research</field><field name="subject">child physical abuse/maltreatment</field><field name="subject">prevalence</field><field name="subject">child emotional abuse/maltreatment</field><field name="subject">associations</field><field name="subject">child neglect</field><field name="subject">health risk behaviours</field><field name="subject">co-occurrence of child maltreatment</field><field name="subject">mental and physical health</field><field name="subject">multiple-type/form maltreatment</field><field name="subject">cumulative effect</field><field name="identifier">http://eprints.qut.edu.au/16331/</field><field name="validLink">True</field></doc><doc><field name="title">Teacher learning : a process of grafting new truths on to old truths : a case study of teacher learning in an independent school</field><field name="creator">Norton, Patricia Jean</field><field name="description">The intent of this professional doctorate study was to clarify theory and develop knowledge that could benefit the researcher's workplace. It achieved two aims. The first was the useful knowledge gained by the insider-researcher about how to effect teacher learning in a reform context. The second was the improved understanding of the uniqueness of contextual conditions that affected teacher learning in one school. A case study of a single school site was the means of examining the problem of what issues confronted teachers in learning new knowledge mandated by curriculum reform, along with why those issues existed and how teachers dealt with them. A genealogical approach to the literature investigation determined where, why and how teacher learning should be effected in a learning community, in what reflected an "outside in" approach to the problem. However, the intent of the study was that this should be balanced by the "inside out" approach evident in the consideration of what teachers in a school had to say about the realities of teacher learning. Interviews with teachers considered good informants resulted in quality data that facilitated the construction of explanatory theory. A comparison of this theory constructed from data grounded in the realities of teachers' experiences with the theory derived from the literature constituted the final stage of clarifying the problem. Results from the study, therefore, represented both useful knowledge and understanding of the problem. These were of benefit to the specific school, while contributing to the professional efficacy of the researcher-insider, responsible for delivering curriculum reform that was dependent on teacher learning.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">teacher learning</field><field name="subject">beliefs</field><field name="subject">truths</field><field name="subject">quilt of knowledge</field><field name="subject">curriculum reform</field><field name="subject">learning community</field><field name="subject">case study</field><field name="subject">insider-researcher</field><field name="identifier">http://eprints.qut.edu.au/16332/</field><field name="validLink">True</field></doc><doc><field name="title">Screening revolution : constructing a Marxist theoretical framework for social documentary filmmakers analysing class structure and the class struggle</field><field name="creator">Sparkes, Daryl John Trevor</field><field name="description">Social documentary filmmaking cannot be undertaken in a theoretical void, regardless of the intentions of the filmmaker. Each film's textual, stylistic and aesthetic composition is dictated by the ideological intent of the filmmaker, either consciously or subconsciously. As a result, social documentary films are a product of either conservative or subversive filmmakers and can be viewed as cultural products of social control by the dominant capitalist ideology or as tools promoting class awareness, class struggle and revolutionary praxis by those sympathetic to Marxist doctrine.    This dissertation examines how Marxist ideology, in particular theories relating to class structure and the class struggle, can be used by filmmakers to analyse social documentary films. It enables the construction of a methodological 'toolkit' for filmmakers from which they are able to determine if individual social documentary films can be regarded as Marxist or not. This 'toolkit' is comprised of the theories of Lenin, Comolli and Narboni, Brecht, Althusser, and Weber among others.    Once a methodological framework is constructed, it is used to evaluate a number of social documentary case studies including 7-Up, Harlan County USA, Roger and Me, and my own film, A Shit of a Job (which was produced by myself for broadcast on SBS television), as to their adherence to the principles of Marxist aesthetics and allegiance to the proletarian cause of class awareness and the class struggle.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">class struggle</field><field name="subject">class structure</field><field name="subject">Marxism</field><field name="subject">documentary filmmaker</field><field name="subject">capitalism</field><field name="identifier">http://eprints.qut.edu.au/16333/</field><field name="validLink">True</field></doc><doc><field name="title">Early childhood art  education in Hong Kong : a phenomenographic study</field><field name="creator">Wong, Kit Mei</field><field name="description">This study was a phenomenographic inquiry into arts education in early childhood. Through the use of this interpretative approach, the study was an inquiry into the internal relationship between human experience and the world environment, based on the core assumption that there is variation in the ways in which people experience the same phenomenon. Drawing on the work of Pramling and other phenomenographers, the study identified and compared the conceptions of art in young children and their teachers.    Twenty-seven young children, aged 5 to 6, studying in the same class in a Hong Kong preschool participated in this study with their two class teachers. Semi-structured interviews were used and the children were asked to describe art experiences in their preschool learning environment. The two teachers working with this group of children were interviewed separately, for their views on their art teaching practices. Through a process of comparing and contrasting themes emergent in the transcriptions, children's conceptions of their art experiences fell into five categories: (1) Art is Human Nature, (2) Art is a Task, (3) Art is a Process, (4) Art is a Product, and (5) Art is Mystery. Teachers' responses fell into two categories: (1) Art is Human Nature, and (2) Art is a Task. A conclusion of the study was that the conceptions of art in children formed at an early age are broad and complex.    Comparison of the conceptions between the young children and their teachers indicated that there were some similarities but also mismatches. The children had a broader perspective than their teachers and they were sensitive to the teachers' conceptions. The teachers and the children shared the conceptions of art as being part of human nature and art as a task, although their variations differed. In addition, the children demonstrated that they had further conceptions of art -- that it was a social process, and that the product was important and valued. Finally, analysis of the data also showed that the children had a conception of art as a mystery, holding contradictory elements together in a tension, where art was important but also a chore.    Research studies into how young children understand and conceive their early experiences with art learning, and how their teachers perceive preschool art education and its practice, are limited. In documenting the views of both the teachers and the children, this study contributes to an understanding of arts education in a preschool context, by exposing the young children's perspectives. Possibilities for improving arts pedagogy are considered, and new questions are emerged. The study also illustrated how a phenomenographic approach could be used in the field of art education and early childhood education.    Recommendations for further research arising from the study include: using phenomenography to study young children's conceptions of other arts experiences (e.g. music, dance, drama); replication of the study with young children of different age groups and cultural backgrounds; longitudinal studies of children's conceptions of art throughout their schooling programme; and detailed examination of the conceptions of art in early childhood student teachers before, during and after their training.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Phenomenography</field><field name="subject">conceptions</field><field name="subject">child</field><field name="subject">teacher</field><field name="subject">art</field><field name="subject">pedagogy</field><field name="subject">art education</field><field name="subject">Hong Kong</field><field name="subject">early childhood</field><field name="identifier">http://eprints.qut.edu.au/16334/</field><field name="validLink">True</field></doc><doc><field name="title">Adaptive brake lights : an investigation into their relative benefits in regards to road safety</field><field name="creator">Roughan, Craig</field><field name="description">The implementation of In-Vehicle Intelligent Transport Systems (ITS) is becoming a common occurrence in modern vehicles. Automobile manufacturers are releasing vehicles with many forms of sophisticated technologies that remove much of the responsibility of controlling an automobile from the driver. These In-Vehicle Intelligent Transport Systems have stemmed from a genuine need in regards to road safety, however there are advantages and disadvantages associated with ITS. Each different form of technology has its own inherent compromises in relation to road safety, driver behaviour and driver comfort. This thesis outlines the benefits and detrimental effects associated with current In-Vehicle Intelligent Transport Systems and details the development and user interface testing of an adaptive brake light. The adaptive brakelight concept aims to provide drivers with the advantages of an In-Vehicle ITS whilst removing the disadvantages. The technology will help drivers judge the braking pattern of the car in front, thus allowing them to react appropriately and potentially reducing the occurrence of rear-end crashes. The adaptive brake light concept was tested in comparison to a standard brake light and BMW inspired brake light in a series of user interface tests. The adaptive brake light was shown overall to be an improved method of displaying the varying levels of deceleration of a lead vehicle. Whilst different age and gender groups responded differently to the adaptive brake light, it was shown to be of benefit to the majority and the most at risk groups responded positively to the adaptive brake light. This research shows that an adaptive brake light can provide a benefit in regards to road safety when compared to a standard brake light interface. It is hoped that further development of variable brake lights will result from this research and possibly lead to the implementation of the technology to automobiles and other forms of transport.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">adaptive brake lights and interfaces</field><field name="subject">automotive design</field><field name="subject">brake light interface user testing</field><field name="subject">driving simulator</field><field name="subject">human factors</field><field name="subject">in-vehicle intelligent transport systems</field><field name="subject">road safety</field><field name="subject">transport design</field><field name="subject">variable brake lights</field><field name="identifier">http://eprints.qut.edu.au/16335/</field><field name="validLink">True</field></doc><doc><field name="title">Weaving worlds : multimedia and space in contemporary theatre</field><field name="creator">Sheldrake, Pauline</field><field name="description">This play, Weaving Worlds, and the accompanying case study of its use of multimedia examine how multimedia can complexify space in theatre. The case study explores the process of writing a play that has multimedia elements scripted into it. Space in theatre can be defined in terms of its function as well as its location, its representational ideas and as an area used to present an argument, otherwise known as the fictional space. This is achieved through the narrative (that is presented traditionally in theatre through movement, gesture, and text). Multimedia has complexified this fictional space by expanding its location and being able to deliver multiple narratives within it. Multimedia has complexified the time and the space continuum of the narrative through its ability to present mediated images from the stage to the audience at the same time as traditional live performance. This challenges the definition of live performance. The multimedia elements in the play are soundscapes, virtual characters composed of multimedia animations captured on pre-recorded digital video, and live video displays of performance. The world of the play exists in an augmented reality of the memories of the two main characters, Bev and Ben. The addition of multimedia assisted me as a playwright to present my idea of augmented reality in the world of the play, as well as a means of presenting the underpinning themes of the play being disassociation and recorded memory, violence as a means of control, and issues on change. Twentieth century theatre theorists, including Erwin Piscator and Bertolt Brecht, pioneered the use of multimedia in the theatre. In some way they contributed to a contemporary theatre that has evolved in tandem with multimedia. Correspondingly, multimedia requires its own skill sets and equipment and brings with it new aesthetic possibilities as well as becoming an agent of narrative. Multimedia creates opportunities for improvisation. This means that despite the pre-recorded nature of multimedia elements each presentation of multimedia that involves live actors can still create a unique performance experience. The exchange of touch is removed between virtual characters created by multimedia technology and live actors. At the same time the idea of live performance is challenged by the inclusion of multimedia elements. New audiences understand the narrative presented by multimedia because their world is filled with technologies that contain multimedia applications. Playwrights, who are aware of the spatial implications of multimedia, can utilise these new elements to create narratives to alter the structure of their work, and to create new ways of presenting characters, soundscapes and thematic digital displays to enhance and support the performance of their plays.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">multimedia</field><field name="subject">playwrighting</field><field name="subject">soundscapes</field><field name="subject">space</field><field name="subject">spatiality</field><field name="subject">theatre</field><field name="subject">virtual characters</field><field name="identifier">http://eprints.qut.edu.au/16336/</field><field name="validLink">True</field></doc><doc><field name="title">Legislating conscience into contract : panacea or pandora's box?</field><field name="creator">Galloway, Kathrine Scott</field><field name="description">Chapter 11 of the Property Agents and Motor Dealers Act 2000 (Qld) and the Retail Shop Leases Act 1994 (Qld) both introduce procedural requirements to the process for creation of land contracts and were both introduced to address a perceived lack of conscience in each of the industries affected.  These represent a recent broadening of the ambit of consumer protection legislation in Queensland which deviates from more traditional methods of statutory intervention into land contracts.  This paper focuses on the extent to which the Acts effectively introducing a conscience element into certain land contracts, and the extent to which this alters classical contract law.  The effectiveness of the approach is then tested against the critiques of two alternative theories of law - law and economics and feminist contract theory - to see whether the legislative approach answers the deficiencies in contract identified within the terms of each theory.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">contract law</field><field name="subject">legal theory</field><field name="subject">classical contract theory</field><field name="subject">reliance theory</field><field name="subject">law and economics</field><field name="subject">feminist legal theory</field><field name="subject">Property Agents and Motor Dealers Act 2000 (Qld)</field><field name="subject">Retail Shop Leases Act 1994 (Qld)</field><field name="identifier">http://eprints.qut.edu.au/16337/</field><field name="validLink">True</field></doc><doc><field name="title">Analysis of dispersion and propagation of fine and ultra fine particle aerosols from a busy road</field><field name="creator">Gramotnev, Galina</field><field name="description">Nano-particle aerosols are one of the major types of air pollutants in the urban indoor and outdoor environments. Therefore, determination of mechanisms of formation, dispersion, evolution, and transformation of combustion aerosols near the major source of this type of air pollution - busy roads and road networks - is one of the most essential and urgent goals. This Thesis addresses this particular direction of research by filling in gaps in the existing physical understanding of aerosol behaviour and evolution. The applicability of the Gaussian plume model to combustion aerosols near busy roads is discussed and used for the numerical analysis of aerosol dispersion. New methods of determination of emission factors from the average fleet on a road and from different types of vehicles are developed. Strong and fast evolution processes in combustion aerosols near busy roads are discovered experimentally, interpreted, modelled, and statistically analysed. A new major mechanism of aerosol evolution based on the intensive thermal fragmentation of nano-particles is proposed, discussed and modelled. A comprehensive interpretation of mutual transformations of particle modes, a strong maximum of the total number concentration at an optimal distance from the road, increase of the proportion of small nano-particles far from the road is suggested. Modelling of the new mechanism is developed on the basis of the theory of turbulent diffusion, kinetic equations, and theory of stochastic evaporation/degradation processes. Several new powerful statistical methods of analysis are developed for comprehensive data analysis in the presence of strong turbulent mixing and stochastic fluctuations of environmental factors and parameters. These methods are based upon the moving average approach, multi-variate and canonical correlation analyses. As a result, an important new physical insight into the relationships/interactions between particle modes, atmospheric parameters and traffic conditions is presented. In particular, a new definition of particle modes as groups of particles with similar diameters, characterised by strong mutual correlations, is introduced. Likely sources of different particle modes near a busy road are identified and investigated. Strong anti-correlations between some of the particle modes are discovered and interpreted using the derived fragmentation theorem. The results obtained in this thesis will be important for accurate prediction of aerosol pollution levels in the outdoor and indoor environments, for the reliable determination of human exposure and impact of transport emissions on the environment on local and possibly global scales. This work will also be important for the development of reliable and scientifically-based national and international standards for nano-particle emissions.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">combustion aerosols</field><field name="subject">urban aerosols</field><field name="subject">outdoor aerosols</field><field name="subject">background aerosols</field><field name="subject">nano-particles</field><field name="subject">ultra-fine particles</field><field name="subject">particle formation</field><field name="subject">aerosol evolution</field><field name="subject">busy road</field><field name="subject">aerosol dispersion</field><field name="subject">air quality</field><field name="subject">transport emissions</field><field name="subject">emission factors</field><field name="subject">canonical correlations analysis</field><field name="subject">multi-variate analysis</field><field name="subject">degradation processes</field><field name="subject">turbulent diffusion</field><field name="subject">atmospheric monitoring</field><field name="subject">hydrodynamics</field><field name="subject">statistical mechanics</field><field name="subject">probability</field><field name="subject">particle deposition</field><field name="identifier">http://eprints.qut.edu.au/16338/</field><field name="validLink">True</field></doc><doc><field name="title">The Argonauts and writer/directors</field><field name="creator">Marshall, Grant</field><field name="description">The Argonauts is a one hundred and ten minute screenplay depicted in the genre of  children's adventure film, set in the suburbs of Brisbane in the early 1990s. It tells the  story of four friends who embark on adventure in an attempt to save their parents' shops  from a corporate takeover. The exegesis explores the dual role of the screenwriter/director  and the affect on the screenplay of the shifts in mindset required when these roles are  undertaken by the same person. Screenwriting and directing are explored as two separate  but interlinked disciplines. In this paper I have draw on my experience in these two roles  to discuss their inter-relationship. In order to understand how the two roles of  screenwriting and directing interact, challenge and compliment one another when carried  out by the same person, I analyse the interplay of these roles within the specific areas of  character, narrative and setting in the writing and revision of the screenplay, The  Argonauts.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">teen adventure film</field><field name="subject">screenwriting</field><field name="subject">directing</field><field name="subject">director&#146;s commentary</field><field name="subject">characters</field><field name="subject">narrative</field><field name="subject">writer/directors</field><field name="identifier">http://eprints.qut.edu.au/16339/</field><field name="validLink">True</field></doc><doc><field name="title">The case of Mary Dean : sex, poisoning and gender relations in Australia</field><field name="creator">Brien, Donna Lee</field><field name="description">The genre of biography is, by nature, imprecise and limited. Real lives are lived synchronously and diversely; they do not divide spontaneously into chapters, subjects or themes. All biographers construct stories, in the process forcing the disordered complexity of an actual life into a neat literary form. This doctoral submission comprises a book length creative work, Poisoned: The Trials of Mary Dean, and a reflective written component on that creative work, Writing Fictionalised Biography.    Poisoned is a biography of Mary Dean, who, although repeatedly poisoned by her husband at the end of the nineteenth century, did not die. This biography, presented in the form of a first-person memoir, is based closely on historical evidence and is supported with discursive notes and a select bibliography.    The reflective written component, Writing Fictionalised Biography, outlines the process and challenges of writing a biography when the source material available is inadequate and unreliable. In writing Poisoned my genre solution has been fictionalised biography - biography which is historically diligent while utilising fictional writing strategies and incorporating fictional passages. This written component reflectively discusses how I arrived at that solution. It includes discussion of the sources I utilised in writing Poisoned, including the limitations of trial transcripts and other court records as biographical evidence; useful precursors to the form; the process wherein I located both a form for my fictionalised biography and a voice for my biographical subject; possible models I considered; how I distinguished established fact from speculative supposition in the text; as well as some of the ambivalences and ethical concerns such a narrative process implies.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">Mary Dean</field><field name="subject">George Dean</field><field name="subject">Caroline Seymour</field><field name="subject">The Dean Case</field><field name="subject">biography</field><field name="subject">fictionalised biography</field><field name="subject">creative nonfiction</field><field name="subject">memoir</field><field name="subject">non-fiction</field><field name="subject">writing processes</field><field name="subject">Australian history</field><field name="subject">women&#146;s history</field><field name="subject">microhistory</field><field name="subject">creative writing</field><field name="subject">women</field><field name="identifier">http://eprints.qut.edu.au/16340/</field><field name="validLink">False</field></doc><doc><field name="title">Experiences of the phenomenon of Internet use for information sharing on construction projects and skills set identification for effective project participation</field><field name="creator">Magub, Andrew Timothy</field><field name="description">The use of Information Technology in construction is below best practice when compared to other industries. The construction industry is now, however, on the verge of widespread acceptance of internet technology and the communications benefits this can bring. Construction collaboration technology, where project teams use the internet as an interface for project communications, have emerged as a potentially valuable tool. Little research has been focused in this area, particularly on how this phenomenon is being experienced. The aim of this research is to develop a better understanding of the way people experience the use of the internet for information sharing on construction projects and the preliminary identification of the skills set (Knowledge, Skills and Abilities - KSAs) required for industry members to effectively participate.    Phenomenography was selected as an appropriate research methodology to provide an empirical, representative and descriptive research approach and to provide a qualitative based study in a field dominated by quantitative studies. This is a 'second-order approach' which focuses on the experiences of the participants as described by them. A pilot and three major case studies were selected to identify research participants for interviews. A total of nineteen interviews were conducted and transcribed during 2003 in Australia, the United States of America and the United Kingdom, which formed the research data. A phenomenographic analysis was performed on the research data revealing seven 'categories of description' which describe the limited number of qualitatively different ways that the phenomenon is being experienced. A relationship exists between the different categories which can be structured in a logical framework called the outcome space. The preliminary identification of the skills set is then proposed from the research data and the phenomenographic outcomes to provide construction project participants and the industry a first pass on what Knowledge, Skills and Abilities (KSAs) may be required for effective participation.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Phenomenography</field><field name="subject">skills set</field><field name="subject">Internet</field><field name="subject">information sharing</field><field name="subject">construction</field><field name="subject">virtual projects</field><field name="subject">construction collaboration technology</field><field name="subject">knowledge skills and abilities (ksas)</field><field name="subject">qualitative research</field><field name="subject">collaborative websites</field><field name="identifier">http://eprints.qut.edu.au/16341/</field><field name="validLink">True</field></doc><doc><field name="title">Statistical modelling and reduction of multiple access interference power in wideband DS-CDMA and MC-CDMA communications systems</field><field name="creator">Carey, Daniel Jeffrey</field><field name="description">With code division multiple access (CDMA) systems being the prominent multiple access scheme for the air interface for 3G cellular systems, most standardisation bodies have based their terrestrial cellular systems on DS-CDMA (W-CDMA, UMTS, cdma2000). With 4G systems fast approaching, bringing with them improved services and quality of service standards, there is growing interest in further investigating and developing more efficient multiple access techniques such as multicarrier CDMA (MC-CDMA) systems. MC-CDMA combines multicarrier modulation (MCM), namely OFDM, with CDMA profiting from the benefits of both multiplexing techniques; as such, MC-CDMA is emerging as a possible candidate for the air interface multiple access scheme for 4G cellular systems. Multiple access interference (MAI) is a limiting factor of CDMA systems in terms of system capacity as orthogonally designed spreading sequences lose their orthogonality in the presence of timing misalignments amongst mobile subscribers in a cell; such is the case over the uplink channel. Ensuring orthogonal code properties minimises the MAI over synchronous environments, however, it is when the users are allowed to transmit asynchronously, as is the case over the uplink channel, that MAI inflicts significant performance degradation. In CDMA systems, all subscribers are active on the same frequency band simultaneously and signal separation is facilitated upon reception via the properties of the assigned spreading codes. Under asynchronous conditions the code properties alone do not provide the necessary separation and an additive MAI term remains in the detection process. In addition to the separation abilities of the spreading codes, a further method of deciphering the desired subscriber signal from the interfering subscriber signals is sought. In this thesis we propose a statistical model for both the probability density function (pdf) of the total MAI power and the corresponding bit-error rate (BER) observed during asynchronous CDMA transmission. The modelling offers the full statistic the MAI power and resulting BER, not just the first and second order statistics. In addition to statistically quantifying the MAI power, the thesis also proposes a technique for the successful reduction of MAI caused by asynchronous transmission. This interference reduction technique is derived from an ambiguity domain analysis of the asynchronous CDMA detection problem and its application to both the DS-CDMA and MC-CDMA multiplexing techniques is presented and the results show significant MAI reduction, and thus an improved the BER.    A methodology for the approximation of the total MAI power pdf and the resulting BER pdf is proposed for the asynchronous DS-CDMA and MC-CDMA techniques. This methodology is derived for the use of Walsh-Hadamard (WH) and Gold spreading sequences, however, it is applicable to any given set of deterministic spreading sequences. The total MAI power pdfs of both systems are statistically modelled as being Nakagamim distributed and the corresponding BER modelling is derived from the Nakagami-m formulation offering the full statistic of both the incurred MAI power and the achievable BER. The proposed pdf acquisition methodology and statistical models can be used as analysis tools to assess the relative performances of the DS-CDMA and MC-CDMA techniques for a variety of communications environments. Here the asynchronous uplink channel is considered in the absence of fading and the results show a clear distinction between the BER performances of the MC-CDMA and DS-CDMA systems, for which the MC-CDMA system offers a superior performance for the purely asynchronous channel considered. The results suggest a higher resistance to MAI in the MC-CDMA technique in comparison to the DS-CDMA system for the considered transmission scenario. Following ambiguity function analysis of the asynchronous CDMA detection problem, the concept of dual-frequency switching is introduced to the existing DS-CDMA and MC-CDMA techniques giving rise to the proposed dual-frequency DS-CDMA (DF/DSCDMA) and dual-frequency MC-CDMA (DF/MC-CDMA) schemes. Periodically switching the carrier frequency between dual frequency bands at consecutive symbol boundaries facilitates partial CDMA signal separation upon asynchronous reception. Such switching of the carrier frequency induces a separation in frequency between offset interference signals and the reference signal; this is equivalent to shifting the energy concentration of the interference signals away form the ambiguity domain origin (representing the decision variable of the matched filter). Further MAI reduction is demonstrated through careful design of the dual carrier frequencies. The newly proposed DF systems clearly outperform the standard DS-CDMA and MC-CDMA systems when adopting equivalent spreading factors. The DF/DS-CDMA technique in particular achieves the most MAI reduction and in doing so, surpasses all other considered techniques to offer the best BER performance for the purely asynchronous channel considered. In terms of bandwidth usage, the DF/DS-CDMA band width is 1.5 times that of the DF/MC-CDMA system and from the BER results presented, one may argue that DF/MC-CDMA offers the better BER given the bandwidth usage. The multicarrier systems presented, MC-CDMA and DF/MC-CDMA, offer attractive BER performances for the bandwidth used and it is concluded that MC-CDMA is a genuine candidate for the uplink air interface multiple access scheme for future mobile cellular technologies.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">asynchronous transmission</field><field name="subject">bit-error rate</field><field name="subject">code division multiple access</field><field name="subject">direct-sequence</field><field name="subject">dual-band</field><field name="subject">multicarrier modulation</field><field name="subject">multiple access interference</field><field name="subject">Nakagami-m</field><field name="subject">statistical modelling</field><field name="identifier">http://eprints.qut.edu.au/16342/</field><field name="validLink">True</field></doc><doc><field name="title">A study of the determinants of effectiveness in relational contracting</field><field name="creator">Cheung, Yan Ki Fiona</field><field name="description">The significance of a link between organisational culture and organisational performance has long been recognised in both mainstream management literature as well as in the construction management literature. Within the construction research domain, the impact of culture and organisation on project performance is becoming an increasingly important topic for the establishment of sound partnering or alliancing, or to what has been referred to increasingly in recent years as relational contracting, in the overall approach to project management. However, studies of the efficacy of alliancing or partnering have so far produced mixed results.    The present study concerns two public sector organisations in Australia, where the interrelationships between organisational culture and structure, commitment and national culture were investigated. The methodology was triangulated; with a detailed questionnaire survey undertaken with both organisations, and with subsequent interviews and case studies carried out for validation. Multivariate statistical techniques were utilised to investigate complex relationships between variables. The research reports the perceptions of professional personnel in the public sector organisations, and some mismatches found between organisational structuring and organisational culture. Key issues affecting project performance, and the set of project team characteristics enhancing the development of a collaborative project culture, were found to include continuous commitment from all levels, right mix of people, formal and informal communication, continuous facilitation, education and training in the universities, institutions and industry. The combined outcomes of the research provided a framework of fundamental elements for successful relational contracting.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Australia</field><field name="subject">case study</field><field name="subject">construction industry</field><field name="subject">culture</field><field name="subject">interviews</field><field name="subject">organisation</field><field name="subject">public sector</field><field name="subject">relational contracting survey</field><field name="identifier">http://eprints.qut.edu.au/16343/</field><field name="validLink">True</field></doc><doc><field name="title">Performance measurements of rail curve lubricants</field><field name="creator">Wilson, Lance Jon</field><field name="description">Wear of railroad rolling stock and rails costs millions of dollars annually in all rail systems throughout the world. The rail industry has attempted to address flange wear using rail curve lubricants and presently use a variety of lubricants and lubricant applicators. The choice of lubricant and applicator is currently based on considerations that do not address the wear problem directly. This research quantified rail curve lubricant performance through laboratory simulation. The effects of lubricants in the wheel/rail contact were investigated. Rail curve lubricant performance was measured with a laboratory rail/wheel simulator for the purpose of optimising the choice of lubricant. New methods for measurement of rail curve lubricant performance have been presented. These performance measurements are total absorbed energy, the energy absorbed in the lubricant film instead of being utilised for wear processes; total distance slid, the sliding distance or accumulated strain achieved prior to development of a set tractive force limit; half life of lubricant, the time taken for a lubricant to lose half of its sliding performance; and apparent viscosity, a measure of the lubricity presented with respect to accumulated strain. The rail/wheel simulator used in this research consists of two dissimilar wheels (disks) rotating in contact with one another simulating a conformal gauge corner contact. The first wheel, a simulated rail, is driven by an electric motor which then drives the second wheel, a simulated railroad wheel, through the contact. Hydraulic braking on the railroad wheel is used to simulate the rolling/sliding conditions. The variables of the simulated contact that are controlled with this equipment are normal force, input wheel speed, slip ratio between samples, sample geometries and material properties, and lubricant types.    Rail curve lubricants were laboratory tested to define their properties using the ASTM and other appropriate standards. The performance differences measured using ASTM standards based tests were susceptible to repeatability problems and did not represent the contact as accurately as the rail/wheel simulator. This laboratory simulator was used to gather data in lubricated and unlubricated conditions for the purpose of providing lubricant performance measurements. These measurements were presented and the tested lubricants were ranked conclusively using three industrially relevant performance criteria. Total sliding distance and total absorbed energy measurements of the rail curve lubricants displayed clear differences in lubricant performance for both of these criteria. Total sliding distance is equivalent to the number of axles in the field situation, while total absorbed energy is the energy unavailable for wear processes of rails and wheels. Lubricants designed using these measurements will increase lubricant performance with respect to these performance criteria which in turn will reduce wear to both rails and wheels.    Measurement of the apparent viscosity of rail curve lubricants, using the rail/wheel simulator, displayed changes in rheological characteristics with respect to accumulated strain. Apparent viscosity is a measure of the shear stress transmitted from the wheels to the rails. Designing a rail curve lubricant after analysing measurements taken from the rail/wheel simulator will assist in identifying lubricant properties to reduce the wear producing shear stresses generated in a rail wheel contact.    Decay of lubricant performance was measured for three different rail curve lubricants under simulated conditions. The research found appreciable and quantifiable differences between lubricants. Industrial application of the findings will improve positioning of lubrication systems, improve choice of lubricants and predict effective lubrication distance from the lubricant application point.    Using the new methods of lubricant performance measurement developed in this thesis, the objective of this research, to quantify rail curve lubricant performance through laboratory simulation, has been achieved.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">rail curve</field><field name="subject">lubricant performance</field><field name="subject">elastohydrodynamic lubrication</field><field name="subject">rheology</field><field name="subject">absorbed energy</field><field name="subject">lubricating grease</field><field name="subject">rail/wheel interface</field><field name="identifier">http://eprints.qut.edu.au/16344/</field><field name="validLink">True</field></doc><doc><field name="title">Organophosphate exposure in Australian agricultural workers : human exposure and risk assessment</field><field name="creator">Johnstone, Kelly Rose</field><field name="description">Organophosphate (OP) pesticides, as a group, are the most widely used insecticides in Australia. Approximately 5 000 tonnes of active ingredient are used annually (Radcliffe, 2002). The OP pesticide group consists of around 30 identifiably distinct chemicals that are synthesised and added to approximately 700 products (Radcliffe, 2002). OP pesticides are used on fruit, vegetable, grain, pasture seed, ornamental, cotton, and viticultural crops, on livestock and domestic animals, as well as for building pest control. OP pesticides all act by inhibiting the nervous system enzyme acetylcholinesterase (AChE) and as such are termed anticholinesterase insecticides. The phosphorylation of AChE and the resultant accumulation of acetylcholine are responsible for the typical symptoms of acute poisoning with OP compounds. In addition to acute health effects, OP compound exposure can result in chronic, long-term neurological effects.    The traditional method of health surveillance for OP pesticide exposure is blood cholinesterase analysis, which is actually biological effect monitoring. However, there are several drawbacks associated with the use of the blood cholinesterase test, including its invasive nature, the need for baseline levels and a substantial exposure to OP pesticide before a drop in cholinesterase activity can be detected. OP pesticides are metabolised fairly rapidly by the liver to form alkyl phosphates (DAPs). Approximately 70% of OP pesticides in use in Australia will metabolise into one or more of six common DAPs. During the last 30 years, scientists have developed a urine test that detects these six degradation products. However, unlike the blood cholinesterase test, there is currently no Biological Exposure Index (BEI) for the urine DAP metabolite test. Workers in the agricultural industry - particularly those involved with mixing, loading and application tasks - are at risk of exposure to OP pesticides. It is therefore important that these workers are able to assess their risk of health effects from exposure to OP pesticides. However, currently in Queensland, workplace health and safety legislation exempts the agricultural industry from hazardous substance legislation that incorporates the requirement to perform risk assessments and health surveillance (blood cholinesterase testing) for OP pesticide exposure. The specific aim of this research was to characterise OP pesticide exposure and to assess the feasibility of using urine DAP metabolite testing as a risk assessment tool for agricultural and related industry workers exposed to OP pesticides. An additional aim among farmers was to conduct an in-depth evaluation of their knowledge, attitudes and behaviours related to handling OP pesticides and how they assess the risks associated with their use of OPs.    A cross-sectional study design was used to assess exposure to OP pesticides and related issues among four groups: fruit and vegetable farmers, pilots and mixer/loaders, formulator plant staff and a control group. The study involved 51 farmers in the interviewer-administered questionnaire and 32 in urine sample provision. Eighteen pilots and mixer/loaders provided urine samples and 9 exposed formulation plant staff provided urine and blood samples. Community controls from Toowoomba Rotary clubs provided 44 urine samples and 11 non-exposed formulation plant staff provided blood and urine samples; all groups also provided responses to a self-administered questionnaire.  Participant farmers were drawn from the main cropping areas in south-east Queensland - Laidley/Lowood, Gatton, and Stanthorpe. The farmer group was characterised by small owner-operators who often had primary responsibility for OP pesticide mixing and application. Farmers had good knowledge of pesticide-related safety practices; however, despite this knowledge, use of personal protective equipment (PPE) was low. More than half of the farmers did not often wear a mask/respirator (56%), gloves (54%) or overalls (65%). Material Safety Data Sheets were never or rarely read and 88.2% of farmers never or rarely read OP pesticide labels before application. There were also problems with chemical suppliers providing farmers with MSDSs. The majority of farmers (90.2%) reported that they had never had any health surveillance performed and three-quarters had never read about or been shown how to perform a formal risk assessment. The main inhibitors to the use of PPE in the farmers' group included the uncomfortable and cumbersome nature of PPE, especially in hot weather conditions, and the fear of PPE use triggering neighbours' complaints to Government authorities. Factors associated with better PPE use included having positive attitudes and beliefs toward PPE use, higher knowledge scores and low risk perception. Farmers' use of OP pesticides was infrequent, of short duration and involved application via a boom on a tractor, a lower risk application method. Consequently, urine DAP metabolite levels in this group were generally low, with 36 out of 96 samples (37.5%) containing detectable levels. Detectable results ranged from 9.00-116.00 &#61549;mol/mol creatinine. Formulators exposed to OP pesticides were found to have the highest urine DAP metabolite levels (detectable levels 13.20-550.00 &#61549;mol/mol creatinine), followed by pilots and mixer/loaders (detectable levels 8.40-304.00 &#61549;mol/mol creatinine) and then farmers. Despite this, pilots and mixer/loaders (particularly mixer/loaders) had the greatest number of samples containing detectable levels (94.4% of samples). The DAP metabolite most frequently detected across all groups was DMTP, which was the only metabolite found in control samples. Levels found in this study are similar to those reported in international research (Takamiya, 1994, Stephens et al., 1996, Simcox et al., 1999, Mills, 2001, Cocker et al., 2002).  The observed DAP levels were not associated with a drop in cholinesterase activity among the formulation plant workers, as expected from the literature.  Such exposure also is unlikely to be associated with acute health effects. In contrast, there is insufficient scientific knowledge to know whether levels recorded in this study and elsewhere may be associated with long-term, chronic health effects. Notably, DMTP levels also were observed among the presumably 'unexposed' comparison groups.  Environmental background level exposures to OPs producing the DAP metabolite DMTP are therefore of potential significance and may be related, at least in part, to consumption of contaminated fruit and vegetables. There is also emerging evidence to suggest that exposure to DAP metabolites themselves through diet and other sources may contribute to the concentration of DAPs, including DMTP in urine, potentially complicating assessment of occupational exposures. Nevertheless, the urine DAP metabolite test was a useful, sensitive indicator of occupational OP pesticide exposure among agricultural workers and may be of use to the industry as part of the risk assessment process. Future research should aim to establish a BEI for the urine DAP test.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">OP pesticide</field><field name="subject">DAP metabolites</field><field name="subject">risk assessment</field><field name="subject">workplace health and safety (WHS)</field><field name="subject">fruit and vegetable farmer</field><field name="subject">agricultural pilot</field><field name="subject">agricultural mixer/loader</field><field name="subject">formulator</field><field name="subject">biological monitoring</field><field name="identifier">http://eprints.qut.edu.au/16345/</field><field name="validLink">True</field></doc><doc><field name="title">Using the knowledge management discourse as a framework for the self examination of a school administrator's professional practice</field><field name="creator">Dillon, Paul Joseph</field><field name="description">Popular management literature routinely presents management discourses that offer managers with strategies or 'recipes' for organisational improvement. Practitioners often uncritically accept and implement strategies prescribed within these discourses. Management discourses are constantly evolving to seemingly provide newer and better solutions to organisations' problems. The evolutionary pressures are evidenced through the limited life spans of many of the strategies proffered in the various management discourses. So short have been the life spans of some of these management strategies that the question of faddism has been raised (Birnbaum, 2001). Over recent years knowledge management has filtered from the broader management discourse into the discourse of educational administration. Knowledge management practices are said to enable individuals within an educational organisation to add value to the information and knowledge that an organisation possesses. This research used self-study to examine the effectiveness of a school administrator attempting to model explicit knowledge management principles within his professional practice. A focus of the research was the critical investigation of knowledge management as a management fad or a framework for sustainable management behaviour. Employing the living theory approach to action research allowed me to ask questions about 'how' to improve my practice and to provide evidence to support my answers. It allowed me to examine my professional practice as an educational administrator who valued knowledge, its creation and use critically. My research learnings been have presented as propositions related to the 'how' of my professional practice and its influence on the creation and management of knowledge. The propositions are as follows. * Proposition 1: As an administrator my practices when working with knowledge are a reflection of my ontology and epistemology. To consciously vary my professional practices to facilitate knowledge creation and management it is essential for me to make my ontology and epistemology explicit. * Proposition 2: My professional practices related to information sharing and knowledge creation are directly influenced by psycho-social filters. Three primary psycho-social filters are context, need and relationships. * Proposition 3: The influence of the relationship filter on my knowledge creation activities is directly linked to the relationships that exist between me and those involved in the knowledge activities. The ongoing capacity for my professional practices to influence knowledge creation is linked through relationships by my personal resilience. * Proposition 4: My knowledge influencing practices are those practices that support the provision of opportunities for information sharing and the creation of knowledge with the specific intent of applying that knowledge in an organisational context. A primary application of the created knowledge is decision making. * Proposition 5: Knowledge creation is an ongoing process and knowledge is only relevant at a point in time and applicable in a particular context. * Proposition 6: My professional practices that influence information sharing, knowledge creation and decision making are explicit iterations of my power as an administrator. * Proposition 7: Involvement in the decision making process is one of my key roles as an administrator. Decision making is a major example of the creation and use of knowledge within a school. * Proposition 8: I acknowledge that stories are a valuable way for individuals to share information and they can act as a catalyst for the creation of knowledge. * Proposition 9: Using the knowledge management discourse as a framework to support the critique of my professional practice challenges its branding as a management fad. The propositions have been developed and tested through reconnaissance and two cycles of action research. These propositions have been integrated into a model representing my capacity as an administrator to influence the creation of knowledge.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">knowledge management</field><field name="subject">knowledge creation</field><field name="subject">management fads</field><field name="subject">living theory action research</field><field name="subject">practitioner investigations</field><field name="subject">research reconnaissance</field><field name="subject">professional practice</field><field name="subject">decision making</field><field name="subject">educational administration</field><field name="subject">educational leadership</field><field name="subject">organisational trust</field><field name="subject">psycho-social filters</field><field name="identifier">http://eprints.qut.edu.au/16346/</field><field name="validLink">True</field></doc><doc><field name="title">Scattering of guided waves in thick gratings at extreme angles</field><field name="creator">Kurth, Martin Lyndon</field><field name="description">The aim of this project was to develop a passive optical compensating arrangement that would allow the formation and continued stability of interference patterns over a long timescale and also to investigate optical wave scattering in thick gratings at extreme angles of scattering. A novel passive arrangement based on a Sagnac interferometer is described that produces interference patterns more stable than those produced by a conventional arrangement. An analysis of the arrangement is presented that shows it to be an order of magnitude more stable than an equivalent conventional approach. The excellent fringe stability allowed holographic gratings with small periods (~ 0.5 &#956;m) to be written in photorefractive lithium niobate with low intensity writing fields (~mW/cm2) produced by a He:Ne laser, despite long grating fabrication times (~ 1000 s). This was possible because the optical arrangement compensated for phase shifts introduced by translational and rotational mirror motion caused by environmental perturbations. It was shown that the rapid introduction of a phase shift in one of the writing fields can change the direction of energy flow in the two-wave mixing process. It was found that the improvement in stability of the modified Sagnac arrangement over a conventional interferometer decreased when the crossing angle was increased and that the point about which the mirrors are rotated greatly affects the stability of the arrangement. For a crossing angle of 12 degrees, the modified Sagnac arrangement is more than twice as stable when the mirrors are rotated about their midpoints, rather than their endpoints. Investigations into scattering in the extremely asymmetrical scattering (EAS) geometry were undertaken by scattering light from a 532nm Nd:YAG laser off gratings written in photorefractive barium titanate and lithium niobate. Despite the difficulties posed by background noise, there was very good agreement between the observed scattered field and that predicted by a previously established theoretical model. Thus, this work represents the first experimental observation of EAS in the optical part of the spectrum.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">holographic grating fabrication</field><field name="subject">Sagnac interferometer</field><field name="subject">photorefractive effect</field><field name="subject">extremely asymmetrical scattering</field><field name="subject">passive stabilisation</field><field name="subject">stable interference patterns</field><field name="identifier">http://eprints.qut.edu.au/16347/</field><field name="validLink">True</field></doc><doc><field name="title">Juxtaposing community with learning: The relationship between learner contributions and sense of community in online environments</field><field name="creator">Dawson, Shane Peter</field><field name="description">Australian Government policy has sought to decrease university reliance on federal support through the re-allocation of funding. Access to this pool of funding is based on teaching and learning performance and the subsequent comparison with similar education institutions. The concept of community has been promoted as a strategy for responding to these government demands whilst facilitating the student learning experience. Despite an intensive investment in strategic initiatives to enhance sense of community among the student cohort, there is a lack of scaleable evaluative measures to assess the overall effectiveness and accomplishment of intended outcomes.    Contemporary methods for the assessment of community primarily rely on the establishment of pre-defined characteristics and the subsequent content analyses of communication artefacts to identify presence or absence. These studies are often small in sample size and limited in scalability and therefore the generalisation of research findings is impeded.    This study aimed to examine the relationship between student sense of community (SOC) and communication interactions. To achieve this aim the study first developed a scaleable quantitative methodology that can be used to benchmark current pedagogical performance and guide future implemented practices relating to the establishment of a student community. The study juxtaposes an established scale of SOC with student online communication behaviours to identify potential relationships.    In developing this methodology the study confirmed that the Classroom Community Scale (CCS) was a valid and robust instrument. The study incorporated a mixed methods paradigm to investigate the research questions. Quantitative data were derived from an online survey (N= 464), student online communication interactions and social network analyses. These data were further explored using more qualitative approaches such as content analyses of the discussion forum transcripts (n = 899) and student interviews (N = 4).    The findings demonstrate that students and teaching units with greater frequencies of communication interactions possess stronger levels of SOC as determined by the CCS (R2 = .24, F = 14.98, p &lt; .001; R2 = .83, F = 16.53, p &lt; .01, respectively). A significant correlation was observed between discussion forum interaction types (learner-learner; learner-content; system) and SOC. Although learner-to-learner interactions demonstrated a positive correlation (r = .48, p &lt; .05), system posts (isolated contributions) illustrated a negative correlation (r = - .50, p &lt; .05). Quantity of discussion forum postings alone was not observed to be a significant indicator of SOC.    Social network analyses demonstrated that the centrality measures closeness and degrees are positive predictors of an individual's reported SOC (t = 3.02 and t = 3.24, p &lt; .001 respectively). In contrast, the centrality measure betweenness revealed a negative correlation (t = -3.86, p &lt; .001). Discussion forum content analyses illustrated the fluid transition of discourse between social and learning oriented communities. Student interviews suggested that pre-existing external networks influence the type of support and information exchanges required and therefore, the degree of SOC experienced.    The study also recognised that a key challenge in the implementation of data mining practices to monitor lead indicators of community lies in the notion of surveillance. This study examined the impact of technologically mediated modes of surveillance on student online behaviour. The findings demonstrate that students' unaware of the surveillance technologies operating within the institution modify their online behaviour more than their cognisant peers.    The results of this study have implications for educational theory, practice, monitoring and evaluation. This research supports the development of a new model of community that illustrates the inter-relationships between student SOC and the education environment. Furthermore, the developed methodology demonstrates the capacity for cost effective data mining techniques to guide and evaluate implemented teaching and learning practices. Consequently, alignment with other theoretical constructs such as student satisfaction and engagement provides the institution with a lead indicator of teaching and learning performance. As the findings from this study illustrate the relationship between communication interactions and SOC, educators have the capacity to monitor communication trends and alter the teaching and learning practices to promote community among the student cohort in a just-in-time environment.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">sense of community</field><field name="subject">computer-mediated communication</field><field name="subject">quantitative</field><field name="subject">lead indicators</field><field name="subject">social network analysis</field><field name="subject">information and communication technologies</field><field name="subject">surveillance</field><field name="identifier">http://eprints.qut.edu.au/16348/</field><field name="validLink">True</field></doc><doc><field name="title">Recombinant production and in silico analysis of the Androgen receptor ligand binding domain</field><field name="creator">Simila, Henry Allan</field><field name="description">The androgen receptor (AR) fulfils important roles for both sexes. By mediating the biological function of androgens, the AR has remained the target for endocrine therapies treating prostate cancer. The AR also determines the effectiveness of medroxyprogesterone acetate (MPA) in treating AR positive breast cancer.    Every man will be affected by prostate cancer if he lives long enough.  Prostate cancer continues to be a leading cause of death for males despite research into this cancer covering more than 60 years since Huggins' seminal 1941 study showing that androgens play a key role in this cancer. Unfortunately, significant advances have not been forthcoming and the effect of treatment has remained largely the same over past decades, whereby initial treatment provides temporary remission but eventually advanced cases become refractory to further intervention and the disease recurs in a more aggressive form.  A plethora of factors are exquisitely sensitive to minute changes in the AR's structural profile, which can be altered by a single mutation, resulting in aberrant activity. A principal feature of these variant ARs associated with prostate cancer, is enhanced capacity to bind a number of molecules other than its cognate ligand, dihydrotestosterone (DHT). The promiscuous activity of this receptor leads to continued AR signalling and stimulus for the cancer despite low androgen levels induced by treatment regimes.  A key question is whether mutations occurring within the AR occur as a result of cancer or contribute to the propagation of the cancer. Recent research has demonstrated that treatments incorporating anti-androgens such as flutamide, which are designed to impede prostate cancer progression by inhibiting AR activity, may actually provide selective pressure favouring somatic mutation of the receptor to take place. The specific changes to the AR which are responsible for gains of function have not been resolved as their crystal structures, which are used to provide conformational analysis of proteins, are tremendously problematic to produce with little success found in literature. Generating representative crystals of the AR protein involves producing soluble recombinant protein. Unfortunately the AR is prone to aggregation and is highly unstable, especially in the presence of antagonistic molecules or absence of a stabilising ligand, preventing the protein from being maintained in the soluble state required for crystallization. In order to produce sufficient quantities of soluble material for crystallization, the androgen receptor's ligand binding domain (LBD) was produced as a recombinant protein in Escherichia coli bacteria strain BL21 (DE3) in the presence of DHT, flutamide, as well as in the absence of ligand. Since soluble unbound AR-LBD has not been produced until now, the bacterial culture containing no ligand was further processed to the stage of cleaving the purification tag from the recombinant protein and represents considerable progress into producing soluble material for crystallizing the troublesome yet considerably important AR in the absence of ligand. Although distinct from prostate cancer in males, AR activity in breast tissue is also a factor determining the action of drugs, such as MPA, included in therapies aimed at breast cancer. The use of MPA has declined primarily due to its adverse effects including unsuccessful generation of a biological response, as well as the advent of other drugs administered for hormonal therapies treating breast cancer. Alternative drugs are needed when breast cancer therapies fail as tumours develop resistance to primary drugs. Although there are a number of drugs on the market, success would be maximised if the determined therapy is matched with the patient, based for example, on their genetic makeup. There is a conundrum whereby some patients with an AR do not respond to MPA, a drug normally recognised by the receptor. In clinical trials it was discovered that an AR with threonine instead of methionine at residue 780 (M780T) fails to activate in response to MPA, but the exact mechanism has remained elusive and needs to be answered at the molecular level. The X-ray crystallographic studies that generate 3D images of macromolecules and wet chemistry, which have traditionally been used to provide insight into science in these dimensions, are incorporated with computer based molecular simulation. This is both complementary and distinct to traditional scientific methodologies, enabling further elucidation of protein-protein interactions, and the influence applied to such inter-relations by natural and drug ligands. This approach has been used, and is continually developed, to understand the binding mechanisms of current drugs as well as designing new drugs.    In order to produce a receptor representing the M780T variant, the crystal structure representing the AR-LBD was mutated in silico, into which MPA was then docked. It was found that MPA binds into the M780T AR-LBD with considerably more spatial displacement compared to the position of DHT in the crystal structure, and is predicted to be the primary reason for the inability of MPA to activate this variant AR. The clarification of MPA binding and failure to elicit a response from the variant AR is significant for a cohort of breast cancer patients, as not only does the presence of an AR in the tumour determine the effectiveness of MPA, but correct composition of the AR, specifically, the absence of a M780T mutation. In the absence of this AR mutation, MPA could effectively be used either as an alternative to primary drugs, or in secondary therapies when primary therapies fail. Aberrant activity of variant ARs in response to MPA should also be taken into consideration when analysing drug studies about the effectiveness of MPA.  The findings on the loss of response to MPA by the M780T variant AR have been included in the journal article &amp;quotDecreased Androgen Receptor Levels and Receptor Function in Breast Cancer Contribute to the Failure of Response to Medroxyprogesterone Acetate" appearing in the September 2005 issue of Cancer Research journal.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">androgen receptor</field><field name="subject">breast cancer mutation methionine 780 to threonine</field><field name="subject">flutamide</field><field name="subject">in vitro recombinant protein expression</field><field name="subject">medroxyprogesterone acetate (MPA)</field><field name="subject">molecular simulation</field><field name="subject">prostate cancer</field><field name="identifier">http://eprints.qut.edu.au/16349/</field><field name="validLink">True</field></doc><doc><field name="title">Characterisation of an Australian isolate of sugarcane bacilliform virus</field><field name="creator">Geijskes, Robert Jason</field><field name="description">Sugarcane bacilliform virus (SCBV) is an economically important pathogen of sugarcane in Australia which limits access to foreign sugarcane germplasm. Although SCBV is present in the major cane growing regions worldwide, very little is known about its variability, virulence and the yield losses resulting from infection. The limited information on SCBV has resulted in quarantine measures being introduced to protect the Australian sugarcane industry, with a major consequence being restricted access to imported sugarcane germplasm for breeding programs. Foreign sugarcane germplasm plays an important role in breeding of new commercial varieties for the Australian sugar industry and is essential for the long term productivity, profitability and sustainability of the sugar industry. This study was aimed at characterising Australian isolates of SCBV to enable the development of reliable and robust molecular and/or antibody-based diagnostic tests which could be used to not only assess the impact of SCBV on the Australian sugarcane industry, but could also be used to screen imported sugarcane germplasm for the virus. SCBV virions (SCBV-IM) were purified from the sugarcane accession "Ireng Maleng" and the dsDNA genome was cloned and sequenced. The genome of SCBV-IM comprised 7687 bp with an organisation typical of other badnaviruses. When the entire nucleotide sequence of SCBV-IM was compared to that of the Moroccan SCBV isolate (SCBV-Mo), less than 75% similarity was present. Within the coding regions, ORF I, ORF II and ORF III had 83%, 71% and 73% nucleotide similarity to SCBV-Mo, respectively. At the amino acid level, ORFs I, II and III from SCBV-IM showed 91%, 84% and 85% similarity to the equivalent regions in SCBV-Mo, respectively. To further investigate the level of sequence variability within Australian SCBV isolates, virions were purified from three further sugarcane accessions and a 220 bp fragment of the reverse transcriptase-coding region was amplified. Five clones from each sub-population were selected and sequenced. Analysis of these sequences revealed considerable variability in the virus population with variability within one plant as great as it was between isolates. However, since the use of specific primers could also be selecting for a sub-population of SCBV sequences, it was possible that the variability may actually be greater than that reported. These results indicated that SCBV isolates are complex and variable and may represent a continuum of genetic variability.    High molecular weight DNA species larger than the SCBV 7.6 kbp unit-length genome were found in DNA extracted from purified SCBV-IM virions. We confirmed that these high molecular weight nucleic acids were virus-specific and open circular in conformation. Using field inversion gel electrophoresis (FIGE), the SCBV-IM DNA was separated into four discrete bands with sizes ranging from between 1 to 4 genome copies. The DNA was shown to comprise overlapped individual genome-length molecules and not covalently-bonded continuous DNA strands. We presume that these DNA molecules are concatamers formed during replication as a result of a terminal overlap on the sense strand. The presence of these concatamers within virions may explain the observation of particles with lengths corresponding to one, two or three times the modal length of 130 nm.    Four SCBV-infected Saccharum officinarum plants were examined for the presence of integrated viral DNA. Southern blot analysis of viral DNA and total DNA extracted from the same plant source were compared with, or without, restriction digestion. The resulting restriction patterns from viral and total DNA were almost identical suggesting that there were no integrated SCBV sequences in the sugarcane cultivars tested. Although larger-than-single-genome copy bands were detected in both the viral and the total DNA samples, this was probably due to the presence of genomic concatamers. SCBV integration studies using Southern analyses were further complicated by high sequence variability which precluded the restriction digestion of all viral DNA species. As such, some of the SCBV DNA species remain as concatamers which appear as larger-than-unit-length SCBV products.  An antiserum derived from a mixture of purified SCBV isolates has been used routinely in the past to screen for SCBV infection, but the heterogeneity reported for badnaviruses has cast doubt on the ability of this antiserum to detect all SCBV isolates. We attempted to determine whether antiserum generated against proteins other than the viral capsid could be used to detect SCBV infections, thus improving the reliability and robustness of SCBV diagnosis. The complete coding regions of SCBV ORF I and ORF II were bacterially expressed and used as antigens for antiserum production. Both ORF I and II proteins were found to be highly immunogenic and generated high-titre antisera, designated AS-I and AS-II, respectively. The diagnostic utility of both antisera to detect SCBV in six different infected sugarcane plants was tested using both immunosorbent electron microscopy (ISEM) and western blots. The currently used SCBV antiserum (AS-V), generated against a mixture of purified SCBV isolates, was included for comparison. In western analyses, neither AS-I nor AS-V was able to conclusively detect SCBV in any of the six infected plants due to reactivity with numerous non-specific proteins. In contrast, AS-II reacted specifically with a protein of the expected size (~13.5 kDa) in 2/6 infected plants. When compared using ISEM, AS-V, AS-I and AS-II trapped virions from 6/6, 6/6 and 2/6 SCBV-infected plants, respectively. However, the number of virions trapped using AS-V was approximately 30-fold more than that trapped using either AS-I or AS-II. These results highlight the variability between SCBV isolates and suggest that ISEM with antisera raised against mixtures of viral proteins may be a useful tool for the detection of viral isolates.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">sugarcane</field><field name="subject">badnavirus</field><field name="subject">Sugarcane bacilliform virus</field><field name="subject">banana</field><field name="subject">Banana streak virus</field><field name="subject">integration</field><field name="subject">field inversion gel electrophoresis</field><field name="subject">protein expression</field><field name="subject">pararetrovirus</field><field name="identifier">http://eprints.qut.edu.au/16350/</field><field name="validLink">True</field></doc><doc><field name="title">Black-winged angels : theoretical underpinnings</field><field name="creator">Slatter, Angela Gaye</field><field name="description">The creative work, Black-Winged Angels, is a collection of nine re-written fairytales. The collection is divided into three sections: Maiden, Mother, Crone and the three stories in each section explore various aspects of these traditional periods in a woman's life. The tales are re-written, or 're-loaded', to offer alternative views of the tales of childhood, to examine other forces that may be at work inside the stories themselves, and the possible consequences of 'living' those tales differently.    The exegesis examines the colonisation and reclamation of a range of fairy tales. It traces the historical shift from oral to literary fairy tale traditions, and the ensuing patriarchal rewriting of those fairytales. The exegesis then considers the writing of Angela Carter and Emma Donoghue (specifically The Bloody Chamber and Kissing the Witch, respectively), in terms of how their work in the fairytale genre has both succeeded in, and failed to, avoid a simple inversion of gender with their revisions of the colonised literary fairytales.  The exegetical work has grown, in large part, out of the process of critical reflexivity to which I have subjected my creative work. I chose Angela Carter's and Emma Donoghue's works of revisionist fairytales to act as 'bookends' for my own work; Carter as a starting point for fairytale reclamation and Donoghue as a more recent incarnation of the fairytale revisionist. In reflecting on my own work, I often looked back at what these two authors had done, to guide me in the eternal writers' struggle of what to leave in, what to leave out, and where to take the tale.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Fairytales</field><field name="subject">Angela Carter</field><field name="subject">Emma Donoghue</field><field name="subject">Brothers Grimm</field><field name="subject">Charles Perrault</field><field name="subject">Feminism</field><field name="subject">Gender roles</field><field name="subject">(Female) agency</field><field name="subject">Creative writing</field><field name="subject">Female collaboration</field><field name="subject">Female community</field><field name="identifier">http://eprints.qut.edu.au/16351/</field><field name="validLink">True</field></doc><doc><field name="title">Identification of novel antigens for the development of a vaccine to prevent sexually transmitted Chlamydia infections</field><field name="creator">McNeilly, Celia Louise</field><field name="description">Chlamydia trachomatis infections are among the most frequently reported causes of human sexually transmitted infection. In Australia, the reported rate of infection in 2004 reached 175 per 100,000 population, the highest rate since surveillance of the condition began in 1991. Severe adverse sequelae that commonly occur following progression of the infection from the lower to the upper genital tract include pelvic inflammatory disease, infertility and ectopic pregnancy. However the frequent prevalance of asymptomatic infection makes diagnosis and treatment often late and therefore ineffective against upper genital tract complications. Hence there is a great need to develop a vaccine to protect against the sexual transmission of C.trachomatis. Despite many years of research investigating potential vaccine strategies to prevent sexually transmitted C.trachomatis infections, there remains no commercially available C.trachomatis vaccine. Early research showed that the use of live, attenuated or inactivated whole Chlamydia as a vaccine was not a viable option due to adverse effects caused by immunopathogenic cellular components. The early human vaccine trials that utilized whole chlamydial cells and resulted in exacerbated disease when immunized individuals were re-exposed to Chlamydia have led to the investigation of chlamydial subunit components as potential vaccine antigens. The most widely investigated vaccine candidate antigen is the major outer membrane protein (MOMP) as it is known to be immunogenic and surface exposed. Much research using this antigen has been undertaken with the antigen being delivered as a protein, peptide or DNA, via many mucosal and systemic routes of immunization, and in combination with various vaccine adjuvants. However, at best only partial protection against a chlamydial genital tract infection has been achieved. Only a few alternative candidate antigens have been investigated as potential vaccine targets to protect against chlamydial infections. These include the outer membrane porin PorB, the large cysteine rich outer membrane protein Omp2 and the heat shock proteins DnaK and GroEL. Although other candidate antigens have been predicted in various models of chlamydial infection (Finco et al., 2005; Stemke-Hale et al., 2005; Li et al., 2006), few have been tested for their protective efficacy. The aim of this study was to use expression library immunization to screen the whole C.muridarum genome for novel vaccine candidates capable of protecting against a chlamydial genital tract infection. C.muridarum was selected as the disease model for chlamydial genital tract infection as it has similarities to C.trachomatis in pathogenesis, immune response to infection and gene content and order. Once protective antigens had been isolated from an expression library, these were screened individually for immunogenicity and protective efficacy in the C.muridarum model of infection. An expression library containing over 21,000 recombinant C.muridarum clones was constructed and divided into pools of clones. DNA was extracted from these pools and used to immunize mice through gene gun technology, delivering 1&#956;g of DNA to the abdomen of mice. Following the immunization regime, mice were challenged intra-vaginally with live C.muridarum as this route of infection best resembles the natural route of infection that is responsible for the sexual transmission of C.trachomatis in humans. Four in vivo screens of the C.muridarum expression library, each time using reduced numbers of clones, resulted in the identification of seven novel vaccine antigens that conferred protection against a genital tract challenge infection in mice. These warrant further investigation as vaccine antigens in the development of a vaccine against C.trachomatis infection. The identified antigens include antigens not conventionally believed to be potential vaccine candidates such as hypothetical proteins and housekeeping genes, including a DNA gyrase subunit, TC0462, and the ATP-dependent Clp protease, ATP-binding subunit ClpC, TC0559. Other antigens identified were more traditional, surface exposed vaccine targets that have not been previously investigated as vaccine targets, including a novel outer membrane protein, TC0512, a polymorphic membrane protein, TC0693, and TC0850, a protein of the type three secretion system, a family of proteins that allow gram-negative bacteria to inject virulence related proteins into the cytoplasm of a host cell. All antigens were shown to be partially protective with the putative outer membrane protein TC0512 showing an overall reduction in chlamydial burden of 55% and other antigens showing overall reductions in chlamydial burden of 26 - 44%. These antigens were also either capable of stimulating an immune response, or predicted to contain epitopes that may stimulate strong immune responses and so warrant further investigation as vaccine antigens to protect against chlamydial genital tract infections. The results of this research demonstrate that it is possible to identify novel vaccine targets through screening an expression library in a disease model. This study has identified several novel vaccine targets that are partially-protective against a C.muridarum infection and that are thought to be capable of stimulating strong immune responses. These antigens have high homology with C.trachomatis sequences, indicating that they have potential as vaccine candidates capable of protecting against the serovars of C.trachomatis that cause sexually transmitted infections in humans. Although the protection observed in this study was only partial, the immunization strategy utilised only fragments of the genes, an immunization mechanism known to elicit Th2 type immune responses, and no adjuvant to enhance the immunogenicity of the antigens. Through different immunization routes and in conjunction with adjuvants that stimulate Th1 type immune responses, complete protection against chlamydial genital tract infections may be achieved.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">chlamydia trachomatis</field><field name="subject">human sexually transmitted infection</field><field name="subject">vaccines</field><field name="subject">antigens</field><field name="subject">major outer membrane protein</field><field name="subject">C.muridarum genome</field><field name="identifier">http://eprints.qut.edu.au/16352/</field><field name="validLink">True</field></doc><doc><field name="title">The impact of socio-cultural factors upon human-centred design in Botswana</field><field name="creator">Moalosi, Richie</field><field name="description">This thesis explores the relationship between culture and human-centred design in Botswana, a topic on which there is little previous research. The pinnacle of good product innovation is when it is grounded on sensitive cultural analysis of users' culture; however, it has been observed that designers have not yet been able to encode cultural phenomena to the same extent as cognitive and physical human factors. The study develops a theoretical framework of cultural analysis, comparing traditional with contemporary socio-cultural factors that can be applied to designing products. The content analysis method was used to extract and synthesise traditional and contemporary socio-cultural factors from Botswana's cultural sources. An experimental study was undertaken in Botswana to investigate how socio-cultural factors can be integrated in product design, and the participants' challenge was to transfer and apply these into product features that reflect Botswana's culture. This data was analysed using the qualitative method of textual and visual content analysis.    A culture-orientated design model has been proposed to assist designers to consciously integrate culture in their design practice. The framework demonstrates how to specify, analyse and integrate socio-cultural factors in the early stages of the design process by advancing local thought, content and solutions. It advances a new approach to design education, theory, research and practice. It emerged that culture can be used as a resource of information and a source of inspiration for product innovation that connects with users' traditions. The research findings show that culture-orientated products have meaningful content that reflects users' lifestyles as well as providing them with symbolic personal, social and cultural values, and that these aspects facilitate product acceptance.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">culture</field><field name="subject">culture-orientated design model</field><field name="subject">emotional factors</field><field name="subject">human-centred design</field><field name="subject">material factors</field><field name="subject">novel design concepts</field><field name="subject">product acceptance</field><field name="subject">product design</field><field name="subject">product innovation</field><field name="subject">socio-cultural factors</field><field name="subject">social practices</field><field name="subject">technology/design factors</field><field name="subject">Botswana</field><field name="identifier">http://eprints.qut.edu.au/16353/</field><field name="validLink">True</field></doc><doc><field name="title">The effect of an experiential learning strategy on nursing students' knowledge and attitudes toward older people in Taiwan</field><field name="creator">Pan, I-Ju</field><field name="description">The aim of the research was to improve Taiwanese undergraduate nursing students' attitudes toward and knowledge about older people in order to encourage them to work with older people. People aged 65 and over currently make up 9.7% of the Taiwanese population (Department of Statistics 2006). With the increasing population of older people, health care professionals will have more experiences of caring for older people. However, an increasingly large body of literature suggests that most health care professionals have negative attitudes toward older people and little knowledge about older people. Studies from Western countries have indicated that attitudes toward and knowledge about older people can be improved through a variety of educational efforts.    Two studies were conducted to examine these issues. Study 1 involved a cross sectional survey of 302 nursing students from four-year and two-year programs in a university in southern Taiwan. Overall, the results showed that nursing students held positive attitudes toward older people but had poor knowledge about older people. Moreover, the findings suggested that nursing students' intention to work with older people and gender were important factors influencing their attitudes toward older people. Age, nursing program, and living with older people were the variables which made independent contributions to knowledge about older people.    Study 2 was a quasi-experimental design using pre-post tests with an intervention (experiental based learning) and control group (usual lecture based learning) (n = 60) to test the impact of a gerontological educational subject. Focus group data were also collected to examine students' reactions to the gerontological nursing subject and the experiential learning strategies used in an experiential-based learning group. The sample was students in the second semester of their second year from the same university used for Study 1. All 60 students were randomly assigned into either experiential-based learning or lecture-based learning groups for their gerontological nursing subject. The data were collected across three time points (pre-test, week 16 and week 20) using 2 validated instruments from Study 1. Qualitative data were also collected from the experimental group after students' clinical practice at week 20. In order to test for the effect of the intervention over time, repeated measures analysis of variance was used to determine the effectiveness of the experiential learning approach and clinical practice on each of the dependent variables of attitudes and knowledge. The results of Study 2 indicated that students' attitudes toward and knowledge about older people did not differ between the two groups In addition, there was no change in attitudes following the completion of the gerontological nursing subject. Students in both groups had improved their level of knowledge at the end of the gerontological subject. Therefore, the study hypotheses were not supported. Several factors such as lack of linkage between theoretical concepts and experience, the dominant 'exam culture', students' usual learning style and the structure of the program may explain the results. This was the first study which had introduced experiential learning into the selected university. It was necessary to conduct this initial study to understand the students' reaction to it. Therefore, based on the research findings from both the quantitative and qualitative results, the study indicates that additional studies are needed to continue exploring how experiential learning strategies may be used to improve students' attitudes toward and knowledge about older people.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">older people</field><field name="subject">attitudes</field><field name="subject">knowledge</field><field name="subject">undergraduate nursing students</field><field name="subject">gerontological nursing</field><field name="subject">experiential learning</field><field name="subject">lecture</field><field name="identifier">http://eprints.qut.edu.au/16354/</field><field name="validLink">True</field></doc><doc><field name="title">The experience of gynaecological cancer survivors : supportive care needs and use</field><field name="creator">Beesley, Vanessa Lea</field><field name="description">Gynaecological cancer survivorship has been addressed in only a limited body of research. After completion of treatment, women with gynaecological cancer face many challenges. It is pertinent that we understand the wellbeing and morbidity issues of this group of survivors, as well as their supportive care needs and use. With this understanding, it will be possible to better target health care initiatives and services to those gynaecological cancer survivors who require help. Accordingly, the objectives of this study were to determine the prevalence of site-specific morbidities, support being utilised, and unmet needs, as well as to determine the correlates of supportive care needs and use.  To address this, a cross-sectional mail survey of 1774 Queensland gynaecological cancer survivors three months to five years post-diagnosis was conducted in 2004 (56.5% response rate, n=802 of 1420 eligible participants). Women were recruited from the Queensland Gynaecological Cancer Registry, which covered approximately 85% of all gynaecological cancer patients in Queensland at the time of this study. The questionnaire measured a range of factors to reflect a social-ecological perspective. This broader perspective was utilised to extend the current understanding which is limited to a biopsychosocial approach.  Main outcomes were measured with standardised and validated instruments where possible, including the Supportive Care Needs Survey, Functional Assessment of Cancer Therapy, Duke-UNC Functional Social Support Questionnaire and the Active Australia Survey. The results of this survey showed that while quality of life was high on average (median 91, range 30-108), some women experienced debilitating site-specific conditions. Ten percent reported being diagnosed with lower limb lymphoedema and eight percent of women reported that their gynaecological cancer had made sexual relations too difficult or too uncomfortable. Women accessed multiple sources of support within their communities including a variety of support services (54%) and complementary therapies (29%). Characteristics associated with use of support services include: younger age, being retired, having been diagnosed with a gynaecological cancer other than uterine, having had open bowel resection, having been treated at multiple centres, being in remission, being obese. On average, women reported having excellent social support (median 37, range 8-40). Some women made changes to healthier behaviours following their cancer diagnosis, such as increasing their fruit and vegetable intake (23%) or physical activity levels (10%) or decreasing their alcohol consumption (24%) or cigarette smoking (10%); however, nearly half (44%) of women decreased their physical activity level. A population comparison of health behaviours between gynaecological cancer survivors and Queensland women highlighted the significantly lower level of sufficient physical activity and higher level of obesity in the cancer survivor population, as well as the low levels of adequate vegetable intake in both populations. Forty-three percent of gynaecological cancer survivors reported having at least one moderate or high level unmet supportive care need. In particular, needing help with fear about the cancer spreading, concerns about the worries of those close to them, uncertainty about the future, lack of energy/tiredness, and not being able to do things they used to do, were most important to this group. These leading need items were all within the psychological and physical/daily living supportive care domains. Some unmet sexuality and health system/information needs were also reported. Groups with higher odds of unmet needs included those women who more recently completed treatment, whose disease was still present, who had children still living in the home, who had diagnosed lymphoedema, who experienced treatment-related menopause, who were unable to work due to illness and who lived in rural and remote regions of Queensland. These results indicate that women with gynaecological cancer in Queensland are doing quite well overall; however, there is still room for improvement in a few key areas of public health importance. In line with the social-ecological model, resources need to be targeted at all levels of support including personal, social, health care and broader organisational, community, policy and media levels. In particular, the following recommendations are made:    1.	Assistance with the particular reported unmet psychological and physical/daily living needs is a priority. Support services should be tailored to the identified groups of survivors who had higher odds of unmet needs, both in terms of development of written materials that reflect these groups' circumstances and implementation of programs or workshops specific to these groups. In particular, the development of a number of programs or workshops are recommended that discuss the specific psychological and physical/ daily living outcomes of women who a) live with cancer, b) live with children after cancer treatment, c) live with lymphoedema, d) have had treatment-related menopause or e) are unable to work due to illness, and how and where women can get help with managing these. These programs should be implemented by support organisations in the period closely following treatment completion and should consider technologies such as video-conferencing to reach women who are in rural and remote areas. 2.	More specific written information for cancer survivors about things they can do to help themselves get well is needed, in lay-person friendly format. This information should address the value of particular dietary items, complementary therapies and types of physical activities that are safe and beneficial to cancer survivors' quality of life.  3.	An evidenced-based physical activity intervention, targeting overweight and obese gynaecological cancer survivors is recommended, to reduce the weight issues of this population. 4.	To facilitate the triage of cancer survivors to appropriate health care information and other support initiatives, cancer survivors' awareness of the Queensland Cancer Fund needs to be raised substantially. Practitioner education and discharge planning directives are recommended to ensure information about the Queensland Cancer Fund is disseminated.  5.	To address the substantially unmet information and physical/ daily living needs specific to lymphoedema sufferers, it is recommended that self-management information and referral information for suppliers and services for lymphoedema management be given to women in high lymphoedema risk groups, as part of the hospital discharge procedure, as well as when symptoms are diagnosed, to ensure a continuum of care is maintained.  6.	Clinical practice guidelines for cancer care and, correspondingly, support programs, need to expand from acute care to managing the long-term psychological, physical and sexual health consequences.  Several topics for research are likely to be important in the future, including more specific research into why uterine cancer survivors reported higher odds of unmet psychological needs and yet were less likely to use support services, what specific help women with unmet needs would prefer, the effects of lower limb lymphoedema on survivors' quality of life, and why there isn't greater use of existing support services, especially among women with morbidity such as lymphoedema and issues associated with treatment-related menopause.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Lymphoedema</field><field name="subject">Service use</field><field name="subject">Survival phases</field><field name="identifier">http://eprints.qut.edu.au/16355/</field><field name="validLink">True</field></doc><doc><field name="title">Robust thin layer coal thickness estimation using ground penetrating radar</field><field name="creator">Strange, Andrew Darren</field><field name="description">One of the most significant goals in coal mining technology research is the automation of underground coal mining machinery. A current challenge with automating underground coal mining machinery is measuring and maintaining a coal mining horizon. The coal mining horizon is the horizontal path the machinery follows through the undulating coal seam during the mining operation. A typical mining practice is to leave a thin remnant of coal unmined in order to maintain geological stability of the cutting face. If the remnant layer is too thick, resources are wasted as the unmined coal is permanently unrecoverable. If the remnant layer is too thin, the product is diluted by mining into the overburden and there is an increased risk of premature roof fall which increases danger.    The main challenge therefore is to develop a robust sensing method to estimate  the thickness of thin remant coal layers. This dissertation addresses this challenge by presenting a pattern recognition methodology to estimate thin remnant coal layer thickness using ground penetrating radar (GPR). The approach is based upon a novel feature vector, derived from the bispectrum, that is used to characterise the early-time segment of 1D GPR data.    The early-time segment is dominated by clutter inherent in GPR systems such as antenna crosstalk, ringdown and ground-bounce. It is common practice to either time-gate the signal, disregard the clutter by rendering the early-time segment unusable, or configure the GPR equipment to minimise the clutter effects which in turn reduces probing range. Disregarding the early-time signal essentially imposes a lower thickness limit on traditional GPR layer thickness estimators.    The challenges of estimating thin layer thickness is primarily due to these inherent clutter components. Traditional processing strategies attempt to minimise the clutter using pre-processing techniques such as the subtraction of a calibration signal. The proposed method, however, treats the clutter as a deterministic but unknown signal with additive noise. Hence the proposed approach utilises the energy from the clutter and monitors change in media from subtle changes in the signal shape.    Two complementary processing methods important to horizon sensing have been also proposed. These methods, near-surface interface detection and antenna height estimation, may be used as pre-validation tools to increase the robustness of the thickness estimation technique.    The proposed methods have been tested with synthetic data and validated with real data obtained using a low power 1.4 GHz GPR system and a testbed with known conditions. With the given test system, it is shown that the proposed thin layer thickness estimator and near-surface interface detector outperform the traditional matched filter based processing methods for layers less than 5 cm in thickness. It is also shown that the proposed antenna height estimator outperforms the traditional height estimator for heights less than 7 cm.    These new methods provide a means for reliably extending layer thickness estimation to the thin layer case where traditional approaches are known to fail.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">ground penetrating radar</field><field name="subject">finite-difference time-domain</field><field name="subject">coal mining</field><field name="subject">coal-rock interface</field><field name="subject">thin layer</field><field name="subject">thickness estimation</field><field name="subject">higher order spectra</field><field name="subject">bispectrum</field><field name="subject">signal processing</field><field name="subject">matched filter</field><field name="subject">pattern recognition</field><field name="subject">classification</field><field name="identifier">http://eprints.qut.edu.au/16356/</field><field name="validLink">True</field></doc><doc><field name="title">Strategies kindergarten teachers use to enhance children's musical creativity : case studies of three Hong Kong teachers</field><field name="creator">Lau, Margaret Wing Chi</field><field name="description">This study explored how kindergarten teachers think and behave in the promotion of creativity in young children, particularly in relation to music.  It centred on three case studies of Hong Kong kindergarten teachers (nursery, lower and upper class) who were recognized in their school communities as demonstrating exemplary music pedagogy.  Using the paradigm of social constructivism, relationships were investigated among creative person, process, product and environment in the promotion of musical creativity in early childhood.  Multi-faceted descriptions of the kindergarten contexts included video-taped transcriptions of children's musical creative processes during free play, the teachers' scaffolding of their learning, stimulated recall with teachers, researcher-collected field notes, anecdotal records and photographs of the classroom context.  Each of these data sources were documented in narrative form in a series of vignettes, and analysis of musical outcomes centred on instrumental play, background music, movement, singing and imaginative play.  Recommendations drawn from the study include several principles for the promotion of musical creativity in young children, such as making room for play within the curriculum, providing environments rich in resources, scaffolding young children's musical creativity, advocating for creative music in the kindergarten curriculum, and providing excellent role models for young children.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">teachers</field><field name="subject">creativity</field><field name="subject">pedagogy</field><field name="subject">music</field><field name="subject">kindergarten</field><field name="subject">Hong Kong</field><field name="subject">constructivism</field><field name="subject">case study</field><field name="identifier">http://eprints.qut.edu.au/16357/</field><field name="validLink">True</field></doc><doc><field name="title">Statistical reasoning at the secondary tertiary interface</field><field name="creator">Wilson, Therese Maree</field><field name="description">Each year thousands of students enrol in introductory statistics courses at universities  throughout Australia, bringing with them formal and informal statistical knowledge and reasoning, as well as a wide range of basic numeracy skills, mathematical inclinations and attitudes towards statistics, which have the potential to impact on their ability to develop statistically. This research develops and investigates measures of each of these components for students at the interface of secondary and tertiary education, and investigates the relationships that exist between them, and a range of background variables. The focus of the research is on measuring and analysing levels and abilities in statistical reasoning for a range of students at the tertiary interface, with particular interest also in investigating their basic numeracy skills and how these may or may not link with statistical reasoning allowing for other variables and factors. Information from three cohorts in an introductory data analysis course, whose focus is real data investigations, provides basis for the research. This course is compulsory for all students in degree programs associated with all sciences or mathematics.    The research discusses and reports on the development of questionnaires to measure  numeracy and statistical reasoning and the students' attitudes and reflections on their  prior school experiences with statistics. Students' attitudes are found to be generally positive, particularly with regard to their self-efficacy. They are also in no doubt as to the links that exist between mathematics and statistics. The Numeracy Questionnaire, developed to measure pre-calculus skills relevant to an introductory data analysis course which emphasises real data investigations, demonstrates that many students who have completed a basic algebra and calculus senior school subject struggle with skills which are in the pre-senior curricula. Direct examination of the responses helps to understand where and why difficulties tend to occur. Rasch analysis is used to validate the questionnaire and assist in the description of levels of skill. General linear models demonstrate that a student's numeracy score depends on the result obtained in senior mathematics, whether or not the student is a mathematics student, gender, whether or not higher level mathematics has been studied, self-efficacy and year. The research indicates that either the pre-senior curricula need strengthening or that exposure to mathematics beyond the core senior course is required to establish confidence with basic skills particularly when applied to new contexts and multi- step situations.    The Statistical Reasoning Questionnaire (SRQ) is developed for use in the Australian  context at the secondary/tertiary interface. As with the Numeracy Questionnaire, detailed examination of the responses provides much insight into the range and features of statistical reasoning at this level. Rasch analyses, both dichotomous and polychotomous, are used to establish the appropriateness of this instrument as a measuring tool at this level. The polychotomous, Rasch partial credit model is also used to define a new approach to scoring a statistical reasoning instrument and enables development and application of a hierarchical model and measures levels of statistical reasoning appropriate at the school/tertiary interface.    General linear models indicate that numeracy is a highly significant predictor of statistical reasoning allowing for all other variables including tertiary entrance score and students' backgrounds and self-efficacy. Further investigation demonstrates that this relationship is not limited to more difficult or overtly mathematical items on the SRQ.    Performance on the end of semester component of assessment in the course is shown to depend on statistical reasoning at the beginning of semester as measured by the partial credit model, allowing for all other variables. Because of the dominance of the relationship between statistical reasoning (as measured by the SRQ) and numeracy on entry, some further analysis of the end of semester assessment is carried out. This includes noting the higher attrition rates for students with less mathematical backgrounds and lower numeracy.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">statistical reasoning</field><field name="subject">statistical thinking</field><field name="subject">statistical literacy</field><field name="subject">numeracy</field><field name="subject">secondary/tertiary interface</field><field name="subject">Rasch analysis</field><field name="subject">partial credit model</field><field name="subject">attitudes towards statistics</field><field name="subject">self-efficacy</field><field name="subject">assessment</field><field name="subject">statistical education</field><field name="subject">introductory data analysis course</field><field name="subject">mathematical thinking</field><field name="identifier">http://eprints.qut.edu.au/16358/</field><field name="validLink">True</field></doc><doc><field name="title">Generation of network-based differential corrections for regional GNSS services</field><field name="creator">Zheng, Yi</field><field name="description">Network-based Differential GPS (DGPS), regardless of its global, regional or local  scales, is enabling technology to improve GPS positioning accuracy from tens of  meters, to the levels of meters, decimetres and centimetres level in real time,  depending on geographical coverage of the network and measurement types. The  method is to use the data from a permanent network of reference stations to  model errors due to inaccurate GPS satellite orbit ephemeris and clock data,  ionospheric and tropospheric effects as well as other GPS satellite and receiver  biases. Then error correction messages can be sent to users via any communication  link in real time.  This PhD research involves algorithm development for generating satellite orbit  and tropospheric delay corrections using a regional or local reference network,  especially tropospheric grid corrections, which have not been included in the  existing DGPS correction vector messages, for the next generation of regional  GNSS positioning services. Contributions of the research are made in the following  three areas:  First of all, research has been undertaken to test orbit interpolation methods, in  order to represent GPS orbits and orbital corrections accurately and efficiently for  (near) real-time GPS applications. For precise and predicted GPS orbits given in  SP3 format and orbital corrections with respect to the broadcast ephemeris,  numerical tests were conducted using different terms of Lagrange, Chebyshev and  trigonometric polynomial functions.  Secondly, this research has implemented a short-arc (9-hour) sliding-window  orbit monitoring strategy to identify larger orbit errors in the predicted part of  IGS ultra-rapid orbit solutions in near real time, using GPS tracking data from a  regional network around Australia. The strategy is to predict the uncertainty  estimates of each orbit over a short orbit arc in near real time, which allows  users to down-weight the problematic satellites and reduces the effects of orbital errors for improved near real time ZTD estimation. Unlike long-arc orbit determination,  we only estimate 6 orbital elements for each satellite.  Finally, this research has proposed a new tropospheric delay correction model,  which uses the Ordinary Kriging (OK) method to interpolate the residual ZTD  within a regional area GPS network to improve the positioning accuracy. ZTD  estimates from 129 EUREF Permanent Network (EPN) stations across Europe for  over 3 months and from 17 GPSnet reference stations (Victoria, Australia) for  one week were collected and processed for this study, respectively. It is concluded  that interpolating residual ZTD is an efficient way to improve regional area  differential GPS positioning.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">network-based</field><field name="subject">regional GNSS</field><field name="subject">GPS</field><field name="subject">DGPS</field><field name="identifier">http://eprints.qut.edu.au/16359/</field><field name="validLink">True</field></doc><doc><field name="title">Experience, context-of-use and the design of product usability</field><field name="creator">Chamorro-Koc, Marianella</field><field name="description">This study argues that including aspects of user experience relevant to the user's knowledge of a product's context-of-use in the early stages of product design can enhance the design of product usability. To explore these issues, research was undertaken to respond to three research questions: (i) What aspects of user experience influence people's understanding of product usability? (ii) What is the nature of the differences between users' and designers' understandings of product usability? (iii) How can context-of-use and human experience enhance the design of product usability? Findings from the study have shown that experience, context-of-use and knowledge about a product's usability are interrelated. Conceptual principles and design principles were established based on findings to explain (i) the relationships between aspects of experience and areas of product usability and (ii) differences between designers' and users' concepts of product usability. These principles responded to the first two research questions. Causal relationships found between experience and product usability suggested the need to implement them in an accessible manner for a product design process. A design tool -- named the Experience and Context Enquiry Design Tool (ECEDT) -- was devised to exemplify the implementation of findings. A trial run verified that the type of information that ECEDT brings to designers could assist them to address usability and experience issues during the early stages of the design process. This result responded to the third research question of the study.    This study's conceptual principles and design principles contribute new knowledge to design theory and practice. This knowledge contributes to design theory in providing greater detail about the differences between designers and users than that addressed by existing theory; it contributes to design practice as it informs designers about the aspects of human experience that prompt users' understanding of a product's use. In doing so, it can potentially assist in the design of products that embed new technological applications, and support the design of product usability.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">experience</field><field name="subject">context-of-use</field><field name="subject">usability</field><field name="subject">design of product usability</field><field name="subject">user&#150;product interaction</field><field name="subject">visual representation of concepts</field><field name="subject">product design</field><field name="subject">user concept</field><field name="subject">designer concept</field><field name="identifier">http://eprints.qut.edu.au/16360/</field><field name="validLink">True</field></doc><doc><field name="title">The space of editing : playing with difference in art, film and writing</field><field name="creator">Stevens, Grant William</field><field name="description">This research project explores the creative and critical functions of editing in art, film and writing. The written component analyses the histories and discourses of 'cutting and splicing' to examine their various roles in processes of signification. The artistic practice uses more speculative and open-ended methods to explore the social 'languages' that inform our inter-subjective experiences. This project argues that editing is a creative methodology for making meaning, because it allows existing symbolic systems to be appropriated, revised and rewritten. By emphasising the operations of spacing, questioning and play, it also identifies editing as an essential tool for critically engaging with the potentials of art and theory.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">art</field><field name="subject">collage</field><field name="subject">creative practice</field><field name="subject">cutting</field><field name="subject">deconstruction</field><field name="subject">Derrida</field><field name="subject">difference</field><field name="subject">editing</field><field name="subject">Eisenstein</field><field name="subject">film</field><field name="subject">graft</field><field name="subject">grammatology</field><field name="subject">language</field><field name="subject">montage</field><field name="subject">play</field><field name="subject">postproduction</field><field name="subject">post-structuralism</field><field name="subject">signification</field><field name="subject">spacing</field><field name="subject">splicing</field><field name="subject">structuralism</field><field name="subject">text</field><field name="subject">trace</field><field name="subject">video</field><field name="subject">writing</field><field name="identifier">http://eprints.qut.edu.au/16361/</field><field name="validLink">True</field></doc><doc><field name="title">The role of annual reports in a system of accountability for public fundraising charities</field><field name="creator">Flack, Edmund Douglas</field><field name="description">Charities are important in modern Australian society because they provide a substantial proportion of the health, community welfare, education and religious services available in the community (Australian Bureau of Statistics 2002). Yet despite their social and economic importance, charities are often characterised in the media as being less accountable than either for-profit entities or government sector organisations. Annual reports are widely regarded as an important means of acquitting accountability in the corporate and government sectors and may be one of the means by which charities can improve stakeholders' perceptions of their accountability. Yet little is known of the annual reporting behaviours of charities or whether annual reports have the potential for improving perceptions of accountability among their stakeholders and the wider community.    This research focuses on a class of charities termed &amp;quotpublic fundraising charities" (those that raise funds from the public rather than just their members), and the role that annual reports play in acquitting accountability and improving perceptions. The research uses a new combination of theories that have previously been used separately to explain accountability and annual reports in other sectors, and using the insights from these theories, examines the role of annual reports in a population of public fundraising charities in Queensland.    The major findings of this research are that annual reports have both functional and symbolic roles in the system of accountability of public fundraising charities.  Functionally, annual reports are a useful and generally valued means by which public fundraising charities communicate a wide range of types of information about their activities and their performance to interested parties. Symbolically, annual reports also serve as an important signal of assurance to those who receive them.  For those who prepare them, annual reports serve as useful signals of managerial and governance competence to those whose opinion is salient to preparers. Annual reports also have a role in the system of accountability for the maintenance of the mission of these organisations, in ways that statutory reports and returns do not. This research makes three original contributions to the literature. First, it provides for the first time a detailed analysis of the role of annual reports in a system of accountability for public fundraising charities in Australia. Second, a new theoretical lens is proposed and tested for its descriptive and explanatory power in the examination the accountability of nonprofit organisations. Third, it makes an original contribution to accountability theory by identifying the importance of the annual report as a quality signaling device. The results of this research will be of use to public fundraising charities, regulators and policy makers, as they respond to the calls for charities to demonstrate that they are accountable.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">nonprofit organisations</field><field name="subject">charities</field><field name="subject">accountability</field><field name="subject">annual Reports</field><field name="subject">regulation</field><field name="subject">fundraising</field><field name="identifier">http://eprints.qut.edu.au/16362/</field><field name="validLink">True</field></doc><doc><field name="title">Multimodal design for hybrid course materials : developing and evaluating a new paradigm for course delivery</field><field name="creator">Sankey, Michael David</field><field name="description">In early 2003, in a major shift in policy, the University of Southern Queensland  (USQ) announced that its learning materials would progressively move from a  predominantly print-based mode of delivery to a new 'hybrid' mode of delivery  across all discipline areas. Central to this delivery would be a resource-rich CDROM  containing all study materials, supported with a range of multimedia based  enhancements, online support and selective print materials.  As this represented a fundamentally new approach to the delivery of materials  at USQ, it was essential to ascertain a clear understanding of about the implications  of this change for student learning. In implementing this policy it was necessary to  establish a range of pedagogically sound, cost effective delivery guidelines, for the  development of the course materials and the multimedia based enhancements. In  response to this need, this study has developed a set of 10 multimodal design  heuristics used to guide the development of these materials. In establishing these  guidelines, this thesis contextualises important issues associated with hybrid delivery  and considers how catering for a multiliterate clientele by using a combination of  multimedia based enhancements in an electronic environment may improve the  learning opportunities for students.  Two Faculty of Business courses delivered in 2004, ECO2000  'Macroeconomics for Business and Government' and MGT2004 'People  Development', were chosen to pilot the new hybrid mode of delivery. The  combination of qualitative and quantitative approaches was used to investigate how  students have utilised this new environment. This approach rendered a clear  indication of student views about the CD based delivery and, more particularly, an appreciation of how they utilised the multimedia based enhancements to augment  their studies.  Analysis of the research data indicated a strong acceptance of the CD based  learning environment. This was particularly true for off-campus and international  students. On the whole, students reported a preference for a CD based resource,  though this acceptance was moderated by a desire to still receive some print-based  materials. Importantly, from this analysis it was possible to add a further four  multimodal design heuristics to the original set of ten which informed the design of  the multimedia based enhancements for each course.  This study demonstrates that higher levels of student engagement are possible  when integrating a range of multimedia based enhancements to cater for a range of  student learning modalities, whilst also maintaining a balanced environment for more  traditional learners1.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">multimodal design</field><field name="subject">multimedia</field><field name="subject">distance education</field><field name="subject">hyperlinking</field><field name="subject">design heuristics</field><field name="identifier">http://eprints.qut.edu.au/16363/</field><field name="validLink">True</field></doc><doc><field name="title">Sharing stories : problems and potentials of oral history and digital storytelling and the writer/producer's role in constructing a public place</field><field name="creator">Klaebe, Helen Grace</field><field name="description">The Kelvin Grove Urban Village (KGUV) is a 16-hectare urban renewal redevelopment project of the Queensland Department of Housing and the
 
 Queensland University of Technology (QUT). Over the last century, the land has housed military and educational institutions that have shaped Brisbane and Queensland. These groups each have their own history. Collectively their stories represented an opportunity to build a multi-art form public history project, consisting of a creative non-fiction historical manuscript and a collection of digital stories (employing oral history and digital storytelling techniques in particular) to construct a personal sense of place, identity and history. This exegesis examines the processes used and difficulties faced by the writer/producer of the public history; including consideration of the artistic selection involved, and consequent assembly of the material. The research findings clearly show that: giving contributors access to the technology required to produce their own digital stories in a public history does not automatically equate to total participatory inclusion; the writer/producer can work with the public as an active, collaborative team to produce shared historically significant works for the public they represent; and the role of the public historian is that of a valuable broker--in actively seeking to maximize inclusiveness of vulnerable members of the community and by producing a selection of multi-art form works with the public that includes new media.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Kelvin Grove Urban Village</field><field name="subject">Kelvin Grove</field><field name="subject">Gona Barracks</field><field name="subject">Australian history</field><field name="subject">creative non fiction</field><field name="subject">creative writing</field><field name="subject">life writing</field><field name="subject">non fiction</field><field name="subject">digital storytelling</field><field name="subject">oral history</field><field name="subject">social history</field><field name="subject">public history</field><field name="subject">writing processes</field><field name="identifier">http://eprints.qut.edu.au/16364/</field><field name="validLink">True</field></doc><doc><field name="title">Narratives beyond civility : moral protest and cooperation in ethical communities</field><field name="creator">Palmer, Victoria Jane</field><field name="description">In spite of the rhetoric of partnership and collaboration in the Australian community sectors, economic values of competition have superseded social and co-operative values of self-help, empowerment, mutual benefit and solidarity.  Reconfiguration of how co-operative practices can be understood in terms of social capital theory and civil society has been of limited success in countering this slide to economic rationalism.  Ironically, many community practices, including co-operatives, explicitly emerged from moral protest against prevailing oppressive policies; that is co-operative and community development practices exist to embody an alternative set of values to oppressive features of dominant political and social institutions of the day.    This thesis identifies and analyses the features of co-operative practices which resist economic capture by the dominant ideology of neo-liberalism.  It examines how co-operative practices can be analysed as forms of moral protest that offer and embody counterstories to master narratives that shape dominant institutions.  Importantly, it is understood that not all forms of moral protest are socially transformative.  While fostering social change, co-operatives must also resist ossification of their own principles and practices into homogenised traditions that exclude rather than include others.    To conduct this analysis, interviews were conducted with subjects engaged in co-operative activities. H. L. Nelson's (2001) narrative approach to ethics was used to identify how co-operatives can be positioned as counterstories to dominant narratives.    T. Cooper's (1997) distinction between moral and ethical communities was then deployed to account for the features of co-operative practice that might lead to exclusion and non-co-operative identities. Finally, A.W. Frank's (1995) body-self type continuum was applied to co-operative practices to further evaluate the degree to which those who participated in these saw themselves contributing to practices of social transformation or defensive strategies of personal survival.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">narrative</field><field name="subject">civility</field><field name="subject">moral protest</field><field name="subject">ethical communities</field><field name="identifier">http://eprints.qut.edu.au/16365/</field><field name="validLink">True</field></doc><doc><field name="title">Minimising track degradation through managing vehicle/track interaction</field><field name="creator">Hawari, Haitham M.</field><field name="description">The rate at which a railway track deteriorates depends on the response of the track  under different static and repeated dynamic forces. These wheel/rail forces lead to  imperfections in the rail surface and deviation in track geometry alignment. The  wheel/rail forces are dependent upon the quality of maintenance of the  characteristics of both train and track. If train components such as wheelsets and  suspensions are maintained to a high standard, less dynamic forces are generated  at the wheel/rail interface and less damage is caused over time. Therefore, the  amount and cost of maintenance of track are reduced. However, there is little  known about how the characteristics of train components affect time-dependent  track degradation.  Track degradation through deviation of track from its ideal position has the most  effect on maintenance costs. Therefore, the present research aims to investigate  this track degradation and improve understanding of the effects of train  characteristics (such as train mass and speed, suspension stiffness and damping)  on railway tracks. The research is conducted by looking into the relationship  between wheel/rail forces and track degradation on one hand and between  wheel/rail forces and train characteristics on the other hand, with the objective of  assisting in managing vehicle/track interaction in order to minimise track  degradation. This aim is achieved by investigating the above two relationships to  attain the desired relationship between track degradation and train characteristics.  The research focuses on wheel/rail vertical forces (both amplitudes and  frequencies), vertical track alignment (longitudinal vertical profile), and rail head  defects.  The study started by collecting wheel/rail vertical forces data in addition to data  on vertical track degradation under sustained traffic loads on a heavy haul railway section of track in Central Queensland. Also, five years of degradation and  maintenance history data were collected on three other test sections of railway  track under variety of traffic conditions and loads in Central Queensland. There  were four main analyses of this data employed to probe the study. The first  analysis was performed by examining the track degradation history data. The  standard deviation method was used in this first analysis to acquire the rate of  deterioration in terms of its relationship to track profile (roughness). The second  analysis was accomplished by correlating the vertical wheel/rail forces to both  vertical track profile and rail roughness using signal processing principles and a  function know as coherence. The third analysis was carried out by using the  computer simulation software NUCARS to obtain the link between wheel/rail  forces and the deterioration of the vertical track profile. The fourth analysis was  achieved by combining the results obtained from the above three analyses to  acquire the rate of track deterioration in terms of its relationship to varying train  characteristics.  The first analysis mentioned above quantified the relationship between the level of  roughness of the track and rate at which that roughness deteriorated. An important  outcome of this relationship is that there is a threshold of roughness below which  track deterioration is minimal. The track maintenance planners can now use that  threshold for cost effective targeting of tamping activities. The correlation study  between track roughness and wheel/rail forces using the coherence function  found, surprisingly, that the overall deterioration of the track roughness, in the  absence of frequencies of forces above 30 Hz, is due to the so-called quasi-static  lower frequency oscillations of dynamic forces. This conclusion together with the  relationship between vehicle characteristics and track forces, established in the  analyses above, has significant implications for the design of wagon bogies and  for charges track owners might levy on trains using their tracks.  This research is part of a larger Rail CRC project 11/4 called 'Enhancing the  Optimisation of Maintenance/Renewal' being carried out in the School of Urban  Development in Queensland University of Technology.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">railway track</field><field name="subject">vertical forces</field><field name="subject">vertical profile</field><field name="subject">rail roughness</field><field name="subject">train characteristics</field><field name="subject">vehicle/track interaction</field><field name="subject">track degradation or deterioration</field><field name="subject">track maintenance</field><field name="subject">coal wagon</field><field name="subject">track recording vehicle (TRV)</field><field name="subject">corrugation analysis trolley (CAT)</field><field name="subject">signal processing techniques</field><field name="subject">coherence correlation</field><field name="subject">NUCARS</field><field name="subject">rate of deterioration</field><field name="identifier">http://eprints.qut.edu.au/16366/</field><field name="validLink">True</field></doc><doc><field name="title">Promoted ignition testing : an investigation of sample geometry and data analysis techniques</field><field name="creator">Suvorovs, Terese</field><field name="description">Metallic materials and oxygen can be a volatile combination when accompanied by  ignition mechanisms. Once ignited, metallic materials can readily burn in high pressure  oxygen atmospheres, releasing an enormous amount of energy and potentially  destroying equipment, space missions and resulting in the loss of life. The potential  losses associated with these fires led to research into the conditions under which metal  fires propagate. Several organisations, including the American Society for Testing  and Materials (ASTM) and the International Organisation for Standardisation (ISO),  have published recommended standard test practices with which to assess the relative  flammability of metallic materials. These promoted ignition tests, so called because  samples are ignited with an overwhelming source of energy, are typically used to examine  two important parameters as an indication of a metallic material's flammability:  Threshold Pressure (TP) and the Regression Rate of the Melting Interface (RRMI). A  material's TP is the minimum pressure at which it burns, therefore, TPs of different  materials can be compared to assess which materials are most suited for a range of  high pressure applications. The RRMI is a useful measure for ranking materials, particularly  if they have the same TP, but can be used as a ranking method irrespective of  TP. In addition, it is a crucial parameter to aid in understanding the complex burning  process and is one of the few experimental parameters that can be measured.  Promoted ignition test standards specify a standard sample geometry to use when  performing the test, typically a 3.2 mm diameter cylindrical rod. The recent addition  of a 3.2 &#215; 3.2 mm square rod as an optional standard sample geometry raises  the issue of how the geometry of a sample affects its flammability. Promoted ignition  test results for standard geometries are often applied to assess the flammability  risk for the complex geometries of real components within oxygen systems, including  regulators, valves, piping etc. Literature shows that sample geometry has a significant  effect on material rankings when rankings are based on testing of standard geometries,  for example, cylindrical rods, compared to non-standard geometries, for example, sintered  filters and meshes. In addition, the RRMI has been shown to be dependent on a sample's cross-sectional area (XA). However, it remains unclear, from a simple heat  transfer analysis, why the RRMI is dependent on XA or how the shape of a sample  affects its melting rate. These questions are particularly relevant since understanding  how sample geometry affects burning contributes to two important research goals: to  be able to accurately model and predict the flammability risk of a metallic component  without the need for physical testing, and to understand the effects of different sample  geometries on their relative flammabilities within the standard tests used.  Promoted ignition tests were conducted on iron rods with cylindrical, rectangular  and triangular cross sections for a range of XAs. Their RRMIs were measured and  analysed using a statistical approach which allowed differences in RRMI to be quantitatively  assessed. Statistically significant differences in RRMI were measured for rods  with the same XA but of different shape. Furthermore, the magnitude of the difference  was dependent on XA. Triangular rods had the fastest RRMIs, followed by rectangular  rods and then cylindrical rods. Differences in RRMI based on rod shape are due to heat  transfer effects and the dynamic motion of the attached molten mass during the drop  cycle. The corners of the rectangular and triangular rods melt faster due to their locally  higher Surface Area to Volume ratio (SA/V). This dynamic effect increases the area of  contact between the molten mass and the solid rod (solid liquid interface (SLI)) which  facilitates increased heat transfer to the rod resulting in a faster RRMI. This finding  highlights the importance of the SLI in the heat transfer process. Although the SLI is  largely dependent on the XA, the shape of the rod causes subtle changes to the size of  the SLI and thus affects heat transfer, burning and observed RRMI.  The relationship between rod diameter, test pressure and Extent of Reaction (ER),  the proportion of metal that reacts (oxidises) whilst attached to the burning rod, was  investigated. During promoted ignition testing of iron rods of varying diameter the  detached drops were rapidly quenched by immersion in a water bath. Microanalysis  techniques were used to qualitatively assess the ER as a function of pressure and  rod diameter. It was found that the pressure dramatically affects ER. High pressure  tests resulted in a slag mass consisting of oxide, with no unreacted iron, whereas low  pressure tests resulted in a significant fraction of unreacted iron within the slag. This  indicates that the ER contributes directly to the observed increase in RRMI with increasing  test pressure. At high pressures the ER is not affected by rod diameter, since  all available liquid metal reacted, but at low pressures ER is a function of rod diameter,  ER decreases as XA increases.  This thesis also investigates the analysis of promoted ignition test data through suitable statistical methods. Logistic regression is identified as an appropriate method  for modelling binary burn/no-burn test data. The relationship between the reaction  probability, defined as the probability that a sample will undergo sustained burning,  and pressure, is evaluated for two different data sets. The fits of the logistic regression  models are assessed and found to model the available data well. The logistic regression  method is contrasted with the confidence levels associated with binary data based  on the Bernoulli distribution. It is concluded that a modelling approach is beneficial  in providing an overall understanding of the transition between pressures where no  burning occurs and pressures where burning is expected.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">promoted ignition</field><field name="subject">sample geometry</field><field name="subject">metallic material</field><field name="subject">oxygen</field><field name="subject">iron</field><field name="subject">burning</field><field name="subject">combustion</field><field name="subject">flammability</field><field name="subject">statistics</field><field name="subject">logistic regression</field><field name="subject">confidence interval</field><field name="subject">microanalysis</field><field name="identifier">http://eprints.qut.edu.au/16367/</field><field name="validLink">True</field></doc><doc><field name="title">Rational avoidance of accountability by Queensland governments</field><field name="creator">Lauchs, Mark Adam</field><field name="description">Anthony Downs public choice theory proposes that every rational person would try to meet their own desires in preference to those of others, and that such rational persons would attempt to obtain these desires in the most efficient manner possible. This thesis submits that the application of this theory would mean that public servants and politicians would perform acts of corruption and maladministration in order to efficiently meet their desires. As such action is unavoidable, political parties must appear to meet the public demand for accountability systems, but must not make these systems viable lest they expose the corruption and maladministration that would threaten the government&#8217;s chance or re-election. The thesis demonstrates this hypothesis through a study of the history of the public sector in Queensland. It shows that all governments have displayed a commitment for accountability whilst simultaneously ensuring the systems would not be able to interfere with government control or expose its flaws.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Queensland history</field><field name="subject">public sector ethics</field><field name="subject">accountability</field><field name="subject">public service</field><field name="subject">Anthony Downs</field><field name="subject">public choice theory</field><field name="subject">public service reform</field><field name="subject">freedom of information</field><field name="subject">whistleblowers</field><field name="subject">Integrity Commissioner</field><field name="subject">Criminal Justice Commission</field><field name="subject">Electoral and Administrative Review Commission</field><field name="subject">Public Service Commissioner</field><field name="identifier">http://eprints.qut.edu.au/16368/</field><field name="validLink">True</field></doc><doc><field name="title">The role of urothelium in induced ossification in skeletal muscle</field><field name="creator">Podagiel, Christopher</field><field name="description">It is a well established phenomenon that the epithelial lining of the urinary bladder  (urothelium) when implanted into skeletal muscle induces ectopic ossification. However,  despite numerous observations, this reaction is poorly understood. This research further  studied this reaction by - (a) demonstrating the reaction in a suitable small animal model;  (b) attempting to induce the reaction by implanting urothelial cells purified by cell  culture techniques; and (c) comparing the bone forming reaction induced by implanted urothelium to the reaction induced by implanting Bone Marrow Stem Cells (BMSC's) and Osteophyte Stem Cells (OSC's). By demonstrating newly formed bone after the implantation of guinea pig urothelium into the skeletal muscle of a Severe Combined Immuno-Deficient Mouse (SCID-Mouse) this research demonstrated that a suitable small animal model had been established. This is despite inherent difficulties (particularly bacterial contamination) associated with establishing a primary cell culture of guinea pig urothelial cells. Additionally, the intramuscular ectopic osteoinductive potential of human BMSC's (hBMSC's) in the SCID-mouse has also been demonstrated. Confirming that the injection of cultured cells in suspension is an adequate intramuscular delivery technique, this research demonstrates that hBMSC's induce ectopic ossification by non-immunological means. This research has demonstrated a number of differences between urothelium induced ectopic ossification and ectopic ossification induced by BMSC's, suggesting they are two separate processes. This is important because the chemotaxis and subsequent osteogenic differentiation of BMSC's has previously been one of the more popular postulated mechanisms of urothelium induced ectopic ossification. Finally, this research has demonstrated the ectopic osteoinductive potential of stem cells isolated from the marrow of human osteophytes (human Osteophyte Stem Cells, hOSC's). This observation has not been previously reported, and will hopefully provide a valuable contribution to a body of knowledge that has important ramifications in both the treatment of osteoarthritis, and the use of BMSC's in tissue engineering.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">urothelium</field><field name="subject">ectopic ossification</field><field name="subject">skeletal muscle</field><field name="subject">epithelial mesenchymal transition</field><field name="subject">bone marrow stem cell</field><field name="identifier">http://eprints.qut.edu.au/16369/</field><field name="validLink">True</field></doc><doc><field name="title">Producing literacy practices that count for subject English</field><field name="creator">Nicolson-Setz, Helen Ann</field><field name="description">This thesis presents a study of the production of literacy practices in Year 10 English lessons in a culturally diverse secondary school in a low socio-economic area. The study explored the everyday interactional work of the teacher and students in accomplishing the literacy knowledge and practices that count for subject English. This study provides knowledge about the learning opportunities and literacy knowledge made available through the interactional work in English lessons. An understanding of the dynamics of the interactional work and what that produces opens up teaching practice to change and potentially to improve student learning outcomes. 
 
 
 
 This study drew on audio-recorded data of classroom interactions between the teacher and students in four mainstream Year 10 English lessons with a culturally diverse class in a disadvantaged school, and three audio-recorded interviews with the teacher. This study employed two perspectives: ethnomethodological resources and Bernsteinian theory. The analyses of the interactional work using both perspectives showed how students might be positioned to access the literacy learning on offer. In addition, using both perspectives provided a way to associate the literacy knowledge and practices produced at the classroom level to the knowledge that counted for subject English. 
 
 
 
 The analyses of the lesson data revealed the institutional and moral work necessary for the assembly of knowledge about literacy practices and for constructing student-teacher relations and identities. Documenting the ongoing interactional work of teacher and students showed what was accomplished through the talk-in-interaction and how the literacy knowledge and practices were constructed and constituted. The detailed descriptions of the ongoing interactional work showed how the literacy knowledge was modified appropriate for student learning needs, advantageously positioning the students for potential acquisition.
 
 
 
 The study produced three major findings. First, the literacy practices and knowledge produced in the classroom lessons were derived from the social and functional view of language and text in the English syllabus in use at that time. Students were not given the opportunity to use their learning beyond what was required for the forthcoming assessment task. The focus seemed to be on access to school literacies, providing students with opportunities to learn the literacy practices necessary for assessment or future schooling. Second, the teacher&#8217;s version of literacy knowledge was dominant. The teacher&#8217;s monologues and elaborations produced the literacy knowledge and practices that counted and the teacher monitored what counted as relevant knowledge and resources for the lessons. The teacher determined which texts were critiqued, thus taking a critical perspective could be seen as a topic rather than an everyday practice. Third, the teacher&#8217;s pedagogical competence was displayed through her knowledge about English, her responsibility and her inclusive teaching practice. The teacher&#8217;s interactional work encouraged positive student-teacher relations. The teacher spoke about students positively and constructed them as capable. Rather than marking student ethnic or cultural background, the teacher responded to students&#8217; learning needs in an ongoing way, making the learning explicit and providing access to school literacies. 
 
 
 
 This study&#8217;s significance lies in its detailed descriptions of teacher and student work in lessons and what that work produced. It documented which resources were considered relevant to produce literacy knowledge. Further, this study showed how two theoretical approaches can be used to provide richer descriptions of the teacher and student work, and literacy knowledge and practices that counted in English lessons and for subject English.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">literacy practices</field><field name="subject">cultural diversity</field><field name="subject">English education</field><field name="subject">literacy policy</field><field name="subject">genre pedagogy</field><field name="subject">critical literacy</field><field name="subject">talk-in-interaction</field><field name="subject">ethnomethodology</field><field name="subject">conversation analysis</field><field name="subject">membership categorisation analysis</field><field name="subject">Bernsteinian theory</field><field name="subject">pedagogic discourse</field><field name="subject">vertical discourse</field><field name="identifier">http://eprints.qut.edu.au/16370/</field><field name="validLink">True</field></doc><doc><field name="title">Inventing cultural heroes : a critical exploration of the discursive role of culture, nationalism and hegemony in the Australian rural and remote health sector</field><field name="creator">Fitzpatrick, Lesley Maria Gerard</field><field name="description">Rural and remote areas of Australia remain the last bastion of health disadvantage in a developed nation with an enviable health score-card. During the last ten years, rural and remote health has emerged as a significant issue in the media and the political arena.  This thesis examines print media, policy documents and interviews from selected informants to ascertain how they represent medical practitioners and health services in rural and remote areas of Australia, why they do so, and the consequences of such positions. In many of these representations, rural and remote medical practitioners are aligned with national and cultural mythologies, while health services are characterised as dysfunctional and at crisis point. 	Ostensibly, the representations and identity formulations are aimed at redressing the health inequities in remote rural and Australia. They define and elaborate debates and contestations about needs and claims and how they should be addressed; a process that is crucial in the development of professional identity and power (Fraser; 1989).  The research involves an analysis and critical reading of the entwined discourses of culture, power, and the politics of need. Following Wodak and others (1999), these dynamics are explored by examining documents that are part of the discursive constitution of the field. In particular, the research examines how prevailing cultural concepts are used to configure the Australian rural and remote medical practitioner in ways that reflect and advance socio-cultural hegemony. 	The conceptual tools used to explore these dynamics are drawn from critical and post-structural theory, and draw upon the work of Nancy Fraser (1989; 1997) and Ruth Wodak (1999). Both theorists developed approaches that enable investigation into the effects of language use in order to understand how the cultural framing of particular work can influence power relations in a professional field. The research follows a cultural studies approach, focussing on texts as objects of research and acknowledging the importance of discourse in the development of cultural meaning (Nightingale, 1993). The methodological approach employs Critical Discourse Analysis, specifically the Discourse Historical Method (Wodak, 1999). It is used to explore the linguistic hallmarks of social and cultural processes and structures, and to identify the ways in which political control and dominance are advanced through language-based strategies. An analytical tool developed by Ruth Wodak, Rudolf de Cillia, Martin Reisigl and Karin Leibhart (1999) was adapted and used to identify nationalistic identity formulations and related linguistic manoeuvres in the texts. 	The dissertation argues that the textual linguistic manoeuvres and identity formulations produce and privilege a particular identity for rural and remote medical practitioners, and that cultural myth is used to popularise, shore up and advance the goals of rural doctors during a period of crisis and change. Important in this process is the differentiation of rural and remote medicine from other disciplines in order to define and advance its political needs and claims (Fraser, 1989). This activity has unexpected legacies for the rural and remote health sector. 	In developing a strong identity for rural doctors, discursive rules have been established by the discipline regarding roles, personal and professional characteristics, and practice style; rules which hold confounding factors for the sustainability of remote and rural medical practice and health care generally. These factors include: the professional fragmentation of the discipline of primary medical care into general practice and rural medicine; and identity formulations that do not accommodate an ageing workforce characterised by cultural diversity, decreasing engagement in full time work, and a higher proportion of women participants. Both of these factors have repercussions for the recruitment and retention of rural and remote health professionals and the maintenance of a sustainable health workforce. 	The dissertation argues that the formulated identities of rural and remote medical practitioners in the texts maintain and reproduce relationships of cultural, political and social power. They have also influenced the ways in which rural and remote health services have been developed and funded. They selectively represent and value particular roles and approaches to health care. In doing so, they misrepresent the breadth and complexities of rural and remote health issues, and reinforce a reputational economy built on differential professional and cultural respect, and political and economic advantage. This disadvantages the community, professions and interest groups of lower value and esteem, and other groups whose voices are often not heard. Thus, regardless of their altruistic motivations, the politics of identity and differentiation employed in the formulated identities in the texts are based on an approach that undermines the redistributive goals of justice and equity (Fraser 1997), and works primarily to develop and advantage the discipline of rural medicine.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">rural and remote health</field><field name="subject">Australia</field><field name="subject">culture</field><field name="subject">nationalism</field><field name="subject">hegemony</field><field name="subject">discursive linguistic strategies</field><field name="subject">identity formulation</field><field name="subject">identity politics</field><field name="subject">special interest groups</field><field name="subject">rural medicine</field><field name="subject">rural doctors</field><field name="subject">health professions</field><field name="subject">policy development</field><field name="subject">health sector reform</field><field name="identifier">http://eprints.qut.edu.au/16371/</field><field name="validLink">True</field></doc><doc><field name="title">Cryptographic hash functions : cryptanalysis, design and applications</field><field name="creator">Gauravaram, Praveen Srinivasa</field><field name="description">Cryptographic hash functions are an important tool in cryptography to achieve certain security goals such as authenticity, digital signatures, digital time stamping, and entity authentication. They are also strongly related to other important cryptographic tools such as block ciphers and pseudorandom functions. The standard and widely used hash functions such as MD5 and SHA-1 follow the design principle of Merkle-Damgard iterated hash function construction which was presented independently by Ivan Damgard and Ralph Merkle at Crypto'89. It has been established that neither these hash functions nor the Merkle-Damgard construction itself meet certain security requirements. This thesis aims to study the attacks on this popular construction and propose schemes that offer more resistance against these attacks as well as investigating alternative approaches to the Merkle-Damgard style of designing hash functions. This thesis aims at analysing the security of the standard hash function Cellular Authentication and Voice Encryption Algorithm (CAVE) used for authentication and key-derivation in the second generation (2G) North American IS-41 mobile phone system. In addition, this thesis studies the analysis issues of message authentication codes (MACs) designed using hash functions. With the aim to propose some efficient and secure MAC schemes based on hash functions.    This thesis works on three aspects of hash functions: design, cryptanalysis and applications with the following significant contributions:    * Proposes a family of variants to the Damgard-Merkle construction called 3CG for better protection against specific and generic attacks. Analysis of the linear variant of 3CG called 3C is presented including its resistance to some of the known attacks on hash functions.    * Improves the known cryptanalytical techniques to attack 3C and some other similar designs including a linear variant of GOST, a Russian standard hash function.    * Proposes a completely novel approach called Iterated Halving, alternative to the standard block iterated hash function construction.    * Analyses provably secure HMAC and NMAC message authentication codes (MACs) based on weaker assumptions than stated in their proofs of security. Proposes an efficient variant for NMAC called NMAC-1 to authenticate short messages. Proposes a variant for NMAC called M-NMAC which offers better protection against the complete key-recovery attacks than NMAC. As well it is shown that M-NMAC with hash functions also resists side-channel attacks against which HMAC and NMAC are vulnerable. Proposes a new MAC scheme called O-NMAC based on hash functions using just one secret key.    * Improves the open cryptanalysis of the CAVE algorithm.    * Analyses the security and legal implications of the latest collision attacks on the widely used MD5 and SHA-1 hash functions.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">cryptography</field><field name="subject">hash functions</field><field name="subject">cryptanalysis</field><field name="subject">design</field><field name="subject">applications</field><field name="subject">Merkle-Damgard construction</field><field name="subject">CAVE</field><field name="subject">3CG</field><field name="subject">3C</field><field name="subject">GOST-L</field><field name="subject">F-Hash</field><field name="subject">NMAC</field><field name="subject">HMAC</field><field name="subject">O-NMAC</field><field name="subject">M-NMAC</field><field name="subject">NMAC-1</field><field name="subject">iterated halving</field><field name="subject">digital signatures</field><field name="subject">side-channel attacks</field><field name="subject">practical and legal implications</field><field name="identifier">http://eprints.qut.edu.au/16372/</field><field name="validLink">True</field></doc><doc><field name="title">The experiences of undergraduate women nursing students : a feminist study</field><field name="creator">Mee, Jenny</field><field name="description">This study explores the experiences of women undergraduate nursing students within a feminist framework. In enquiring into the lives of undergraduate women nurses, this study sought to develop a deeper understanding of the social, historical and political factors that shape the lives of these women. An important aim of the study was to provide the women participants a political voice by which they could communicate their experiences.    The methodology is developed from the theoretical insights of a range of feminist theorists and researchers and draws on some fundamental assumptions about the gendered social location of women.  The study sought to test out these assumptions through an exploration of key themes within data collected from unstructured interviews with a purposeful sample of 13 undergraduate women students from a School of Nursing within a major Brisbane university.  The emerging themes reveal that women have roles that are gendered in construction and that their personal stresses and traumas are shaped by gender role construction.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">nursing student</field><field name="subject">feminist</field><field name="subject">political voice</field><field name="subject">gendered social location</field><field name="identifier">http://eprints.qut.edu.au/16373/</field><field name="validLink">True</field></doc><doc><field name="title">Mixed model predictive control with energy function design for power system</field><field name="creator">Tavahodi, Mana</field><field name="description">For reliable service, a power system must remain stable and capable of withstanding a wide range of disturbances especially for the large interconnected systems. In the last decade and a half and in particular after the famous blackout in N.Y. U.S.A. 1965, considerable research effort has gone in to the stability investigation of power systems. To deal with the requirements of real power systems, various stabilizing control techniques were being developed over the last decade. Conventional control engineering approaches are unable to effectively deal with system complexity, nonlinearities, parameters variations and uncertainties.  This dissertation presents a non-linear control technique which relies on prediction of the large power system behaviour. One example of a large modern power system formed by interconnecting the power systems of various states is the South-Eastern Australian power network made up of the power systems of Queensland, New South Wales, Victoria and South Australia. The Model Predictive Control (MPC) for the total power system has been shown to be successful in addressing many large scale nonlinear control problems. However, for application to the high order problems of power systems and given the fast control response required, total MPC is still expensive and is structured for centralized control. This thesis develops a MPC algorithm to control the field currents of generators incorporating them in a decentralized overall control scheme. MPC decisions are based on optimizing the control action in accordance with the predictions of an identified power system model so that the desired response is obtained. Energy Function based design provides good control for direct influence items such as SVC (Static Var Compensators), FACTS (Flexible AC Transmission System) or series compensators and can be used to define the desired flux for generator.  The approach in this thesis is to use the design flux for best system control as a reference for MPC. Given even a simple model of the relation between input control signal and the resulting machine flux, the MPC can be used to find the control sequence which will start the correct tracking. The continual recalculation of short time optimal control and then using only the initial control value provides a form of feedback control for the system in the desired tracking task but in a manner which retains the nonlinearity of the model.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">mixed model</field><field name="subject">energy function design</field><field name="subject">power system</field><field name="subject">stability</field><field name="subject">nonlinearity</field><field name="identifier">http://eprints.qut.edu.au/16374/</field><field name="validLink">True</field></doc><doc><field name="title">Anger and anxiety in patients with primary aldosteronism treated with amiloride hydrochloride or spironolactone or adrenalectomy</field><field name="creator">Armstrong, Robin Sherill</field><field name="description">In Primary Aldosteronism (PAL) excessive amounts of aldosterone cause sodium and water retention and, in many individuals, this leads to moderate to severely high blood pressure. Although the chemistry and physiology are increasingly well understood, including the outcomes of treatment on physical health, there has been no systematic study of the psychological dimension of PAL. Anecdotally, patients exhibit symptoms such as angry outbursts, irritability, anxiety and defensiveness, and partners of these patients sometimes mention poor anger control and brittle or unpredictable moods. This thesis reports a systematic study of anger and anxiety among patients undergoing treatment for PAL. Eighty-three patients were recruited over an 11-month period to a prospective, pre-post design study to determine if treatment was associated with change in psychological state. Participants completed the State-Trait Anger Expression Inventory (STAXI-2), State-Trait Anxiety Inventory (STAI) and Psychosocial Adjustment to Illness Scale (PAIS) questionnaires. Adrenal Vein Sampling confirmed overproduction of aldosterone in one or both adrenal glands. Patients with Aldosterone Producing Adenoma (APA) were offered adrenalectomy. As per usual treatment protocols, patients with Bilateral Adrenal Hyperplasia (BAH) were prescribed spironolactone or amiloride depending predominantly on severity of blood pressure and potassium levels. Post-test questionnaires were completed after 6-8 months. Analysis was by mixed design (between-within subjects) ANOVA. Participant numbers in the adrenalectomy group fell far short of expectations. Fourteen past patients who had undergone unilateral adrenalectomy completed a retrospective semi-structured questionnaire. This qualitative data was analysed to identify themes similar to quantitative data. At baseline, 'non-completers' (ie those who did not complete the post-test; n=19), were significantly more angry than 'completers' (n=50) in State Anger (p&lt; .01), Trait Anger (p&lt; .05) and Anger Expression Index (p&lt; .001). Trait Anxiety was also higher (p&lt; .05), as was Psychological Distress (p&lt; .05). Among those who participated at both interviews, there was small but statistically significant adverse treatment effect with higher scores for State Anger (p&lt; .05), and Feeling Angry (p&lt; .05). However for Trait Anger (p&lt; .01), and 2 of its 3 sub-scales Angry Temperament (p&lt; .05) and Angry Reaction (p&lt; .01) there was a slight to moderate decrease in negative affect with treatment. Psychological Distress scores also improved (p&lt; .05). Across all ANOVAs, there were no significant interaction effects, suggesting that any treatment effect was equivalent for the two drugs. Qualitatively collected data elucidated participants' changes in approach to life and relationships since adrenalectomy. Themes that emerged in the data included improved ability to cope with external stress, better control of emotions, more relaxed relationships and attitude to work, and a greater vitality and quality of life. Generally the comments were consistent with the drug treatments; there was noticeable benefit, including perceived better anger control and less anxiety.  Positive psychological effects of treatment observed in the two drug groups were triangulated with data from a qualitative study. The combined evidence suggests that when excess circulating aldosterone is reduced (adrenalectomy), or blocked (spironolactone), or aldosterone's salt and water retaining effects are minimised (amiloride), then nervous irritability and its subsequent psycho-behavioural manifestations are reduced. The effect however is slight and the conclusions are weakened by an apparent attrition bias, and the absence of a control group. Implications for further research are discussed.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">primary aldosteronism</field><field name="subject">amiloride hydrochloride</field><field name="subject">spironolactone</field><field name="subject">adrenalectomy</field><field name="subject">STAXI-2</field><field name="subject">state-trait anger expression inventory</field><field name="identifier">http://eprints.qut.edu.au/16375/</field><field name="validLink">True</field></doc><doc><field name="title">University students' leisure exercise behaviours</field><field name="creator">Ng, Judy K.</field><field name="description">This research study was divided into three phases. Phase I included 157 university undergraduate students. It was designed to assess the content (face) validity of the Leisure Exercise Efficacy Scale (LEES). Phase II consisted of 240 university undergraduates. This phase investigated the internal consistency, factorial structure, and construct validity of the LEES. Phase III was the main study, a total of 331 university undergraduate students were involved. It has three objectives: 1) to examine the theoretical relationships among the variables of "leisure exercise efficacy", "leisure exercise motives", "leisure exercise barriers", and "leisure exercise behaviours" of university students using Social Cognitive Theory as the framework; 2) to assess the effect of a required physical education program, with interventions based on Bandura's self-efficacy theory, on the leisure exercise behaviours of university students; and 3) to examine the role that the Hong Kong environment plays and identify possible ways to increase university students' participation in leisure exercise. Path analysis results showed that leisure exercise efficacy was a significant and direct predictor of leisure exercise behaviours 3 months after the commencement of the semester. The re-specified Model of University Students' Leisure Exercise Behaviours was found to be tenable. However, repeated measures analysis of variance results showed that there were no significant 3-way interaction effects (Group x Gender x Assessment Time) or 2-way interaction effects (Gender x Assessment Time) (Group x Assessment Time) for all variables. Qualitative results showed three perceived leisure exercise barriers: 1) time; 2) attitudes towards exercise; and 3) structural. Three general dimensions emerged from the qualitative data to increase university students' participation in leisure exercise: 1) reinforcement of leisure exercise efficacy; 2) enhancement of leisure exercise motives; and 3) encouragement of a university sports culture. Practical implications of the research findings and recommendations for future research are given in this study.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">barrier</field><field name="subject">behaviour</field><field name="subject">exercise</field><field name="subject">Hong Kong</field><field name="subject">intervention</field><field name="subject">leisure</field><field name="subject">motivation</field><field name="subject">path-model</field><field name="subject">quantitative-qualitative</field><field name="subject">questionnaire</field><field name="subject">self-efficacy</field><field name="subject">undergraduate</field><field name="identifier">http://eprints.qut.edu.au/16376/</field><field name="validLink">True</field></doc><doc><field name="title">The impact of risk management on the changing nature of a principal's work</field><field name="creator">Perry, Lee-Anne</field><field name="description">Risk has now become part of the common forensic vocabulary used in the new global culture to hold persons (such as principals) and institutions (such as schools) accountable. Thus, in a risk society (Giddens 2000; Beck1992), the nature of a principal's work is changing. Risk and its management have become integral parts of a principal's professional repertoire as the commonplace activities of schooling have become framed as risks to be managed. Tensions arise for school principals when external and internal pressures to measure performance threaten to overwhelm their responsibility for paying attention to the learning that is, or should be, occurring in their schools. A problem that emerges out of all this is the extent to which the nature and scope of contemporary accountability and audit regimes are underpinned by a negative logic that impacts directly on choices made by school leaders about the learning environment of their school.    This dissertation addresses this problem by examining the impact of risk management on the nature of a principal's work and the implications of this impact for secondary school leadership. It does so through a series of nested publications and an empirical study, beginning with the testing of conceptual understandings through international and national journals, and moving to dissemination of key findings through professional journals and conference and workshop delivery. The strategy was one of moving from global feedback on a locally experienced problem, to national feedback and then to engagement with professional colleagues. This approach was chosen to verify the quality of the analysis and to target the dissemination of findings to professional colleagues, facilitating professional dialogue on the core issues both during and subsequent to the dissertation process, and, in so doing, contributing to improved professional practice of the principalship. The dissertation begins by addressing risk and its minimisation as a powerful rationality and organisational logic driving leadership practices in contemporary schools. It explores the impact of risk-consciousness on the work of school leaders with particular reference to the impact such risk-consciousness can have on their role in fostering a learning culture within schools. It then moves to examine how this risk-consciousness has fostered a new 'attentional economy' (Taylor, 2005) in which schools must be seen to perform, and to perform in ways that are measurable and rendered visible for all. Rationalities of risk now require principals as school managers to pay attention to, and require of others, the forensic work of making schools calculable (that is, auditable on pre-determined risk minimisation metrics). Such forensic work has its place in schools and, indeed, has improved professional practice in some areas, particularly related to student safety. The dissertation raises questions about the extent to which this calculability is becoming the dominant, even the only, leaderly imperative for school principals. The dissertation positions the school as a risk organisation, and the strengths and limitations of that positioning are carefully examined. Carol Dweck's (1999) work on performance and learning goals provides a basis for an empirical analysis of the demands of school leadership. This analysis reveals the dominance of performance goals and the struggle experienced by the author, a school leader, in maintaining a balance between learning and performance, between being a risk-taker and a risk-minimiser, between being both appropriately accountable and socially responsible. It provides further evidence for the view developed through the dissertation that the dominant and prevailing negative logic of risk can overwhelm broader ethical responsibilities. The author argues strongly that proactive engagement with risk management underpinned by a positive logic of risk and focused, not on the imposition of ever-increasing controls, but on refining and improving judgement, offers new and more promising possibilities. A model for risk management is then presented which has a robust, flexible and systematic approach to risk management built on informed trust in professional human judgement. Such an approach, it is argued, may not only make the school safer but it may also provide a greater capacity to respond to opportunities to dare and to grow. School leaders are encouraged to move beyond risk minimisation to an educative approach to risk management in the interests of a dynamic learning environment.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">school principals</field><field name="subject">secondary schools</field><field name="subject">risk management</field><field name="subject">accountability</field><field name="subject">school leadership</field><field name="identifier">http://eprints.qut.edu.au/16377/</field><field name="validLink">True</field></doc><doc><field name="title">Vernacular creativity and new media</field><field name="creator">Burgess, Jean Elizabeth</field><field name="description">This study takes a cultural studies approach to investigating the ways in which the articulation of vernacular creativity with digital technologies and the networked cultural public sphere might constitute sites of cultural citizenship. In the thesis, the concept of 'vernacular creativity' describes the everyday practices of material and symbolic creativity, such as storytelling and photography, that both predate digital culture and are remediated by it in particular ways. The first part of thesis, covering Chapters 2 and 3, develops a theoretical framework and cultural history of vernacular creativity in new media contexts. Chapter 2 introduces the idea of vernacular creativity and connects it to cultural studies approaches to participatory media and cultural citizenship. Chapter 3 theorises and historicises the relationships among vernacular creativity, technological innovation and new media literacy, drawing on social constructionist approaches to technology, and discussing concrete examples. The first of these examples is the mass amateurisation of photography in the first half of the twentieth century, as represented by the monopoly of popular photography by Kodak in the United States and beyond. The second is the domestication of personal computing in the second half of the twentieth century, culminating in a discussion of the Apple brand and the construction of an ideal 'creative consumer'. The second part of the thesis, covering Chapters 4 and 5, is devoted to the investigation of two major case studies drawn from contemporary new media contexts. The first of these case studies is the photosharing network flickr.com, and the second is the Digital Storytelling movement, structured around collaborative offline workshops in which participants create short multimedia works based on their biographies and personal images. These case studies are used to explore the ways vernacular creativity is being remediated in contemporary new media contexts, the socio-technical shaping of participation in digital culture, and the implications for cultural citizenship. In Chapter 6, the thesis concludes by suggesting some further implications of the research findings for cultural and media studies approaches to the relations of cultural production and the politics of popular culture.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">vernacular creativity</field><field name="subject">new media</field><field name="subject">technology</field><field name="subject">cultural studies</field><field name="subject">cultural citizenship</field><field name="subject">literacy</field><field name="subject">photography</field><field name="subject">personal computing</field><field name="subject">Flickr</field><field name="subject">digital storytelling</field><field name="subject">Web 2.0</field><field name="identifier">http://eprints.qut.edu.au/16378/</field><field name="validLink">True</field></doc><doc><field name="title">Enhancing security in distributed systems with trusted computing hardware</field><field name="creator">Reid, Jason Frederick</field><field name="description">The need to increase the hostile attack resilience of distributed and internet-worked computer systems is critical and pressing. This thesis contributes to concrete improvements in distributed systems trustworthiness through an enhanced understanding of a technical approach known as trusted computing hardware. Because of its physical and logical protection features, trusted computing hardware can reliably enforce a security policy in a threat model where the authorised user is untrusted or when the device is placed in a hostile environment.
 
 
 
 We present a critical analysis of vulnerabilities in current systems, and argue that current industry-driven trusted computing initiatives will fail in efforts to retrofit security into inherently flawed operating system designs, since there is no substitute for a sound protection architecture grounded in hardware-enforced domain isolation. In doing so we identify the limitations of hardware-based approaches. We argue that the current emphasis of these programs does not give sufficient weight to the role that operating system security plays in overall system security. New processor features that provide hardware support for virtualisation will contribute more to practical security improvement because they will allow multiple operating systems to concurrently share the same processor. New operating systems that implement a sound protection architecture will thus be able to be introduced to support applications with stringent security requirements. These can coexist alongside inherently less secure mainstream operating systems, allowing a gradual migration to less vulnerable alternatives.
 
 
 
 We examine the effectiveness of the ITSEC and Common Criteria evaluation and certification schemes as a basis for establishing assurance in trusted computing hardware. Based on a survey of smart card certifications, we contend that the practice of artificially limiting the scope of an evaluation in order to gain a higher assurance rating is quite common. Due to a general lack of understanding in the marketplace as to how the schemes work, high evaluation assurance levels are confused with a general notion of 'high security strength'. Vendors invest little effort in correcting the misconception since they benefit from it and this has arguably undermined the value of the whole certification process.
 
 
 
 We contribute practical techniques for securing personal trusted hardware devices against a type of attack known as a relay attack. Our method is based on a novel application of a phenomenon known as side channel leakage, heretofore considered exclusively as a security vulnerability. We exploit the low latency of side channel information transfer to deliver a communication channel with timing resolution that is fine enough to detect sophisticated relay attacks. We avoid the cost and complexity associated with alternative communication techniques suggested in previous proposals. We also propose the first terrorist attack resistant distance bounding protocol that is efficient enough to be implemented on resource constrained devices.
 
 
 
 We propose a design for a privacy sensitive electronic cash scheme that leverages the confidentiality and integrity protection features of trusted computing hardware. We specify the command set and message structures and implement these in a prototype that uses Dallas Semiconductor iButtons. 
 
 
 
 We consider the access control requirements for a national scale electronic health records system of the type that Australia is currently developing. We argue that an access control model capable of supporting explicit denial of privileges is required to ensure that consumers maintain their right to grant or withhold consent to disclosure of their sensitive health information in an electronic system. Finding this feature absent in standard role-based access control models, we propose a modification to role-based access control that supports policy constructs of this type. Explicit denial is difficult to enforce in a large scale system without an active central authority but centralisation impacts negatively on system scalability. We show how the unique properties of trusted computing hardware can address this problem. We outline a conceptual architecture for an electronic health records access control system that leverages hardware level CPU virtualisation, trusted platform modules, personal cryptographic tokens and secure coprocessors to implement role based cryptographic access control. We argue that the design delivers important scalability benefits because it enables access control decisions to be made and enforced locally on a user's computing platform in a reliable way.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">trusted computing</field><field name="subject">trusted computing hardware</field><field name="subject">trusted systems</field><field name="subject">operating system security</field><field name="subject">distributed systems security</field><field name="subject">smart card</field><field name="subject">security evaluation</field><field name="subject">tamper resistance</field><field name="subject">distance bounding protocol</field><field name="subject">side channel leakage</field><field name="subject">electronic cash</field><field name="subject">electronic health records</field><field name="subject">role-based access control</field><field name="identifier">http://eprints.qut.edu.au/16379/</field><field name="validLink">True</field></doc><doc><field name="title">Mobility enhancement using simulated artificial human vision</field><field name="creator">Dowling, Jason Anthony</field><field name="description">The electrical stimulation of appropriate components of the human visual system can result in the perception of blobs of light (or phosphenes) in totally blind patients. By stimulating an array of closely aligned electrodes it is possible for a patient to perceive very low-resolution images from spatially aligned phosphenes. Using this approach, a number of international research groups are working toward developing multiple electrode systems (called Artificial Human Vision (AHV) systems or visual prostheses) to provide a phosphene-based substitute for normal human vision. Despite the great promise, there are currently a number of constraints with current AHV systems. These include limitations in the number of electrodes which can be implanted and the perceived spatial layout and display frequency of phosphenes. Therefore the development of computer vision techniques that can maximise the visualisation value of the limited number of phosphenes would be useful in compensating for these constraints. The lack of an objective method for comparing different AHV system displays, in addition to comparing AHV systems and other blind mobility aids (such as the long cane), has been a significant problem for AHV researchers. Finally, AHV research in Australia and many other countries relies strongly on theoretical models and animal experimentation due to the difficult of prototype human trials. Because of this constraint the experiments conducted in this thesis were limited to simulated AHV devices with normally sighted research participants and the true impact on blind people can only be regarded as approximated. In light of these constraints, this thesis has two general aims. The first aim is to investigate, evaluate and develop effective techniques for mobility assessment which will allow the objective comparison of different AHV system phosphene presentation methods. The second aim is to develop a useful display framework to guide the development of AHV information presentation, and use this framework to guide the development of an AHV simulation device. The first research contribution resulting from this work is a conceptual framework based on literature reviews of blind and low vision mobility, AHV technology, and computer vision. This framework incorporates a comprehensive number of factors which affect the effectiveness of information presentation in an AHV system. Experiments reported in this thesis have investigated a number of these factors using simulated AHV with human participants. It has been found that higher spatial resolution is associated with accurate walking (reduced veering), whereas higher display rate is associated with faster walking speeds. In this way it has been demonstrated that the conceptual framework supports and guides the development of an adaptive AHV system, with the dynamic adjustment of display properties in real-time. The second research contribution addresses mobility assessment which has been identified as an important issue in the AHV literature. This thesis presents the adaptation of a mobility assessment method from the blind and low vision literature to measure simulated AHV mobility performance using real-time computer based analysis. This method of mobility assessment (based on parameters for walking speed, obstacle contacts and veering) is demonstrated experimentally in two different indoor mobility courses. These experiments involved sixty-five participants wearing a head-mounted simulation device. The final research contribution in this thesis is the development and evaluation of an original real-time looming obstacle detector, based on coarse optical flow, and implemented on a Windows PocketPC based Personal Digital Assistant (PDA) using a CF card camera. PDA based processors are a preferred main processing platform for AHV systems due to their small size, light weight and ease of software development. However, PDA devices are currently constrained by restricted random access memory, lack of a floating point unit and slow internal bus speeds. Therefore any real-time software needs to maximise the use of integer calculations and minimise memory usage. This contribution was significant as the resulting device provided a selection of experimental results and subjective opinions.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">artificial human vision</field><field name="subject">visual prosthesis</field><field name="subject">blind mobility</field><field name="subject">image processing</field><field name="subject">computer vision</field><field name="subject">mobility assessment</field><field name="subject">visual simulation</field><field name="subject">human computer interface</field><field name="identifier">http://eprints.qut.edu.au/16380/</field><field name="validLink">True</field></doc><doc><field name="title">Message processing of fear-based anti-drink driving advertisements</field><field name="creator">Fry, Marie-Louise</field><field name="description">While overall road deaths in Australia have fallen since the late 1980's and the impact of road-safety advertising appears to be positive, alcohol-related road fatalities remain the leading cause of death among young Australian adults. Fatality and injury rates continue within this cohort despite increases in alcohol-related knowledge, continuing education efforts in the Australian school system, increased funding for police enforcement and high media presence of road safety advertising (Peder et al 2004). Notwithstanding advances in communication technologies, highly graphic, emotional, shock style television advertising remains the primary medium for road safety message dissemination. Rather than targeting those highest at-risk for drink driving, road safety advertisements typically target an undifferentiated general audience. To date understanding the process by which road safety advertising influences attitudes and behaviour has been the centre of fear arousal research. Nonetheless, there has been little examination of how young adults who differ in drink-driving risk-propensity (high versus low) respond to and process anti-drink driving advertisements designed to modify an avoidable behaviour.  Taking a receiver oriented approach, the focus of this study examines how young adult, novice drivers who differ in 'need-for-sensation' (NFS) risk propensity respond to, and process, anti-drink driving advertisements that differ in arousal capacity (i.e. high, low sensation-value). The investigation was conducted in two stages: Study 1 (qualitative) and Study II (quantitative). Study I, the qualitative phase, explored by focus group interviews attitudes, perceptions, beliefs and experiences of sixty young adults aged 18 to 25 years towards alcohol consumption, drink-driving, and anti-drink driving advertising. The major qualitative finding is that young adults characterise drink-driving as a rational, deliberate, planned and accepted behaviour. Young adults were aware of the choices available for not drinking and driving and were aware of the health, social and physical (self and property) risks associated with alcohol consumption and associated behaviours. Nonetheless, the short-term personal experiences of revelry and group cohesion were more pertinent to them on an everyday basis. Alcohol consumption and drink-driving behaviour did not appear to differ between university and nonuniversity students or gender, yet there were differences in attitudes and behaviour across the degree studied within the university cohort.  Study II, the quantitative phase, was segmented into three sections. First, the study provides empirical support for NFS as a relevant a priori individual differences segmentation variable for differentiating between those more likely, versus less likely, to engage in responsible drink-driving behaviour. As expected low NFS individuals were more likely to not drink and drive. Second, findings support an interaction effect between an advertisement's sensation value and individual differences variable, NFS, on response outcomes. High NFS individuals engaged in higher levels of adaptive appraisal on the high sensation-value advertisement condition as compared to the low sensationvalue advertisement condition. Low NFS individuals did not discriminate across either advertisement condition. Adaptive appraisal was not counteracted by a corresponding increase in maladaptive appraisal. Both high and low NFS individuals viewed the high sensation-value advertisement condition with high levels of perceived threat and viewed the low sensation-value advertisement with higher levels of perceived efficacy. Yet, although high NFS individuals viewed the high sensation-value advertisement with high levels of threat they simultaneously viewed this advertisement with low levels of perceived efficacy.  Third, NFS was not found to be a strong predictor moderating the relationship between message processing (cognitive, sensory, narrative) and response outcomes. The findings indicate strong support for a direct relationship between two modes of message processing: cognitive and narrative processing and response outcomes. Message recipients processed anti-drink driving advertisements via two routes to persuasion. There was stronger cognitive processing evident on advertisements possessing high arousal capacity, whereas stronger narrative processing was evident on low arousal capacity advertisements. This study suggests that those advertisements that possess high arousal capacity have the capability of facilitating attention to the central argument, the consequences of drinking and driving, as well as how drinking and driving may affect the message recipients' life. Alternatively, those messages that impart high levels of rational information have the capability of increasing attention to the peripheral cues in the message. It is also suggested that different styles of message processing, central versus peripheral, act in a synergistic way to influence response outcomes which indicates that there is no single route to persuasion. Individuals process messages in a complex manner attending to various signals in order to evaluate various components of the message.  For road safety practitioners and social marketers the results of this study illustrates practical benefits for the design of anti-drink driving advertisements based on the segmentation variable NFS. The finding that high NFS individuals require advertisements that possess high levels of arousal capacity (i.e.: high in sensation-value) is an important development. Importantly, low NFS individuals do not discriminate in accepting the recommendations of advertisements that differ in arousal capacity clearly suggests that they accept messages regardless of their arousal capacity. This finding indicates that the goal of road traffic authorities, advertising agencies and social marketers should be directed towards targeting high NFS individuals who are more atrisk for a drink-drive fatality. That message recipients process anti-drink driving messages via two routes to persuasion indicates that message designers need to consider the mix between the sensation-value of the message and consideration of the way message recipients' process the message, i.e. via central/systematic versus peripheral/heuristic components of the advertisement. Further investigation into the dual processing of anti-drink driving advertisements once individuals are exposed to the message is warranted to further understand the psychological processes influencing message processing. The findings of this research have important implications for both practitioners and academics. This research has provided an insight into the complexity of young adult's response outcomes and message processing of fear-based anti-drink driving messages.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">sensation seeking</field><field name="subject">fear arousal</field><field name="subject">message processing</field><field name="subject">drink-driving</field><field name="subject">advertising</field><field name="subject">alcohol</field><field name="subject">young adults</field><field name="identifier">http://eprints.qut.edu.au/16381/</field><field name="validLink">True</field></doc><doc><field name="title">Personal responsibility : the creation, implementation and evaluation of a school-based program</field><field name="creator">Mergler, Amanda Gay</field><field name="description">We live in a society where the individual is prioritised over the collective.  Newspaper articles abound lamenting adolescents' lack of personal responsibility and social commentators are increasingly highlighting the need to recapture and interweave an agenda of personal responsibility into the social fabric.  Personal responsibility has been defined as being accountable to oneself and the needs and well-being of others (Ruyter, 2002).  Doherty (1998) has argued that there is an increasing trend in society to refuse accountability and to blame others for one's situation.  Despite these assertions, there is little empirical research that has attempted to define and examine personal responsibility.  This dissertation is about the role of personal responsibility in the lives of adolescents.  The research program was divided into three studies utilising quantitative and qualitative research methods to answer four research questions.  Study 1: How do adolescents and teachers understand 'personal responsibility?' Study 2: Can a quantitative questionnaire define and measure an adolescent's level of personal responsibility? Study 3: Can a program aimed at enhancing the personal responsibility level of adolescents be taught in a high school and demonstrate measurable effect? Is there a relationship between personal responsibility, emotional intelligence and self-esteem? Study 1 used focus groups to address research question 1.  Four focus groups with a total of 20 Year 11 students, and two focus groups with a total of 10 teachers were conducted.  The results revealed that key components of the personal responsibility variable were choices and consequences, behavioural control, thoughts and feelings, and consideration for others.  This finding complemented the definition derived from the literature review.  Additionally, the focus group data served to inform Study 2, the development of the Personal Responsibility Questionnaire and Study 3, the creation, implementation and evaluation of the Personal Responsibility Program. Study 2 involved examining appropriate literature, focus group data from Study 1, and related measures to create a quantitative measure assessing personal responsibility in adolescents.  A 100-item measure was created and tested on more than 500 adolescents.  Exploratory Factor Analysis (EFA) and Confirmatory Factor Analysis (CFA) were used to determine a final 30-item Personal Responsibility Questionnaire with two factors (factor 1 - 'self control of emotion and thoughts' and factor 2 - 'self control of behaviour').  This measure was to serve in the evaluation of the Personal Responsibility Program. A fundamental aim of the study was to determine whether a Personal Responsibility Program could be implemented in a high school and demonstrate measurable effect.  Study 3 involved the creation of the Personal Responsibility Program through examining other values-based education programs and the focus group data obtained in Study 1.  Once created, the five-lesson program was implemented twice in one high school, with approximately half of the Year 11 students undertaking the first implementation (the experimental group), and the remaining Year 11 students completing the program during its second implementation (the control group). To assess whether the program had generated any changes in the adolescents' levels of personal responsibility, the Personal Responsibility Questionnaire developed in Study 2 was administered pre- and post-intervention to both the experimental and control groups.  Additionally, the well-established constructs of emotional intelligence and self-esteem were assessed using the Emotional Intelligence Scale (Schutte et al., 1998) and the Rosenberg Self-Esteem Scale (Rosenberg, 1965) to determine potential relationships between these variables and to provide additional construct validity for the measure.  The results from Study 3 revealed no significant findings on any variable at any time (pre- or post-intervention).  Despite this finding, certain data trends were apparent between males and females across the experimental and control groups.  Overall, females demonstrated slightly higher mean scores on emotional intelligence and personal responsibility than males, while males had slightly higher mean scores than females on self-esteem.  In order to gather additional feedback about the program and the students' learning, qualitative data were gathered from the students and the teachers by completion of a feedback sheet at the end of each lesson and a teacher focus group interview after the first implementation of the Personal Responsibility Program.  In relation to student learning, the qualitative data offered by the students showed that learning in the key areas targeted had occurred, with students reflecting on their growth and changing understandings about personal responsibility.  With reference to the program, the students commented that the program was fun, interesting, relevant, valuable, and enabled them to learn new things about themselves.  Feedback from the teachers highlighted that the students appeared to engage with the program, and that teaching it was rewarding. This research program has contributed to the literature by providing a theoretically and empirically derived definition of personal responsibility.  The focus group process highlighted that personal responsibility could be understood and considered by adolescents due to the cognitive and moral sophistication that develops early in this developmental timeframe.  Study 2 generated a Personal Responsibility Questionnaire that can be used to assess personal responsibility in adolescents, and Study 3 contributed a Personal Responsibility Program which has been developed from conceptual and empirical literature.  The program was designed to be "teacher friendly' and allowed the schools to gather qualitative and quantitative feedback on the success of the program's implementation.  As school administrators and teachers often lament the lack of personal responsibility in their students (Lickona, 1992), this program could be used to address this concern and put the issue of personal responsibility firmly on the agenda in high schools.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">personal responsibility</field><field name="subject">social responsibility</field><field name="subject">values</field><field name="subject">morals</field><field name="subject">character</field><field name="subject">cognition</field><field name="subject">constructivism</field><field name="subject">education</field><field name="subject">pedagogy</field><field name="subject">intervention</field><field name="subject">schools</field><field name="subject">adolescents</field><field name="subject">students</field><field name="subject">teachers</field><field name="subject">qualitative research</field><field name="subject">questionnaire development</field><field name="subject">mixed-method design</field><field name="subject">emotional intelligence</field><field name="subject">self-esteem</field><field name="identifier">http://eprints.qut.edu.au/16382/</field><field name="validLink">True</field></doc><doc><field name="title">Defining the nature and outcomes of Australian professional supervision : applying Holloway's systems approach</field><field name="creator">Johnston, Karla Gai</field><field name="description">The goal of this thesis was to define the nature and outcomes of Australian professional supervision by applying Holloway's (1995) Systems Approach to Supervision (SAS) across professional groups. Many Australian professionals such as psychologists, counsellors, and accountants are required to participate in some form of supervision before being granted permission, via registration, to practice independently within their respective fields. This is the first study of its kind to investigate the supervision experience of a range of professional groups within Australia. The SAS model (Holloway, 1995) provided a well-researched theoretical and practical framework with the potential to be applied across professional groups for the purposes of developing, evaluating and enhancing supervisor and supervisee practice. Based on the model, Holloway proposed a number of teaching tasks and functions in a matrix to explain the process of supervision and to assist in the professional and personal development of supervisees. To date, most of the literature on professional supervision has failed to provide a theoretical framework from which results could be meaningfully interpreted. This thesis outlines a program of research which used the SAS model as a theoretical basis for understanding and evaluating the experience of supervision amongst a range of Australian professional and its relationship to effective professional practice.    Four studies were conducted in accordance with Mackenzie and House's (1979) Model of Scientific Inquiry. The first study (Study One) was exploratory in nature, and aimed to define the term "supervision" and the anticipated outcomes of supervision activities. The second study (Study Two) was also exploratory in nature, and aimed to evaluate the modes of supervision delivery as well as to collect information regarding the key tasks and functions utilised in professional supervision.  The third study (Study Three) was empirical in nature, and investigated the supervision experience of psychologists engaged in supervision in accordance with the SAS model (Holloway, 1995). It longitudinally tracked their performance over a 12-month period as evaluated by both their supervisors and work managers. The fourth study (Study Four) was confirmatory in nature, and was the same as the third study but comprised a different sample of business and accounting (who were not Certified Public Accountants) graduates.    The four studies consisted of four separate samples surveyed with self-report measures developed from the SAS model (Holloway, 1995) by the researcher. Study One comprised a sample of 210 supervisor-supervisee dyads. Professional groups in this sample were psychologists, counsellors, nurses, occupational therapists, financial advisors, business consultants, and accountants (without CPA) all of whom were participating in a supervision process. Study Two comprised a total of 200 supervisees broken down into four groups of 50. The professional types included in this sample were psychologists, counsellors, nurses and business consultants and accountants (without a CPA). Study Three comprised 513 supervisees who were participating in supervision as part of the criteria to become fully registered psychologists.  Study Four included 480 business consultants and accountants (without CPA) who were in the early years of their career and were participating in supervision as part of their professional development. The central aims of the supervision experience, according to supervisees and supervisors, were to develop skills in counselling, case experience, professional experience, emotional awareness, the ability to self-evaluate and network. The six reported outcomes of supervision were that professional supervision enhanced supervisees' ability to self-evaluate, gain academic knowledge, become emotionally aware, develop profession networks, develop both professional and work skills and to build on relationship skills. The findings supported and extended the SAS model (Holloway, 1995) by adding the tasks of academic knowledge and networking. The definition of supervision found in this research program also supported and built on the definitions already provided in the literature. There was considerable support for the SAS model's matrix in that particular supervision functions employed to teach certain supervision tasks were more effective than others. For example, on the one hand, to teach a supervisee the skill of emotional awareness, a supervisor is best advised to take a supportive/sharing approach. On the other hand, it was shown that the teaching strategy of monitoring/evaluating was not found to be conducive to teaching case conceptualisation skills. The findings also suggested two enhancements to Holloway's original conceptualisation of the SAS model of supervision delivery mode and supervisor allocation. Furthermore, the findings confirmed that the SAS model can be applied to teach and objectively evaluate supervision success by supervisors and managers across professional groups.    There were six major contributions of this research program to the field of professional supervision: First, there was the application and validation of a theoretical model, Holloway's (1995) Systems Approach to Supervision, to the supervision experience. Second, there was the development and application of scales to measure supervision performance and satisfaction reliably and with demonstrated construct validity. Third, the methodology which included the collection of both qualitative and quantitative responses from supervisees, supervisors, and managers provided a multi-method approach to understanding professional supervision across professional groups. Fourth, a uniform definition of supervision was identified across a range of professional groups. Fifth, Holloway's supervision teaching matrix was empirically supported and the findings recommend it as a mechanism for developing, evaluating and enhancing supervisor and supervisee practice across a range of professional types. The SAS model was found to be relevant to health-related professional groups but also supported in business-related professional groups. Finally, the research recommended some modifications to the SAS model to incorporate factors such as supervision delivery mode. These additions and the results of the longitudinal research suggested that supervision effectiveness was a predictor of on the job performance ratings by managers. Based on a scan of the literature to date, this research program outlines the first longitudinal empirical study of the relationship between supervision effectiveness and on-the-job performance using a range of professional groups. Limitations and future directions were discussed.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">professional supervision</field><field name="subject">systems approach to supervision (SAS)</field><field name="subject">Elizabeth Holloway</field><field name="subject">supervision functions</field><field name="subject">supervision tasks</field><field name="subject">supervision delivery mode</field><field name="subject">effectiveness of supervision</field><field name="identifier">http://eprints.qut.edu.au/16383/</field><field name="validLink">True</field></doc><doc><field name="title">Evaluation of interactive effects between temperature and air pollution on health outcomes</field><field name="creator">Ren, Cizao</field><field name="description">A large number of studies have shown that both temperature and air pollution (eg, particulate  matter and ozone) are associated with health outcomes. So far, it has received limited  attention whether air pollution and temperature interact to affect health outcomes. A few  studies have examined interactive effects between temperature and air pollution, but produced  conflicting results. This thesis aimed to examine whether air pollution (including ozone and  particulate matter) and temperature interacted to affect health outcomes in Brisbane, Australia  and 95 large US communities.  In order to examine the consistency across different cities and different countries, we used  two datasets to examine interactive effects of temperature and air pollution. One dataset was  collected in Brisbane City, Australia, during 1996-2000. The dataset included air pollution  (PM10, ozone and nitrogen dioxide), weather conditions (minimum temperature, maximum  temperature, relative humidity and rainfall) and different health outcomes. Another dataset  was collected from the 95 large US communities, which included air pollution (ozone was  used in the thesis), weather conditions (maximum temperature and dew point temperature)  and mortality (all non-external cause mortality and cardiorespiratory mortality).  Firstly, we used three parallel time-series models to examine whether maximum temperature  modified PM10 effects on cardiovascular hospital admissions (CHA), respiratory hospital  admissions (RHA), cardiovascular emergency visits (CEV), respiratory emergency visits  (REV), cardiovascular mortality (CM) and non-external cause mortality (NECM), at lags of  0-2 days in Brisbane. We used a Poisson generalized additive model (GAM) to fit a bivariate  model to explore joint response surfaces of both maximum temperature and particulate matter  less than 10 &#956;m in diameter (PM10) on individual health outcomes at each lag. Results show  that temperature and PM10 interacted to affect different health outcomes at various lags. Then,  we separately fitted non-stratification and stratification GAM models to quantify the  interactive effects. In the non-stratification model, we examined the interactive effects by  including a pointwise product for both temperature and the pollutant. In the stratification  model, we categorized temperature into two levels using different cut-offs and then included  an interactive term for both pollutant and temperature. Results show that maximum  temperature significantly and positively modified the associations of PM10 with RHA, CEV,  REV, CM and NECM at various lags, but not for CHA.  Then, we used the above Poisson regression models to examine whether PM10 modified the  associations of minimum temperature with CHA, RHA, CEV, REV, CM and NECM at lags  of 0-2 days. In this part, we categorized PM10 into two levels using the mean as cut-off to fit  the stratification model. The results show that PM10 significantly modified the effects of  temperature on CHA, RHA, CM and NECM at various lags. The enhanced adverse  temperature effects were found at higher levels of PM10, but there was no clear evidence for  synergistic effects on CEV and REV at various lags. Three parallel models produced similar  results, which strengthened the validity of these findings.  Thirdly, we examined whether there were the interactive effects between maximum  temperature and ozone on NECM in individual communities between April and October,  1987-2000, using the data of 60 eastern US communities from the National Morbidity,  Mortality, and Air Pollution Study (NMMAPS). We divided these communities into two  regions (northeast and southeast) according to the NMMAPS study. We first used the  bivariate model to examine the joint effects between temperature and ozone on NECM in  each community, and then fit a stratification model in each community by categorizing  temperature into three levels. After that, we used Bayesian meta-analysis to estimate overall  effects across regions and temperature levels from the stratification model. The bivariate  model shows that temperature obviously modified ozone effects in most of the northeast  communities, but the trend was not obviously in the southeast region. Bayesian meta-analysis  shows that in the northeast region, a 10-ppb increment in ozone was associated with 2.2%  (95% posterior interval [PI]: 1.2%, 3.1 %), 3.1% (95% PI: 2.2%, 3.8 %) and 6.2 % (95% PI:  4.8%, 7.6 %) increase in mortality for low, moderate and high temperature levels, respectively,  while in the southeast region, a 10-ppb increment in ozone was associated with 1.1% (95% PI:  -1.1%, 3.2 %), 1.5% (95% PI: 0.2%, 2.8%) and 1.3% (95% PI: -0.3%, 3.0 %) increase in  mortality.  In addition, we examined whether temperature modified ozone effects on cardiovascular  mortality in 95 large US communities between May and October, 1987-2000 using the same  models as the above. We divided the communities into 7 regions according to the NMMAPS  study (Northeast, Industrial Midwest, Upper Midwest, Northwest, Southeast, Southwest and  Southern California). The bivariate model shows that temperature modified ozone effects in  most of the communities in the northern regions (Northeast, Industrial Midwest, Upper  Midwest, Northwest), but such modification was not obvious in the southern regions  (Southeast, Southwest and Southern California). Bayesian meta-analysis shows that  temperature significantly modified ozone effects in the Northeast, Industrial Midwest and  Northwest regions, but not significant in Upper Midwest, Southeast, Southwest and Southern  California. Nationally, temperature marginally positively modified ozone effects on  cardiovascular mortality. A 10-ppb increment in ozone was associated with 0.4% (95%  posterior interval [PI]: -0.2, 0.9 %), 0.3% (95% PI: -0.3%, 1.0%) and 1.6% (95% PI: 4.8%,  7.6%) increase in mortality for low, moderate and high temperature levels, respectively. The  difference of overall effects between high and low temperature levels was 1.3% (95% PI: -  0.4%, 2.9%) in the 95 communities.  Finally, we examined whether ozone modified the association between maximum temperature  and cardiovascular mortality in 60 large eastern US communities during the warmer days,  1987-2000. The communities were divided into the northeast and southeast regions. We  restricted the analyses to the warmer days when temperature was equal to or higher than the  median in each community throughout the study period. We fitted a bivariate model to  explore the joint effects between temperature and ozone on cardiovascular mortality in  individual communities and results show that in general, ozone positively modified the  association between temperature and mortality in the northeast region, but such modification  was not obvious in the southeast region. Because temperature effects on mortality might  partly intermediate by ozone, we divided the dataset into four equal subsets using quartiles as  cut-offs. Then, we fitted a parametric model to examine the associations between temperature  and mortality across different levels of ozone using the subsets. Results show that the higher  the ozone concentrations, the stronger the temperature-mortality associations in the northeast  region. However, such a trend was not obvious in the southeast region.  Overall, this study found strong evidence that temperature and air pollution interacted to  affect health outcomes. PM10 and temperature interacted to affect different health outcomes at  various lags in Brisbane, Australia. Temperature and ozone also interacted to affect NECM  and CM in US communities and such modification varied considerably across different  regions. The symmetric modification between temperature and air pollution was observed in  the study. This implies that it is considerably important to evaluate the interactive effect while  estimating temperature or air pollution effects and further investigate reasons behind the  regional variability.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">interactive effect</field><field name="subject">temperature</field><field name="subject">air pollution</field><field name="subject">health outcome</field><field name="subject">particulate matter</field><field name="subject">cardio-respiratory disease</field><field name="subject">ozone</field><field name="subject">NMMAPS</field><field name="subject">cardiovascular</field><field name="identifier">http://eprints.qut.edu.au/16384/</field><field name="validLink">True</field></doc><doc><field name="title">Effectiveness of self-management for persons with type 2 diabetes following the implementation of a self-efficacy enhancing intervention program in Taiwan</field><field name="creator">Wu, Shu Fang</field><field name="description">Objective  The aim of this study firstly, was to translate and test the validity and reliability of two diabetes-specific self-efficacy instruments (the Diabetes Management Self-Efficacy Scale; DMSES and the Perceived Therapeutic Efficacy Scale; PTES) in a Taiwanese population. The main aim of this study was then to develop an intervention based on self-efficacy theory that was appropriate for the Taiwanese population and to examine the effects of a self-efficacy enhancing intervention program (SEEIP).    Background  In Taiwan, the prevalence, mortality rate and healthcare cost of diabetes has dramatically increased. People with diabetes have low participation rates in performing self-care activities, with some two-thirds of diabetic patients not controlling their disease appropriately. Moreover, few studies in Taiwan have conducted randomised controlled trials or had improvement in patient self-care or self-management as their primary goal and no instruments that measure self-efficacy related to the management of diabetes (especially for outcome expectations) have yet been found and appropriately used to measure the effectiveness of self-management. Therefore, there is a particular need for research on self-efficacy enhancing intervention programs for people with type 2 diabetes. Design  A convenience sample survey (n=230) was used in order to test the validity and reliability of C-DMSES and C-PTES in a Taiwanese population. Moreover, a randomised controlled trial (RCT) (n=145; the intervention group (72); the control group (73)) design was conducted in the main study with pre (baseline) and post-testing (undertaken at 3 months and 6 months following baseline collection).    Intervention  Both the control group and intervention group received the standard diabetic educational program in the outpatient clinic. The intervention group participants received the standard diabetic educational program and the following additional interventions: (1) viewed a 10-minute DVD (2) received a &amp;quotDiabetes Self-Care" booklet (3) participated in four efficacy- enhancing counselling intervention sessions, and (4) participated in telephone follow-up. The self-efficacy model was adapted from Shortridge-Baggett &amp; van der Bijl (1996). Diabetes self-management principles were used in program development and evaluation.    Main outcome measures  Instruments used in data collection included 1) Self-efficacy towards management of type 2 diabetes (as measured by the Chinese version of the Diabetes Management Self-Efficacy Scale; C-DMSES and the Chinese version of the Perceived Therapeutic Efficacy Scale; C-PTES); 2) self management behavior (as measured by the Summary of Diabetes Self-Care Activities; SDSCA); 3) health-related quality of life for diabetes (as measured by the Short Form-12; SF-12); 4) psychosocial well-being (as measured by the Medical Outcomes Study (MOS), Social Support Survey (SSS) tool and the Center for Epidemiology Studies Short Depression Scale; CES-D) and 5) health care utilisation (as measured by health care utilisation self report instrument).    Data analysis  Data were double-entered for verification using SPSS&#174; statistical software. Study I: Descriptive statistics, regression analysis, Pearson's correlation, Cronbach's alpha-coefficients, factor analysis and Bland-Altman plots with 95% limits of agreement (LOA) were performed to evaluate validity and reliability of C-DMSES and C-PTES.    Study II: Descriptive analysis was used to examine demographic variables and outcome variables. T-tests were used to analyse differences on continuous data between mean scores for the intervention and control groups. Categorical data were analysed using Chi-square statistics to test the significance of different proportions. To assess the group differences of dependent variable changes, repeated measures ANOVA/ ANCOVA were used. Results  Study I: Convergent validity showed that C-DMSES correlated well with the validated measure of the General Self-Efficacy Scale (GSE) in measuring self-efficacy. Criterion-related validity showed that the C-DMSES was a significant predictor of the Summary of Diabetes Self-Care Activities (SDSCA) scores. Factor analysis supported the C-DMSES being composed of four subscales with good internal consistency (Cronbach's alpha=.77 to .93) and stability (ICC=.82). Similarly, significant criterion-related validity was demonstrated between the C-PTES and SDSCA scores. Convergent validity was confirmed as the C-PTES converged well with the GSE Scale in measuring self-efficacy. Construct validity of the C-PTES was confirmed through factor analysis and a single subscale formed. Internal consistency with a Cronbach's alpha was .95 and the test-retest reliability (ICC) was .77 and a Bland-Altman plot showed 97% of the subjects were within 2 standard deviations of the mean. Study II: The 3- and 6-month benefits of the intervention over usual care were increases in self-efficacy, outcome expectation, self-care activities, and social support.  However, the results of the health-related quality of life and depression scores indicated that the change over time was not different in the two groups.  A smaller proportion of the participants significantly in the intervention group, had been hospitalised and visited the emergency room than participants who were in the control group at the 6-month period. However, health-related quality of life and depression were not significantly increased in the intervention group at the 3- and 6-month compared to the control group.    Conclusion  Results of Study I support the psychometric properties of C-DMSES and C-PTES in providing a measure for self-efficacy specific to persons with type 2 diabetes in Taiwan. The main study revealed that the SEEIP for type 2 diabetes based on self-efficacy theory was culturally acceptable to Taiwanese people with diabetes and that the SEEIP was effective in the self-management of people with type 2 diabetes.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">type 2 diabetes</field><field name="subject">randomised controlled trial</field><field name="subject">self-management</field><field name="subject">self-efficacy</field><field name="subject">outcome expectations</field><field name="subject">self-efficacy enhancing intervention program (SEEIP)</field><field name="subject">self-care</field><field name="subject">health-related quality of life</field><field name="subject">psychosocial well-being</field><field name="subject">social support</field><field name="subject">depression</field><field name="subject">health care utilisation</field><field name="identifier">http://eprints.qut.edu.au/16385/</field><field name="validLink">True</field></doc><doc><field name="title">Secure public-key encryption from factorisation-related problems</field><field name="creator">Brown, Jaimee</field><field name="description">Public key encryption plays a vital role in securing sensitive data in practical  applications. The security of many encryption schemes relies on mathematical  problems related to the difficulty of factoring large integers. In particular,  subgroup problems in composite order groups are a general class of problems  widely used in the construction of secure public-key encryption schemes. This  thesis studies public-key encryption schemes that are provably secure based on  the difficulty of subgroup or other integer factorisation related problems in the  standard model.  Firstly, a number of new public-key encryption schemes are presented which  are secure in the sense of indistinguishability against chosen-ciphertext attack  in the standard model. These schemes are obtained by instantiating the two  previous paradigms for chosen-ciphertext security by Cramer and Shoup, and  Kurosawa and Desmedt, with three previously studied subgroup membership  problems. The resulting schemes are very efficient, and are comparable if not  superior in terms of efficiency when compared to previously presented instantiations.  Secondly, a new approach is presented for constructing RSA-related public  key encryption schemes secure in the sense of indistinguishability against chosenciphertext  attack without random oracles. This new approach requires a new  set of assumptions, called the Oracle RSA-type assumptions. The motivating  observation is that RSA-based encryption schemes can be viewed as tag-based  encryption schemes, and as a result can be used as a building block in a previous  technique for obtaining chosen-ciphertext security. Two example encryption  schemes are additionally presented, each of which is of comparable efficiency to  other public key schemes of similar security.  Finally, the notion of self-escrowed public-key infrastructures is revisited,  and a security model is defined for self-escrowed encryption schemes. The security definitions proposed consider adversarial models which reflect an attacker's  ability to recover private keys corresponding to public keys of the attacker's  choice. General constructions for secure self-escrowed versions of ElGamal, RSA,  Cramer-Shoup and Kurosawa-Desmedt encryption schemes are also presented,  and efficient instantiations are provided. In particular, one instantiation solves  the 'key doubling problem' observed in all previous self-escrowed encryption  schemes. Also, for another instantiation a mechanism is described for distributing  key recovery amongst a number of authorities.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">public key encryption</field><field name="subject">subgroup membership problems</field><field name="subject">provable security</field><field name="subject">chosenciphertext security</field><field name="subject">Cramer-Shoup</field><field name="subject">RSA</field><field name="subject">self-escrowed encryption</field><field name="subject">key recovery</field><field name="identifier">http://eprints.qut.edu.au/16386/</field><field name="validLink">True</field></doc><doc><field name="title">Toward a scientific taxonomy of musical styles</field><field name="creator">Bellmann, Hector Guillermo</field><field name="description">The original aim of the research was to investigate the conceptual dimensions of style in tonal music in order to provide grounds for an objective, measurable categorization of the phenomenon that could be construed as the basis of a scientific taxonomy of musical styles. However, this is a formidable task that surpasses the practical possibilities of the project, which would hence concentrate on creating the tools that would be needed for the following stage.  A review of previous attempts to deal with style in music provided a number of guidelines for the process of dealing with the material. The project intends to avoid the subjectivity of musical analysis concentrating on music observable features. A database of 250 keyboard scores in MusicXML format was built to the purpose of covering the whole span of styles in tonal music, from which it should be possible to extract features to be used in style categorization. Early on, it became apparent that most meaningful pitch-related features are linked to scale degrees, thus essentially depending on functional labeling, requiring the knowledge of the key of the music as a point function. Different proposed alternatives to determine the key were considered and a method decided upon. Software was written and its effectiveness tested. The method proved successful in determining the instant key with as much precision as feasible. On this basis, it became possible to functionally label scale degrees and chords. This software constitutes the basic tool for the extraction of pitch-related features. As its first use, the software was applied to the score database in order to quantify the usage of scale degrees and chords. The results indisputably showed that tonal music can be characterized by specific proportions in the use of the different scale degrees, whereas the use of chords shows a constant increase in chromaticism.  Part of the material of this work appeared in the Springer-Verlag's 2006 volume of Lecture Notes in Computer Science.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">style</field><field name="subject">stylometry</field><field name="subject">musicXML</field><field name="subject">key-determination</field><field name="subject">algorithm</field><field name="subject">dot product</field><field name="subject">scale degree</field><field name="subject">chord</field><field name="subject">functional labeling</field><field name="identifier">http://eprints.qut.edu.au/16387/</field><field name="validLink">True</field></doc><doc><field name="title">The derivative imperative : how should Australian criminal trial courts treat evidence deriving from illegally or improperly obtained evidence?</field><field name="creator">Mellifont, Kerri Anne</field><field name="description">How should Australian criminal trial courts treat evidence deriving from illegally or improperly obtained evidence? The fact that derivative evidence gives rise to factors distinct from primary evidence makes it deserving of an examination of its peculiarities. In doing so, the assumption may be put aside that derivative evidence falls wholly within the established general discourse of illegally or improperly obtained evidence. Just as the judicial response to primary evidence must be intellectually rigorous, disciplined and principled, so must be the response to derivative evidence. As such, a principled analysis of how Australian courts should approach derivative evidence can significantly contribute to the discourse on the law with respect to the exclusion of illegally or improperly obtained evidence. This thesis provides that principled analysis by arguing that the principles which underpin and inform the discretionary exclusionary frameworks within Australia require an approach which is consistent as between illegally obtained derivative evidence and illegally obtained primary evidence.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">evidence-illegally</field><field name="subject">unfairly or improperly obtained evidence</field><field name="subject">criminal procedure</field><field name="subject">exclusion of evidence</field><field name="subject">real evidence</field><field name="subject">confessions</field><field name="subject">judicial discretion to exclude evidence</field><field name="subject">primary evidence</field><field name="subject">derivative evidence</field><field name="identifier">http://eprints.qut.edu.au/16388/</field><field name="validLink">True</field></doc><doc><field name="title">Professional development supporting the integration of dance in the primary classroom</field><field name="creator">Donovan, Samantha Jane</field><field name="description">In 2002, the Queensland Schools Curriculum Council launched the Years 1-10 Arts Syllabus as one of the eight Key Learning Areas. This syllabus requires primary teachers to provide arts learning programs in the areas of Dance, Drama, Media, Music and Visual Arts. This syllabus was a landmark for arts education in Queensland as it became a mandate for primary teachers to teach each strand of the arts. This move is one of many recent changes in arts education evident across the globe reflecting a common move towards a broad arts education in schools. In alignment with the mandatory requirement of the Years 1-10 Arts Syllabus, primary teachers are now required to teach Dance, a subject which most have had little to no training or professional development in. This thesis will explore the research question, 'Which strategies used in professional development build competence and confidence in primary teachers to integrate dance in the primary classroom?' Through a series of school-based professional development workshops conducted at two Gold Coast primary schools, the research project utilized an action research approach (Kemmis, 1988) to investigate the effectiveness of this professional development approach. After collating and analyzing the data gathered from these two research sites, a number of key themes emerged around the initial resistance factors to dance professional development and the integration of dance learning in the classroom as well as the impact and influence of this professional development on teachers' competence and confidence. The research identified a range of professional development strategies including learning experiences, structures, resources and conditions that have impacted on the effectiveness of this professional development.  Some of these strategies are dance specific while others are more generic and have broader implications for the development and facilitation of professional development of Queensland primary teachers.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">professional development</field><field name="subject">dance education</field><field name="subject">dance teaching. primary schools</field><field name="subject">education queensland</field><field name="subject">confidence</field><field name="subject">competence</field><field name="subject">strategies</field><field name="subject">adult learning</field><field name="subject">action research</field><field name="subject">teachers.</field><field name="identifier">http://eprints.qut.edu.au/16389/</field><field name="validLink">True</field></doc><doc><field name="title">The Separation of Powers in Australia: Issues For the States</field><field name="creator">Alvey, John Ralph</field><field name="description">A study of the separation of powers (legislative, executive, and judicial) in Australia at the Commonwealth and the State level including three Australian States, Queensland, Victoria and New South Wales. The separation of powers (SOP) theory from Locke and Blackstone is used for the SOP theory in Australia. In practice, the English rather than the American system of government and SOP is the model used for the Australian Commonwealth Government and SOP. The Commonwealth SOP is used as a guide for the States SOP. Queensland, Victoria and New South Wales are case studies used to compare and contrast with the Commonwealth. The concept of the SOP in Australia is articulated by the High Court and is derived from the Blackstonian SOP theory rather than the Federalist SOP theory. The implementation of the SOP theory into practice is problematic. The SOP theory is used as a conceptual framework to understand current events. The advantages and disadvantages or problems of the Commonwealth model are presented as a guide for the States. The same structure is used for the study of the three States in the form of the advantages and disadvantages or problems of the SOP at the State level. The entrenchment of the SOP at the State level will help to partly overcome the problems highlighted in the case study chapters. The federal SOP situation is better than at the State level but the entrenchment of Bills of Rights at the Commonwealth and State levels would help to counter the trend in reduction of civil rights. The SOP is important in protecting citizens from the abuse of government power. The lack of separation of powers, especially separation of judicial power at State level, has meant the increasing abuse of powers by the executive and the executive dominating the other two branches of government.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">separation of powers</field><field name="subject">Federal Goverment</field><field name="subject">Westminster model</field><field name="subject">US presidential model</field><field name="identifier">http://eprints.qut.edu.au/16390/</field><field name="validLink">True</field></doc><doc><field name="title">Mathematical modelling through top-level structure</field><field name="creator">Doyle, Katherine Mary</field><field name="description">Mathematical modelling problems are embedded in written, representational, and graphic text. For students to actively engage in the mathematical-modelling process, they require literacy. Of critical importance is the comprehension of the problems' text information, data, and goals. This design-research study investigated the application of top-level structuring; a literary, organisational, structuring strategy, to mathematical-modelling problems. The research documents how students' mathematical modelling was changed when two classes of Year 4 students were shown, through a series of lessons, how to apply top-level structure to two scientifically-based, mathematical-modelling problems.    The methodology used a design-based research approach, which included five phases.  During Phase One, consultations took place with the principal and participant teachers. As well, information on student numeracy and literacy skills was gathered from the Queensland Year 3 'Aspects of Numeracy' and 'Aspects of Literacy' tests. Phase Two was the initial implementation of top-level structure with one class of students. In Phase Three, the first mathematical-modelling problem was implemented with the two Year 4 classes. Data was collected through video and audio taping, student work samples, teacher and researcher observations, and student presentations. During Phase Four, the top-level structure strategy was implemented with the second Year 4 class. In Phase Five, the second mathematical-modelling problem was investigated by both classes, and data was again collected through video and audio taping, student work samples, teacher and researcher observations, and student presentations.    The key finding was that top-level structure had a positive impact on students' mathematical modelling. Students were more focussed on mathematising, acquired key mathematical knowledge, and used high-level, mathematically-based peer questioning and responses after top-level structure instruction.    This research is timely and pertinent to the needs of mathematics education today because of its recognition of the need for mathematical literacy. It reflects international concerns on the need for more research in problem solving. It is applicable to real-world problem solving because mathematical-modelling problems are focussed in real-world situations. Finally, it investigates the role literacy plays in the problem-solving process.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">mathematical modelling</field><field name="subject">problem solving</field><field name="subject">mathematising</field><field name="subject">mathematical knowledge</field><field name="subject">literacy</field><field name="subject">top-level structure</field><field name="subject">comprehension</field><field name="subject">discourse</field><field name="subject">oral communication</field><field name="subject">written communication</field><field name="subject">science</field><field name="subject">design research</field><field name="subject">metacognition</field><field name="subject">meta-language</field><field name="identifier">http://eprints.qut.edu.au/16391/</field><field name="validLink">True</field></doc><doc><field name="title">Denial of service : prevention, modelling and detection</field><field name="creator">Smith, Jason</field><field name="description">This research investigates the denial of service problem, in the context of services provided over a network, and contributes to improved techniques for modelling, detecting, and preventing denial of service attacks against these services. While the majority of currently employed denial of service attacks aim to pre-emptively consume the network bandwidth of victims, a significant amount of research effort is already being directed at this problem. This research is instead concerned with addressing the inevitable migration of denial of service attacks up the protocol stack to the application layer. Of particular interest is the denial of service resistance of key establishment protocols (security protocols that enable an initiator and responder to mutually authenticate and establish cryptographic keys for establishing a secure communications channel), which owing to the computationally intensive activities they perform, are particularly vulnerable to attack. Given the preponderance of wireless networking technologies this research hasalso investigated denial of service and its detection in IEEE 802.11 standards based networks. Specific outcomes of this research include: - investigation of the modelling and application of techniques to improve the denial of service resistance of key establishment protocols; - a proposal for enhancements to an existing modelling framework to accommodate coordinated attackers; - design of a new denial of service resistant key establishment protocol for securing signalling messages in next generation, mobile IPv6 networks; - a comprehensive survey of denial of service attacks in IEEE 802.11 wireless networks; discovery of a significant denial of service vulnerability in the clear channel assessment procedure implemented by the medium access control layer of IEEE 802.11 compliant devices; and - design of a novel, specification-based intrusion detection system for detecting denial of service attacks in IEEE 802.11 wireless networks.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">denial of service resistance</field><field name="subject">key establishment</field><field name="subject">attack prevention</field><field name="subject">specificationbased intrusion detection</field><field name="subject">security modelling</field><field name="subject">cost-based modelling</field><field name="subject">mobile IP</field><field name="subject">IEEE 802.11 wireless networks</field><field name="subject">crypto-based identifiers.</field><field name="identifier">http://eprints.qut.edu.au/16392/</field><field name="validLink">True</field></doc><doc><field name="title">Environmental risk factors for Parkinson's disease</field><field name="creator">Gartner, Coral Elizabeth</field><field name="description">Parkinson's disease (PD) is a progressive, degenerative, neurological disease. The progressive disability associated with PD results in substantial burdens for those with the condition, their families and society in terms of increased health resource use, earnings loss of affected individuals and family caregivers, poorer quality of life, caregiver burden, disrupted family relationships, decreased social and leisure activities, and deteriorating emotional well-being. Currently, no cure is available and the efficacy of available treatments, such as medication and surgical interventions, decreases with longer duration of the disease. Whilst the cause of PD is unknown, genetic and environmental factors are believed to contribute to its aetiology. Descriptive and analytical epidemiological studies have been conducted in a number of countries in an effort to elucidate the cause, or causes, of PD. Rural residency, farming, well water consumption, pesticide exposure, metals and solvents have been implicated as potential risk factors for PD in some previous epidemiological studies. However, there is substantial disagreement between the results of existing studies. Therefore, the role of environmental exposures in the aetiology of PD remains unclear.    The main component of this thesis consists of a case-control study that assessed the contribution of environmental exposures to the risk of developing PD. An existing, previously unanalysed, dataset from a local case-control study was analysed to inform the design of the new case-control study. The analysis results suggested that regular exposure to pesticides and head injury were important risk factors for PD. However, due to the substantial limitations of this existing study, further confirmation of these results was desirable with a more robustly designed epidemiological study. A new exposure measurement instrument (a structured interviewer-delivered questionnaire) was developed for the new case-control study to obtain data on demographic, lifestyle, environmental and medical factors. Prior to its use in the case-control study, the questionnaire was assessed for test-retest repeatability in a series of 32 PD cases and 29 healthy sex-, age- and residential suburb-matched electoral roll controls. High repeatability was demonstrated for lifestyle exposures, such as smoking and coffee/tea consumption (kappas 0.70-1.00). The majority of environmental exposures, including use of pesticides, solvents and exposure to metal dusts and fumes, also showed high repeatability (kappas &amp;gt0.78).    A consecutive series of 163 PD case participants was recruited from a neurology clinic in Brisbane. One hundred and fifty-one (151) control participants were randomly selected from the Australian Commonwealth Electoral Roll and individually matched to the PD cases on age (&#177; 2 years), sex and current residential suburb. Participants ranged in age from 40-89 years (mean age 67 years). Exposure data were collected in face-to-face interviews. Odds ratios and 95% confidence intervals were calculated using conditional logistic regression for matched sets in SAS version 9.1. Consistent with previous studies, ever having been a regular smoker or coffee drinker was inversely associated with PD with dose-response relationships evident for packyears smoked and number of cups of coffee drunk per day. Passive smoking from ever having lived with a smoker or worked in a smoky workplace was also inversely related to PD. Ever having been a regular tea drinker was associated with decreased odds of PD. Hobby gardening was inversely associated with PD. However, use of fungicides in the home garden or occupationally was associated with increased odds of PD. Exposure to welding fumes, cleaning solvents, or thinners occupationally was associated with increased odds of PD. Ever having resided in a rural or remote area was inversely associated with PD. Ever having resided on a farm was only associated with moderately increased odds of PD. Whilst the current study's results suggest that environmental exposures on their own are only modest contributors to overall PD risk, the possibility that interaction with genetic factors may additively or synergistically increase risk should be considered.    The results of this research support the theory that PD has a multifactorial aetiology and that environmental exposures are some of a number of factors to contribute to PD risk. There was also evidence of interaction between some factors (eg smoking and welding) to moderate PD risk.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Parkinson&#146;s disease</field><field name="subject">aetiology</field><field name="subject">risk factors</field><field name="subject">environmental exposures</field><field name="subject">epidemiology</field><field name="subject">case-control study</field><field name="subject">test-retest repeatability</field><field name="subject">exposure assessment</field><field name="subject">questionnaire</field><field name="subject">pesticides</field><field name="subject">solvents</field><field name="subject">metals</field><field name="subject">welding</field><field name="subject">rural residency</field><field name="subject">groundwater</field><field name="subject">agriculture</field><field name="subject">smoking</field><field name="subject">tobacco</field><field name="subject">nicotine</field><field name="subject">coffee</field><field name="subject">caffeine</field><field name="subject">tea</field><field name="subject">alcohol</field><field name="identifier">http://eprints.qut.edu.au/16393/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation into a dramatic writing toolset for the creation of a new work of drama</field><field name="creator">Player, Glen J.</field><field name="description">In this exegesis I have attempted to formulate a primary toolset for dramatic writing that I can apply to create dramatic structure in plays, the chief example being my play Albatross (included herein). This toolset is contingent upon Aristotle's basic tenet of drama, that "tragedy is an imitation of an action" (2002: 10). This exegesis theorises that the work of modern writers on drama such as Spencer, Packard, Catron, Lamott, See, Hicks and many others, fundamentally accords with Aristotle on this point, such that the tools they espouse can collectively be considered a standard set for dramatic writing. Beyond this, my research has led me to believe that there is a primary subset of tools specific to creating dramatic structure. These tools, formulated from dramatic theory, best capture my own way of thinking about my writing practice. I divide them into two types: the first, tools of creation, comprise Theme and Values; Character and their Values; Characters and Action; Character Orchestration and Obstacles; and Event and Significant Change. The second, tools of evaluation, are Passivity; Stakes; and Premise. Together these eight tools have been responsible for creating dramatic structure in the play, Albatross.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">action-reflection spiral</field><field name="subject">character</field><field name="subject">climax</field><field name="subject">conflict</field><field name="subject">drama</field><field name="subject">dramatic action</field><field name="subject">playwriting</field><field name="subject">playwriting toolset</field><field name="subject">practice-led research</field><field name="subject">premise</field><field name="subject">reflexivity</field><field name="subject">theme</field><field name="identifier">http://eprints.qut.edu.au/16394/</field><field name="validLink">True</field></doc><doc><field name="title">Writing women into the law in Queensland</field><field name="creator">Currie, Susan</field><field name="description">Writing Women into the Law in Queensland consists, as well as an exegesis, of profiles of seven significant women in the law in Queensland which have been published in A Woman's Place: 100 years of women lawyers edited by Susan Purdon and Aladin Rahemtula and published by the Supreme Court of Queensland Library in November 2005. Those women are Leneen Forde, Chancellor of Griffith University and former Governor of Queensland; Kate Holmes, Justice of the Supreme Court and now of the Court of Appeal; Leanne Clare, the first female Director of Public Prosecutions; Barbara Newton, the first female Public Defender; Carmel MacDonald, President of the Aboriginal Land Tribunals and the first female law lecturer in Queensland; Fleur Kingham, formerly Deputy President of the land and Resources Tribunal and now Judge of the District Court and Catherine Pirie, the first Magistrate of Torres Strait descent. The accompanying exegesis investigates the development of the creative work out of the tensions between the aims of the work, its political context, the multiple positions of the biographer, and the collaborative and collective nature of the enterprise.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">biography</field><field name="subject">women</field><field name="subject">Queensland</field><field name="subject">legal profession</field><field name="subject">creative non-fiction</field><field name="subject">feminism</field><field name="identifier">http://eprints.qut.edu.au/16395/</field><field name="validLink">True</field></doc><doc><field name="title">Effectiveness of a collaborative case management education program for Taiwanese public health nurses</field><field name="creator">Liu, Wen-I</field><field name="description">Taiwanese health authorities are increasingly applying case management as a health care delivery strategy in the community. However, most Taiwanese public health nurses (PHNs) do not receive case management education because there are few education programs available. Several limitations in existing evaluative studies of case management continuing education programs were identified. These methodological weaknesses limit the conclusions that can be drawn about the effectiveness of these education programs. Hence, the purpose of this study was to develop, implement and evaluate a collaborative case management continuing education program for Taiwanese PHNs. The study was divided into three phases, with an expanded theoretical framework used to guide the program development, implementation and evaluation. Phase One conducted focus group discussions in order to assess the educational needs of Taiwanese PHNs. Phase Two developed a collaborative education program based on the findings of a literature review and the needs assessment. The initial program was evaluated by an expert panel and pilot testing was undertaken. Phase Three implemented and evaluated the program using an experimental research design and mixed evaluation methods. Three outcome levels were assessed, namely reaction, learning and performance by examining changes in PHNs' case management knowledge, skills and practice. The participants in the study were PHNs employed in health centres in Taipei City. The program itself involved 16 hours of workshops through four half-day sessions, conducted every two weeks during the participants' work time and at their workplace.  Two types of data, focus group data and questionnaire data, were collected during the course of the study. The focus groups were conducted before and after the program delivery, for the needs assessment and program evaluation, using a subset of the participants. The focus groups were moderated by the researcher, who used a focus group discussion guide to collect data. The other data set was collected using self-report questionnaires. The participants were randomly allocated into two groups using cluster sampling, the experimental and comparison groups. Both groups were given questionnaires before the education program commenced, and then again eight weeks after the program was completed. For ethical considerations, PHNs in the comparison group also received the same program after data collection.  The results revealed that the majority of participants were satisfied with the program. The education intervention significantly improved PHNs' case management knowledge, performance skills confidence, preparedness for case manager role activities, frequency of using case management skills, and frequency of using these role activities. A number of changes in case management practice were reported, in particular that the participants tended to follow the case management process more often and focus more on the quality of case management. This study was guided by an integrated theoretical framework, and used a clustered randomised controlled design to assess the effectiveness of the program across multiple levels of outcomes, hence addressing the design deficits identified in the prior evaluative studies. This study therefore provides an important contribution to the fields of nursing and case management by developing, implementing and evaluating a case management education program. Additionally, the program itself offers an evidence-based educational experience for PHNs and provides a new tool for nursing education in the context of Taiwan.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">case management</field><field name="subject">collaboration</field><field name="subject">continuing professional education</field><field name="subject">public health nurses</field><field name="subject">case management knowledge</field><field name="subject">case management skills</field><field name="subject">case management practice</field><field name="identifier">http://eprints.qut.edu.au/16396/</field><field name="validLink">True</field></doc><doc><field name="title">Process modelling success factors and measures</field><field name="creator">Bandara, Wasana</field><field name="description">Business process modelling has gained widespread acceptance, particularly in  large IT-enabled business projects. It is applied as a process design and  management technique across all project lifecycle phases. While there has been  much research on process modelling, there has been little attention on 'how to'  conduct process modelling effectively, or on the evaluation of process modelling  initiatives and outcomes. This study addresses this gap by deriving a process  modelling success model that contains both the success factors (independent  variables) and success dimensions (dependent variables) of process modelling.  The study employs a multi-method approach, blending both qualitative and  quantitative research methods. The research design commenced with a  comprehensive literature review, which includes the first annotated bibliography  in process modelling research. A multiple case study approach was used to build  the conceptual process modelling success model which resulted in a model with  eleven (11) success factors (namely Modeller Expertise, Team Structure, Project  Management, User Competence, User Participation, Management Support,  Leadership, Communication, Modelling Tool, Modelling Language and Modelling  Methodology), two (2) moderating variables (namely Process Complexity and  Project Importance) and five (5) process modelling success dimensions (namely  Modeller Satisfaction, Model Quality, User Satisfaction, Model Use and Modelling  Impact). This conceptual model was then operationalised and tested across a  global sample, with an online survey instrument.  290 valid responses were received. The constructs were analysed seeking a  parsimonious, valid and reliable model. The statistical analysis of this phase  assisted in deriving the final process modelling success model. The dependent  variables of this model consisted of three (3) contextual success factors (namely  Top Management Support, Project Management and Resource Availability), two  (2) Modelling specific success factors (namely Modelling Aids and Modeller  Expertise), and two (2) moderating variables (namely Importance and Process  Complexity). The dependent variable; Process Modelling Success (PMS) was  derived with three (3) success measurement dimensions (namely Model Quality,  Process Impacts and Process Efficiency). All resulting success factors proved to  have a significant role in predicting process modelling success. Interaction  effects with the moderating variables (Importance and Process Complexity)  proved to exist with Top Management Support (TMS) and Resource Availability  (RA). A close analysis to their interaction relationship illustrated that Importance  (IMP) moderated the relationship between Top Management Support (TMS) and  Process Modelling Success (PMS) in a linear manner and that Process Complexity  (PC) moderated the relationship between Resource Availability (RA) and Process  Modelling Success (PMS), also in a linear manner.  This is the first reported study with empirical evidence on process modelling  success. The progressive outcomes of this study have been readily accepted by  the practitioner and academic community, with 16 published internationalrefereed-  conference papers [including best paper award at the Pacific Asian  Conference on Information Systems (PACIS 2004)], 2 journal publications, and  over 5 major industry presentations made upon invitation.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">process modelling</field><field name="subject">success factors</field><field name="subject">success measures</field><field name="subject">moderating variables</field><field name="subject">case study method</field><field name="subject">survey method</field><field name="subject">multi-method approach</field><field name="identifier">http://eprints.qut.edu.au/16397/</field><field name="validLink">True</field></doc><doc><field name="title">Health, well-being and sexual violence among female sex workers : a comparative study</field><field name="creator">Seib, Charrlotte</field><field name="description">Background: Prostitution has been documented in most societies, although the context in which it occurs may vary greatly.  In Queensland, Australia, sex workers can operate from legal brothels or privately but all other sectors of the sex industry are prohibited.  It is assumed that regulation of the sex industry through legalization leads to better health and social outcomes for sex workers and their clients.  However, this assumption has rarely been subjected to empirical scrutiny.  Aims: This research examined the occupational health and safety of female sex workers in Queensland and explored the relationship between legislative change, workplace violence, mental health and job satisfaction.  Sex workers interviewed in 2003 (after legalisation) were compared to a prior study of this population conducted in 1991 (before official regulation of the sex industry).  Further, in-depth analysis of the 2003 cohort compared sex workers employed in legal and illegal sectors, to assess violence, health status and job satisfaction. Methods: Cross-sectional, convenience sampling was used to collect data from female sex workers in 2003.  This data was compared with data collected earlier (in 1991) and explored differences in the two samples using bivariate analysis.  Similar recruitment strategies on both occasions were used to recruit women from all known sectors of the Queensland sex industry.  The 1991 comparison sample (Boyle et al. 1997) included 200 women (aged between 16 and 46 years), and in 2003, 247 women (aged 18 to 57) participated.  The 2003 sample included workers from legal brothels (n=102), private sole-operators (n=103) and illegal street-based sex workers (n=42).  Using data collected in 2003, this study assessed the relationship between physical and mental health and job satisfaction and two main independent variables, i.e., current work sector and recent workplace violence.  Bivariate analysis of physical health and independent variables showed no significant relationships and therefore further analysis was not undertaken.   However, analysis of mental health and job satisfaction showed complex interactions between multiple variables and therefore linear modeling was performed to adjust for confounding.  Results: Analysis of the 1991 and 2003 samples showed little apparent change over time in self-reported sexually transmitted infections (STIs). There were substantial changes over time in the types of sexual services being provided to clients, with the 2003 sample more likely to provide 'exotic' services.  Violence experienced ever in their lifetime differed; in 1991, 29% reported having ever been raped compared with 42% in 2003 (p= &amp;lt0.01).  In 2003, 50% of illegal sex workers reported having ever been raped by a client compared with 12% of private sex workers and 3% of brothel-based sex workers (p=&amp;lt0.01).  Overall, the sex workers reported roughly equivalent job satisfaction to Australian women.  A desire to leave the sex industry was most strongly correlated with reduced job satisfaction (p=&amp;lt0.01).  Satisfaction was also relatively low among those whose family was not aware of their sex work (p=&amp;lt0.01).  Similarly, the mental and physical health of this sample was comparable to age-matched women from the general population. Wanting to leave the sex industry was most strongly associated with poor mental health (p=&amp;lt0.01), as was recent sexual or physical assault by a client (p=0.06) and the woman's main work sector (p=0.05).  Illegal sex workers reported substantially lower mental health scores than their counterparts in legal sex work.  Conclusions: Self-reported STI diagnosis was high in these samples but the prevalence appears not to have changed over time.  Comparing 2003 to 1991, there were trends towards safer and more diverse sexual practices.  It is likely the sex industry has 'professionalized' and now includes more sex workers providing specialist, 'exotic' services.  This sample of female sex workers reported high rates of violence, with those working illegally at greatest risk.  Analysis suggests a complex interaction between variables contributing to mental health and job satisfaction. In general, it appears that the majority of sex workers enjoyed at least as much job satisfaction as women working in other occupations. It also appears that this sample had equivalent mental health to women from the general population, although the sub-group of illegal workers generally had poorer health.  Job satisfaction and the extent of workplace hazards (especially risk of violence) were also strongly associated with different sectors of the sex industry. It is probable that legalisation has benefited some (perhaps most) but there are health and safety concerns for those outside the legal framework.  Legislative reform should focus on violence prevention, promoting reporting of violent events to police, and further exploration of the impact of legislation on the health of workers in the sex industry.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">correlation</field><field name="subject">female sex worker</field><field name="subject">job satisfaction</field><field name="subject">legalization</field><field name="subject">legislative structure</field><field name="subject">mental health</field><field name="subject">occupational health and safety</field><field name="subject">occupational demand</field><field name="subject">physical health</field><field name="subject">physical assault</field><field name="subject">rape</field><field name="subject">prostitution</field><field name="subject">regulated sex industry</field><field name="subject">sex industry</field><field name="subject">sex work</field><field name="subject">sexual abuse</field><field name="subject">sexual assault</field><field name="subject">sexually transmitted infection</field><field name="subject">SF 36</field><field name="subject">workplace</field><field name="identifier">http://eprints.qut.edu.au/16398/</field><field name="validLink">True</field></doc><doc><field name="title">Risk factors leading to cost overrun in the delivery of highway construction projects</field><field name="creator">Creedy, Garry D.</field><field name="description">Accurate client budget estimates are critical to the initial decision-to-build process for the highway construction projects. This decision-to-build point in a project's development is seen as the international standard for measuring any subsequent cost estimate inaccuracies involved (National Audit Office/Department of Transport, 1992; World Bank, 1994; Nijkamp and Ubbels, 1999), with accuracy being defined as the difference between the initial project estimate at the decision-to-build stage and the real, accounted project cost determined at the time of project completion. Expressed as a percentage of estimated cost, this is often termed cost escalation, cost overrun or cost growth, and occurs as a result of many factors, some of which are related to each other, but all are associated with forms of risks. The analysis of these risks is often a necessary step for the improvement of any given estimating system and can be used to diagnose trouble spots and to pinpoint areas where project estimating accuracy improvement might be obtained.    In this research, highway projects in Queensland, Australia that have suffered significant cost overrun are analysed. The research seeks to address the gap in the knowledgebase as to why highway projects overrun their costs. It focuses on understanding how client projects budgets go wrong, when dealing with project risk.    The foundation for this research is drawn from the post-mortem analysis of highway projects, each costing in excess of A$1m and whose final total expenditure exceeded budget by 10% or greater. The research identifies client risk variables which have contributed to significant cost overrun and then uses factor analysis and also expert elicitation, using nominal group technique, to establish groups of importance ranked client risks. Stepwise multivariate regression analysis is then used to investigate any correlation of these risks, along with project attributes such as highway project type, indexed project cost, geographic location and project delivery method to the percentage of cost overrun.    The research results indicates a correlation between the reciprocal of project budget size and percentage cost overrun that can be useful in clients determining more realistic decision-to build highway budget estimates when taking into account project size in relation to economy of scale.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">highway construction</field><field name="subject">project budgeting</field><field name="subject">cost performance</field><field name="subject">construction management</field><field name="identifier">http://eprints.qut.edu.au/16399/</field><field name="validLink">True</field></doc><doc><field name="title">Wind-induced natural ventilation of the refuge floor of a high-rise building in Hong Kong</field><field name="creator">Cheng, Charles Chor Kwan</field><field name="description">An important element in the building fire safety of high-rise buildings in Hong Kong since 1996 has been the use of refuge floors in the building's evacuation system. To prevent smoke collecting and remaining in the refuge floors, the Building Code of Hong Kong requires these floors to have openings on opposite sides to provide adequate wind-induced ventilation. Other researchers using CFD simulations without wind tunnel verification have indicated that under certain conditions smoke could still remain on these floors and thereby reducing the fire safety of the refuge floors. This thesis explores these situations and presents a detailed scientific investigation of the wind movement in and around a refuge floor at mid-height of a high-rise building using wind tunnel testing together with CFD simulations (using CFD CFX-5.6 package). Besides identifying problem areas for smoke logging, this thesis also identifies how the design of a refuge floor can be modified to improve its fire safety.    A significant factor on the fire safety of a refuge floor is the blocking effect of the building's central core and its effect on the wind-induced ventilation. Under Hong Kong Building Code, the central core can occupy up to 50% of the refuge floor. Previous investigators did not take into consideration the effect of the maximum core size on natural ventilation of the refuge floor. This thesis investigates the worst case scenario for a refuge floor that has a core occupying 50% of the floor and has two solid walls on opposite side of the floor to identify the problem areas where smoke could collect and remain.    In exploring the worst case scenario with two parallel solid walls, the investigations revealed that the ceiling height and the wind direction have a significant effect on the wind ventilation of the refuge floor. These factors were not identified by previous investigators. In the case of the ceiling height, it was found that the head height of the refuge floor should be greater than 0.02 times the building height to achieve the desirable wind environment on the refuge floor. Regarding wind directions, the wind from most angles escapes the floor via the channel-like corridors next to the central core of the building. The main problem area occurred when the wind was perpendicular to the solid side walls. This resulted in noticeable stagnant areas where smoke could remain.    To validate the CFD method used in the thesis, wind tunnel experiments were performed to provide the scientific field velocity data of wind flowing over the building and in the refuge floor located at mid-height of the building. Earlier researchers of the refuge floor did not have access to wind tunnel data of a refuge floor. In comparing the wind tunnel experiments with the CFD simulations used in the thesis, acceptable agreement was achieved. These results make it possible for a significant reduction in the CFD computational effort that previous studies required.    Based on the findings of the investigations undertaken, design recommendations are proposed to improve the fire safety of the refuge floor in multistorey buildings in Hong Kong.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">refuge floor</field><field name="subject">high-rise building design</field><field name="subject">fire safety of high-rise building</field><field name="subject">wind-induced natural ventilation of building</field><field name="identifier">http://eprints.qut.edu.au/16400/</field><field name="validLink">True</field></doc><doc><field name="title">Identification of epitopes on the Dengue virus type 4 envelope glycoprotein involved in neutralisation by antibodies</field><field name="creator">Howard, Christopher Bruce</field><field name="description">Dengue virus (DENV) is the causative agent of dengue fever (DF), the most prevalent arthropod-borne viral disease in the world and therefore is considered an emerging global health threat.  The four DENV serotypes (DENV-1, DENV-2, DENV-3 and DENV-4) that infect humans are distinguished from one another by unique antigenic determinants (epitopes) on the DENV envelope (E) protein. The E protein is the primary antigenic site of the DENV and is responsible for inducing neutralising antibody (Ab) and cell mediated immune response in DENV infected hosts.  The DENV E protein also mediates attachment of virions to host cell receptors and entry of virions into host cells by membrane fusion.  The study of epitopes on DENV E protein is necessary for understanding viral function and for the design of unique polyvalent vaccines capable of inducing a neutralising antibody response against each DENV serotype.  Reverse genetics using infectious cDNA clones has enabled the construction of functional intertypic DENV, where the E protein of one DENV serotype is put in the genetic background of a different DENV serotype.  In addition, observations from our laboratory indicate that chimeric E proteins, consisting of E protein structural domains from different DENV serotypes can fold into functional proteins.  This suggests that there is potential to engineer viruses with intertypic DENV E proteins as potential DENV vaccine candidates, which is the long term goal of studies within our research group.  However, if a chimeric E protein was to be constructed containing epitopes involved in antibody mediated neutralisation of each DENV serotype, then knowledge of the location of these epitopes on the E protein of each DENV serotype would be essential.   Prior to this study, monoclonal antibodies (MAbs) had been used to identify epitopes involved in antibody mediated neutralisation on the E protein of all DENV serotypes, except DENV-4.  The primary objective of this study was to identify epitopes on the DENV-4 E protein involved in neutralisation by antibodies. In order to achieve this objective, a panel of 14 MAbs was generated against DENV-4 in BALB/c mice and characterised using various serological and functional assays.  The identification of DENV-4 specific neutralising MAbs in the panel was essential for subsequent experiments aimed at determining antigenic domains, structural domains or specific epitopes (peptides or amino acids) involved in the neutralisation of DENV-4.    The majority of MAbs (11/14) generated against DENV-4 recognised the E protein.  The remaining three MAbs reacted with the non-structural (NS) 1 protein.  The majority of MAbs against the E protein were DENV or Flavivirus group reactive, but four MAbs were DENV-4 specific.  All MAbs against the E protein recognised conformationally dependent epitopes and were able to capture DENV-4 in an enzyme linked immuno-adsorbent assay (ELISA).  Eighty percent (9/11) of the anti-E MAbs produced for this study neutralised infection of cells by DENV-4 in vitro. Three of the neutralising MAbs (F1G2, 18F5 and 13H8) were DENV-4 specific and also demonstrated the strongest neutralisation activity of the panel, reducing DENV-4 infectivity by 100-1000 fold.  The amount of virus neutralised by the MAbs was not related to the avidity of the MAbs.  The DENV-4 specific MAbs F1G2, 18F5 and 13H8 were used to identify epitopes involved in neutralisation of DENV-4.    The MAbs that effectively captured DENV-4 were used in competitive binding assays (CBAs) to determine spatial relationships between epitopes and therefore define antigenic domains on the DENV-4 E protein. The CBAs indicated that the epitopes recognised by the panel of MAbs segregated into two distinct domains (D4E1 and D4E2) and both contained epitopes involved in neutralisation.  CBAs incorporating human serum from DENV-4 infected patients suggested that the MAbs recognised the same, or spatially related, epitopes in domain D4E2 as antibodies from humans who had experienced natural dengue infections, indicating the clinical relevance of such epitopes for the development of DENV vaccines.  The reactivity of the capture MAbs with low pH treated DENV-4 was also evaluated in an attempt to identify epitopes that might be more accessible during low pH-mediated virus fusion.  Only one of the MAbs (13H8) recognised an acid resistant epitope.  Initial attempts to identify epitopes on the DENV-4 E protein involved in neutralisation followed the traditional epitope mapping approach of selecting subpopulations of DENV-4 which escaped neutralisation by MAbs.  These attempts were unsuccessful so a variety of strategies for mapping epitopes were used including DENV-4 variant analysis and site directed mutagenesis of the DENV-4 E protein, MAb screening of chimeric DENV-3/4 E proteins and MAb screening of a bacterial peptide display library. DENV-4 variants including DENV-4 isolates from different geographical locations or chemically mutagenised DENV-4 were screened with neutralising MAbs to identify neutralisation escape mutant (n.e.m.) viruses. Site directed mutagenesis of the DENV-4 E protein confirmed whether amino acid changes identified in DENV-4 n.e.m.s were essential for the binding of neutralising MAbs to an epitope. The MAb screening of DENV-4 variants identified n.e.m.s with amino acid changes at residues E95, E96, E156, E157, E203, E329 and E402 of the DENV-4 E protein.  Site directed mutagenesis of the DENV-4 E protein identified two epitopes recognised by the DENV-4 specific neutralising MAbs F1G2 and 18F5 at specific amino acid residues within domains II and III of the DENV-4 E protein.  No specific epitopes were identified for the MAb 13H8; however this MAb did recognise domain I and II of the DENV-4 E protein, when screened against DENV-3/4 chimeric DENV E proteins.    The first epitope, which was recognised by the MAb F1G2, contained residue E95 which was located in domain II of the DENV-4 E protein. The aspartate (Asp) to alanine (Ala) change at E95 prevented the binding of F1G2 to the DENV-4 E protein.  The binding of F1G2 to the E95 residue was confirmed using the pFlitrX bacterial peptide display library, which demonstrated binding of F1G2 to a peptide homologous with residues E99-E104.  No peptides recognised by 13H8 and 18F5 were identified by this method.  The MAb F1G2 also bound to the domain III region (E300-E495) of the DENV-4 E protein when screened against DENV-3/4 chimeric DENV E proteins.  This implied that F1G2 may be recognising a discontinuous epitope consisting of domains II and III. The second epitope, which was recognised by MAb 18F5, contained residue E329 which was located in domain III of the DENV-4 E protein.  The alanine (Ala) to threonine (Thr) change at E329 prevented the binding of 18F5 to the DENV-4 E protein.  MAb 18F5 also bound to the domain III region (E300-E495) of the DENV-4 E protein when screened against DENV-3/4 chimeric E proteins, thus confirming the E329 epitope. The potential mechanisms by which the DENV-4 specific MAbs neutralise virus infection were evaluated by the virus overlay protein binding assay (VOPBA).  The binding of MAb 18F5 to a domain III (E329) epitope of the DENV-4 E protein and the binding of MAb F1G2 to domain II (E95, E99-E104) and domain III epitopes (chimeric E protein) of the DENV-4 E protein, prevented the attachment of DENV-4 to a 40 kDa C6/36 cell protein.  In contrast the binding of MAb 13H8 to domains I and II of the DENV-4 E protein did not prevent attachment of DENV-4 to the same protein.  This was preliminary evidence that the binding of domain III epitopes by the MAbs F1G2 and 18F5 may be important in preventing virus attachment.  The binding of MAb 13H8 to domains I and II, and the ability of this MAb to recognise DENV-4 treated at low pH, suggested that MAb 13H8 may block epitopes exposed at low pH that are required for low pH mediated virus fusion to host cell membranes.    Overall, the different methods used in this study identified epitopes involved in the neutralisation of DENV-4.  The distribution of epitopes involved in neutralisation throughout the DENV-4 E protein were similar to the distribution of epitopes involved in neutralisation on the DENV-1, 2 and 3 E proteins.  This suggested that it might be possible to elicit neutralising antibodies against multiple DENV serotypes using chimeric E-proteins derived from two or more DENV serotypes and therefore, facilitate the design of novel tetravalent DENV vaccines.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Dengue virus</field><field name="subject">envelope protein</field><field name="subject">neutralisation</field><field name="subject">monoclonal antibody</field><field name="subject">epitope</field><field name="subject">neutralisation escape mutant</field><field name="subject">chimeric E protein</field><field name="subject">site directed mutagenesis</field><field name="subject">peptide display</field><field name="subject">tetravalent vaccine</field><field name="identifier">http://eprints.qut.edu.au/16401/</field><field name="validLink">True</field></doc><doc><field name="title">Benchmarking of the biomechanical characteristics of normal and degraded articular cartilage to facilitate mathematical modelling</field><field name="creator">Moody, Hayley Ruscoe</field><field name="description">In order to validate the appropriate functional characteristics of cartilage, we need to systematically study and understand what constitutes normality and degradation in cartilage. This thesis provides an important step in this direction.    To understand the mechanical repercussions of disruption to the matrix properties, cartilage is often artificially degraded using common enzymes. Although the process of artificial degradation does not provide an accurate representation of osteoarthritis, it can provide insight into the biomechanical properties of single matrix components by examining the behaviour of the tissue following its removal. Through histological analysis utilising the optical absorbance measurements of Safranin O stain, this work has demonstrated that for a given time and enzyme concentration, the action of Trypsin on proteoglycans is highly variable and is dependent on:  *	The initial distribution and concentration of proteoglycans at different depths  *	The intrinsic sample depth  *	The location in the joint space, and *	The medium type. These findings provide initial data towards a mathematical model which researchers can use to optimise Trypsin treatment of articular cartilage, and therefore model degeneration in vitro with a better degree of certainty.    The variability noted in the distribution and concentration of proteoglycans, and most likely the collagen network, creates a large variation in the compressive and tensile stiffness of all samples, and total failure strain energy. The average values for each of these tests indicate that a loss of proteoglycan through Trypsin treatment results in decreased compressive stiffness, increased tensile stiffness, and little change to the failure strains or total failure strain energy. Conversely, disruption to the collagen network shows increased compressive and tensile stiffness, as well as failure strain and total failure strain energy. Due to the large variation in the results for each treatment group, the average values for the treated samples fall within the range of results for normal cartilage. These values cannot therefore be used as dependable parameters to benchmark cartilage, since the parameters for artificially degraded cartilage are within the normal levels. The Yeoh and Polynomial hyperelastic laws were found to best represent the material characteristics of cartilage across the range of tested samples, regardless of differences in health and strength.    The results presented here provide important insight into the biomechanical outcomes of artificial degradation and provide direction for future research in this area.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">articular cartilage</field><field name="subject">enzyme degradation</field><field name="subject">compression</field><field name="subject">hyperelasticity</field><field name="subject">fracture mechanics</field><field name="identifier">http://eprints.qut.edu.au/16402/</field><field name="validLink">True</field></doc><doc><field name="title">A shock to the system : the structural implications of enterprise system technology</field><field name="creator">Murphy, Glen Desson</field><field name="description">The last two decades have seen an increasing sophistication in the type of information systems employed by organizations. In particular we have seen the emergence of enterprise systems technology - advanced information technology specifically designed  to integrate the vast majority of an organization's processes and data flows. As the  characteristics of ES technology have encroached beyond individual user domains  and have become integrated throughout organizations, user acceptance issues have  also broadened beyond the individual unit of analysis. At the same time numerous  examples can be found both in the trade press and academic literature of organizations  wishing to use enterprise systems as a primary driver of widespread organizational  change and restructuring.  A fundamental premise of this study is that while it may be intuitively appealing to  consider technology as a primary catalyst for organizational change, it neglects to  acknowledge the presence of what is referred to as the &amp;quoteduality of structure&amp;quote (Giddens,  1993). Duality of structure proponents contend that while IT system protocols may  to a certain extent determine individual action, human agency can also determine the  extent to which the technology is incorporated into everyday operations. The failure  of past research to acknowledge the role of individual action and the influence of social  context in determining IT usage is considered to be a significant oversight (DeSanctis  &amp; Poole, 1994).  Underpinned by the theory of structuration and its notion of duality, a theory of user  acceptance is put forward capable of clarifying the process by which users evaluate  and react to enterprise systems technology. The thesis reports on an empirical  investigation into the relationship between three representations of structure within an  organization: the characteristics of ES technology; job design; and social networks.  The capacity of ES technology to alter the structural elements of both job design and  social networks, and hence form user's attitudes and behavior towards the system,  is the fundamental theoretical premise of the thesis. As such this represents a clear  step forward in understanding the implications of ES technology for both users and  organizational structure.  Using a longitudinal embedded single case design, this study examines the user  acceptance and structural implications of introducing an ES into a large public sector  educational institution. A social network and job design perspective was adopted to  offer fresh insight into the dynamics of employee reaction to the introduction of ES  technology. Five hypotheses support the job design component of the thesis. It was argued that given the inherent design elements of ES technology, along with the specific  intent of the system's introduction, that users would both anticipate and perceive a  decrease in job characteristics following an ES implementation. Further, that the  positive relationship between job change and user acceptance would be moderated  by the amount of system usage reported by users. Users with a greater exposure to  the system were hypothesized to have a far stronger relationship between job change  and acceptance than low users. The ramifications of perceived or actual changes to  embedded resource exchange networks and subsequent employee reactions to those  changes were also considered. Essentially social networks were argued to play a  dual role in the user acceptance process, one being a conduit for the facilitation and  transfer of user attitudes towards new systems, the other acting as a catalyst for attitude  formation towards new systems.  Overall the findings only partially supported four of the eight hypotheses put forward.  While users were seen to anticipate an &amp;quoteacross the board&amp;quote decrease in job characteristics  at Time 1 following the introduction of an ES, perceived changes in job characteristics  at Time 2 were dependant on user hierarchy and the extent of system usage. Those  high in formal authority reported an increase in job enrichment following the system's  introduction, while those low in formal authority reported a decrease in overall job  enrichment. Usage was also seen to moderate the relationship between job change  and user acceptance. At Time 1 low users reported a positive relationship between  anticipated changes in meaningfulness and user acceptance. Conversely at Time 1 high  users reported a negative relationship between anticipated skill variety levels at Time 2  and user acceptance. Only one job characteristic reported a relationship between usage  and user acceptance. Low users reported a positive relationship between changes in  task identity and user acceptance. A post-hoc profile of the usage categories indicated  that high users were more likely to be a lower hierarchical position than low users.  The positive relationship reported by low users at Time 1 and Time 2 was explained by  both the nature of the system, as well as the type and quantity of information received  by low users. As senior members of the organization they were considered more likely  to receive information that highlighted its attributes in the context of their job roles. The  inherent design of ES technology, along with the specific intent it was being introduced,  facilitated largely management orientated objectives. Therefore it is unsurprising  that low users anticipating an increase in experienced meaningfulness following the  introduction of a system that enhanced their job role reported corresponding acceptance  levels. In contrast, the negative relationship between anticipated levels of skill variety  at Time 2 and perceived ease of use was explained by the affinity that high users were likely to have with the old system. To high users with a high degree of proficiency  associated with a redundant skill set, increased skill variety only represented a steeper  learning curve and an increased pressure to adapt to the new system.  The network component of the study also produced mixed results. Of the two networks  that were measured over time, only one supported the hypothesized increase in both  advice and resource exchange networks over time. Post-hoc analyses indicated that  two of the four groups exhibited network change consistent with the hypothesized  relationship. Anecdotal reports suggested that contextual elements such as geographical  location and managerial policy at a localized level determined the nature of the change  for the remaining two groups. The results failed to support the relationship between  network change and user acceptance. However, a weak but significant negative  relationship between the measure of network efficiency and user acceptance was  found. In simple terms users developing an increasingly redundant set of contacts  reported higher levels of user acceptance.  In sum, the thesis represents a contribution to enterprise systems, user acceptance  and social network literatures. In the first instance the research validates the call by  Orlikowski &amp; Iacono (2001) to readily acknowledge the specific nature of the technology  under investigation. Despite the growth and saturation of enterprise system types,  comparatively little research has been undertaken to examine the user and organizational  issues surrounding their implementation. This research has demonstrated the capacity  for the inherent design elements of ES technology to have differential effects in terms  of job design for different user classifications. This and other findings represent a  step forward in understanding the structural and user acceptance implications of this  technology, while sign-pointing a number of promising future research avenues.  The job design results, and to a lesser extent the network efficiency results, demonstrate  the effect of social context on user acceptance. As such they provide further insight  regarding the potential determinants of user acceptance beyond the individual unit of  analysis. The findings also indicate an increasing need for user acceptance research to  stretch beyond the transitory, short term measures of user acceptance such as perceived  ease of use, usefulness, training and computer efficacy.  Finally the thesis contributes to a small, but growing literature examining the role of  social networks in the process of organizational change. In particular this thesis has  considered in detail, the attitudinal and behavioral consequences of artificially altering  established patterns of interaction. As such the study highlights the need to better  understand the role of networks not only in the case of facilitating change, but the  effect of network change in terms of change intervention success.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">enterprise systems</field><field name="subject">job design</field><field name="subject">job characteristics model</field><field name="subject">social network analysis</field><field name="subject">organisational change</field><field name="subject">user acceptance</field><field name="identifier">http://eprints.qut.edu.au/16403/</field><field name="validLink">True</field></doc><doc><field name="title">Price and volatility relationships in the Australian electricity market</field><field name="creator">Higgs, Helen</field><field name="description">This thesis presents a collection of papers that has been published, accepted or submitted for publication. They assess price, volatility and market relationships in the five regional electricity markets in the Australian National Electricity Market (NEM): namely, New South Wales (NSW), Queensland (QLD), South Australia (SA), the Snowy Mountains Hydroelectric Scheme (SNO) and Victoria (VIC). The transmission networks that link regional systems via interconnectors across the eastern states have played an important role in the connection of the regional markets into an efficient national electricity market. During peak periods, the interconnectors become congested and the NEM separates into its regions, promoting price differences across the market and exacerbating reliability problems in regional utilities. This thesis is motivated in part by the fact that assessment of these prices and volatility within and between regional markets allows for better forecasts by electricity producers, transmitters and retailers and the efficient distribution of energy on a national level.    The first two papers explore whether the lagged price and volatility information flows of the connected spot electricity markets can be used to forecast the pricing behaviour of individual markets. A multivariate generalised autoregressive conditional heteroskedasticity (MGARCH) model is used to identify the source and magnitude of price and volatility spillovers within (intra-relationship) and across (inter-relationship) the various spot markets. The results show evidence of the fact that prices in one market can be explained by their own price lagged one-period and are independent of lagged spot prices of any other markets when daily data is employed. This implies that the regional spot electricity markets are not fully integrated. However, there is also evidence of a large number of significant ownvolatility and cross-volatility spillovers in all five markets indicating that shocks in some markets will affect price volatility in others. Similar conclusions are obtained when the daily data are disaggregated into peak and off-peak periods, suggesting that the spot electricity markets are still rather isolated.    These results inspired the research underlying the third paper of the thesis on modelling the dynamics of spot electricity prices in each regional market. A family of generalised autoregressive conditional heteroskedasticity (GARCH), RiskMetrics, normal Asymmetric Power ARCH (APARCH), Student APARCH and skewed Student APARCH is used to model the time-varying variance in prices with the inclusion of news arrival as proxied by the contemporaneous volume of demand, time-of-day, day-of-week and month-of-year effects as exogenous explanatory variables. The important contribution in this paper lies in the use of two latter methodologies, namely, the Student APARCH and skewed Student APARCH which take account of the skewness and fat tailed characteristics of the electricity spot price series. The results indicate significant innovation spillovers (ARCH effects) and volatility spillovers (GARCH effects) in the conditional standard deviation equation, even with market and calendar effects included. Intraday prices also exhibit significant asymmetric responses of volatility to the flow of information (that is, positive shocks or good news are associated with higher volatility than negative shocks or bad news).    The fourth research paper attempts to capture salient feature of price hikes or spikes in wholesale electricity markets. The results show that electricity prices exhibit stronger mean-reversion after a price spike than the mean-reversion in the normal period, suggesting the electricity price quickly returns from some extreme position (such as a price spike) to equilibrium; this is, extreme price spikes are shortlived. Mean-reversion can be measured in a separate regime from the normal regime using Markov probability transition to identify the different regimes.    The fifth and final paper investigates whether interstate/regional trade has enhanced the efficiency of each spot electricity market. Multiple variance ratio tests are used to determine if Australian spot electricity markets follow a random walk; that is, if they are informationally efficient. The results indicate that despite the presence of a national market only the Victorian market during the off-peak period is informationally (or market) efficient and follows a random walk.    This thesis makes a significant contribution in estimating the volatility and the efficiency of the wholesale electricity prices by employing four advanced time series techniques that have not been previously explored in the Australian context. An understanding of the modelling and forecastability of electricity spot price volatility across and within the Australian spot markets is vital for generators, distributors and market regulators. Such an understanding influences the pricing of derivative contracts traded on the electricity markets and enables market participants to better manage their financial risks.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">spot electricity price markets</field><field name="subject">mean and volatility spillovers</field><field name="subject">multivariate GARCH</field><field name="subject">normal asymmetric power ARCH (APARCH)</field><field name="subject">Student APARCH</field><field name="subject">skewed Student APARCH</field><field name="subject">price spikes</field><field name="subject">mean-reversion</field><field name="subject">multiple variance ratio tests</field><field name="subject">market efficiency and random walk</field><field name="identifier">http://eprints.qut.edu.au/16404/</field><field name="validLink">True</field></doc><doc><field name="title">Haemostatic activation and its relationship to neuropsychological changes following cardiopulmonary bypass surgery</field><field name="creator">Raymond, Paul Douglas</field><field name="description">Neuropsychological impairment following cardiopulmonary bypass (CPB) remains a serious consequence of otherwise successful surgery. The incidence of neuropsychological decline is poorly understood due to varied measurement intervals, and perhaps more importantly the use of unreliable detection and classification methods. The reported incidence varies considerably, ranging anywhere from 30% to 90% of subjects. While the nature of this impairment has not been fully elucidated, recent evidence suggests that microembolism during surgery may be the principal causative agent of postoperative cerebral dysfunction. The work described in this thesis investigates one possible source of microembolism leading to postoperative decline, namely thromboembolism arising from excessive activation of the haemostatic mechanism. Crucial to the accurate detection of significant decline in individual patients, this work also focuses on the development and use of meaningful criteria to be used when describing change in neuropsychological performance measures.
 
 
 
 The strong haemostatic activation during CPB is controlled by heparin anticoagulation. The clinical performance of the Hepcon heparin-monitoring instrument was compared to the activated clotting time (ACT), which is used in most cardiac centres. An analysis of samples from 42 elective coronary artery bypass grafting (CABG) patients shows that the ACT does not detect the significant decline in heparin concentration seen upon connection to CPB, in comparison to the Hepcon. The Hepcon appears to be in satisfactory agreement with laboratory anti-Xa analysis of heparin concentration, with the mean difference for the Hepcon at -0.46 U/ml, and the limits of agreement +/- 1.12 U/ml. Further analysis shows that that for 95% of cases, the Hepcon will give values that are between 0.53 and 1.27 times the value for anti-Xa. 
 
 
 
 The loss of relationship between ACT and heparin concentration was further investigated by converting ACT values to heparin concentration. The results provide data on the degree of prolongation in ACT times brought about by factors associated with CPB. A methodology is presented by which users can adjust for the loss of relationship between ACT and heparin. This work also demonstrates that under normal usage of the ACT, the user may obtain values up to 3 times appropriate for the plasma heparin concentration. 
 
 
 
 The computer-administered neuropsychological testing tool (the MicroCog) was validated using 40 age-matched control subjects. Using a two-week interval, the summary score correlation coefficients ranged from .49 to .84, with all scores demonstrating significant practice effects. Also presented are retest normative data that may be used to determine significant change in a homogeneous sample using both reliable change and regression models of analysis. The performance of four different models of change analysis was then analysed using data from the clinical group. The regression technique of analysis was shown to be the most useful prediction model as it provides correction for both practice effects and regression toward the mean in each individual. A novel statistical rationale is presented for the choice of criteria in the identification of patients that may be defined as overall impaired when using a battery of test scores. When using one-tailed prediction models for decline, the binomial distribution of scores was shown to be a useful descriptive statistic providing an estimate of change due to chance. When applied to a suitable selection of scores that minimise shared variance, a value +/- 20% of test scores used was demonstrated to be a rational cut-off for an individual to be classified as impaired. Using this methodology, 32.7% of patients were identified as significantly deteriorated in neuropsychological test function immediately prior to discharge from hospital. Patient age was shown to be a significant predictor of neuropsychological decline following CPB. No significant relationship was identified between thrombin generation and neuropsychological change scores, however problems with patient recruitment and retention limited the statistical power of this study. An intriguing relationship with heparin concentration was noted that might warrant further investigation. 
 
 
 
 This work highlights the complex nature of post-bypass neuropsychological dysfunction and the complexities in assessing decline. The regression-based model was shown to be highly useful in the analysis of data from a suitably validated neuropsychological testing tool. The argument that no suitable criterion exists for the identification of patients as overall impaired has been challenged with the development of a rational cut-off based on the likely distribution of change scores across a series. The work presented here confirms the need for standardised testing methods based on sound statistical criteria. This work also highlights the problems associated with current methods for monitoring anticoagulation therapy during bypass surgery. Methodology is presented that allows adjustment of ACT results to account for CPB-induced prolongation of clotting times. Current techniques for heparin monitoring overestimate heparin levels on bypass by up to threefold, which may predispose to subclinical coagulation and increased delivery of protamine.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">cardiopulmonary bypass</field><field name="subject">coronary artery bypass graft</field><field name="subject">neuropsychological</field><field name="subject">neurocognitive</field><field name="subject">stroke</field><field name="subject">heparin</field><field name="subject">haemostatic activation</field><field name="subject">thrombin</field><field name="subject">activated clotting</field><field name="subject">time</field><field name="subject">reliable change</field><field name="subject">practice effect</field><field name="subject">MicroCog</field><field name="subject">S100</field><field name="identifier">http://eprints.qut.edu.au/16405/</field><field name="validLink">True</field></doc><doc><field name="title">A component-based layered abstraction model for software portability across autonomous mobile robots</field><field name="creator">Smith, Robert</field><field name="description">Today's autonomous robots come in a variety of shapes and sizes from all terrain  vehicles clambering over rubble, to robots the size of coffee cups zipping about a laboratory.  The diversity of these robots is extraordinary; but so is the diversity of the  software created to control them even when the basic tasks many robots undertake  are practically the same (such as obstacle detection, tracking, or path planning). It  would be beneficial if some reuse of these coded sub-tasks could be achieved. However,  most of the present day robot software is monolithic, very specialised and not  at all modular, which hinders the reuse and sharing of code between robot platforms.  One difficulty is that the hardware details of a robot are usually tightly woven  into the high-level controllers. When these details are not decoupled and explicitly  encapsulated, the entire code set must be revised if the robot platform changes. An  even bigger challenge is that a robot is a context-aware device. Hence, the possible  interpretations of the state of the robot and its environment vary along with its  context. For example, as the robots differ in size and shape, the meaning of concepts  such as direction, speed, and distance can change { objects that are considered far  from one robot, might seem near to a much larger robot. When designing reusable  robot software, these variable interpretations of the environment must be considered.  Similarly, so must variations in context dependent robot instructions { for example,  `move fast' has different abstractions; a `virtual robot' layer to manage the robot's platform abstractions;  and high-level abstraction components that are used to describe the state of the robot  and its environment. The prototype is able to support binary code portability  and dynamic code extensibility across a range of different robots (demonstrated on  eight diverse robot platform configurations).  These outcomes significantly ease the burden on robot software developers when  deploying a new robot (or even reconfiguring old robots) since high-level binary  controllers can be executed unchanged on different robots. Furthermore, since the  control code is completely decoupled from the platform information, these concerns  can be managed separately, thereby providing a flexible means for managing different  configurations of robots. These systems and techniques all improve the robot  software design, development, and deployment process.  Different meanings depending on the robot's size, environmental  context and task being undertaken.  What is needed is a unifying cross-platform software engineering approach for  robots that will encourage the development of code that is portable, modular and  robust. Toward this end, this research presents a complete abstraction model and  implementation prototype that contain a suite of techniques to form and manage the  robot hardware, platform, and environment abstractions. The system includes the  interfaces and software components required for hardware device and operating system abstractions; a `virtual robot' layer to manage the robot's platform abstractions;  and high-level abstraction components that are used to describe the state of the robot  and its environment. The prototype is able to support binary code portability  and dynamic code extensibility across a range of different robots (demonstrated on  eight diverse robot platform configurations).  These outcomes significantly ease the burden on robot software developers when  deploying a new robot (or even reconfiguring old robots) since high-level binary  controllers can be executed unchanged on different robots. Furthermore, since the  control code is completely decoupled from the platform information, these concerns  can be managed separately, thereby providing a flexible means for managing different  configurations of robots. These systems and techniques all improve the robot  software design, development, and deployment process.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">software portability</field><field name="subject">platform abstraction</field><field name="subject">hardware abstraction</field><field name="subject">code reuse</field><field name="subject">robot</field><field name="identifier">http://eprints.qut.edu.au/16406/</field><field name="validLink">True</field></doc><doc><field name="title">The role of the notary in secure electronic commerce</field><field name="creator">Smith, Leslie Gordon</field><field name="description">The profession of the notary is at a cross roads. The Notary operates in a world of paperbased transactions where the use of traditional signatures and seals are mandatory. The practices and procedures which have evolved over centuries simply cannot be applied directly in a digital environment.    Establishing a framework for the authentication of computer-based information in today's commercial environment requires a familiarity with concepts and professional skills from both the legal and computer security fields. Combining these two disciplines is not an easy task. Concepts from the information security field often correspond only loosely with concepts from the legal field, even in situations where the terminology is similar.    This thesis explores the history of the Notary, the fundamental concepts of e-commerce, the importance of the digital or electronic signature and the role of the emerging &amp;quotCyber" or &amp;quotElectronic" Notary (E-Notary) in the world of electronic commerce. The research investigates whether or not the functions of the &amp;quotNotary Public" can successfully evolve in the world of E-Commerce, and if so what are the ramifications.    This thesis comprises a survey and critical analysis of proposed architectures and implementations for &amp;quotElectronic Notary Services" in an Internet based, electronic commerce environment. It includes an analysis of relevant historical and legal factors relevant to these emerging technologies. Given the highly dynamic nature of this topic, this thesis does not propose or recommend a single architecture or implementation but emphasises the need for further research not only into technological factors but also into the real legal and social needs that affect the role of the E-Notary.    The approach undertaken was an analytical approach to the available current documentation against input from leading practitioners included practicing Notaries from Australia, the United States and the Court of Faculties - London.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Notarial act</field><field name="subject">Notary</field><field name="subject">electronic commerce</field><field name="subject">e-commerce</field><field name="subject">information security</field><field name="subject">digital information</field><field name="identifier">http://eprints.qut.edu.au/16407/</field><field name="validLink">True</field></doc><doc><field name="title">The relationship between culture, attitude, social networks and quality of life in midlife Australian and Taiwanese men and women</field><field name="creator">Fu, Shiu Yun</field><field name="description">Background of the Study  The aims of this study was to specifically investigate the differences in culture, attitude towards life and social networks between Australian and Taiwanese men and women in addition to determining the factors that predict midlife men and women's quality of life in both countries. Because individualism and collectivism are the two most thoroughly researched constructs in inter-cultural and cross-cultural studies we should look at how these construct affects societies. The theme for individualist cultures (such as Western cultures) is autonomy, while the theme for collectivist cultures (such as Asian cultures) is connection. Most literature available on individualism and collectivism note all cultures have different values that influence their society and ultimately a person's individual health outcome. Very little work has been undertaken in this domain in Australia or Taiwan, particularly in the area of midlife transition and from a cultural perspective.    Methodology  Data was collected from a cross-sectional, supervised self-administered survey using census data and a probability proportional sampling (PPS) strategy on a general population of men and women aged 40-59 years old who live permanently in Brisbane, Australia and Taipei, Taiwan. The study population was divided into 163 Statistical Local Areas (SLAs) in Brisbane, and 449 Local Government Communities (LGCs) in Taipei. Sixty clusters were randomly selected using probability proportional sampling (PPS) to obtain 30 Australian clusters and 30 Taiwanese clusters. In this study, the 30 (areas) by 7(people) method was used with an additional strategy. The variables were measured including: culture (vertical and horizontal individualism and collectivism), attitude towards life (the total score of optimism), social networks (the total score of emotional, informational, affectionate, tangible, and positive social interaction) and quality of life (physical, psychological, social, and environmental health), social demographical factors and religion and spiritualty. The data analysis procedure included descriptive, bivarite and multivariate multiple regressions and classifications and regression trees (CART). A comparison of the linear regression and regression tree results were discussed. All data analysis was performed by SPSS and S-Plus softwares.    Results  The overall response rate for the study was 84.2% for midlife Australian men and women and 88.4% for midlife Taiwanese men and women this resulted in 278 Australians (45.3% men) and 398 Taiwanese (35.4% men) providing data to be analysed. Findings in this study indicated country of residence has an overwhelming impact on quality of life with significant differences seen between midlife Australian and Taiwanese men and women (F4, 666= 59.31, P&lt; .001). Results suggest midlife Australian men and women have a better quality of life than midlife Taiwanese men and women. In addition, a comparison of the linear regression and regression tree results reveals that two models identified the same major affect variable for different countries of residence: which was attitude towards life in midlife Australians and social networks in midlife Taiwanese. However, regression trees were able to capture important nonlinear effects as well as interactions between cultural attribute variables. This study demonstrated culture significantly involves multiple functions and interacts with attitude towards life, social networks and individual factors to influence a person's quality of life. The interaction of cultural circumstances and the internal and external factors involved, show less comparative attributes and increased equality attributes, defining the need for people to have a good social networks and a healthy positive disposition.    Conclusion  Because of the ever increasing flexibility of world travel and a global population, people have much more opportunity to interact with many other cultures which would create improvement in learning opportunities and better health management effectiveness for people the world over. This study has addressed and contributed to the assessment of multi-cultural quality of life research and has important implications for all health professions in addition to government departments and organisational policy makers of both countries. And finally, this study has identified that there needs to be a concerted effort to implement major policy shifts in the near future because of the changing fabric of modern societies. At the same time technology and globalisation have advanced rapidly and point to new opportunities within and across countries for more diverse approaches in research and the implementation of policy initiatives to occur. This study has highlighted that opportunities exist to reflect on current policies for Australian and Taiwanese societies to provide enhanced opportunities to care for the growing midlife populations.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">multicultural quality of life research</field><field name="subject">individualism and collectivism</field><field name="subject">horizontal and vertical culture</field><field name="subject">midlife Australian and Taiwanese men and women</field><field name="subject">Brisbane and Taipei</field><field name="subject">probability proportional sampling (PPS)</field><field name="subject">statistical local area (SLA)</field><field name="subject">local government community (LGC)</field><field name="subject">national survey</field><field name="identifier">http://eprints.qut.edu.au/16408/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis and investigations of novel alkenylporphyrins and bis(porphyrins)</field><field name="creator">Locos, Oliver Brett</field><field name="description">Twelve porphyrin dyads linked by an ethene bridge were synthesised as model  systems for conjugated polymers. The extent of interporphyrin interaction was  investigated for meso-meso and meso-&#946; linked homo- and heterobimetallo-porphyrin  dyads. To complement these dyads, model monomers with alkenyl substituents were  also studied. Once the synthesis of these compounds was achieved, the extent of  interaction was studied using UV-visible and fluorescence spectroscopy and  molecular modelling.  In order to gain a true indication of the extent of interaction in a dyad, the effect of  the bridge as a substituent must be accounted for. This was achieved by studying the  series of monomers by UV-visible and fluorescence spectroscopy. The increased  conjugation resulting from mono- and bis-alkenyl substituents results in a red shift of  the origin of transition energies in the absorption spectrum which is accompanied by  a broadened and less intense Soret band and an increase in the intensity of the Q  bands. The emission of these compounds also displays an increase in Stokes shift and  a loss of vibronic coupling due to the increased conjugation.  The serendipitous synthesis of three asymmetric meso-&#946; ethene-linked porphyrin  dyads was achieved by the use of palladium-catalysed Heck coupling of mesoethenyl-  with meso-bromoporphyrins. A possible mechanism for this meso to &#946;  rearrangement was proposed. A series of nine meso-meso ethene-linked dyads was  synthesised by palladium-catalysed Suzuki coupling of meso-(2-iodoethenyl)- with  meso-borolanylporphyrins. All of these dyads were characterised by 1D and 2D  NMR as well as MS analysis. The absorption spectra of ethene-linked dyads exhibit  a split Soret band and a red-shifted and intensified HOMO-LUMO band. In the  meso-&#946; dyads, the degree of splitting in the Soret band is sufficient only to generate a  shoulder on the red edge, whereas in the meso-meso dyads two separate bands  appear. The extent of splitting is believed to be an indication of the amount of  porphyrin-porphyrin interaction.  The fluorescence profiles of the dyads change dramatically depending upon the  central substituents in the porphyrins and the wavelength used for irradiation, which suggests that different conformations of these compounds give rise to different parts  of their absorption and emission profiles. The fluorescence profiles of the dyads also  do not reflect their absorption profiles, and therefore the excitation of the dyad is  believed to be accompanied also by a change in geometry. All ethene-linked dyads  exhibited an anti-Stokes shift, and the excitation spectra of the different parts of the  fluorescence envelope also support the possibility of different conformers  contributing to the fluorescence spectra.  Molecular mechanics and time-dependent quantum mechanical calculations were  performed on seven ethene-linked porphyrin dyads. These calculations further  support the proposal of different conformations contributing to the physical  properties of ethene-linked dyads. Electronic structure calculations also show  considerable electron density on the alkene for the meso-meso ethene-linked dyads,  which highlights the important influence of this bridge upon the electronic nature of  these conjugated diporphyrins.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">novel alkenylporphyrins</field><field name="subject">bis-porphyrins</field><field name="subject">porphyrin dyads</field><field name="subject">ethene bridge</field><field name="subject">conjugated polymers</field><field name="identifier">http://eprints.qut.edu.au/16409/</field><field name="validLink">True</field></doc><doc><field name="title">Evaluation of the implementation of a preferred music intervention for reducing agitation and anxiety in institutionalised elders with dementia</field><field name="creator">Sung, Huei-Chuan (Christina)</field><field name="description">There is some evidence about the efficacy of preferred music on agitation in  elders with dementia; however, little is known about its effectiveness on agitation  when implemented by nursing staff in long-term care facilities. Even less is known  about use of preferred music for managing anxiety in those with dementia. This  quasi-experimental study aimed to evaluate the implementation of a preferred music  intervention delivered by nursing staff on agitation and anxiety of institutionalised  elders with dementia.  The sample comprised of 57 elders with dementia residing in two building  complexes which provided similar care routines and staffing in a large Taiwanese  residential care facility. These two building complexes were randomly assigned as  the experimental and control group. Nursing staff in the experimental group received  a facilitation program to prepare them for implementing the preferred music  intervention; whereas nursing staff in the control group received no facilitation  program. The music intervention based on each resident's music preferences was  then provided by the trained nursing staff for 32 experimental residents twice a week  for six weeks. Meanwhile, 25 residents in the control group only received the usual  standard care without music. All residents were assessed by Cohen-Mansfield  Agitation Inventory (CMAI) for overall and three subtypes of agitated behaviours  and by Rating of Anxiety in Dementia for anxiety at baseline and week 6.  Additionally, the modified CMAI measured the 30-minute occurrence of agitation at  baseline, session 4, and session 12. The results indicate that institutionalised elders with dementia who received six weeks of preferred music intervention implemented by trained nursing staff had significant reductions on overall, three subtypes of agitated behaviours, anxiety, and 30-minute occurrence of agitation over time compared to those who received the usual standard care without music. Preferred music shows promise as a strategy for reducing agitation and anxiety in those with dementia when implemented by trained nursing staff. Such intervention can be incorporated into routine activities to improve the quality of care provided by nursing staff and the quality of life of those with dementia in long-term care settings. Our study results provide clinically relevant evidence which contribute to closing the gap between research and practice.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">preferred music</field><field name="subject">dementia</field><field name="subject">agitated behaviours</field><field name="subject">anxiety</field><field name="subject">older people</field><field name="subject">long-term care</field><field name="subject">institutionalisation</field><field name="subject">nursing home staff</field><field name="subject">effectiveness study</field><field name="subject">quasi-experimental design</field><field name="identifier">http://eprints.qut.edu.au/16410/</field><field name="validLink">True</field></doc><doc><field name="title">An examination of the interface between commercial property assets and contemporary knowledge-intensive firms - demands, responses and priorities</field><field name="creator">Hefferan, Michael</field><field name="description">Economic and other forces over recent years have resulted in the rise, in size and importance, of a group within the business community known as &amp;quotknowledge-intensive firms".  These organisations typically operate in such sectors as information and communication technology, specialist engineering and other services, consulting, research spin-out companies, multimedia, advertising and education and, in effect, trade in the development, management and adaptation of contemporary knowledge.  They are often small-to-medium enterprises and use new business and operational models drawing together human and social capital, contemporary ICT, technologies and networks to produce intangible knowledge products.  This research work investigates the interface between those firms and the commercial property assets that provide a platform and environment for their activities.  The accommodation of significant change may hold challenges for such large-scale built assets.  However, this work considers that evolutionary change is achievable and will present new opportunities for property as integrated and adaptable business environments, responsive to changing demands.  The research methodology involves a literature review establishing key economic, business, built environment and social capital parameters for these emerging firms and their operations.  That review is reinforced by both primary data collection from 36 knowledge-intensive firms and by the investigation of four relevant but diverse case studies.  To allow this wide body of information to be distilled, a Delphi process, using a panel of ten experts, has been successfully applied to prioritise the demand drivers for start-up, established and mature knowledge-intensive firms in the South East Queensland environment.  Consensus was secured after four rounds.  These outcomes have been again tested against the four previous case studies and a further case study not previously investigated.  Conclusions establish that these firms do have priority requirements in their demands for commercial property and that such demands evolve as firms progress through their various stages of development.  Overall, firms through all development stages were strongly influenced in locational decisions by business plans parameters, the importance of attracting quality staff, and the provision of an office environment most conducive to the performance of these individuals and teams.  Only in the early, start-up stage was accommodation cost a determining factor. Further, the research establishes that significant opportunities exist for the development sector, particularly in the re-use of older buildings and in the creation of clusters.  To achieve this, however, new approaches to development and asset and property management may be required.  As a result of this research, it is anticipated that asset owners and managers will be better able to align both new and existing commercial buildings to these emerging demands and opportunities.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Australian business change</field><field name="subject">knowledge-intensive firms</field><field name="subject">tenant demand</field><field name="identifier">http://eprints.qut.edu.au/16411/</field><field name="validLink">True</field></doc><doc><field name="title">Mathematical modelling of primary alkaline batteries</field><field name="creator">Johansen, Jonathan Frederick</field><field name="description">Three mathematical models, two of primary alkaline battery cathode discharge, and one of primary alkaline battery discharge, are developed, presented, solved and investigated in this thesis. The primary aim of this work is to improve our understanding of the complex, interrelated and nonlinear processes that occur within primary alkaline batteries during discharge.    We use perturbation techniques and Laplace transforms to analyse and simplify an existing model of primary alkaline battery cathode under galvanostatic discharge. The process highlights key phenomena, and removes those phenomena that have very little effect on discharge from the model. We find that electrolyte variation within Electrolytic Manganese Dioxide (EMD) particles is negligible, but proton diffusion within EMD crystals is important. The simplification process results in a significant reduction in the number of model equations, and greatly decreases the computational overhead of the numerical simulation software. In addition, the model results based on this simplified framework compare well with available experimental data.    The second model of the primary alkaline battery cathode discharge simulates step potential electrochemical spectroscopy discharges, and is used to improve our understanding of the multi-reaction nature of the reduction of EMD. We find that a single-reaction framework is able to simulate multi-reaction behaviour through the use of a nonlinear ion-ion interaction term.    The third model simulates the full primary alkaline battery system, and accounts for the precipitation of zinc oxide within the separator (and other regions), and subsequent internal short circuit through this phase. It was found that an internal short circuit is created at the beginning of discharge, and this self-discharge may be exacerbated by discharging the cell intermittently. We find that using a thicker separator paper is a very effective way of minimising self-discharge behaviour.    The equations describing the three models are solved numerically in MATLABR, using three pieces of numerical simulation software. They provide a flexible and powerful set of primary alkaline battery discharge prediction tools, that leverage the simplified model framework, allowing them to be easily run on a desktop PC.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">advection</field><field name="subject">anode</field><field name="subject">asymptotic analysis</field><field name="subject">BET surface area</field><field name="subject">binary electrolyte</field><field name="subject">boundary condition</field><field name="subject">Butler-Volmer equation</field><field name="subject">cathode</field><field name="subject">closed circuit voltage</field><field name="subject">concentration polarisation</field><field name="subject">control volume</field><field name="subject">current path</field><field name="subject">discretisation</field><field name="subject">diffusion</field><field name="subject">electrochemical reaction</field><field name="subject">electrode</field><field name="subject">electrolytic manganese dioxide</field><field name="subject">EMD crystals</field><field name="subject">EMD particles</field><field name="subject">exchange current density</field><field name="subject">geometric surface area</field><field name="subject">initial condition</field><field name="subject">linearisation</field><field name="subject">macrohomogeneous porous electrode theory</field><field name="subject">mathematical model</field><field name="subject">Nernst equation</field><field name="subject">ohmic losses</field><field name="subject">open circuit voltage</field><field name="subject">ordinary differential equation</field><field name="subject">overpotential</field><field name="subject">partial differential equation</field><field name="subject">perturbation techniques</field><field name="subject">potassium hydroxide</field><field name="subject">potassium zincate</field><field name="subject">precipitation reaction</field><field name="subject">primary battery</field><field name="subject">separator paper</field><field name="subject">simulation</field><field name="subject">step potential electrochemical spectroscopy</field><field name="subject">ternary electrolyte</field><field name="subject">theoretical capacity</field><field name="subject">utilisation</field><field name="subject">zinc</field><field name="subject">zinc oxide</field><field name="identifier">http://eprints.qut.edu.au/16412/</field><field name="validLink">True</field></doc><doc><field name="title">Statistical methods for assessing and managing wild populations</field><field name="creator">Hoyle, Simon David</field><field name="description">This thesis is presented as a collection of five papers and one report, each of which has been either published after peer review or submitted for publication. It covers a broad range of applied statistical methods, from deterministic modelling to integrated Bayesian modelling using MCMC, via bootstrapping and stochastic simulation. It also covers a broad range of subjects, from analysis of recreational fishing diaries, to genetic mark recapture for wombats. However, it focuses on practical applications of statistics to the management of wild populations.    The first chapter (Hoyle and Jellyman 2002, published in Marine and Freshwater Research) applies a simple deterministic yield per recruit model to a fishery management problem: possible overexploitation of the New Zealand longfin eel. The chapter has significant implications for longfin eel fishery management.    The second chapter (Hoyle and Cameron 2003, published in Fisheries Management and Ecology) focuses on uncertainty in the classical paradigm, by investigating the best way to estimate bootstrap confidence limits on recreational harvest and catch rate using catch diary data.    The third chapter (Hoyle et al., in press with Molecular Ecology Notes) takes a different path by looking at genetic mark-recapture in a fisheries management context. Genetic mark-recapture was developed for wildlife abundance estimation but has not previously been applied to fish harvest rate estimation.    The fourth chapter (Hoyle and Banks, submitted) addresses genetic mark-recapture, but in the wildlife context for estimates of abundance rather than harvest rate. Our approach uses individual-based modeling and Bayesian analysis to investigate the effect of shadows on abundance estimates and confidence intervals, and to provide guidelines for developing sets of loci for populations of different sizes and levels of relatedness.    The fifth chapter (Hoyle and Maunder 2004, Animal Biodiversity and Conservation) applies integrated analysis techniques developed in fisheries to the modeling of protected species population dynamics - specifically the north-eastern spotted dolphin, Stenella attenuata. It combines data from a number of different sources in a single statistical model, and estimates parameters using both maximum likelihood and Bayesian MCMC.    The sixth chapter (Hoyle 2002, peer reviewed and published as Queensland Department of Primary Industries Information Series) results directly from a pressing management issue: developing new management procedures for the Queensland east coast Spanish mackerel fishery. It uses an existing stock assessment as a starting point for an integrated Bayesian management strategy evaluation.    Possibilities for further research have been identified within the subject areas of each chapter, both within the chapters and in the final discussion chapter.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Anguilla reinhardtii</field><field name="subject">fishery management</field><field name="subject">population modelling</field><field name="subject">bootstrap</field><field name="subject">recreational catch</field><field name="subject">confidence intervals</field><field name="subject">Scomberomorus commerson</field><field name="subject">genetic mark-recapture</field><field name="subject">shadow effect</field><field name="subject">individual-based modelling</field><field name="subject">protected species</field><field name="subject">Bayesian</field><field name="subject">integrated analysis</field><field name="subject">management strategy evaluation</field><field name="subject">fisheries</field><field name="subject">Queensland</field><field name="subject">Stenella attenuata</field><field name="identifier">http://eprints.qut.edu.au/16413/</field><field name="validLink">True</field></doc><doc><field name="title">Mapping interior environment and integrated health systems research using the psychoneuroimmunological (PNI) model</field><field name="creator">Suresh, Mini</field><field name="description">This study maps research concerning person environment interrelationships with  health and wellbeing outcomes. The purpose of this study is to provide insights into  the inter-relationship between the built environment (BE) and human health and  wellbeing as it is conveyed in research literature. It particularly focuses on literature  that connects built environment, emotions, feelings, mind and body. This thesis  therefore provides a review of relevant literature on the physical environment, with a  focus on person environment (PE) relationship that may influence the person's  psychological and physiological systems consequently affecting health and  wellbeing. Specifically, psychoneuroimmunology (PNI) is used to identify  dimensions of the BE which are significant for this study.  The understanding of PE interrelationships to health outcomes is achieved by  undertaking a transdisciplinary outlook. To conceptualise the 'person' as a whole and  the workings of the mind and human system PNI has been recognised as a main  platform. PNI is the study of mind-body relationships (Evans, et al, 2000), providing  a scientific framework which captures the understanding of the inter-relationship of  the mind to the neuroendocrine systems and the immune systems with the aim of  understanding the influence of the mind on eliciting as well as preventing illnesses.  The work was motivated by the need for better understanding of the human  interaction/transaction in an interior environment and their consequences on health.  An exploration of literature from both the environmental and health fields provided a  knowledge base upon which to develop an understanding of the interrelationship.  Research has demonstrated a link between the BE and wellbeing, however, this is  limited in its application and/or scope. For example, over the past years there has  been an increasing amount of research showing the possible influence of the  environment in reducing stress (Sommer &amp; Oslen, 1980; Kaplan, 1983; O'Neill,  1991; Wapner &amp; Demick, 2000; Parsons &amp; Tassinary, 2002, Frumkin, 2006). In  addition, there is growing evidence that indicates there is a relationship between BE  and health including the psychological and physiological systems, in healthcare  environments (Ulrich &amp; Zimring, 2004). However, while there is ample research in  the areas of environmental stressors and other determinants of the environment in contributing to health, less research has been undertaken in studying the impact of  the environment on health (Evans&amp; McCoy, 1998). The potential of the environment  in contributing to the mental wellbeing of a person and how this could affect the  physical health therefore needs further investigation (Solomon, 1996).  The methodology followed was Coopers (1998) 'research synthesis' and the tool to  sort the domains and PE interrelationships was adapted from White's (1989) 'space  adjacency analysis'. The scope of this study was limited to explorations of literature  that inquired into PE relationships that fit into the primarily established 'integrative  systems model'; a parameter that enabled categorisation of the literature into the  areas that related to the PNI framework.  The findings illustrate that the person is interrelated to the environment in several  ways and can be interpreted and explained in terms of various dimensions such as  the psychological, physical, social, and spatial dimensions. Furthermore,  empirical research indicates that the environment impacts on a person's health and  wellbeing through psychological and physiological systems. PNI  acknowledges the interrelationship of the mind and body systems contributing to an  integrative systems model of human health and wellbeing.  As an outcome, the study has produced an analysis method and a navigation map of  the various literature domains related to PE interrelationships in terms of health and  wellbeing. This has been facilitated by the development of, a 'PE integrative systems  model'. Apart from demonstrating the need for transdisciplinary research and  contributing to research methodology, the study also adds to the current design  knowledge base providing BE professionals and creators with a better understanding  of the health outcomes from PE interrelationships.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">interior environment</field><field name="subject">built environment</field><field name="subject">physical environment</field><field name="subject">design</field><field name="subject">psychoneuroimmunology</field><field name="subject">health and wellbeing</field><field name="subject">mental wellbeing</field><field name="subject">physiological wellbeing</field><field name="subject">integrative systems</field><field name="subject">person environment interrelationship</field><field name="subject">space</field><field name="subject">place</field><field name="identifier">http://eprints.qut.edu.au/16414/</field><field name="validLink">True</field></doc><doc><field name="title">Modes of engagement in theatrical documentary</field><field name="creator">Fergusson, Annie</field><field name="description">This research aims to chart four modes of engagement in post-verite documentary films, devoted to an exclusive examination of theatrical formats, that being those documentaries which are originally intended for a cinema audience. As these theatrical documentaries provide a means for spectators to see through the cinema screen and into the real world, it is important to understand how this 'seeing through' is constructed by the documentary production itself. This thesis acknowledges that the 'learning' of documentary stories and subjects has broadened for the global audience of today. After exploring various separate critiques of documentary voice theory, the definition of documentary and film semiotics, I have devised eight paradigms for creating this 'learning' or 'documentary consciousness' in these theatrical or cinema documentaries. I have explored how these eight paradigms can be observed to function in four different modes. These modes contribute to an evolving understanding of viewer comprehension; that thing called documentary consciousness. This is demonstrated through the audio-visual appendix of clips taken from the proto-typical theatrical documentaries I have chosen to analyse, which are:    'Bowling For Columbine' by Michael Moore (2003), which is illustrative of what I have dubbed the 'Outcome Mode';    'Etre et Avoir' ('To Be And To Have') by Nicholas Philibert (2004), which exemplifies what I call the 'Participant Mode';    'My Architect' by Nathaniel Kahn (2005), an example of the 'Journey Mode';    'Baraka' by Magidson Films (1996), a model of the 'Mandala Mode'.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">theatrical documentary</field><field name="subject">cinema documentary</field><field name="subject">documentary voice</field><field name="subject">definition of documentary consciousness</field><field name="subject">film semiotics</field><field name="subject">modes of engagement</field><field name="subject">spectator comprehension</field><field name="subject">&#145;Bowling for Columbine&#146;</field><field name="subject">&#145;Etre et Avoir&#146; (&#145;To Be and To Have&#146;)</field><field name="subject">&#145;My Architect&#146;</field><field name="subject">&#145;Baraka&#146;</field><field name="identifier">http://eprints.qut.edu.au/16415/</field><field name="validLink">True</field></doc><doc><field name="title">Repeat adherence to colorectal cancer screening utilising faecal occult blood testing : a community-based approach in a rural setting</field><field name="creator">Hughes, Karen Leigh</field><field name="description">In Australia, colorectal cancer (CRC) is the most common registrable cancer affecting both men and women, and the third most common cause of cancer deaths. Clinical data from randomised, controlled trials indicate that population-based screening utilising the faecal occult blood test (FOBT) can reduce mortality from this disease. However, high adherence rates with repeated testing are required to secure these outcomes. This study examines repeat adherence with FOBT screening in a rural community two years after a first screening round was conducted. Patients, aged 50 to 74 years, registered with four local general practices were mailed a FOBT kit with a letter of invitation from their general practitioner. Following the intervention, 119 telephone interviews were conducted with adherers and non-adherers to examine knowledge and attitudes related to screening. Compliance with screening was recorded and compared with first round-data. Participation in the screening program was modest. Of the 3,406 participants eligible for both screening rounds, 34.1% and 34.7% participated in rounds 1 and 2, respectively. A majority of participants (56.8%) did not adhere to either screening, a quarter (25.7%) participated in both rounds, and 17.5% participated in one of the two rounds. First-round adherence was the strongest predictor of second-round adherence (OR=16.29; 95% CI: 13.58, 19.53) with 75.2% of first-round adherers completing a FOBT in round 2. Females were also more likely to adhere in both rounds, although the difference between females and males decreased across rounds. Knowledge and attitudes differed between adherers and non-adherers and are discussed within the context of the major findings. Results from this trial indicate that achieving high levels of compliance in a national screening program will be challenging. Strategies to increase repeat adherence are suggested.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">colorectal cancer</field><field name="subject">mass screening</field><field name="subject">faecal occult blood test</field><field name="subject">patient participation</field><field name="subject">patient compliance</field><field name="subject">secondary prevention</field><field name="subject">public health</field><field name="identifier">http://eprints.qut.edu.au/16416/</field><field name="validLink">True</field></doc><doc><field name="title">Distortional buckling behaviour of cold-formed steel compression members at elevated temperatures</field><field name="creator">Ranawaka, Thanuja</field><field name="description">In recent times, light gauge cold-formed steel sections have been used extensively in  residential, industrial and commercial buildings as primary load bearing structural  components. This is because cold-formed steel sections have a very high strength to  weight ratio compared with thicker hot-rolled steel sections, and their manufacturing  process is simple and cost-effective. However, these members are susceptible to  various buckling modes including local and distortional buckling and their ultimate  strength behaviour is governed by these buckling modes. Fire safety design of  building structures has received greater attention in recent times due to continuing  loss of properties and lives during fires. Hence, there is a need to fully evaluate the  performance of light gauge cold-formed steel structures under fire conditions. Past  fire research has focused heavily on heavier, hot-rolled steel members. The buckling  behaviour of light gauge cold-formed steel members under fire conditions is not well  understood. The buckling effects associated with thin steels are significant and have  to be taken into account in fire safety design. Therefore, a research project based on  extensive experimental and numerical studies was undertaken at the Queensland  University of Technology to investigate the distortional buckling behaviour of light  gauge cold-formed steel compression members under simulated fire conditions.  As the first phase of this research program more than 115 tensile coupon tests of  light gauge cold-formed steels including two steel grades and five thicknesses were  conducted at elevated temperatures. Accurate mechanical properties including the  yield strength, elasticity modulus and stress-strain curves were all determined at  elevated temperatures since the deterioration of the mechanical properties is one of  the major parameters in the structural design under fire conditions. An appropriate  stress-strain model was also developed by considering the inelastic characteristics.  The results obtained from the tensile coupon tests were then used to predict the  ultimate strength of cold-formed steel compression members.  In the second phase of this research more than 170 laboratory experiments were  undertaken to investigate the distortional buckling behaviour of light gauge coldformed steel compression members at ambient and elevated temperatures. Two types of cross sections were selected with various thicknesses (nominal thicknesses are  0.6, 0.8, and 0.95 mm) and both low and high strength steels (G250 and G550 steels  with minimum yield strengths of 250 and 550 MPa). The experiments were  conducted at six different temperatures in the range of 20 to 800&#176;C. A finite element  model of the tested compression members was then developed and validated with the  help of experimental results. The degradation of mechanical properties with  increasing temperatures was included in finite element analyses.  An extensive series of parametric analyses was undertaken using the validated finite  element model to investigate the effect of all the influential parameters such as  section geometry, steel thickness and grade, mechanical properties and temperature.  The resulting large data base of ultimate loads of compression members subject to  distortional buckling was then used to review the adequacy of the current design  rules at ambient temperature. The current design rules were reasonably accurate in  general, but in order to improve the accuracy further, this research has developed  new design equations to determine the ultimate loads of compression members at  ambient temperature. The developed equation was then simply modified by  including the relevant mechanical properties at elevated temperatures. It was found  that this simple modification based on reduced mechanical properties gave  reasonable results, but not at higher temperatures. Therefore, they were further  modified to obtain a more accurate design equation at elevated temperatures. The  accuracy of new design rules was then verified by comparing their predictions with  the results obtained from the parametric study.  This thesis presents a description of the experimental and numerical studies  undertaken in this research and the results including comparison with simply  modified current design rules. It describes the laboratory experiments at ambient and  elevated temperatures. It also describes the finite element models of cold-formed  steel compression members developed in this research that included the appropriate  mechanical properties, initial geometric imperfections and residual stresses. Finally,  it presents the details of the new design equations proposed for the light gauge coldformed  steel compression members subjected to distortional buckling effects at  elevated temperatures.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">light gauge cold-formed steel</field><field name="subject">distortional buckling</field><field name="subject">compression members</field><field name="subject">elevated temperatures</field><field name="subject">axial compression load</field><field name="subject">reduced yield strength</field><field name="subject">reduced elasticity modulus</field><field name="subject">stress-strain model</field><field name="subject">fire safety design</field><field name="subject">fire test</field><field name="subject">finite element analysis</field><field name="identifier">http://eprints.qut.edu.au/16417/</field><field name="validLink">True</field></doc><doc><field name="title">Bovine serum albumin adhesion force measurements using an atomic force microscopy</field><field name="creator">Lai, Chun-Chih</field><field name="description">In this thesis, a direct method of Atomic Force Microscopy (AFM) technique has been developed to measure the adhesion forces between BSA and two different surfaces: mica (a hydrophilic surface); and polystyrene (a hydrophobic surface); in PBS solution. We have shown possible to measure interactions between proteins and substrate surface directly without any modification to the substrate and the AFM tip; this means protein molecules can keep the natural elastic property within the force measurements. The average measured value of adhesion forces between BSA and mica is 0.036 &#177; 0.002 nN, and between BSA and polystyrene is 0.066 &#177; 0.003 nN. The polystyrene surface is more adhesive to BSA than the mica surface. This is consistent with previous research, which assessed that hydrophobic surfaces enhance protein adhesion but hydrophilic surfaces do not.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Atomic Force Microscopy (AFM) technique</field><field name="subject">hydrophobic surfaces</field><field name="subject">protein adhesion</field><field name="subject">hydrophilic surfaces</field><field name="subject">Bovine Serum Albumin adhesion</field><field name="subject">measuring adhesion forces</field><field name="identifier">http://eprints.qut.edu.au/16418/</field><field name="validLink">True</field></doc><doc><field name="title">Epidemic models and inference for the transmission of hospital pathogens</field><field name="creator">Forrester, Marie Leanne</field><field name="description">The primary objective of this dissertation is to utilise, adapt and extend current stochastic models and statistical inference techniques to describe the transmission of nosocomial pathogens, i.e. hospital-acquired pathogens, and multiply-resistant organisms within the hospital setting. The emergence of higher levels of antibiotic resistance is threatening the long term viability of current treatment options and placing greater emphasis on the use of infection control procedures. The relative importance and value of various infection control practices is often debated and there is a lack of quantitative evidence concerning their effectiveness. The methods developed in this dissertation are applied to data of methicillin-resistant Staphylococcus aureus occurrence in intensive care units to quantify the effectiveness of infection control procedures.    Analysis of infectious disease or carriage data is complicated by dependencies within the data and partial observation of the transmission process. Dependencies within the data are inherent because the risk of colonisation depends on the number of other colonised individuals. The colonisation times, chain and duration are often not visible to the human eye making only partial observation of the transmission process possible. Within a hospital setting, routine surveillance monitoring permits knowledge of interval-censored colonisation times. However, consideration needs to be given to the possibility of false negative outcomes when relying on observations from routine surveillance monitoring.    SI (Susceptible, Infected) models are commonly used to describe community epidemic processes and allow for any inherent dependencies. Statistical inference techniques, such as the expectation-maximisation (EM) algorithm and Markov chain  Monte Carlo (MCMC) can be used to estimate the model parameters when only partial observation of the epidemic process is possible. These methods appear well suited for the analysis of hospital infectious disease data but need to be adapted for short patient stays through migration. This thesis focuses on the use of Bayesian statistics to explore the posterior distributions of the unknown parameters. MCMC techniques are introduced to overcome analytical intractability caused by partial observation of the epidemic process. Statistical issues such as model adequacy and MCMC convergence assessment are discussed throughout the thesis.    The new methodology allows the quantification of the relative importance of different transmission routes and the benefits of hospital practices, in terms of changed transmission rates. Evidence-based decisions can therefore be made on the impact of infection control procedures which is otherwise difficult on the basis of clinical studies alone.    The methods are applied to data describing the occurrence of methicillin-resistant  Staphylococcus aureus within intensive care units in hospitals in Brisbane and London</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Bayesian inference</field><field name="subject">Markov chain Monte Carlo</field><field name="subject">reversible jump</field><field name="subject">transdimensional</field><field name="subject">stochastic epidemic model</field><field name="subject">susceptible-infected model</field><field name="subject">SI model</field><field name="subject">generalised linear model</field><field name="subject">hospital epidemiology</field><field name="subject">infectious diseases</field><field name="subject">infection control</field><field name="subject">nosocomial infection</field><field name="subject">hospital-acquired infection</field><field name="subject">multiply-resistant organisms</field><field name="subject">antibioticresistant bacteria</field><field name="subject">Staphylococcus aureus</field><field name="subject">methicillin-resistant Staphylococcus aureus</field><field name="subject">sensitivity</field><field name="subject">detectability</field><field name="identifier">http://eprints.qut.edu.au/16419/</field><field name="validLink">True</field></doc><doc><field name="title">Exploring the abstract language of contemporary dance in order to create emotional states/nuances</field><field name="creator">Buday, Csaba Steven</field><field name="description">This study investigates how a choreographer, through the abstract  language of contemporary dance, generates emotional states/nuances  which can be recognised but at the same time allow for ambiguity in the  reading of the work. This investigation was addressed through a series of  performance projects, culminating in the final dance work Inhabited Space.  The setting for the work, triggered by Bachelard's The Poetics of Space,  became the imagined spaces of a domestic urban environment,  specifically the lounge and bedroom. In order to create a work reflecting  emotional states and nuances, a range of choreographic processes were  explored to inform the construction of movement vocabulary, framed by  performer/space/object relationships. This studio-based study with  performative outcomes was supported by a hybrid methodological  approach of predominantly practice-led research, incorporating aspects of  action research and phenomenology. Findings and understandings  emerged from reflective practice in the exegesis but were primarily  embedded within the creative work itself.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">abstract movement language</field><field name="subject">artistic practice</field><field name="subject">choreographic processes</field><field name="subject">contemporary dance</field><field name="subject">emotional states/nuances</field><field name="subject">performer/space object</field><field name="identifier">http://eprints.qut.edu.au/16420/</field><field name="validLink">True</field></doc><doc><field name="title">A study of the relationships between work values, job involvement and organisational commitment among Taiwanese nurses</field><field name="creator">Ho, Chin-Chih</field><field name="description">Aim: The aim of this study is to investigate the relationship between work values, job involvement and organisational commitment among Taiwanese nurses in Taiwan. The objectives of this study are to: (1) describe the work values of Taiwanese nurses; (2) describe the job involvement of Taiwanese nurses; (3) describe the organisational commitment of Taiwanese nurses; (4) identify variables that affect work values, job involvement, and organisational commitment among Taiwanese nurses; and (5) identify the mediating effects of job involvement on work values and organisational commitment among Taiwanese nurses. Design: The study utilises a cross-sectional survey design. The sample consisted of RNs (N=1,047) recruited from a convenience sample in nine regional and teaching hospitals in Taiwan. Methods: Data was collected using a survey instrument consisting of 86 questions, including sociodemographic data, work values, job involvement, and organisational commitment. The data was analysed using descriptive bivariate analysis, Pearson Product Moment Correlation (PPMC), General Linear Model (GLM) analysis with random effect, and structural equation modelling (SEM). Findings: Four sociodemographic variables, age, SES (i.e., education status, personal income, and position) were shown to be partially statistically significant to work values, job involvement and organisational commitment. Subsequent GLM analysis were shown work values were positively related to job involvement and organisational commitment, and job involvement is positively related to organisational commitment. Results of the proposed model using SEM revealed that job involvement could play an important role with mediation, and that establishing a higher level of job involvement may be more important than focusing only on organisational commitment. Conclusions: This study has implications for organisations attempting to enhance organisational commitment through increased job involvement. It is anticipated that by improving these various factors the outcome will be reduced turnover and absenteeism and more effective organisations. A more effective organisational environment will be more conducive to good nursing practice.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">work values</field><field name="subject">job involvement</field><field name="subject">organisational commitment</field><field name="subject">Taiwanese nurses</field><field name="identifier">http://eprints.qut.edu.au/16421/</field><field name="validLink">True</field></doc><doc><field name="title">Stealing a car to be a man : the importance of cars and driving in the gender identity of adolescent males</field><field name="creator">Williams, Clive Kenneth</field><field name="description">Nationally vehicle theft is associated with approximately 40 fatalities per year with an estimated annual cost of one billion dollars.  During 2000 - 2001 almost 139,000 motor vehicles (cars, motor cycles, campervans, and trucks) were stolen across Australia.  Vehicle theft is an overwhelmingly adolescent male crime yet gender has not been considered in either policy or program initiatives.----- 
 
 
 
 This thesis used Spence's Multifactorial Gender Identity theory to examine the relationships between vehicle theft, offending, and adolescent male gender identity.  Four central research questions were posed:-----
 
 1.	Is vehicle theft a gendered behaviour, that is, do some adolescent males engage in vehicle theft to create a particular adolescent male gender identity?-----
 
 2.	Do vehicle theft offenders engage in other offending behaviours?----- 
 
 3.	Are these other offences also used to create a particular adolescent male gender identity and----- 
 
 4.	Will the use of a variety of gender-related scales to measure gender identity support Spence's Multifactorial Gender Identity Theory that gender identity is multifactorial?-----
 
 
 
 Study One Parts A and B provided the empirical basis for Studies Two and Three.  Part A of Study One examined the &amp;quotmaleness" of vehicle theft and two other problem behaviours: problem drinking and traffic offence involvement.  Cross-sectional and longitudinal methodologies were used to investigate a representative sample of 4,529 male high school students in relation to vehicle theft, problem drinking, and traffic offence involvement as a novice driver.  Results indicated that &amp;quotmaleness" was significantly related to vehicle theft, problem drinking, and traffic offence involvement.  Subsequent analyses, based on Jessor's Problem Behaviour Theory, found a significant relationship between vehicle theft offenders and problem drinking. Study One Part B examined the relationship between masculinity as measured by the Australian Sex Role Scale (ASRS) and problem drinking in a rural sample of 1,248 male high school students.  Using a cross sectional methodology, Masculine students were more likely than students in the other gender trait groups to report a range of problem drinking behaviours.  Contrary to previous research, both socially desirable and socially undesirable masculine traits were significantly related to most problem drinking behaviours.-----   
 
 
 
 Having established significant relationships between &amp;quotmaleness" and vehicle theft and masculinity and the adolescent problem behaviour of underage drinking, Study Two qualitatively examined the perceptions of adolescent males with histories of vehicle theft in relation to &amp;quotdoing masculinity".  Using semi-structured interviews, 30 adolescent males, clients of the juvenile justice system were asked &amp;quotwhat do you have to do to be a man?"  Vehicle theft was clearly identified as a masculine defining behaviour as were other offending behaviours.  Overall, participants nominated very traditional behaviours such as having a job and providing financially for families as essential behaviours in &amp;quotdoing masculinity".  It was suggested that in the absence of legal options for creating a masculine gender identity, some adolescent males adopted more readily accessed illegal options.  Study Two also canvassed the driving behaviour of adolescent males in stolen vehicles.  Crash involvement was not uncommon.  Speed, alcohol, and the presence of other adolescent males were consistent characteristics of their driving behaviour.   Indigenous and non-Indigenous participants were similar in their responses.----- 
 
 
 
 Study Three compared the gender identity of offender and non-offender adolescent males as measured by three gender-related measures:  the ASRS, the Toughness Subscale of the Male Role Norm Scale (TSMRNS) and the Doing Masculinity Composite Scale (DMCS).  While the ASRS measured gender traits, the TSMRNS measured masculinity ideology.  The DMCS was developed from the responses of participants in Study Two and sought to measure how participants &amp;quotdo masculinity".  Analyses indicated vehicle theft was endorsed by just over a third of the sample as a masculine defining behaviour.  Overall, offenders were again very traditional in the behaviours they endorsed.  When compared to non-offenders, offenders were more likely to endorse illegal behaviours in &amp;quotdoing masculinity" while non-offenders were more likely to endorse legal behaviours.  Both offenders and non-offenders strongly endorsed having a car and the ability to drive as masculine defining behaviours.-----
 
 
 
 In relation to gender traits, non-offenders were more likely than offenders to be classified as Masculine by the ASRS.  Surprisingly offenders were more likely to be classified as Androgynous.  In relation to masculinity ideology, offenders and non-offenders were similar in their results on the TSMRNS however offenders were more likely to endorse beliefs concerning the need to be tough.  Overall Indigenous and non-Indigenous offenders were similar in their responses though Indigenous males were more likely to endorse beliefs concerning the need to be tough.  Spence's Multifactorial Gender Identity theory was supported in that the relations between the three gender-related measures were significant but low.-----
 
 
 
 Results confirmed that vehicle theft was endorsed by a minority of participants as a gendered behaviour.  Other offending behaviours were also endorsed by some adolescent males as means to create masculine gender identity.  Importantly though both offenders and non-offenders endorsed very traditional behaviours in relation to &amp;quotdoing masculinity".  The implications for policy and program initiatives include the acknowledgement of gender identity as an important component in relation to vehicle theft and offending and the desire of adolescent male offenders to engage in legal, traditional male behaviours.  In the absence of legal avenues however, some adolescent males may use illegal behaviours to create gender identity.  Cars and driving also feature as important components of gender identity for both offenders and non-offenders and these needs to be considered in relation to road safety initiatives.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">vehicle theft</field><field name="subject">gender identity</field><field name="subject">adolescents</field><field name="subject">driving</field><field name="subject">offenders</field><field name="subject">non-offenders</field><field name="subject">indigenous</field><field name="subject">multifactorial gender identity theory</field><field name="subject">masculinity</field><field name="identifier">http://eprints.qut.edu.au/16422/</field><field name="validLink">True</field></doc><doc><field name="title">Motivators and inhibitors to knowledge sharing in I.T. project teams</field><field name="creator">Jewels, Tony John</field><field name="description">The potential importance of managing knowledge for competitive advantage has been widely discussed according to Nonaka and Takeuchi (1995), with the sharing and application of knowledge being widely identified in recent years as key sources of sustained competitive advantage (Hall &amp; Sapsed 2005, p57). While Alavi and Leidner (2001, p216) agree that much theory already exists on knowledge management, they argue that little empirical work has been undertaken and hence there are large gaps in the body of knowledge in this area. Bresnen, Edelman, Newell, Scarbrough, and Swan (2003) further suggest that only recently has attention been specifically directed towards managing knowledge in project environments.    Evidence of poor IT project success continues to be provided by many researchers even though today's corporations recognize that to be successful, they need to understand modern project management techniques (Schwalbe 2002, p2). With Kotnour (2000) finding that project performance is positively associated with project knowledge, a better understanding of how to effectively manage knowledge in IT projects should have considerable practical significance for increasing the chances of project success.    The focus of this research centres on the question of why individuals working within IT project teams might be motivated towards, or inhibited from, sharing their knowledge and experience in their activities, procedures, and processes.    Using a combined qualitative/quantitative method of data collection in multiple case studies spanning four continents, and comprising a variety of organisational types, the research concludes with the development of a new theoretical model of knowledge sharing behaviour, &amp;quotThe Alignment Model of Motivational Focus". This model suggests that an individual's propensity to share knowledge and experience is a function of perceived personal benefits and costs associated with the activity, balanced against the individual's alignment to a group of 'institutional' factors. These factors are identified as alignments to the project team, to the organisation, and dependent on the circumstances, to either the professional discipline or community of practice, to which the individual belongs.    The model might be used within knowledge intensive projects, to help identify an individual's latent propensity to share knowledge, and to identify actions that may need to be taken in order to modify knowledge sharing behaviour.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">knowledge management</field><field name="subject">knowledge sharing behaviour</field><field name="subject">knowledge sharing</field><field name="subject">competitive advantage</field><field name="subject">IT project teams</field><field name="subject">IT projects</field><field name="identifier">http://eprints.qut.edu.au/16423/</field><field name="validLink">True</field></doc><doc><field name="title">Assessment and reduction of the impacts of large freight vehicles on urban traffic corridor performance</field><field name="creator">Ramsay, Euan Douglas</field><field name="description">Increasing demand for road freight has lead to a widespread adoption of more-productive large freight vehicles (LFVs), such as B-Doubles, by Australia's road freight industry. Individual LFVs have a greater potential to impact traffic efficiency through their greater length and poorer longitudinal performance.  However, this is offset to an extent as fewer vehicles are required to perform a given freight task on a tonne-km basis.    This research has developed a means of characterising the effects that large freight vehicles have on the performance of an urban arterial corridor managed by signalised intersections. A corridor-level microsimulation model was developed from first principles, which modelled the longitudinal performance of individual vehicles to a greater accuracy than most existing traffic simulation software does. The model was calibrated from traffic counts and GPS-equipped chase car surveys conducted on an urban arterial corridor in Brisbane's southern suburbs.    The model was applied to various freight policy and traffic management scenarios, including freight vehicle mode choice, lane utilisation and traffic signal settings; as well as the effectiveness of green time extension for approaching heavy vehicles. Benefits were able to be quantified in terms of reduced travel times and stop rates for both heavy and light vehicles in urban arterial corridors.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">traffic management</field><field name="subject">traffic analysis</field><field name="subject">signalised intersection</field><field name="subject">microsimulation</field><field name="subject">passenger car equivalence</field><field name="subject">delay</field><field name="subject">truck</field><field name="subject">heavy vehicle</field><field name="subject">B-double</field><field name="identifier">http://eprints.qut.edu.au/16424/</field><field name="validLink">True</field></doc><doc><field name="title">Bottom-up constructions of top-down transformational change : change leader interventions and qualitative schema change in a spatially differentiated technically-oriented public professional bureaucracy</field><field name="creator">Thompson, Robert M.</field><field name="description">In the face of knowledge deficits in and poor outcome assessments of Organisation Transformation (OT), there is a need for a better understanding of the relationship between change leader interventions and qualitative organisational schema change, the collective knowledge structures that must be replaced or significantly elaborated if OT is to be realised.
 
 
 
 Previous research on this relationship has (a) focused on imposed structural interventions and given little attention to large-scale human process interventions, (b) given little attention to the radical structural interventions frequently involved in the transformation of public organisations, (c) given little scrutiny to how organisational schema have been conceptualised, (d) given little scrutiny to recent propositions on schema change dynamics that may be contentious, and (e) given little consideration to the change management contexts in which leader influence may be neutralised.
 
 
 
 In the light of these gaps in the literature, this thesis investigates, from the perspective of change recipients, the relationship between complex large-scale change leader interventions and qualitative organisational schema change in change management contexts thought to be inimical to leader influence.  In particular, how efficacious are change leader interventions in realising qualitative organisational schema change in such contexts?
 
 
 
 An interpretive longitudinal case study design was used to address this question.  The case organisation is a spatially differentiated technically-oriented public Professional Bureaucracy located in Queensland.  In this context, this thesis investigates, over a three-year period, the creation and evolution of three schema change contexts, or change trajectories, created by two temporally disconnected yet functionally inter-related change leader interventions.
 
 
 
 Data collection techniques included focus group interviews, semi-structured interviews, and secondary sources.  Data were collected from several sites, including Head Office functions and Regional and District offices, across Queensland.  Data were collected on four occasions across the three-year period from early 2000 to late 2002.
 
 
 
 The results reveal that (a) while there are no panaceas, public managers need more sophisticated intervention theories based on a knowledge of the relative efficacy of different interventions rather than relying on, predominantly, structural interventions, (b) viewing organisational schema in one-dimensional rather than multidimensional terms masks both the complexity of organisational schema change and the possibility of partial rather than configurational schema change, (c) while inter-schema conflict or dialectical processes were apparent, successful schema change was better explained by teleological processes than by dialectical processes, and (d) change leaders can have a powerful influence on OT in change management contexts thought to be inimical to change leader influence yet their influence is linked to high investments of time and effort.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">organisational transformation</field><field name="subject">leadership</field><field name="subject">schema change</field><field name="subject">public sector</field><field name="identifier">http://eprints.qut.edu.au/16425/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation of the writing strategies three Chinese post-graduate students report using while writing academic papers in English</field><field name="creator">Mu, Congjun</field><field name="description">Due to a lack of effective writing strategies and inhibition of English language proficiency, university students in China are found to produce little and shallow content in their English academic writing. Similar problems are also embodied in the academic writing of Chinese overseas students who struggle to survive in the target academic community. The purpose of this study was to investigate the writing processes of second language (L2) writers, specifically examining the writing strategies of three Chinese post-graduate students in an Australian higher education institution. The study was prompted by the paucity of research in the writing strategies used by Chinese students in English academic writing in an authentic context. Although it was too small in scale to generalise in the field of L2 writing, the study will stimulate research in L2 writing theory and practice. Based on a review of theories related to L2 writing and research in Chinese and English writing strategies, the writing strategies used by three Chinese post-graduate students while writing academic papers in English were investigated. Their understandings of English and Chinese writing processes, the issue of transfer of Chinese writing into English writing and cultural influence of native language on L2 writing were explored as well.
 
 
 
 Qualitative hermeneutic multi-case study methods were employed to provide a richer description of the writing strategies used by the three students to develop a deeper understanding of the L2 writing process. Data were provided by three Chinese post-graduate student writers in Public Health who were observed undertaking different tasks. Ally, a Masters student, was observed completing one of the assignments for a course. Susan and Roger, both doctoral students, were observed working on a second stage proposal and a journal paper respectively. Data collected from semi-structured interviews, questionnaires, retrospective post-writing discussions and papers were categorised and analysed using topical structure analysis and cohesion analysis. 
 
 
 
 The findings suggest that writing in a second language is a complicated idiosyncratic developmental process influenced by cognitive development, social/educational experience, the writer's first language (L1) and second language (L2) proficiency and cultural factors as well. These proficient writers were found to utilise a broad range of writing strategies while writing academic papers in English. This study in some degree supports Silva's (1993) finding that the L2 writing process is strategically, rhetorically, and linguistically different from the L1 writing process. Most of the metacognitve, cognitive, communicative and social/affective strategies except rhetorical strategies (operationally defined in this study as organisation of text or paragraphs) were found to transfer across languages positively. These student writers were noticed to have difficulties in acculturating into the target academic discourse community because of their background of reader-responsibility which is regarded as a crucial feature in Eastern rhetoric and is distinguished from writer-responsibility in English rhetoric (Hinds, 1987, 1990).</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">second language writing</field><field name="subject">Chinese students</field><field name="subject">rhetorical strategies</field><field name="subject">metacognitive strategies</field><field name="subject">cognitive strategies</field><field name="subject">communicative strategies</field><field name="subject">social/affective strategies</field><field name="subject">multi-case study</field><field name="subject">hermeneutic approach</field><field name="identifier">http://eprints.qut.edu.au/16426/</field><field name="validLink">True</field></doc><doc><field name="title">Electrochemical synthesis of melanin-like polyindolequinone</field><field name="creator">Subianto, Surya</field><field name="description">Conducting polymer is a rapidly developing area of research due to its potential in combining the physical properties of polymers with electrical properties previously found only in inorganic systems. These conducting polymers owe their unique properties to a conjugated polymer backbone and become conducting upon oxidation or reduction.    Melanin, a biopolymer, possess a conjugated backbone required of a conducting polymer, and has shown properties of an amorphous semiconductor. However, there has not been much study done in this area despite its potential, and this is partially due to the lack of processing methods as melanin is generally synthesised as an intractable powder. Thus, a better synthetic method was required, and a possible solution is the use of electrochemical synthesis.    In our previous study we have shown that melanin can be synthesised electrochemically as a free-standing film, which was the first step towards the use of melanin as a bulk material. This project aims to continue from this preliminary work, investigating the various synthetic parameters and possible modifications as well as investigating possible applications for the electrochemically synthesised melanin film.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">electrochemical synthesis</field><field name="subject">melanin-like</field><field name="subject">polyindolequinone</field><field name="subject">polymers</field><field name="subject">oxidation</field><field name="subject">biopolymer</field><field name="subject">conjugated backbone</field><field name="subject">amorphous semiconductor</field><field name="subject">intractable powder</field><field name="identifier">http://eprints.qut.edu.au/16427/</field><field name="validLink">True</field></doc><doc><field name="title">Chemical and physical characterization of aerosols from the exhaust emissions of motor vehicles</field><field name="creator">Lim, McKenzie C. H.</field><field name="description">The number concentration and size distribution of particles in Brisbane have been studied extensively by the researchers at The International Laboratory for Air Quality and Health, Queensland University of Technology (Morawska et al., 1998, 1999a, 1999b). However, the comprehensive studies of chemical compositions of atmospheric particles, especially with regard to the two main classes of pollutants (polycyclic aromatic hydrocarbons and trace elements), that are usually of environmental and health interest, have not been fully undertaken. Therefore, this thesis presents detailed information on polycyclic aromatic hydrocarbons (PAHs) and elemental compositions of vehicle exhausts and of urban air in Brisbane. The levels of polycyclic aromatic hydrocarbons (PAHs) and elements in three of Brisbane's urban sites (Queensland University of Technology, Woolloongabba and ANZ stadium sites) were measured. The most common PAHs found in all sites were naphthalene, phenanthrene, anthracene, fluoranthene, pyrene and chrysene while Al, Cd, Co, Cr, Cu, Fe, Mn, Mo, Si, Sn, Sr and Zn were the most common elements detected in the total suspended particles and fine particle (PM2.5). With the aid of multivariate analysis techniques, several outcomes were obtained. For example:  -- Major human activities such as vehicular and industrial sources were the most contributing pollution sources in Brisbane. However, these two sources have different influential strength on the compositions of the polycyclic aromatic hydrocarbons and trace inorganic elements found in the urban air.  -- Woolloongabba bus platform was the most polluted site on the basis of the elemental and PAH compositions in its air samples while QUT site was the worst polluted site in terms of PM2.5 elemental contents. These results demonstrated that the impact of traffic related pollutants on Brisbane's urban air is significant. This led to the investigations of the direct emissions of pollutants from exhaust vehicular source in the second part of this research work. The exhaust studies included the investigations of PAHs, trace inorganic elements and particles. At the time of the study, the majority of vehicles in Brisbane used low sulfur diesel (LSD) fuel or unleaded petrol (ULP). However, the importance of vehicles using ultra low sulfur diesel (ULSD) and liquefied petroleum gas (LPG) is constantly growing. Therefore, the exhaust emission studies on chassis dynamometer from heavy duty non-catalyst-equipped buses powered by LSD and ULSD with 500 ppm and 50 ppm sulfur contents respectively as well as passenger cars powered by ULP and LPG were explored. The outcomes of such studies are summarized as follows:  -- Naphthalene, acenaphthene, acenaphthylene, anthracene, phenanthrene, fluorene, fluoranthene and pyrene were frequently emitted by the buses powered by LSD and ULSD. However, buses powered by ULSD emitted 91% less PAHs than those powered by LSD. On the other hand, Mg, Ca, Cr, Fe, Cu, Zn, Ti, Ni, Pb, Be, P, Se, Ti and Ge were found in measurable quantities in the exhaust of the buses. The emissions of the elements were found to be strongly influenced by the engine driving conditions of the buses and fuel parameters such as sulfur content, fuel density and cetane index. -- Naphthalene, fluorene, phenanthrene, anthracene, pyrene, chrysene, benzo(a)anthracene and benzo(b)fluoranthene were predominantly emitted by ULP and LPG cars. On the average, the total emission factors of PAHs from LPG cars were generally lower than those of ULP cars, but given the large variations in the emission factors of cars powered by the same type of fuel, differences in the emission factors from both car types were statistically insignificant. In general, platinum group elements and many other elements were found in the exhausts of cars powered by both fuels. Emissions of inorganic elements from the cars were dependent on the type and the mileage of the cars. For example, ULP cars generally emitted higher levels of Cu, Mg, Al and Zn while LPG cars emitted higher level of V. In addition, cars with higher mileages were associated with higher emissions of the major elements (Zn, Al, Fe, V and Cu).  -- Buses powered by ULSD usually emitted fewer particles, which were generally 31% to 59% lower than those emitted by LSD powered buses. Similarly, cars powered by LPG emitted less particles from those powered by ULP fuel. However, more nanoparticles (those with aerodynamic diameters of less than 50 nm) were emitted by LPG powered cars than their ULP counterparts. Health effect assessment of the exhaust PAHs was evaluated in terms of benzo(a)pyrene toxicity equivalent (BAPeq). The potential toxicities of PAHs emitted by ULSD powered buses were generally lower than those emitted by their LSD counterparts. A similar trend with lower emissions of PAHs from LPG cars than from ULP cars was observed when otherwise identical passenger cars were powered by LPG and ULP fuels.    In summary, this thesis has shown that the majority of airborne particles found around Brisbane have anthropogenic origins, particularly vehicle emissions, and that fuel or lubricant formulations and engine operating conditions play important roles in the physical and chemical characteristics of pollutants emitted by vehicles. The implications of these results on worldwide strategies to reduce the environmental and health effects of particles emitted by motor vehicles were discussed. In this regard, direct emission measurements from vehicles powered by LSD, ULSD, ULP and LPG unveiled the relative environmental benefits associated with the use of ULSD in place of LSD to power diesel engines, and of LPG in place of ULP to power passenger cars.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">vehicular exhaust emissions</field><field name="subject">heavy duty diesel buses</field><field name="subject">light passenger cars</field><field name="subject">low and ultra low sulfur diesel fuels</field><field name="subject">liquefied petroleum gas</field><field name="subject">unleaded petrol</field><field name="subject">urban pollution</field><field name="subject">fine particles</field><field name="subject">total suspended particles</field><field name="subject">ultrafine particles</field><field name="subject">nanoparticles</field><field name="identifier">http://eprints.qut.edu.au/16428/</field><field name="validLink">True</field></doc><doc><field name="title">Resonances of scattering in non-uniform and anisotropic periodic gratings at extreme angles</field><field name="creator">Goodman, Steven John</field><field name="description">Bragg scattering of optical waves in thick gratings at extreme angles, where the scattered wave propagates parallel (extremely asymmetric scattering - EAS) or nearly parallel (grazing angle scattering - GAS) to the grating boundaries, is associated with many unique and practically important resonant phenomena.  It has been demonstrated that one of the main physical mechanisms for these resonant phenomena is the diffractional divergence of the scattered wave inside and outside the grating region. This thesis fills the gaps in the theoretical and experimental understanding of Bragg scattering in gratings at extreme angles by investigating EAS and GAS in structures where diffractional divergence of waves is significantly affected by anisotropy and/or non-uniformities of the dielectric permittivity.
 
 Unusually high sensitivity of wave scattering in thick periodic gratings to small step-like variations of mean structural parameters at the grating boundaries is predicted and described for the case when the scattered wave (the +1 diffracted order) propagates almost parallel to the front grating boundary (the geometry of GAS). A unusual pattern of strong multiple resonances for bulk electromagnetic waves is predicted and analysed numerically in thick periodic holographic gratings in a guiding slab with mean permittivity that is greater than that of the surrounding media. It is demonstrated that these resonances are related to resonant generation of a new type of eigenmodes in a thick slab with a periodic grating. These eigenmodes are generically related to the grating -- they do exist not if the grating amplitude is zero.
 
 A new type of resonant coupling of bulk radiation into the conventional guided modes of a slab with a thick holographic grating is predicted and explained theoretically. It occurs in the presence of strong frequency detunings of the Bragg condition by means of interaction of the strongly non-eigen +1 diffracted order with the slab-grating boundaries. Therefore, it is only in the presence of step-like variations of the mean permittivity at the grating boundaries that this type of resonant coupling can occur. 
 
 A new method for the analysis of EAS and GAS in anisotropic gratings is developed.  This method is based on the consideration of the diffractional divergence of the scattered wave and the two-wave approximation in anisotropic gratings.  Special efforts are focused on the analysis of EAS and GAS of extraordinary waves in uniaxial gratings.  In particular, it is demonstrated that increasing curvature of the normal surface in the direction of propagation of the scattered wave results in increase of its diffraction divergence and the resonant amplitude.
 
 A theoretical model is developed for comparison of the theoretical predictions with data obtained from experimental observations of EAS in a holographic grating written in a photorefractive medium.  The developed model is applied for the interpretation of experimental observations of EAS in BaTiO3 photorefractive crystals. Good agreement with the theoretical predictions is demonstrated.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Bragg scattering</field><field name="subject">extremely asymmetric scattering</field><field name="subject">grazing angle scattering</field><field name="subject">diffraction gratings</field><field name="subject">anisotropic gratings</field><field name="subject">anisotropy</field><field name="subject">diffractional divergence</field><field name="subject">eigenmodes</field><field name="subject">guided modes</field><field name="subject">Fourier analysis</field><field name="subject">optics</field><field name="subject">photonics</field><field name="subject">diffractive optics</field><field name="subject">coupled wave theory</field><field name="subject">rigorous coupled wave theory</field><field name="subject">paraxial wave equation.</field><field name="identifier">http://eprints.qut.edu.au/16429/</field><field name="validLink">True</field></doc><doc><field name="title">The use of complementary and alternative medications by menopausal women living in South East Queensland</field><field name="creator">Gollschewski, Sara Emilie</field><field name="description">Complementary and alternative medication (CAM) use during menopause is a growing public and women's health issue.  The use of CAMs is increasing and evidence of CAM use in the general population suggests that women in the menopausal age range are more likely to use CAMs.  In the context of menopause, preliminary research has indicated that women are using a number of CAMs to address symptoms.  In a study of American women aged 45 to 65 years, 22% of women used CAMs during menopause, specifically herbal or naturopathic remedies (13%), relaxation techniques (9%) and dietary soy supplements (7%). Fourteen percent (14%) of women strongly agreed with the proposition that approaches such as nutrition and vitamins were better than hormones (Newton et al., 2002).  The term 'menopause' is a concept of varying perceptions and perspectives.  From the biological perspective, menopause is constant, however from the individual perspective, menopause is a unique experience shaped by cultural, emotional, psychological and physical characteristics.  Symptoms commonly cited during menopause include hot flushes, night sweats palpitations, irregular menses and muscle and bone pain.  The use of CAMs during menopause has the potential to address current symptoms and promote long term health and wellness.  The reviewed literature indicated that while a preliminary understanding of CAM use during menopause is evident, further research is needed to clarify and contextualise current prevalence rates and types used.  In addition, an understanding of the reasons and factors that influence women to use CAMs during this transition is crucial to understanding women's menopausal experience.  This project aimed to explore the prevalence of CAM use during menopause and to identify the reasons that influence women to use these therapies during the transition.  To address this question, a two phase study was designed to incorporate both quantitative and qualitative research methods.  For Phase 1, a secondary data analysis was undertaken on a dataset that explored women's menopausal experiences and therapies used to address symptoms and for phase 2, focus groups were used to explore women's personal experiences and perceptions of CAM use during menopause.  The secondary data analysis was undertaken on a population based sample of 886 women aged 47-67 years.  Women were randomly selected from the electoral roll on the basis of gender, age and postcode, which were selected to ensure representation of urban and rural and varying socioeconomic status.  From this analysis, the findings indicated that 80% of women used at least one type of CAM with therapeutic techniques (activities such as walking and swimming) the most commonly used (83.0%), followed by nutrition (66.8%), phytoestrogens (55.8%), herbal therapies (41.3%) and CAM medications (25.1%).  Women who used CAMs were more likely to experience anxiety and vasomotor (hot flushes and night sweats) symptoms, have higher education levels, be low to middle income earners, be aged under 55 years, be previous users of hormone therapy (HT) and have participated in self breast examinations.  CAM users were 40 to 90% less likely to be currently using HT or to smoke more than 20 cigarettes per day.  The results of the secondary data analysis indicated the prevalence and factors associated with CAM use, however the factors that influence women to use CAMs during the menopause were unclear.  A series of three focus groups and two telephone interviews were undertaken with a group of 15 women, who were current users of CAMs, aged 47-67 years and fluent in English.  Women were recruited through an advertisement placed in a newsletter distributed by a large metropolitan hospital; a flyer displayed on noticeboards of libraries and shopping centres; and a media release through the local community newspaper and on a state wide radio station.  Analysis of the transcripts indicated that a number of factors interact to influence a woman's decision to use CAMs.  Influences included relationships with family, friends and health practitioners, effects of symptoms, information on CAMs and menopause, current menopause research, personal perceptions of health, wellness and effectiveness of CAM therapies to alleviate symptoms. Taken together, the results of the Phase 1 and 2 combined with the literature indicated that women were using multiple forms of CAMs.  A post hoc analysis was undertaken and the CAM questions analysed in Phase 1 were critiqued within this new knowledge of CAM use.  As a consequence, CAMs were redefined into four groups to enhance current understandings. After reclassification, the use of at least one CAM was 71.6%, with the most commonly used dietary phytoestrogens (60.0%), followed by dietary supplements (47.0%), herbal therapies (35.9%) and phytoestrogen supplements (33.0%).  Sociodemographic, health and symptom characteristics were further profiled against the redefined categories of dietary phytoestrogens, dietary supplements, herbal therapies, phytoestrogen supplements and users of multiple CAMs.  The consistency of associations varied according to the CAM category with no significant association present across all four CAM categories.  This post hoc analysis clarified CAM categorisation and highlighted the high prevalence of women who were using multiple forms of CAMs.  Additionally, multivariable analysis validated and confirmed the results of Phase 1 as similar profiles of a CAM user were found.        This research has identified the prevalence of CAM use during menopause in Queensland women and has begun to elucidate the reasons that influence women to use these therapies during this transition.  The utilisation of both quantitative and qualitative methods has provided a comprehensive and holistic depiction of women's use of CAMs during menopause.  The results and conclusions drawn from this research have highlighted areas that need addressing within the research and health service domain.  For future research, development of a comprehensive CAM survey instrument is required and clarification of the definition of CAMs is also needed.  Multiple definitions are currently used to describe CAM use, creating confusion in classifying types of CAMs and comparing prevalence rates between studies.  With regard to health service recommendations, there is a need for increased access to information on menopause and alternative therapies for women.  Open, active and participatory relationships between health practitioners and menopausal women are essential and health practitioners need to be aware women are using a variety of CAMs during the menopause and are likely to continue to do so even if health practitioner support is not apparent.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">complementary and alternative medications</field><field name="subject">menopause</field><field name="subject">symptoms</field><field name="subject">Australian</field><field name="subject">SF-36</field><field name="subject">demographic characteristics</field><field name="subject">focus groups</field><field name="subject">influences of use</field><field name="identifier">http://eprints.qut.edu.au/16430/</field><field name="validLink">True</field></doc><doc><field name="title">Advertising and the Internet : a study of agency-client expectations of the Internet as a promotional tool</field><field name="creator">Browne, Jennifer Michelle</field><field name="description">Undoubtedly one of the most significant developments to affect marketing  worldwide in the 21st century has been the development of the Internet. As a  communication tool the Internet is emerging as a new challenge to mass media  advertising. As a result advertising agencies need to readdress their techniques,  services and agency structure. Additionally, the shape and form of the traditional  advertising agency will need to change along with the adoption and usage of this  new interactive media channel. Agencies are now being forced to consider  broadening their service offerings to clients. Apart from widening their service  offerings, advertising agencies are being driven to invest in building and  sustaining valuable client relationships to establish client loyalty, with profit and a  healthy bottom-line being the ultimate objectives. Bush, Bush and Harris (1998)  point out however, that whilst a growing number of companies are interested in  developing an online presence, significant confusion remains about what this new  medium will offer stakeholders in the advertising industry. The study undertaken  in this thesis explores the relationship between two influential stakeholders in the  advertising industry - advertising agencies and their clients.  To explore this relationship, the study modified Parasuraman, Zeithamal and  Berry's (1988) SERVQUAL model to explore whether gaps exist between  agency-client expectations of the value of the Internet as a promotional tool. The  SERVQUAL model, which was designed for measuring gaps between service  expectations and perceptions, was adapted for use in the business-to-business  environment (B2B). In the marketing literature there is little evidence of B2B  research in relation to agency-client relationships, nor has there been significant  scholarly work exploring the effect of the introduction of the Internet as a  promotional tool on the agency-client relationship. The research undertaken in  this study aims to respond to this gap in the marketing literature by addressing the  broad research question: &amp;quotHow will the introduction of the Internet as a  promotional tool impact agency-client relationships?" Undertaking a review of  agency-client expectations of the value of the Internet will ascertain whether gaps exist between agency and client expectations of the value of the Internet as a  promotional tool. The discovery of gaps in the agency-client relationship in  relation to Internet perceptions will indicate potential opportunities and challenges  that need to be addressed by advertising agencies interested in extending their  advertising services to embrace the Internet as a promotional tool.  A major assumption in this inquiry was that gaps would exist between agency and  client perceptions of Internet value. In particular, that advertising agencies would  perceive the Internet to be a more valuable promotional tool than their clients.  This assumption was informed from mass media and industry press, which  indicated that advertising agencies were embracing new advertising creative in  website design and strategic marketing activities using interactive media such as  newsgroups and email to reach customers. However, the research of Bush et al.  (1998) and Ducoffe (1996) suggests that little is known about the value of these  Internet-based activities. Such thinking raises questions, such as: are advertisers  feeling compelled to jump on the Internet bandwagon because of its popularity, or  are businesses' desires to use Internet advertising a manifestation of Internet  hype? To begin to answer these questions advertising industry stakeholders need  to identify whether gaps do exist between agency and client perceptions of the  value of the Internet as a promotional tool. The existence of such gaps could lead  to tension in the agency-client relationship, which may ultimately mean a loss of  client accounts for the advertising agency. Identifying and remedying such gaps  could therefore aid in ensuring long-term and profitable working relationships  with the agency's clients.  To undertake this advertising industry research and respond to the research  questions in this study an international advertising agency network, made up of  206 offices in 90 countries and a selection of their clients, were recruited to  participate in the study. A two stage survey method approach was adopted  because it was a time-efficient and affordable method for collecting detailed  information from a dispersed network of professionals. The survey tool was a  web-based questionnaire which was firstly submitted to a selection of advertising agencies within the international agency network. On completion of the  questionnaire, agencies were asked to provide contact details for their top three  billing clients. The second stage of the survey research involved the submission of  a client questionnaire to the client contacts provided by the advertising agency.  Both questionnaires used a modified SERVQUAL multi-item scale to measure  service expectations. Discrete agency and client questions were also included in  the respective questionnaires to situate the SERVQUAL analysis within the  context of Internet usage, value perceptions and organisational characteristics (e.g.  agency size, advertising spend, experience in using interactive media).  The major finding of this study is that within the international advertising agency  network there were no significant gaps in agency-client expectations concerning  the value of the Internet as a promotional tool. Whilst several statistical analyses  were undertaken, including bivariate and multivariate techniques such as  Pearson's Chi-Square cross-tabulations, independent t-tests and ANOVAs, no  statistically significant results are reported. In fact, it was found that advertising  agencies and clients have similar expectations of the value of the Internet as a  promotional tool. Gaps actually exist in relation to the clients who use the Internet  as a promotional tool and agencies who supply Internet advertising services.  Many agencies within this international agency network were found to be actively  using the Internet, but their Internet advertising functions were not being provided  by their traditional advertising agency. Descriptive analyses reported in the  findings from this research study indicate that advertising agencies in this  international network need to better understand their clients' Internet promotion  needs. This will ensure the establishment of healthy, profitable and long-term  agency-client relationships in the future.  The research findings from this study offer advertising agencies worldwide insight  into client expectations of the Internet, as well as other agency services.  Furthermore, the findings reported contribute to the current small body of research  in relation to B2B relationships in the advertising industry. The groundwork is set  for future analysis of agency-client relationships in the advertising industry. In summary, while gaps between agency and client expectations of the value of the  Internet as a promotional tool were expected, this research study found that  agency and client expectations are quite similar. Analysis did reveal that one  important factor, which influences the agency-client relationship, relates to the  provision of Internet advertising services. Specifically, when an agency is not  responsible for developing and maintaining clients' Internet advertising, these  clients are utilising services from external providers of Internet services. These  new stakeholders, who provide specialist services (i.e. graphic design houses,  Internet advertising specialists and client's in-house Internet services), are  changing the competitive environment of advertising services in the industry.  Another interesting discovery, specific to the sample population, was that one  third of agencies within the study did not provide Internet advertising services to  current clients. However, these agencies have clients that use Internet advertising.  On the one hand, this finding indicates that opportunities exist for these agencies  to extend their service portfolio to embrace Internet advertising. However, it also  raises an important question: that is, have these agencies created greater  competition by not providing a full service communication portfolio for clients?  These factors, and other methodological issues will inform directions for future  research to explain the influential role of the Internet within the agency-client  relationship in the advertising industry.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">advertising</field><field name="subject">internet</field><field name="subject">agency-client expectations</field><field name="subject">promotional tool</field><field name="subject">tele-marketing</field><field name="subject">marketing</field><field name="subject">e-business</field><field name="subject">e-commence</field><field name="subject">SERVQUAL multi-item scale</field><field name="identifier">http://eprints.qut.edu.au/16431/</field><field name="validLink">True</field></doc><doc><field name="title">Rolling element bearing fault diagnostics using the blind deconvolution technique</field><field name="creator">Karimi, Mahdi</field><field name="description">Bearing failure is one of the foremost causes of breakdown in rotating machinery. Such failure can be catastrophic and can result in costly downtime. Bearing condition monitoring has thus played an important role in machine maintenance. In condition monitoring, the observed signal at a measurement point is often corrupted by extraneous noise during the transmission process. It is important to detect incipient faults in advance before catastrophic failure occurs. In condition monitoring, the early detection of incipient bearing signal is often made difficult due to its corruption by background vibration (noise). Numerous advanced signal processing techniques have been developed to detect defective bearing signals but with varying degree of success because they require a high Signal to Noise Ratio (SNR), and the fault components need to be larger than the background noise. Vibration analyses in the time and frequency domains are commonly used to detect machinery failure, but these methods require a relatively high SNR. Hence, it is essential to minimize the noise component in the observed signal before post processing is conducted. In this research, detection of failure in rolling element bearing faults by vibration analysis is investigated. The expected time intervals between the impacts of faulty bearing components signals are analysed using the blind deconvolution technique as a feature extraction technique to recover the source signal. Blind deconvolution refers to the process of learning the inverse of an unknown channel and applying it to the observed signal to recover the source signal of a damaged bearing. The estimation time period between the impacts is improved by using the technique and consequently provides a better approach to identify a damaged bearing. The procedure to obtain the optimum inverse equalizer filter is addressed to provide the filter parameters for the blind deconvolution process. The efficiency and robustness of the proposed algorithm is assessed initially using different kinds of corrupting noises. The result show that the proposed algorithm works well with simulated corrupting periodic noises. This research also shows that blind deconvolution behaves as a notch filter to remove the noise components. This research involves the application of blind deconvolution technique with optimum equalizer design for improving the SNR for the detection of damaged rolling element bearings. The filter length of the blind equalizer needs to be adjusted continuously due to different operating conditions, size and structure of the machines. To determine the optimum filter length a simulation test was conducted with a pre-recorded bearing signal (source) and corrupted with varying magnitude noise. From the output, the modified Crest Factor (CF) and Arithmetic Mean (AM) of the recovered signal can be plotted versus the filter length. The optimum filter length can be selected by observation when the plot converges close to the pre-determined source feature value. The filter length is selected based on the CF and AM plots, and these values are stored in a data training set for optimum determination of filter length using neural network. A pre-trained neural network is designed to train the behaviour of the system to target the optimum filter length. The performance of the blind deconvolution technique was assessed based on kurtosis values. The capability of blind deconvolution with optimum filter length developed from the simulation studies was further applied in a life bearing test rig. In this research, life time testing is also conducted to gauge the performance of the blind deconvolution technique in detecting a growing potential failure of a new bearing which is eventually run to failure. Results from unseeded new bearing tests are different, because seeded defects have certain defect characteristic frequencies which can be used to track a specific damaged frequency component. In this test, the test bearing was set to operate continuously until failures occurred. The proposed technique was then applied to monitor the condition of the test bearing and a trend of the bearing life was established. The results revealed the superiority of the technique in identifying the periodic components of the bearing before final break-down of the test bearing. The results show that the proposed technique with optimum filter length does improve the SNR of the deconvolved signal and can be used for automatic feature extraction and fault classification. This technique has potential for use in machine diagnostics.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">rolling element</field><field name="subject">bearing fault</field><field name="subject">blind deconvolution technique</field><field name="identifier">http://eprints.qut.edu.au/16432/</field><field name="validLink">True</field></doc><doc><field name="title">Modelling strategies for the healing of burn wounds</field><field name="creator">Denman, Paula Kerri</field><field name="description">Epidermal wound healing requires the coordinated involvement of complex cellular and biochemical processes. In the case of epidermal wounds associated with burns, the healing process may be less than optimal and may take a significant amount of time, possibly resulting in infection and scarring.    An innovative method to assist in the repair of the epidermis (the outer layer of skin) is to use an aerosolised apparatus. This method involves taking skin cells from an area of the patient's undamaged skin, culturing the cells in a laboratory, encouraging them to rapidly proliferate, then harvesting and separating the cells from each other. The cells are then sprayed onto the wound surface.    We investigate this novel treatment strategy for the healing of epidermal wounds, such as burns. In particular, we model the application of viable cell colonies to the exposed surface of the wound with the intent of identifying key factors that govern the healing process.    Details of the evolution of the colony structure are explored in this two-dimensional model of the wound site, including the effect of varying the initial population cluster size and the initial distribution of cell types with different proliferative capacities.  During injury, holoclones (which are thought to be stem cells) have a large proliferative capacity while paraclones (which are thought to be transient amplifying cells) have a more limited proliferative capacity. The model predicts the coverage over time for cells that are initially sprayed onto a wound.    A detailed analysis of the underlying mathematical models yields novel mathematical results as well as insight into phenomena of healing processes under investigation. Two one-dimensional systems that are simplifications of the full model are investigated. These models are significant extensions of Fisher's equation and incorporate the mixed clonal population of quiescent and active cells.    In the first model, an active cell type migrates and proliferates into the wound and undergoes a transition to a quiescent cell type that neither migrates nor proliferates. The analysis yields the identification of the key parameter constraints on the speed of the healing front of the cells on this model and hence the rate of healing of epidermal wounds. Approximations for the maximum cell densities are also obtained, including conditions for a less than optimal final state.    The second model involves two active cell types with different proliferative capacity and a quiescent cell type. This model exhibits two distinct behaviours: either both cell types coexist or one of them dies out as the wound healing progresses leaving the other cell type to fill the wound space. Conditions for coexistence are explored.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">epidermis</field><field name="subject">keratinocytes</field><field name="subject">skin</field><field name="subject">clonal subtypes</field><field name="subject">stem cells</field><field name="subject">transient amplifying cells</field><field name="subject">holoclones</field><field name="subject">meroclones</field><field name="subject">paraclones</field><field name="subject">wound healing</field><field name="subject">burns</field><field name="subject">aerosolised skin grafts</field><field name="subject">mathematical modelling</field><field name="subject">travelling waves</field><field name="subject">reaction-diffusion</field><field name="subject">asymptotic approximation</field><field name="subject">perturbation theory</field><field name="identifier">http://eprints.qut.edu.au/16433/</field><field name="validLink">True</field></doc><doc><field name="title">Researching educational disadvantage : using participatory research to engage marginalised students with education</field><field name="creator">Bland, Derek Clive</field><field name="description">Educational disadvantage, long recognised as a factor in determining post-school options, manifests in forms of marginalisation from and resistance to education, and in under-representation in tertiary education. Moreover, while student voice is becoming a more normalised aspect of decision making in schools, marginalised students have limited opportunities to participate in education reform processes. The practice of &amp;quotstudents as researchers" (SaR) extends student voice through engaging students in researching the educational issues that directly affect them and inviting participation in pedagogical and school reform issues. In this research, I examine the application of an SaR model with marginalised secondary school students, and the outcomes for the participants and their schools. The Student Action Research for University Access (SARUA) project provides the site of my empirical investigation. The research is informed by two complementary lines of theory: Habermasian critical theory, which provides the framework for participatory research, and Bourdieuian social reproduction theory, which scaffolds the aims of empowerment underlying SaR. These theories are extended by a theory of imagination to take account of difference and to establish a link to post-modern considerations. I employed a participatory action research methodology to investigate changes in the students' awareness of post-school options, their aspirations regarding tertiary study, and the development of related educational skills as a result of their participation in the project. The principal findings from the research are that the SARUA model provides an effective medium for the empowerment of marginalised students through engagement in meaningful, real-life research; that participant schools are positioned to benefit from the students' research and interventions when school and student habitus are in accord; and that the SARUA model complements current pedagogical reforms aimed at increasing student engagement, retention, and progression to higher education.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">critical theory</field><field name="subject">educational disadvantage</field><field name="subject">imagination</field><field name="subject">participatory action research</field><field name="subject">students-as-researchers</field><field name="subject">students at risk</field><field name="subject">student voice</field><field name="identifier">http://eprints.qut.edu.au/16434/</field><field name="validLink">True</field></doc><doc><field name="title">Millennium bridge: a contemporary Australian history</field><field name="creator">Beaton, Hilary</field><field name="description">The script, Millennium Bridge, is an investigation into the passions and fears that are shaping contemporary Australia today. Charting the political climate of the past decade, at the play's centre a man is building a bridge from Australia to Asia. The central dramatic question being asked is &amp;quotIn an environment where the emphasis on economic prosperity overrides that of human rights and freedom of speech--what will be the consequences for the Australian people?" The accompanying analysis of the ten-year period it took to write Millennium Bridge illuminates the significance of institutional issues on a play and playwright's development. Written from the perspective of a mid-career playwright, the paper argues that the professional and personal circumstances within which a work of art is created (and their effect on the playwright's confidence and financial capacities) are a significant determinant of the productivity of playwrights.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">mid career</field><field name="subject">playwright profile</field><field name="subject">playwrighting</field><field name="subject">early career</field><field name="subject">commissioning process</field><field name="subject">theatre reviews</field><field name="subject">theatre industry</field><field name="subject">creative industries</field><field name="subject">government funding</field><field name="subject">audience development</field><field name="subject">consumers and distributors</field><field name="subject">Asian-Australian relations</field><field name="subject">globalisation</field><field name="subject">human rights abuse</field><field name="subject">bridge-building</field><field name="identifier">http://eprints.qut.edu.au/16435/</field><field name="validLink">True</field></doc><doc><field name="title">Hybrid 2D and 3D face verification</field><field name="creator">McCool, Christopher Steven</field><field name="description">Face verification is a challenging pattern recognition problem. The face is a biometric that, we as humans, know can be recognised. However, the face is highly deformable and its appearance alters significantly when the pose, illumination or expression changes. These changes in appearance are most notable for texture images, or two-dimensional (2D) data. But the underlying structure of the face, or three dimensional  (3D) data, is not changed by pose or illumination variations.    Over the past five years methods have been investigated to combine 2D and  3D face data to improve the accuracy and robustness of face verification. Much of this research has examined the fusion of a 2D verification system and a 3D verification system, known as multi-modal classifier score fusion. These verification systems usually compare two feature vectors (two image representations), a and b, using distance or angular-based similarity measures. However, this does not provide the most complete description of the features being compared as the distances describe at best the covariance of the data, or the second order statistics (for instance Mahalanobis based measures).    A more complete description would be obtained by describing the distribution of the feature vectors. However, feature distribution modelling is rarely applied to face verification because a large number of observations is required to train the models. This amount of data is usually unavailable and so this research examines two methods for overcoming this data limitation:    1. the use of holistic difference vectors of the face, and  2. by dividing the 3D face into Free-Parts.    The permutations of the holistic difference vectors is formed so that more observations are obtained from a set of holistic features. On the other hand, by dividing the face into parts and considering each part separately many observations are obtained from each face image; this approach is referred to as the Free-Parts approach. The extra observations from both these techniques are used to perform holistic feature distribution modelling and Free-Parts feature distribution modelling respectively. It is shown that the feature distribution modelling of these features leads to an improved 3D face verification system and an effective 2D face verification system. Using these two feature distribution techniques classifier score fusion is then examined.    This thesis also examines methods for performing classifier fusion score fusion.  Classifier score fusion attempts to combine complementary information from multiple classifiers. This complementary information can be obtained in two ways: by using different algorithms (multi-algorithm fusion) to represent the same face data for instance the 2D face data or by capturing the face data with different sensors (multimodal fusion) for instance capturing 2D and 3D face data. Multi-algorithm fusion is approached as combining verification systems that use holistic features and local features (Free-Parts) and multi-modal fusion examines the combination of 2D and 3D face data using all of the investigated techniques.    The results of the fusion experiments show that multi-modal fusion leads to a consistent improvement in performance. This is attributed to the fact that the data being fused is collected by two different sensors, a camera and a laser scanner. In deriving the multi-algorithm and multi-modal algorithms a consistent framework for fusion was developed.    The consistent fusion framework, developed from the multi-algorithm and multimodal experiments, is used to combine multiple algorithms across multiple modalities. This fusion method, referred to as hybrid fusion, is shown to provide improved performance over either fusion system on its own. The experiments show that the final hybrid face verification system reduces the False Rejection Rate from 8:59% for the best 2D verification system and 4:48% for the best 3D verification system to 0:59% for the hybrid verification system; at a False Acceptance Rate of 0:1%.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">computer vision</field><field name="subject">face recognition</field><field name="subject">two-dimensional</field><field name="subject">three-dimensional</field><field name="subject">multi-modal</field><field name="subject">multi-algorithm</field><field name="subject">fusion</field><field name="subject">pattern recognition</field><field name="subject">biometrics</field><field name="subject">principal component analysis</field><field name="subject">two-dimensional discrete cosine transform</field><field name="subject">classifier fusion</field><field name="subject">face verification</field><field name="subject">feature distribution modelling and Gaussian mixture modelling</field><field name="identifier">http://eprints.qut.edu.au/16436/</field><field name="validLink">True</field></doc><doc><field name="title">Does behavioural plasticity contribute to differences in population genetic structure in wild rabbit populations in arid and semi-arid Australia?</field><field name="creator">de Zylva, Geoffrey Anthony</field><field name="description">The European rabbit, Oryctolagus cuniculus, was introduced to Australia in 1859 and quickly became a significant vertebrate pest species in the country across a wide distribution. In arid and semi-arid environments, rabbit populations exist as metapopulations - undergoing frequent extinction recolonisation cycles. Previous studies identified population genetic structuring at the regional level between arid and semi-arid environments, and habitat heterogeneity was suggested as a possible causal factor. For the most part, rabbit behaviour has been overlooked as a factor that could contribute to explaining population genetic structure in arid and semi-arid environments.  This study utilised a combination of genetic sampling techniques and a simulated territorial intrusion approach to observing wild rabbit behaviour in arid and semi-arid environments.  The genetic component of the study compared population samples from each region using four polymorphic microsatellite loci. The behavioural component examined variation in the level of territoriality exhibited by three study populations in the arid region towards rabbits of known versus unknown origins (resident vs transgressor (simulating dispersal)).    A difference was observed in population genetic structure determined from nuclear markers between arid and semi-arid regions, which supports findings of previous research using mitochondrial DNA data in the same area. Additionally, differences in aggressive response to known vs unknown rabbits were identified in parts of the arid region, which together with the effects of habitat heterogeneity and connectivity may explain the observed differences in population genetic structure. Knowledge of behavioural plasticity and its effect on relative dispersal success and population genetic structure may contribute to improved management and control of feral rabbit populations at the regional level within Australia; and may assist with conservation efforts in the species' natural range in Europe.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Oryctolagus cuniculus</field><field name="subject">European rabbit</field><field name="subject">Australia</field><field name="subject">DNA</field><field name="subject">mtDNA</field><field name="subject">microsatellite</field><field name="subject">behaviour</field><field name="subject">flexible behaviour</field><field name="subject">genetic variability</field><field name="subject">metapopulations</field><field name="subject">genetic bottleneck</field><field name="identifier">http://eprints.qut.edu.au/16437/</field><field name="validLink">True</field></doc><doc><field name="title">Infrared and photocatalytic studies of model bacterial species for water treatment</field><field name="creator">Ede, Sarah Melinda</field><field name="description">The use of a CO2 infrared (IR) laser and photocatalysis for water treatment microorganism disinfection purposes was investigated. During CO2 infrared (IR) laser treatment E. cloacae inactivation was comparable to inactivation via ultraviolet (UV) treatment; however no inactivation of the more resistant B. subtilis endospores occurred. Fourier Transform Infrared-Attenuated Total Reflectance (FTIR-ATR) spectroscopy of the bacterial cells displayed increased polysaccharide contents after IR treatment. FTIR and Raman spectroscopy of simple carbohydrates before and after IR laser treatment displayed no spectral changes, with the exception of N-acetyl-D-glucosamine (NAG), which was partially attributed to sampling techniques. E. cloacae inactivation during IR treatment was attributed to localised and overall temperature increases within the water. Due to the inability to inactivate B. subtilis endospores this technique is not suitable for water treatment purposes.    Photocatalytic water treatment using novel TiO2 colloids prepared via a postsynthetic microwave-modification process (MW-treated) was also examined. These colloids were characterised using X-ray photoelectron spectroscopy (XPS), X-ray diffraction (XRD) and Brunauer-Emmett-Teller (BET) analyses and compared to Degussa P25 and convection hydrothermally-treated (HT-treated) TiO2. Slurry suspensions displayed comparable E. coli inactivation rates, so the colloids were examined in immobilised form using both a model organic degradant, oxalic acid, and E. coli. Oxalic acid degradation studies showed that the MW-treated colloids displayed similar inactivation rates to the HT-treated TiO2, due to their pure anatase composition, while Degussa P25 displayed higher inactivation rates. Investigations into the effect of shortening UV wavelength were also performed. Degussa P25 was the only catalyst which displayed higher apparent quantum yields upon shortening the UV wavelength, which was attributed to its mixed-phase anatase-rutile composition.    As E. coli inactivation was observed using distilled water, photocatalysis in natural river water was trailed. It was discovered that the pH had to be lowered from 7.5 to 5.0 and the initial cell concentration must be approximately 1 x 103 colony forming units (CFU) per cm3 or less for inactivation to be observed during a 5 hour treatment period. At a catalyst loading of 1.0 mg per cm2, Degussa P25 absorbed all the applied UVA irradiation; however the MW- and HT-treated TiO2 colloids did not due to their smaller particle size. Therefore sandwich experiments were devised to evaluate the effect of unabsorbed UV irradiation within the system. Small colony variants were identified after photocatalytic and UV treatment, which pose a potential threat to public health.    Further investigation of the different TiO2 colloids was performed using in situ  FTIR, both with and without an applied potential and compared to a thermally prepared TiO2 catalyst. The latter displayed potential dependent photocatalysis, while the mesoporous TiO2 catalysts displayed potential independent photocatalysis. All catalyst types displayed increased degradation rates upon the application of a positive bias, which was followed in situ via the production of CO2. Sodium oxalate and NAG was examined for photocatalytic degradation, both of which were degraded to CO2, with proposed break-down products identified when using NAG.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">titanium dioxide photocatalyst</field><field name="subject">water purification</field><field name="subject">water treatment</field><field name="subject">photocatalytic effect</field><field name="subject">infrared and photocatalytic studies</field><field name="subject">infrared (IR) laser</field><field name="subject">photocatalysis</field><field name="subject">model bacterial species</field><field name="identifier">http://eprints.qut.edu.au/16438/</field><field name="validLink">True</field></doc><doc><field name="title">Mapping posthuman discourse and the evolution of living information</field><field name="creator">Swift, Adam Glen</field><field name="description">The discourse that surrounds and constitutes the post-human emerged as a response to earlier claims of an essential or universal human or human nature. These discussions claim that the human is a discursive construct that emerges from various configurations of nature, embodiment, technology, and culture, configurations that have also been variously shaped by the forces of social history. And in the absence of an essential human figure, post-human discourses suggest that there are no restrictions or limitations on how the human can be reconfigured. This axiom has been extended in light of a plethora of technological reconfigurations and augmentations now potentially available to the human, and claims emerge from within this literature that these new technologies constitute a range of possibilities for future human biological evolution.    This thesis questions the assumption contained within these discourses that technological incursions or reconfigurations of the biological human necessarily constitute human biological or human social evolution by discussing the role the evolution theories plays in our understanding of the human, the social, and technology. In this thesis I show that, in a reciprocal process, evolution theory draws metaphors from social institutions and ideologies, while social institutions and ideologies simultaneously draw on metaphors from evolution theory. Through this discussion, I propose a form of evolution literacy; a tool, I argue, is warranted in developing a sophisticated response to changes in both human shape and form. I argue that, as a whole, our understanding of evolution constitutes a metanarrative, a metaphor through which we understand the place of the human within the world; it follows that historical shifts in social paradigms will result in new definitions of evolution. I show that contemporary evolution theory reflects parts of the world as codified informatic systems of associated computational network logic through which the behaviour of participants is predefined according to an evolved or programmed structure.    Working from within the discourse of contemporary evolution theory I develop a space through which a version of the post-human figure emerges. I promote this version of the post-human as an Artificial Intelligence computational programme or autonomous agent that, rather than seeking to replace, reduce or deny the human subject, is configured as an exosomatic supplement to and an extension of the biological human.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">posthuman</field><field name="subject">discourse</field><field name="subject">evolution</field><field name="subject">evolution theory</field><field name="subject">evolution literacy</field><field name="subject">metaphor</field><field name="subject">environmentalism</field><field name="subject">network theory</field><field name="subject">systems theory</field><field name="subject">cybernetics</field><field name="subject">autopoiesis</field><field name="subject">evolutionary psychology</field><field name="subject">genetics</field><field name="subject">code structures</field><field name="subject">technology</field><field name="subject">technological change</field><field name="subject">technological determinism</field><field name="subject">social shaping of technology</field><field name="subject">symbiosis</field><field name="subject">cyborgs</field><field name="subject">cyborg theory</field><field name="subject">hybrid theory</field><field name="subject">informatics</field><field name="subject">artificial intelligence</field><field name="subject">intelligent agents</field><field name="subject">bots</field><field name="identifier">http://eprints.qut.edu.au/16439/</field><field name="validLink">True</field></doc><doc><field name="title">Emerging trends in contemporary festival practice</field><field name="creator">Seffrin, Georgia Karolina</field><field name="description">The Festival is a form that transcends cultures, histories and regimes.  It is a construct that has been utilised in a variety of ways, for a variety of purposes, but its raison d'etre is always community, sometimes as celebrated from a popularist level, at other points manipulated by the wielders of power.  In its modern context, the festival has similarly been deployed as either a means of celebrating a sense of local community, or embraced by governments as a symbol of sophisticated cosmopolitanism.    This research aims to contextualise a particular kind of festival practice within both an historical and contemporary context.  This is structured through three key areas: at the heart of the thesis is a study of a particular kind of contemporary festival model, the boutique festival, as produced by the Programming Unit of the Queensland Performing Arts Centre.  This festival construct is significant in its positioning of the audience as both producer and consumer in a playful and intelligent manner.  This kind of model is different from the more conventional high arts or community arts festival models.  Secondly, the research explores how current renderings of the festival can be contextualised within historical functions, so as to highlight points of connection and departure.  Thirdly, the study positions the boutique festival as but one example of a range of current local festival practices that highlight the manner in which the festival construct engages with contemporary life. This portion of the study places these local renderings within Creative Industries discourse, focussing on the notion of the Creative City.    The thread that ties the areas of focus together is the role of the audience in the festival.  The trope of community remains central to contemporary festival practice, but it is a term that is becoming increasingly problematic and opaque, especially within an urban context.  Through a variety of constructs, contemporary festivals encourage a cultural discussion about what community means in a current context, and in so doing, invite explorations of space, identity and authenticity as well.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Creative city</field><field name="subject">creative industries</field><field name="subject">cultural studies</field><field name="subject">festival</field><field name="subject">Queensland Performing Arts</field><field name="subject">Out of the Box Festival</field><field name="subject">Stage X Festival</field><field name="subject">youth culture</field><field name="identifier">http://eprints.qut.edu.au/16440/</field><field name="validLink">True</field></doc><doc><field name="title">Seed dispersal, germination and fine-scale genetic structure in the stream lily, Helmholtzia glaberrima (philydraceae)</field><field name="creator">Prentis, Peter</field><field name="description">Seed dispersal in aquatic habitats is often considered to be a complex multistage process, where initial seed shadows are redistributed by water (hydrochory). The roles of hydrochory in seed dispersal and influencing population genetic structure were examined in Helmholtzia glaberrima using both ecological and genetic techniques. Ecological experiments showed that water can redistribute seeds and seedlings over local scales and that hydrochory can provide the potential for very long distance seed and seedling dispersal. Patterns of seedling genetic structure were affected by micro-drainages that direct water flow within populations and influence water-borne seed dispersal on a local scale. Strong non-equilibrium dynamics and persistent founder effects were responsible for the patterns of genetic structure observed among established populations of H. glaberrima. Classical metapopulation models best described dispersal patterns, while water-borne seed dispersal could potentially explain patterns of genetic differentiation within a stream system, it could not explain the distribution of genetic variation among stream systems. The current study found that although hydrochory influenced seed dispersal and seedling genetic structure within a population, it had little effect on the spatial pattern of genetic variation among established populations of H. glaberrima. Moreover, even though prolonged buoyancy and viability in water provide the potential for long-distance hydrochory, results presented here do not support the hypothesis that flowing water is an effective long distance seed dispersal vector for H. glaberrima.  Taken together, these results suggest that the relative importance of gene flow via water-born seed dispersal in H. glaberrima may be low compared with that of some other riparian species.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">genetic diversity</field><field name="subject">Helmholtzia</field><field name="subject">hydrochory</field><field name="subject">seed dispersal</field><field name="identifier">http://eprints.qut.edu.au/16441/</field><field name="validLink">True</field></doc><doc><field name="title">The development of normoxic polymer gel dosimetry using high resolution MRI</field><field name="creator">Hurley, Christopher Anthony</field><field name="description">Dosimetry is a vital component of treatment planning in radiation therapy.  Methods of radiation dosimetry currently include the use of: ionization chambers, thermoluminescent dosimeters (TLDs), solid-state detectors and radiographic film.  However, these methods are inherently either 1D or 2D and their use involves the perturbation of the radiation beam.  Although the dose distribution within tissues following radiation therapy treatments can be modeled using computerized treatment planning systems, a need exists for a dosimeter that can accurately measure dose distributions directly and produce 3D dose maps.  Some radiation therapy and brachytherapy treatments require mapping the dose distributions in high-resolution (typically &lt; 1 mm).  A dosimetry technique that is capable of producing high resolution 3D dose maps of the absorbed dose distribution within tissues is required.    Gel dosimetry is inherently a 3D integrating dosimeter that offers high spatial resolution, precision and accuracy.  Polymer gel dosimetry is founded on the basis that monomers dissolved in the gel matrix polymerize due to the presence of free radicals produced by the radiolysis of water molecules.  The amount of polymerization that occurs within a polymer gel dosimeter can be correlated to the absorbed dose.  The gel matrix maintains the spatial integrity of the polymers and hence a dose distribution can be determined by imaging the irradiated polymer gel dosimeter using an imaging modality such as MRI, x-ray computed tomography (CT), ultrasound, optical CT or vibrational spectroscopy.  Polymer gel dosimeters, however, suffer from oxygen contamination.  Oxygen inhibits the polymerization reaction and hence polymer gel dosimeters must be manufactured, irradiated and scanned in hypoxic environments.  Normoxic polymer gel dosimeters incorporate an anti-oxidant into the formulation that binds the oxygen present in the gel and allows the dosimeter to be made under normal atmospheric conditions.  The first part of this study was to provide a comprehensive investigation into various formulations of polymer and normoxic polymer gel dosimeters.  Several parameters were used to characterize and assess the performance of each formulation of polymer gel dosimeter including: spatial resolution and stability, temporal stability of the R2-dose response, optimal R2-dose response for changes in concentration of constituents and the effects of oxygen infiltration.  This work enabled optimal formulations to be determined that would provide greater dose sensitivity.  Further work was done to investigate the chemical kinetics that take place within normoxic polymer gel dosimeters from manufacture to post-irradiation.   This study explored the functions that each of the constituent chemicals plays in a polymer gel dosimeter.  Although normoxic polymer gel dosimeters exhibit very similar characteristics to polyacrylamide polymer gel dosimeters, one important difference between them was found to be a decrease in R2-dose sensitivity over time in the normoxic polymer gel dosimeter compared to an increase in the polyacrylamide polymer gel dosimeters.    From an investigation into the function of anti-oxidants in normoxic polymer gel dosimeters, alternatives were proposed.  Several alternative anti-oxidants were explored in this study that found that whilst some were reasonably effective, tetrakis (hydroxymethyl) phosphonium chloride (THPC) had the highest reaction rate.  THPC was found not only to be an aggressive scavenger of oxygen, but also to increase the dose sensitivity of the gel.  Hence, a formulation of normoxic polymer gel dosimeter was proposed, called MAGAT, that comprised: methacrylic acid, gelatin, hydroquinone and THPC.  This formulation was examined in a similar fashion to the studies of the other formulations of polymer and normoxic polymer gel dosiemeters.  The gel was found to exhibit spatial and temporal stability and an optimal formulation was proposed based on the R2-dose response.  Applications such as IVBT require high-resolution dosimetry.  Combined with high-resolution MRI, polymer gel dosimetry has potential as a high-resolution 3D integrated dosimeter.  Thus, the second component of this study was to commission a micro-imaging MR spectrometer for use with normoxic polymer gel dosimeters and investigate artifacts related to imaging in high-resolutions.  Using high-resolution MRI requires high gradient strengths that, combined with the Brownian motion of water molecules, was found to produce an attenuation of the MR signal and hence lead to a variation in the measured R2.  The variation in measured R2 was found to be dependent on both the timing and amplitude of pulses in the pulse sequence used during scanning.  Software was designed and coded that could accurately determine the amount of variation in measured R2 based on the pulse sequence applied to a phantom.  Using this software, it is possible to correct for differences between scans using different imaging parameters or pulse sequences.  A normoxic polymer gel dosimeter was irradiated using typical brachytherapy delivery and the resulting dose distributions compared with dose points predicted by the computerized treatment planning system.The R2-dose response was determined and used to convert the R2 maps of the phantoms to dose maps.  The phantoms and calibration vials were imaged with an in-plane resolution of 0.1055 mm/pixel and a slice thickness of 2 mm.  With such a relatively large slice thickness compared to the in-plane resolution, partial volume effects were significant, especially in the region immediately adjacent the source where high dose gradients typically exist.  Estimates of the partial volume effects at various distances within the phantom were determined using a mathematical model based on dose points from the treatment planning system. The normalized and adjusted dose profiles showed very good agreement with the dose points predicted by the treatment planning system.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">polymer gel dosimetry</field><field name="subject">radiotherapy</field><field name="subject">brachytherapy</field><field name="subject">radiation dosimetry</field><field name="subject">PAG</field><field name="subject">MAGIC</field><field name="subject">MAGAT</field><field name="subject">PAGAT</field><field name="subject">normoxic polymer gel dosimeters</field><field name="subject">high-resolution MRI</field><field name="identifier">http://eprints.qut.edu.au/16442/</field><field name="validLink">True</field></doc><doc><field name="title">Comparative analysis of perceptions of metacognitive processes in traditional school leavers and mature age entry students in their first year of university education</field><field name="creator">Derrington, Kathryn</field><field name="description">Within the educational psychology literature there is an abundance of research in the field of metacognition. The concentration of this research however has been in primary and secondary school contexts with little attention given to tertiary students' understanding or use of metacognition; there has been even less attention to whether age is a factor in tertiary students' perceptions of their metacognitive processes. The primary purpose of this study was to explore the perceptions of two distinct groups of first year university students, towards their understanding and usage of metacognitive processes and strategies. The two groups defined were traditional school leavers and mature age students. The findings from the exploration of these perceptions were compared to ascertain the similarities and differences in metacognitive processes between the two cohorts. The data collected for this study were obtained through a process of individual face-to-face in- depth interviews. The choice of this methodology was deliberate in order to gather rich data about the students' perceptions and experiences rather than attempt to measure their levels of metacognition against some predetermined standard. Data were collected and analyzed on the two constructs of metacognition which were identified in the literature search. These were metacognitive knowledge and metacognitive control. A range of affective variables such as self efficacy, motivation and expectancy of success, which impact on students' metacognitive abilities and processes, were also considered in the data collection and analysis. The findings indicated that age was a factor in determining some differences and similarities in students' perceptions of their own and others metacognitive processes. In certain cases the traditional school leavers' recency of experience with formal study was deemed an advantage; in others the life experience of the mature age students was perceived an advantage. In some instances the age of the student had no discernable impact on their understanding of, and ability to, utilize metacognitive strategies. These findings assist to broaden the understanding of student perceptions of metacognition in the tertiary context. The findings also make it imperative that tertiary institutions make fewer assumptions about the skills and abilities of their commencing students based on the criterion of age and offer more opportunities to assist students to understand the value of developing and improving their metacognitive processes.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">adjusting</field><field name="subject">affective variables</field><field name="subject">evaluating</field><field name="subject">expectancy of success</field><field name="subject">in-depth interviewing</field><field name="subject">mature age learners</field><field name="subject">metacognition</field><field name="subject">metacognitive awareness</field><field name="subject">metacognitive control</field><field name="subject">metacognitive experience</field><field name="subject">metacognitive knowledge</field><field name="subject">monitoring</field><field name="subject">motivation</field><field name="subject">nature of material</field><field name="subject">performance awareness</field><field name="subject">person awareness</field><field name="subject">predicting</field><field name="subject">prior knowledge</field><field name="subject">reading structure</field><field name="subject">reflecting</field><field name="subject">regulating</field><field name="subject">self-efficacy</field><field name="subject">skim reading</field><field name="subject">strategy awareness</field><field name="subject">task awareness</field><field name="subject">tertiary learners</field><field name="subject">university learners</field><field name="subject">traditional school leavers</field><field name="subject">writing structure</field><field name="subject">youth learners</field><field name="identifier">http://eprints.qut.edu.au/16443/</field><field name="validLink">True</field></doc><doc><field name="title">Statistical language modelling for large vocabulary speech recognition</field><field name="creator">McGreevy, Michael</field><field name="description">The move towards larger vocabulary Automatic Speech Recognition (ASR) systems places greater demands on language models. In a large vocabulary system, acoustic confusion is greater, thus there is more reliance placed on the language model for disambiguation. In addition to this, ASR systems are increasingly being deployed in situations where the speaker is not conscious of their interaction with the system, such as in recorded meetings and surveillance scenarios. This results in more natural speech, which contains many false starts and disfluencies. In this thesis we investigate a novel approach to the modelling of speech corrections.  We propose a syntactic model of speech corrections, and seek to determine if this model can improve on the performance of standard language modelling approaches when applied to conversational speech. We investigate a number of related variations to our basic approach and compare these approaches against the class-based N-gram.    We also investigate the modelling of styles of speech. Specifically, we investigate whether the incorporation of prior knowledge about sentence types can improve the performance of language models. We propose a sentence mixture model based on word-class N-grams, in which the sentence mixture models and the word-class membership probabilities are jointly trained. We compare this approach with word-based sentence mixture models.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">language modelling</field><field name="subject">automatic speech recognition</field><field name="subject">syntax</field><field name="subject">grammar</field><field name="subject">disfluency</field><field name="subject">sentence mixture model</field><field name="identifier">http://eprints.qut.edu.au/16444/</field><field name="validLink">True</field></doc><doc><field name="title">Automatic relative debugging</field><field name="creator">Searle, Aaron James</field><field name="description">Relative Debugging is a paradigm that assists users to locate errors in programs that have been corrected or enhanced. In particular, the contents of key data structures in the development version are compared with the contents of the corresponding data structures, in an existing version, as the two programs execute. If the values of two corresponding data structures differ at points where they should not, an error may exist and the user is notified.    Relative Debugging requires users to identify the corresponding data structures within the two programs, and the locations at which the comparisons should be performed.  To quickly and effectively identify useful data structures and comparison points requires that users have a detailed knowledge of the two programs under consideration. Without a detailed knowledge of the two programs, the task of locating useful data structures and comparison points can quickly become a difficult and time consuming process. Prior to the research detailed in this thesis, the Relative Debugging paradigm did not provide any assistance that allowed users to quickly and effectively identify suitable data structures and program points that will help discover the source of an error.    Our research efforts have been directed at enhancing the Relative Debugging paradigm. The outcome of this research is the discovery of techniques that empower  Relative Debugging users to become more productive and allow the Relative Debugging paradigm to be significantly enhanced. Specifically, the research has resulted in the following three contributions:  1. A Systematic Approach to Relative Debugging.  2. Data Flow Browsing for Relative Debugging.  3. Automatic Relative Debugging.    These contributions have enhanced the Relative Debugging paradigm and allow errors to be localized with little human interaction. Minimizing the user's involvement reduces the cost of debugging programs that have been corrected or enhanced, and has a significant impact on current debugging practices.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Relative Debugging</field><field name="subject">Automatic Debugging</field><field name="subject">Automatic Relative Debugging</field><field name="subject">data flow browsing</field><field name="subject">testing and debugging tools</field><field name="identifier">http://eprints.qut.edu.au/16445/</field><field name="validLink">True</field></doc><doc><field name="title">Beast Sellers: The Necessary Evils of Paratexts in the Development and Marketing of the Horror-Thriller Screenplay</field><field name="creator">Armstrong, Shayne</field><field name="description">Monster Business is a feature film project comprising a horror-thriller feature screenplay and an accompanying exegesis. The screenplay is about a best-selling author who is behind on the delivery of the sequel to his money-spinning first novel and is made an offer by an enigmatic stranger to help rearrange his working environment to facilitate the rapid completion of the manuscript. Over the coming hours, then months, the author discovers just how far the stranger will go to complete the terms of this bizarre and brutal new contract.    This accompanying exegesis examines a series of 'paratexts' (a logline, a one-pager and a treatment) that the screenplay has given rise to. The thesis argues that the role of the screenwriter does not end with the production of the core text--the screenplay.  Instead, in order to support the development and/or the marketing of the script into a feature film, the screenwriter is an ongoing generator of supplemental documents or  paratexts. The paper explores the status and function of paratexts (loglines, onepagers, treatments and explanatory development notes). It further argues that developmental paratexts are a necessary evil, providing a sifting or culling mechanism for producers and production executives, and that they are intended to guide a project toward being 'greenlit' but will more often have, at best, benign or, at worst, negative or destructive effects on its development. In this way, developmental paratexts, although ubiquitous and pro forma, are inherently problematic.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">paratexts</field><field name="subject">horror film</field><field name="subject">thriller</field><field name="subject">screenplay</field><field name="subject">Australian film industry</field><field name="subject">Hollywood</field><field name="subject">spec script</field><field name="subject">logline</field><field name="subject">one-pager</field><field name="subject">treatment</field><field name="identifier">http://eprints.qut.edu.au/16446/</field><field name="validLink">True</field></doc><doc><field name="title">Dance curriculum for a Renaissance Singapore: A framework for Dance elective Programme in secondary schools</field><field name="creator">Chua, Poh Yi (Joey)</field><field name="description">Within the social, cultural and political contexts for arts education in Singapore today, this thesis describes a framework for the development of a dance curriculum for 13 to 16 years old secondary school students. This study considers the question: What kind of Dance Elective Programme will address the needs of the diverse communities in Singapore? The framework for the Dance Elective Programme that emerges from the research describes rationale, content, and approaches as identified by the research participants. Research data collected includes dance syllabi; dance journals; questionnaires and interviews with various individuals in Singapore. The significance of dance in the school curriculum is accentuated by several Singapore government reports where the issue of the promotion of arts education is raised. Currently in the secondary school curriculum in Singapore, the arts subjects offered are visual art and music; dance has yet to be offered as an academic subject. A comprehensive arts education should encompass other disciplines, so as to provide a holistic learning environment in schools. It is hoped that this suggested framework will provide an impetus for further development and implementation of dance curriculum in Singapore schools in the near future.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">curricular</field><field name="subject">dance education</field><field name="subject">secondary school</field><field name="subject">Singapore</field><field name="identifier">http://eprints.qut.edu.au/16447/</field><field name="validLink">True</field></doc><doc><field name="title">Analysis of the Underwater Emissions From Outboard Engines</field><field name="creator">Kelly, Charles</field><field name="description">The development of Environmentally Adapted Lubricants (EALs) and their use has been gaining momentum over the last decade.  It has been shown that raw EALs degrade in the environment in about one tenth the time of an equivalent mineral based lubricant.  Estimates and findings such as these serve to highlight the potential benefits of the EAL products, it is also important however to investigate the by-products of their use to ensure that the benefits are not cancelled by an increase of, for instance, combustion by-products.  This thesis compares the emissions from a two-stroke outboard engine when using an EAL and an equivalent mineral lubricant, where the primary objective of the study is to characterise and quantify the pollutants that remain within the water column after combustion.  To accomplish this, tests were conducted both in the laboratory (freshwater) and in the field (seawater) for a range of throttle settings.  A 1.9kW two-stroke outboard engine was set-up in a test tank and water samples were taken from the tank after the engine had been run for a period at each of the throttle settings.  The tests were repeated for a 5.9kW four-stroke engine, however, the experiments were only conducted in the laboratory (freshwater) and using only a standard mineral lubricant.  Statistical analyses of the results were conducted using a Principal Components Analysis (PCA).  A simple dilution model was used to estimate the initial outboard engine emission concentrations, which was extended to determine the concentrations at distances of 1, 10 and 100 metres from the source.  An investigation of the Total Toxicity Equivalence of the PAH pollutant concentrations (TEQPAH) was conducted using Toxicity Equivalent Factors (TEFs).  Results for both types of engine and in both fresh and seawater showed that even the initial concentrations at the source, in almost all instances, were well below the ANZECC water quality guidelines trigger levels.  At a distance of 1 metre from the source all concentrations were well below, and therefore, the Total Toxicity Equivalents of the PAHs were found to be even lower.  It is concluded that the emissions from a single outboard engine when using either an EAL or a mineral based lubricant are similar.  However, the use of EALs has further reaching advantages in that spilt raw lubricants will degrade in the environment up to 10 times faster than a mineral lubricant.  Also EALs are less toxic to aquatic and marine organisms and therefore the benefits of using them has to be viewed from a wider perspective.  The results in this thesis for a single outboard engine now form the basis for a more detailed environmental assessment of their impacts.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Environmentally Adapted Lubricants (EALs)</field><field name="subject">outboard engine emissions</field><field name="subject">water pollution</field><field name="identifier">http://eprints.qut.edu.au/16448/</field><field name="validLink">True</field></doc><doc><field name="title">Not Welcome: Writing Horror in Australia</field><field name="creator">Krause, Shane Peter</field><field name="description">&amp;quotNot Welcome" is a thesis containing an original dark genre screenplay called Acolytes and an exegesis called &amp;quotNot Welcome": Writing Horror in Australia.    The screenplay is about two boys, victims of years of bullying, who find a way to rid themselves of their bully for good, exchanging one problem for something much worse. But it's an elaborate and calculated lie. The truth is Acolytes is about the concealment of a crime and not the vengeance of a victim. Acolytes is intentionally moody, oppressive and obtuse--it has a true crime-scene ambience. The power of the story lies in its truth--the truth that it seeks to uncover and the truth of the style of its telling--and, just as is the case with real-life crime, the &amp;quottruth" is often murky and far from clear-cut.    The accompanying exegesis explores the domestic funding and production climate for dark genre projects. It argues that Australian genre scriptwriters and filmmakers have often faced hostile funding agencies and genre-timid producers. It examines the requirements of dark genre scriptwriters and filmmakers in bringing their work from page to screen. It argues that the onus is on Australian dark genre writers and filmmakers to think beyond funding agencies and institutionalised Australian producers to realise their projects.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">producers</field><field name="subject">projects</field><field name="subject">writing</field><field name="subject">pitching</field><field name="subject">drama</field><field name="subject">screenplay</field><field name="subject">horror</field><field name="identifier">http://eprints.qut.edu.au/16449/</field><field name="validLink">True</field></doc><doc><field name="title">Dynamic characteristics of slender suspension footbridges</field><field name="creator">Huang, Ming-Hui</field><field name="description">Due to the emergence of new materials and advanced engineering technology, slender footbridges are increasingly becoming popular to satisfy the modern transportation needs and the aesthetical requirements of society. These structures however are always &amp;quotlively" with low stiffness, low mass, low damping and low natural frequencies. As a consequence, they are prone to vibration induced by human activities and can suffer severe vibration serviceability problems, particularly in the lateral direction. This phenomenon has been evidenced by the excessive lateral vibration of many footbridges worldwide such as the Millennium Bridge in London and the T-Bridge in Japan. Unfortunately, present bridge design codes worldwide do not provide sufficient guidelines and information to address such vibrations problems and to ensure safety and serviceability due to the lack of knowledge on the dynamic performance of such slender vibration sensitive bridge structures.    A conceptual study has been carried out to comprehensively investigate the dynamic characteristics of slender suspension footbridges under human-induced dynamic loads and a footbridge model in full size with pre-tensioned reverse profiled cables in the vertical and horizontal planes has been proposed for this purpose. A similar physical suspension bridge model was designed and constructed in the laboratory, and experimental testings have been carried out to calibrate the computer simulations. The synchronous excitation induced by walking has been modelled as crowd walking dynamic loads which consist of dynamic vertical force, dynamic lateral force and static vertical force. The dynamic behaviour under synchronous excitation is simulated by resonant vibration at the pacing rate which coincides with a natural frequency of the footbridge structure. Two structural analysis software packages, Microstran and SAP2000 have been employed in the extensive numerical analysis.    Research results show that the structural stiffness and vibration properties of suspension footbridges with pre-tensioned reverse profiled cables can be adjusted by choosing different structural parameters such as cable sag, cable section and pretensions in the reverse profiled cables. Slender suspension footbridges always have four main kinds of vibration modes: lateral, torsional, vertical and longitudinal modes. The lateral and torsional modes are often combined together and become two kinds of coupled modes: coupled lateral-torsional modes and coupled torsionallateral modes. Such kind of slender footbridges also have different dynamic performance in the lateral and vertical directions, and damping has only a small effect on the lateral vibration but significant effect on the vertical one.    The fundamental coupled lateral-torsional mode and vertical mode are easily excited when crowd walking dynamic loads are distributed on full bridge deck. When the crowd walking dynamic loads are distributed eccentrically on half width of the deck, the fundamental coupled torsional-lateral mode can be excited and large lateral deflection can be induced. Higher order vertical modes and coupled lateral-torsional modes can also be excited by groups of walking pedestrians under certain conditions.  It is found that the coupling coefficient introduced in this thesis to describe the coupling of a coupled mode, is an important factor which has significant effect on the lateral dynamic performance of slender suspension footbridges. The coupling coefficient, however, is influenced by many structural parameters such as cable configuration, cable section, cable sag, bridge span and pre-tensions, etc. In general, a large dynamic amplification factor is expected when the fundamental mode of a footbridge structure is the coupled lateral-torsional mode with a small coupling coefficient.    The research findings of this thesis are useful in understanding the complex dynamic behaviour of slender and vibration sensitive suspension footbridges under humaninduced dynamic loads. They are also helpful in developing design guidance and techniques to improve the dynamic performance of such slender vibration sensitive footbridges and similar structures and hence to ensure their safety and serviceability.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">footbridge</field><field name="subject">suspension bridge</field><field name="subject">dynamics</field><field name="subject">vibration</field><field name="subject">pedestrian</field><field name="subject">walking</field><field name="subject">humaninduced</field><field name="subject">synchronous excitation</field><field name="subject">resonance</field><field name="subject">serviceability</field><field name="subject">natural frequency</field><field name="subject">coupled mode</field><field name="subject">coupling coefficient</field><field name="subject">pacing rate</field><field name="subject">damping</field><field name="subject">slender</field><field name="subject">dynamic amplification factor</field><field name="subject">dynamic characteristics</field><field name="subject">pre-tension</field><field name="subject">reverse profiled cable</field><field name="subject">non-linear time history analysis</field><field name="identifier">http://eprints.qut.edu.au/16450/</field><field name="validLink">True</field></doc><doc><field name="title">Organisational barriers and facilitators to the effective operation of Random Breath Testing (RBT) in Queensland</field><field name="creator">Hart, Susan</field><field name="description">Random breath testing (RBT) is one of the most successful drink driving countermeasures employed by police in Australia. Its success over the years has been evidenced by reductions in drink driving behaviour, reductions in alcohol-related crashes and fatal crashes and a corresponding community-wide increase in the disapproval of drink driving. Although a great deal of research has been able to highlight the relationship between increased police enforcement and road safety benefits, little is known about the organisational factors that assist or hinder the management and operation of RBT. The purpose of this thesis is to explore the perceived barriers and facilitators to the effective operation of RBT in the Queensland Police Service (QPS). Findings will have human resource implications for the QPS and will highlight areas that are currently functioning effectively.-----
 
 
 
 Study One involved 22 semi-structured interviews with 36 QPS managers involved in the day-to-day organisation and delivery of RBT operations. Managers were recruited with assistance from members of the QPS's State Traffic Support Branch. The interviews were approximately one hour long and involved exploration of the perceptions of managers involved in the planning and delivery of RBT operations using the concept of organisational alignment to structure the interviews. The results revealed that RBT management activity is facilitated by a range of factors, including: the belief in the importance of RBT; belief that the purpose of RBT has both a deterrent function and a detection function; the increasing use of intelligence to guide RBT strategies; the increasing use of RBT to support other crime reduction strategies; and a genuine desire to improve the current state of affairs. However, a number of apparent barriers to the effective operation of RBT were identified. These included concern about the strategy of the 1.1 testing strategy (i.e. conducting the equivalent of one test per licensed driver per annum), a misunderstanding of the role of general and specific deterrence and a lack of feedback in relation to the success of RBT.-----
 
 
 
 The second study involved a questionnaire that was distributed to a random sample of 950 operational police stratified across the regions who are responsible for undertaking RBT on a regular basis. There were 421 questionnaires returned representing a response rate of 44%. Questionnaires were also based on the concepts and constructs of organisational alignment and explored perceptions, beliefs and self- reported behaviour of officers. The results revealed that facilitating factors included a belief in QPS ownership of the RBT program, the agreement that the RBT vision includes road safety goals and apprehension goals, and overall motivation, support and belief in their capability to carry out RBT duties. Barriers included perceived strain related to the 1:1 testing strategy, the lack of feedback in relation to the success of RBT, misunderstanding about the role of deterrence and lack of rewards for participating in RBT duties.-----
 
 
 
 The results of both studies have implications for the planning and operation of RBT in the QPS. While the findings revealed that there were many aspects of the RBT program that were currently aligned with best practice guidelines, there are areas of misalignment. In particular, the main areas of misalignment included concern about the strain caused by the current 1:1 testing strategy, a lack of feedback about the success of RBT and a lack of education of the nature and role of deterrence in road safety and RBT operations in particular.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">random breath testing</field><field name="subject">drink driving</field><field name="subject">enforcement</field><field name="subject">road safety</field><field name="subject">deterrence</field><field name="subject">organisational alignment</field><field name="identifier">http://eprints.qut.edu.au/16451/</field><field name="validLink">True</field></doc><doc><field name="title">A cause for animation : Harry Reade and Cuban revolution</field><field name="creator">Bannah, Maxwell Joseph</field><field name="description">This monographic study examines the life of the Australian artist Harry Reade (1927-1998), and his largely overlooked contribution to animation within historical, social, political and cultural contexts of his time.    The project constitutes a biography of Reade, tracing his life from his birth in 1927 through to his period of involvement with animation between 1956 and 1969. The biography examines the forces that shaped Reade and the ways in which he tried to shape his world through the medium of animation. It chronicles his experiences as a child living in impoverished conditions during the Great Depression, his early working life, the influence of left wing ideology on his creative development, and his contribution to animation with the Waterside Workers' Federation Film Unit, in Sydney. The study especially focuses on the period between 1961 and 1969 during which Reade supported the Cuban Revolution's social and cultural reform process by writing and directing animated films at the Instituto Cubano del Arte e Industria Cinematogr&#225;ficos (Cuban Institute of the Art and Industry of Cinema - ICAIC), in Havana.    The thesis argues that Reade played a significant role in the development of Cuban animation during the early years of the Cuban Revolution. Further, his animated work in this cultural sphere was informed by a network of political alliances and social philosophies that were directly linked to his experiences and creative development in Australia.    Theoretical approaches to biographical method and animation studies have been used to provide a cohesive framework for an investigation of Reade's life and animation work. The thesis also draws on Reade's autobiography and his animated works, oral histories, newspaper articles, press cartoons, illustrations, photographs, and official government archival documents. This project also has an archival purpose in collecting and compiling Reade's animation work onto CD.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Harry Reade</field><field name="subject">Australian animation</field><field name="subject">Cuban animation</field><field name="subject">Waterside Workers&#146; Federation Film Unit</field><field name="subject">social realism</field><field name="subject">Australian social history 1930s &#150; 1950s</field><field name="identifier">http://eprints.qut.edu.au/16452/</field><field name="validLink">True</field></doc><doc><field name="title">Design and implementation of hypermedia learning environments that facilitate the construction of knowledge about analytical geometry</field><field name="creator">Pavaputanon, Lha</field><field name="description">This study aimed to develop a teaching and learning model, based on principles derived from the fields of constructivist theory, schema theory, critical literacy theory, and design theory, to inform the development of hypermedia-mediated learning environments that facilitate the construction of mathematical knowledge by secondary school students in Thailand. In this study, the participants were a group of three secondary school students from the Demonstration school attached to the Faculty of Education at Khon Kaen University (Thailand). In order to ascertain how mathematical learning could be facilitated by the process of designing a web page that could be used to introduce other students to analytic geometry, all three participants were asked to work collaboratively to design an analytic geometry web page. The process of designing the web page was informed by a theoretical model derived from an analysis and synthesis from the research literature on constructivist theory, schema theory, critical literacy theory, and design theory. Findings from the study indicated that the creation of a web page facilitated and enhanced the Thai students' learning about analytic geometry. The major outcomes from the study are a revised theoretical framework to inform the integration of the design of mathematical web pages into Thai mathematics classrooms and a conceptual map framework to assess qualitative and quantitative changes to students' repertoires of knowledge about analytic geometry that emerge during the process of designing a webpage.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">hypermedia</field><field name="subject">mathematics education</field><field name="subject">analytic geometry</field><field name="subject">constructivism</field><field name="subject">web page</field><field name="subject">secondary school mathematics</field><field name="identifier">http://eprints.qut.edu.au/16453/</field><field name="validLink">True</field></doc><doc><field name="title">Functional analyses of polymorphisms in the promoters of the KLK3 and KLK4 genes in prostate cancer</field><field name="creator">Lai, John</field><field name="description">This PhD aimed to elucidate the mechanisms by which polymorphisms may alter androgen-induced transactivation of androgen receptor (AR) target genes which may be important in prostate cancer aetiology. The second aspect of this PhD focused on identifying and characterising functional polymorphisms that may have utility as predictive risk indicators for prostate cancer and which may aid in earlier therapeutic intervention and better disease management. Analyses were carried out on the kallikrein-related peptidase 3 (KLK3), also known as the prostate specific antigen (PSA), gene and the kallikrein-related peptidase 4 (KLK4) gene. The PSA and KLK4 genes are part of the serine protease family that have trypsin or chymotrypsin like activity and are thought to play a role in the development of hormone-dependent cancers in tissues such as those in the prostate, breast, endometrium and ovaries.    In the prostate, PSA is regulated by androgens and three androgen response elements (AREs) have been described in the promoter and upstream enhancer region. The PSA ARE I harbours a polymorphism at -158 bp from the transcription initiation site (TIS) that results in a G to A transition (G-158A). This PhD investigated the functional significance of the PSA G-158A polymorphism which has been reported to be associated with prostate cancer risk. Electromobility shift assays (EMSAs) investigating the interaction of ARE I variants with the AR DNA binding domain (AR-DBD) demonstrated that the A allele had a two-fold increased binding affinity for the AR-DBD when compared with the G allele. This was confirmed with endogenous AR in limited proteolysis-EMSA experiments. The limited proteolysis-EMSA experiments also demonstrated differential sensitivities of PSA ARE I alleles to trypsin digestion, which suggests that the G-158A polymorphism has an allosteric effect on the AR that alters AR/ARE I complex stability. Furthermore, Chromatin Immunoprecipitation (ChIP) assays suggest that the A allele more readily recruited the AR in vivo when compared with the G allele and is consistent with the in vitro binding data. Luciferase reporter assays carried out in both LNCaP and 22Rv1 prostate cancer cells, and using the natural (dihydrotestosterone; DHT) ligand demonstrated that the A allele was more responsive to androgens in LNCaP cells. Hence, this study has elucidated the potential mechanisms by which the G-158A polymorphism may differentially regulate PSA expression (of which up-regulation of PSA is thought to be important in prostate cancer development and progression).    KLK4 has similar tissue-restricted expression as PSA and is up-regulated by steroid hormones in many endocrine cells including those in the prostate. A putative ARE (KLK4-pARE) located at -1,005 to -1019 relative to the more predominantly used transcription initiation site, TIS3, was initially found in supershift assays using AR antibodies to interact with endogenous AR. However, subsequent EMSA analysis using purified AR-DBD suggest that KLK4-pARE may be interacting with the AR indirectly. To investigate this hypothesis, a tandem construct of KLK4-pARE was cloned into the pGL3-Promoter vector for hormone-induced reporter assays. However, reporter assays did not demonstrate any responsiveness of KLK4-pARE to androgens, estradiol or progestins. Consequently, Real-Time PCR was carried out to reassess the hormonal regulation of KLK4 at the mRNA level. Consistent with the literature, data from this study suggests that KLK4 may be up-regulated by androgens, progestins and estradiol in a cyclical manner. Hormone-induced luciferase reporter assays were then carried out on seven promoter constructs that span 2.8 kb of the KLK4 promoter from TIS3. However, none of the seven promoter constructs demonstrated any significant responsiveness to androgens, estradiol or progestins. This study suggests that hormone response elements (HREs) that may drive the hormonal regulation of KLK4 in prostate cancer may be located further upstream from the promoter region investigated in this PhD, or alternatively, may lie 3' of TIS3. The characterisation of KLK4 promoter polymorphisms and their flanking sequences were also carried out in parallel to the functional work with the intent to assess the functional significance of any polymorphisms that may be located within HREs. In total 19 polymorphisms were identified from the public databases and from direct sequencing within 2.8 kb of the KLK4 promoter from TIS3. However, the functional and clinical significance of these 19 polymorphisms were not further pursued given the negative findings from the functional work.    The PSA AR enhancer region was also assessed for potential polymorphisms that may be associated with prostate cancer risk. A total of 12 polymorphisms were identified in the PSA enhancer of which two (A-4643G and T-5412C) have been reported to alter functionality of the enhancer region and thus, prioritised for further analysis. Association analysis for prostate cancer risk was then carried out on these PSA enhancer polymorphisms as none of the KLK4 promoter polymorphisms were found in functional HREs. No significant association for either the A-4643G or T-5412C polymorphism with prostate cancer risk was found at the P = 0.05 level. However, under an age-adjusted dominant model a 1.22- (95% CI = 1.16-1.26) and 1.23-fold (95% CI = 1.17-1.29) increased risk for prostate cancer was found for the A-4643G or T-5412C polymorphisms, respectively. Both polymorphisms were also assessed for association with tumour grade and stage and PSA levels. Genotypes were significantly different for the A-4643G and T-5412C polymorphisms with tumour stage and PSA levels, respectively. However, these results are likely to be biased by the case population which consist primarily of men who presented with incidental (pT1) and organ-confined (pT2) tumours. To summarise, the A-4643G and T-5412C polymorphisms are unlikely to be associated with prostate cancer risk, PSA levels or stage/grade of disease. However, further analyses in a larger cohort is warranted given that these polymorphisms alter androgen responsiveness of the PSA enhancer and that elevated PSA levels are indicative of men with prostate cancer.    To summarise, this PhD has elucidated the functional significance of the PSA G-158A polymorphism in prostate cancer and which may be important in prostate cancer patho-physiology. This PhD has also furthered the understanding of the hormonal regulation of KLK4 in prostate cancer cells. Finally, this PhD has carried out a pilot study on two functional PSA enhancer polymorphisms (A-4643G and T-5412C) with prostate cancer risk.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">prostate cancer</field><field name="subject">single nucleotide polymorphism (SNP)</field><field name="subject">kallikreins (KLKs)</field><field name="subject">kallikrein 4 (KLK4)</field><field name="subject">prostate specific antigen (PSA)</field><field name="subject">androgens</field><field name="subject">hormones</field><field name="subject">androgen receptor (AR)</field><field name="subject">androgen receptor DNA binding domain (AR-DBD)</field><field name="subject">androgen response element (ARE)</field><field name="subject">electromobility shift assay (EMSA)</field><field name="subject">luciferase reporter assay</field><field name="identifier">http://eprints.qut.edu.au/16454/</field><field name="validLink">True</field></doc><doc><field name="title">Looking modern : fashion journalism and cultural modernity in Shanghai, Singapore and Hong Kong</field><field name="creator">Tay, Jinna</field><field name="description">This thesis examines the development of Asian cultural modernity in the cities of Singapore, Hong Kong and Shanghai through their fashion magazines. These three cities have positioned themselves as aspirants to global city status, concurrently facilitating their ambitions by relaxing media laws and emphasising cultural production. One outcome is a growth in the production and consumption of fashion magazines. There has been a parallel growth in the consumption of and interest in fashion and self-adornment in these cities, particularly through global brand names. This thesis investigates these cultural transformations by examining the production of fashion texts in the context of their cities. It does this by utilising the concept of fashion journalism (as a product of fashion, journalism and the city) as a means of identifying the contemporary social, cultural and political articulations of these fashion texts. To do so, this research draws together a framework that takes into account different fields (fashion, journalism, modernity, city, Asia) that contribute to the concept of fashion journalism, thereby approaching fashion texts through a multi-disciplinary perspective anchored by establishing the contexts of each city and its specific magazine. The subsequent analyses of Vision (Shanghai), WestEast (Hong Kong) and Harper's Bazaar Singapore reflect and capture an evolution of these cities coming into their own. With particular emphasis on the cultural assertions of global Chinese identities in WestEast, an escape from national discourses through participating in cosmopolitanism in Harper's, and the emphasis on popular visual culture as a form of popular literacy and knowledge formation in Vision. These findings contribute firstly, towards an understanding of the issues occurring in the cultural modernisation of these cities and secondly, of fashion journalism as a promoter of the experiences of cultural modernity in Asia.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Asia</field><field name="subject">Chinese-ness</field><field name="subject">city</field><field name="subject">consumption</field><field name="subject">cosmopolitanism</field><field name="subject">creative cities</field><field name="subject">culture</field><field name="subject">cultural modernity</field><field name="subject">fashion</field><field name="subject">fashion journalism</field><field name="subject">Hong Kong</field><field name="subject">journalism</field><field name="subject">looking</field><field name="subject">magazines</field><field name="subject">popular culture</field><field name="subject">sex</field><field name="subject">Shanghai</field><field name="subject">Singapore</field><field name="subject">visual culture</field><field name="identifier">http://eprints.qut.edu.au/16455/</field><field name="validLink">True</field></doc><doc><field name="title">Machinery fault diagnostics based on fuzzy measure and fuzzy integral data fusion techniques</field><field name="creator">Liu, Xiaofeng</field><field name="description">With growing demands for reliability, availability, safety and cost efficiency in modern machinery, accurate fault diagnosis is becoming of paramount importance so that potential failures can be better managed. Although various methods have been applied to machinery condition monitoring and fault diagnosis, the diagnostic accuracy that can be attained is far from satisfactory. As most machinery faults lead to increases in vibration levels, vibration monitoring has become one of the most basic and widely used methods to detect machinery faults. However, current vibration monitoring methods largely depend on signal processing techniques. This study is based on the recognition that a multi-parameter data fusion approach to diagnostics can produce more accurate results. Fuzzy measures and fuzzy integral data fusion theory can represent the importance of each criterion and express certain interactions among them. This research developed a novel, systematic and effective fuzzy measure and fuzzy integral data fusion approach for machinery fault diagnosis, which comprises feature set selection schema, feature level data fusion schema and decision level data fusion schema for machinery fault diagnosis. Different feature selection and fault diagnostic models were derived from these schemas. Two fuzzy measures and two fuzzy integrals were employed: the 2-additive fuzzy measure, the   fuzzy measure, the Choquet fuzzy integral and the Sugeno fuzzy integral respectively. The models were validated using rolling element bearing and electrical motor experiments. Different features extracted from vibration signals were used to validate the rolling element bearing feature set selection and fault diagnostic models, while features obtained from both vibration and current signals were employed to assess electrical motor fault diagnostic models. The results show that the proposed schemas and models perform very well in selecting feature set and can improve accuracy in diagnosing both the rolling element bearing and electrical motor faults.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">condition monitoring</field><field name="subject">fault diagnosis</field><field name="subject">fuzzy measures</field><field name="subject">fuzzy integrals</field><field name="subject">fuzzy c-means clustering</field><field name="subject">membership degree</field><field name="subject">feature selection</field><field name="subject">feature level data fusion</field><field name="subject">decision level data fusion</field><field name="identifier">http://eprints.qut.edu.au/16456/</field><field name="validLink">True</field></doc><doc><field name="title">Digital image watermarking methods for copyright protection and authentication</field><field name="creator">Woo, Chaw-Seng</field><field name="description">The ease of digital media modification and dissemination necessitates content protection beyond encryption. Information hidden as digital watermarks in multimedia enables protection mechanism in decrypted contents. The aims of this research are three-fold: (i) to investigate the strength and limitations of current watermarking schemes, (ii) to design and develop new schemes to overcome the limitations, and (iii) to evaluate the new schemes using application scenarios of copyright protection, tamper detection and authentication. We focus on geometrically robust watermarking and semi-fragile watermarking for digital images. Additionally, hybrid schemes that combine the strength of both robust and semi-fragile watermarks are studied.    Robust watermarks are well suited for copyright protection because they stay intact with the image under various manipulations. We investigated two major approaches of robust watermarking. In the synchronization approach, we employed motion estimation for watermark resynchronization. We also developed a novel watermark resynchronization method that has low computational cost using scale normalization and flowline curvature. In another approach, we firstly analyzed and improved a blind watermark detection method. The new method reduces significantly the computational cost of its watermark embedding. Secondly, we created a geometric invariant domain using a combination of transforms, and adapted the blind watermark detection method that we improved. It totally eliminates the need of resynchronization in watermark detection, which is a very desirable achievement that can hardly be found in existing schemes.    On the other hand, semi-fragile watermarks are good at content authentication because they can differentiate minor image enhancements from major manipulations. New capabilities of semi-fragile watermarks are identified. Then, we developed a semi-fragile watermarking method in wavelet domain that offers content authentication and tamper localization. Unlike others, our scheme overcomes a major challenge called cropping attack and provides approximate content recovery without resorting to an original image.    Hybrid schemes combine robust and semi-fragile watermarks to offer deductive information in digital media forensics. We firstly carried out a pilot study by combining robust and fragile watermarks. Then, we performed a comparative analysis on two implementation methods of a hybrid watermarking scheme. The first method has the robust watermark and the fragile watermark overlapped while the second method uses non-overlapping robust and fragile watermarks. Based on the results of the comparative analysis, we merge our geometric invariant domain with our semi-fragile watermark to produce a hybrid scheme. This hybrid scheme fulfilled the copyright protection, tamper detection, and content authentication objectives when evaluated in an investigation scenario.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">digital watermark</field><field name="subject">image watermark</field><field name="subject">robust watermark</field><field name="subject">semi-fragile watermark</field><field name="subject">hybrid watermark</field><field name="subject">copyright protection</field><field name="subject">content authentication</field><field name="subject">tamper detection</field><field name="subject">tamper localization</field><field name="subject">self-embedding</field><field name="subject">self-authentication</field><field name="subject">self-recovery</field><field name="identifier">http://eprints.qut.edu.au/16457/</field><field name="validLink">True</field></doc><doc><field name="title">Transcriptional Analysis of Chlamydial Persistence</field><field name="creator">Hogan, Richard</field><field name="description">Chlamydial infections have been associated with several chronic human diseases, including trachoma, pelvic inflammatory disease, chronic obstructive pulmonary disease and atherosclerotic cardiovascular disease. In Chlamydia-associated disease, the organisms are believed to exist in an atypical, persistent phase that is not well understood at the genetic level. The research presented in this thesis investigated chlamydial gene expression in in vitro cell culture models of persistence.    The first set of studies analysed a continuous-infection model of persistence that has been recently developed for two C. pneumoniae isolates (TW-183 and CM-1). The spontaneous establishment and unique cyclical nature of continuous infections could be particularly relevant to in vivo events. An initial analysis using a semi-quantitative reverse transcriptase PCR (sqRT-PCR) approach provided evidence of differential gene expression in C. pneumoniae TW-183 continuous infections relative to acute control infections. Using a subsequently established fully quantitative real-time reverse transcriptase PCR (rtRT-PCR) assay, up-regulated expression profiles were confirmed for five genes (CPn0483, nlpD, ompA, pmp1 and porB) in the continuous C. pneumoniae TW-183 infections. The omcB, pmp1 and porB genes, all of which encode membrane proteins, showed similar patterns of expression over both the acute and continuous time courses tested. Gene expression data for a second C. pneumoniae isolate, CM-1, revealed similar overall expression trends to those seen for C. pneumoniae TW-183 but also supported previous observations of different growth characteristics between the two isolates in the continuous-infection model.    The rtRT-PCR assay was further optimised for use in gene expression studies of the gamma interferon (IFN-&#947;)-mediated model of C. pneumoniae A-03 persistence, in which altered growth and morphological traits typical of chlamydial persistence have been well characterised. Meanwhile, chlamydial genes such as euo, ftsK and hctB were emerging from the literature as reliable genetic markers of persistence. Therefore, a preliminary rtRT-PCR analysis of marker gene expression was used to assess the likely extent of persistence in individual IFN-&#947;-treated C. pneumoniae A-03 infections from a series of experiments that had been prepared for this persistence model. In this way, an appropriate pair of duplicate experiments was selected for further studies based on strong genetic evidence of persistence in IFN-&#947;-treated samples at 48 h post-infection (PI) in those experiments.    Using rtRT-PCR, 14 genes of interest from the related peptidoglycan, aminosugars and lipopolysaccharide (LPS) biosynthetic pathways were analysed in the validated experiments of the IFN-&#947;-mediated C. pneumoniae A-03 persistence model. Selective up- and down-regulated expression trends were associated with IFN-&#947;-treatment at 48 h PI for genes encoding products that are located at specific enzymatic points in these pathways. Most strikingly, the expression of glmU, the product of which controls the amount of an essential precursor metabolite that enters both peptidoglycan and LPS biosynthesis, was strongly and reproducibly down-regulated in the 48-h PI IFN-&#947;-treated samples. This expression profile may contribute to a reduced rate of peptidoglycan biosynthesis in this persistence model and may therefore be related to the inhibited cell division and RB-to-EB differentiation that characterise chlamydial persistence. While most other genes in these pathways showed unchanged expression associated with IFN-&#947; treatment, murA and kdsB (from peptidoglycan and LPS biosynthesis, respectively) were selectively up-regulated in the 48-h PI IFN-&#947;-treated samples. Taken together, these data supported the concept of a persistence stimulon in C. pneumoniae that is regulated at key points in various metabolic pathways.    In addition to the analysis of biosynthetic genes, the up-regulated gene set from continuous C. pneumoniae TW-183 infections was also analysed in the validated IFN-&#947;-mediated C. pneumoniae A-03 persistence experiments. The data revealed similarities and differences in gene expression patterns between these two in vitro persistence models. Furthermore, the profiles obtained for genes such as pmp1 and porB provided insights into the widely predicted phenomenon of late developmental gene shut-down during chlamydial persistence.    A final investigation into an analogous IFN-&#947;-mediated persistence system for C. trachomatis serovar L2 focussed on one up-regulated (murA) and one down-regulated (glmU) gene from the validated IFN-&#947;-mediated persistent C. pneumoniae A-03 data set. Both genes were significantly down-regulated in persistent C. trachomatis, adding to a growing body of evidence for key differences among chlamydial species in their persistent gene expression patterns.    This project has contributed significantly to our understanding of the molecular basis of the important persistent phase of chlamydial development.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Chlamydia pneumoniae</field><field name="subject">Chlamydia trachomatis</field><field name="subject">persistence</field><field name="subject">continuous-infection model</field><field name="subject">gamma interferon</field><field name="subject">real-time PCR</field><field name="subject">RT-PCR</field><field name="subject">differential gene expression</field><field name="subject">membrane protein</field><field name="subject">peptidoglycan</field><field name="identifier">http://eprints.qut.edu.au/16458/</field><field name="validLink">True</field></doc><doc><field name="title">An Investigation of the Role Played by Corporate Governance in the Voluntary Disclosure of Forward-Looking Information and the Quality of Corporate Financial Reports</field><field name="creator">O'Sullivan, Madonna</field><field name="description">This study investigates the role played by corporate governance in the firm's decision to disclose forward-looking information in financial reports, as well as the quality of such reports. More effective corporate governance has often been linked to voluntary disclosure within the annual report (Karamanou and Vafeas 2005).  Similarly, recent studies document a positive association between reporting quality and the standard of corporate governance (Wright 2001).  This study proposes that stronger corporate governance will be associated with increased forward-looking disclosures in financial reports and higher financial reporting quality.  The results indicate that audit quality, the presence and quality of board committees and the overall efficacy of corporate governance are positively associated with forward-looking disclosures in 2000. However, corporate governance does not have a positive association with such disclosures in 2002. Regarding the relationship between financial reporting quality and corporate governance, audit quality is the only governance variable that yields a significant result and is only associated with higher reporting quality in 2002.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">corporate governance</field><field name="subject">financial reports</field><field name="subject">forward-looking disclosures</field><field name="identifier">http://eprints.qut.edu.au/16459/</field><field name="validLink">False</field></doc><doc><field name="title">Modelling and analysis of reliability and costs for lifetime warranty and service contract policies</field><field name="creator">Rahman, Anisur</field><field name="description">Reliability of products is becoming increasingly important due to rapid technological development and tough competition in the product market. One effective way to ensure reliability of sold product/asset is to consider after sales services linked to warranty and service contract. One of the major decision variables in designing a warranty is the warranty period. A longer warranty term signals better reliability and provides higher customer/user peace of mind. The warranty period offered by the manufacturer/dealer has been progressively increasing since the beginning of the 20th Century. Currently, a large number of products are being sold with long term warranties in the form of extended warranty, warranty for used product, long term service contracts, and lifetime warranty. Lifetime warranties and service contracts are becoming more and more popular as these types of warranties provide assurance to consumer for a long reliable service and protecting consumers against poor quality and the potential high cost of failure occurring during the long uncertain life of product. The study of lifetime warranty and service contracts is important to both manufacturers and the consumers. Offering a lifetime warranty and long term service contracts incur costs to the manufacturers/service provider over the useful life of the product/contract period. This cost needs to be factored into the price/premium. Otherwise the manufacturer/ dealer will incur loss instead of profit. On the other hand, buyer/user needs to model the cost of maintaining it over the useful life and needs to decide whether these policies/service contracts are worth purchasing or not.    The analysis of warranty policies and costs models associated with short-term or fixed term policies have received a lot of attention. A significant amount of academic research has been conducted in modelling policies and costs for extended warranties and warranty for used products.  In contrast, lifetime warranty policies and longer term service contracts have not been studied as extensively. There are complexities in developing failure and cost models for these policies due to the uncertainties of useful life, usage pattern, maintenance actions and cost of rectifications over longer period.    This thesis defines product's lifetime based on current practices. Since there is no acceptable definition of lifetime or the useful life of product in existing academic literatures, different manufacturer/dealers are using different conditions of life measures of period of coverage and it is often difficult to tell whose life measures are applicable to the period of coverage (The Magnuson-Moss Warranty Act, 1975). Lifetime or the useful life is defined in this thesis provides a transparency for the useful life of products to both manufacturers/service provider and the customers. Followed by the formulation of an acceptable definition of lifetime, a taxonomy of lifetime warranty policies is developed which includes eight different one dimensional and two dimensional lifetime warranty policies and are grouped into three major categories, A. Free rectification lifetime warranty policies (FRLTW),  B. Cost Sharing Lifetime Warranty policies (CSLTW), and C. Trade in policies (TLTW). Mathematical models for predicting failures and expected costs for different one dimensional lifetime warranty policies are developed at system level and analysed by capturing the uncertainties of lifetime coverage period and the uncertainties of rectification costs over the lifetime. Failures and costs are modelled using stochastic techniques. These are illustrated by numerical examples for estimating costs to manufacturer and buyers. Various rectification policies were proposed and analysed over the lifetime.    Manufacturer's and buyer's risk attitude towards a lifetime warranty price are modelled based on the assumption of time dependent failure intensity, constant repair costs and concave utility function through the use of the manufacturer's utility function for profit and the buyer's utility function for cost. Sensitivity of the optimal warranty prices are analysed with numerical examples with respect to the factors such as the buyer's and the manufacturer/dealer's risk preferences, buyer's anticipated and manufacturer's estimated product failure intensity, the buyer's loyalty to the original manufacturer/dealer in repairing failed product and the buyer's repair costs for unwarranted products.    Three new service contract policies and cost models for those policies are developed considering both corrective maintenance and planned preventive maintenance as the servicing strategies during the contract period. Finally, a case study is presented for estimating the costs of outsourcing maintenance of rails through service contracts. Rail failure/break data were collected from the Swedish rail and analysed for predicting failures.  Models developed in this research can be used for managerial decisions in purchasing life time warranty policies and long term service contracts or outsourcing maintenance.  This thesis concludes with a brief summary of the contributions that it makes to this field and suggestions and recommendations for future research for lifetime warranties and service contracts.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">warranty and service contract</field><field name="subject">warranty period</field><field name="subject">buyer risk</field><field name="subject">manufacturer risk</field><field name="identifier">http://eprints.qut.edu.au/16460/</field><field name="validLink">True</field></doc><doc><field name="title">Evaluation of the contribution of reflected UVR to the inner canthus' total dose</field><field name="creator">Birt, Benjamin Joseph</field><field name="description">Basal cell carcinoma is a form of a non-melanoma skin tumour, that commonly forms over the sun exposed regions of the head and neck. Investigation of the rate of occurrence at different sites on face and neck shows considerable variation from site to site. The inner canthus has a disproportionate number when compared to more exposed sites. The eye brow ridge, cheek bone and nose limit the field of view of the inner canthus, thus it is expected to receive less radiation than other more exposed regions. To explain the disproportionate rate, it is hypothesised that a portion of radiation incident onto the eye is reflected to the inner canthus. The aim of this thesis is to investigate the contribution that the radiation reflected off the surface of the eye makes to the overall dose on the inner canthus.    The inter reflections between the eye and inner canthus were studied through the use of the ray tracing program Zemax. Zemax was used to trace rays in a non sequential mode incident onto a model eye and periorbital region. To obtain the models of the eye and periorbital region, both magnetic resonance imaging and a casting process was investigated, with the later being superior for our uses. With the model obtained, it was used in a series of three dimensional ray tracing programs. On a macroscopic scale there is a small increase in the irradiance on the inner canthus (2 % over a 1 cm2 area). Peaks of high irradiance (19 % increase in irradiance above direct irradiance) were discovered over the surface when the detector was divided into 200 mm elements. It was concluded that these increases above the direct irradiance in these small regions, increases the possibility of the occurrence of a Basal cell carcinoma. Individual facial geometry, will greatly effect the location and size of these peaks and as a result an experimental method to measure the dose distribution across the inner canthus was proposed.    Initially it was planned to use polysulphone film to measure the erythemal dose on the inner canthus. Results from the modelling indicated that any measurements made had to be at a high spatial resolution. Polysulphone film was found to be inadequate for this, due to its large uncertainties. An alternative method was investigated so that a population study could be performed in future studies using visible radiation and high dynamic range images gave a simple and effective clinical assessment tool. The high dynamic range images showed hot spots in the irradiance across the inner canthus agreeing with the model.    The small spots of high relative irradiance may not be the only reason for the increased rate in this region. Greater skin sensitivity and absence of sun screen use at this site are other possibilities. It is believed however that the irradiance distribution across the inner canthus on a microscopic scale goes a long way to increasing the risk for certain people.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">basal cell carcinoma</field><field name="subject">ultraviolet radiation</field><field name="subject">three dimensional model</field><field name="subject">ray tracing</field><field name="subject">eye</field><field name="subject">inner canthus</field><field name="subject">surface topography</field><field name="subject">ray trace model</field><field name="subject">polysulphone film</field><field name="identifier">http://eprints.qut.edu.au/16461/</field><field name="validLink">True</field></doc><doc><field name="title">A study of group B streptococcus in Brisbane : the epidemiology, detection by PCR assay and serovar prevalence</field><field name="creator">Taylor, Karen Leigh</field><field name="description">The neonate is still at risk of acquiring Group B Streptococcus (GBS) infection upon delivery even with the implementation of early onset GBS neonatal disease preventative protocols.  GBS was reported as the most prevalent organism causing neonatal morbidity and mortality in the USA and Australia in the 1990s. GBS is also known to cause disease in children, women, the immunocompromised adult and the elderly, but it is the preterm neonates who are at greatest risk of GBS neonatal disease.   The aim of this study was to determine the prevalence of lower genital tract (LGT) colonisation with GBS in Brisbane women of child bearing age. We also aimed: (i) to compare the GBS LGT prevalence rate of Indigenous and non Indigenous women; (ii) to determine whether previously reported risk factors for LGT colonisation with GBS were also risk factors associated with GBS colonisation of women in this study; (iii) to further develop and optimise a rapid PCR assay that could detect maternal LGT GBS colonisation;  and (iv) to serotype  the GBS strains that were isolated from pregnant and non pregnant women who participated in this study. This study recruited 374 women of childbearing age attending public medical providers and found an overall GBS prevalence of 98/374 (26.2%) for these Brisbane women, a rate higher than previously reported in Australia.  When the GBS prevalence for pregnant women (25.6%) was compared to non pregnant women (27.2%) they were similar.  We also compared the GBS LGT colonisation rate of women attending different medical providers.  The GBS LGT prevalence rate for pregnant women attending the Mater was 36/118 (30.5%), whilst those women attending the Redlands Hospital antenatal clinic had a LGT GBS prevalence rate of only 7/53 (13.2%).  By comparison, the LGT GBS prevalence rate for non pregnant women attending Biala Sexual Health clinic was 21/69 (30.4%) and 34/127 (26.8%) of women attending the Brisbane Family Planning Queensland were also GBS positive.  The seven women recruited from Inala community centre tested negative for GBS LGT colonisation.  The LGT GBS prevalence of Australian Aboriginal women was 5/22 (22.7%), a rate which was not significantly different from non-Aboriginal women 78/288 (27.1%).  Established early onset GBS neonatal disease preventative policies have been recently revised.  The CDC now recommends that all pregnant women are screened for LGT GBS colonisation during late gestation, and that any GBS isolates be tested for resistance to antibiotics if the GBS positive women have an allergy to penicillin.  Queensland's Department of Health recommend that Queensland medical agencies implement a non screening based preventative protocol, where clinicians monitor: women prior to labour for reported risk factors associated with maternal GBS colonisation: women in labour for 'obstetric risk factors'.  A number of risk factors have previously been reported in association with GBS LGT colonisation.   However, in this current study we found that only one risk factor was significantly associated with current GBS:  previous reported LGT GBS colonisation was significantly associated with maternal LGT GBS colonisation reported in this study.  Women who previously tested positive for GBS were significantly more likely to be GBS positive in subsequent tests (OR 4.7; 95%CI, 1.8-12.5) compared to women with no previous history of GBS colonisation.  An assessment of adverse pregnancy outcomes, preterm deliveries, and GBS colonisation data was made.  It was established that 30 women had previously given birth to one or more preterm neonates and of these 30 women, nine (30%) of them tested positive for GBS in this current study.  Of the 71 women who had given birth to neonates and who had suffered an adverse pregnancy outcome 25.3% also tested positive for GBS in this current study.  GBS was identified in up to 30% of all mothers who had delivered their neonate preterm, 27.4% of women who had previously suffered miscarriages and 16.7% of women who had previously had stillbirths.  In this study we found that Australian Aboriginal women also had a greater risk of delivering neonates who suffered from an adverse pregnancy outcome in comparison to all other women.  Twenty one of the 22 Aboriginal women had previously been pregnant at least once, and nine (42.9%) of these women had at least one prior adverse pregnancy outcome while seven (33.3%) of these women had previously delivered at least one neonate preterm.  Of the 21 Aboriginal women who had a previous pregnancy more than half the total number of Aboriginal women (11/21) had either delivered one or more neonates preterm or had suffered from one or more adverse pregnancy outcomes.   When the incidence of adverse pregnancy outcomes was compared for Aboriginal and all other women the results were surprising.  Overall, this study found 216 women including Aboriginal women had previously been pregnant and of these women 71 (32.8%) of them suffered an adverse pregnancy outcome.  By comparison, only 62 of 195 (31.8%) non Aboriginal women but nine out of 21 (41.9%) Australian Aboriginal women suffered from a previous adverse pregnancy outcome.  The clinical LGT GBS isolates found in this study of Brisbane women were typed and all nine GBS serotypes plus non typeable GBS serotypes were detected.  Seventy women tested GBS culture positive and vaginal and/or perianal samples obtained from these women were evaluated.  GBS serotype III was the serotype most frequently isolated from this total population, from 47.4% of pregnant women and 51.7% of non pregnant women.  From some women only a single GBS serotype was isolated: in these women we found that GBS serotype III (50%) was the predominant isolate, followed by GBS serotype Ia isolated from 16.7% women.  In addition 4.2% of women were colonised with GBS serotypes; Ib, II and V, whilst GBS serotypes IV and VII were isolated from 2.1% women.  Non typeable GBS strains confirmed by latex agglutination tests accounted for 11.9% of all strains isolated from these Brisbane women.  This study identified multiple serovars in 15 clinical samples and found that 22 (31.4%) women were colonised with mixed GBS serotypes in samples collected from both vaginal and perianal regions.  In five women the combination of serotypes III/Ia were identified and in other women combinations of serotypes III/II, III/IV, III/V, III/VIII, Ia/IV and Ib/NT were also detected.  In two instances three serotype combinations were detected in samples from one woman and these included serotypes III/Ib/II and III/Ia/Ib.  Isolates were also typed for women who were colonised in both vaginal and perianal regions and it was found that only 10 participants had identical isolates in both regions.  GBS serotype III was the predominant serotype detected in women tested in this study and this is the serotype that has previously been associated with invasive infections in neonates.  GBS neonatal disease is a world wide economic, health and social burden affecting different ethnic groups and is preventable.  Currently no vaccine technology is available for the prevention of GBS neonatal disease and the most effective EOGND preventative protocol would be to test for maternal GBS colonisation during labour, or screen women for GBS at &amp;gt36 weeks' gestation and administer intrapartum antibiotic prophylaxis (IAP) to all women who tested positive for GBS.  In this current study we utilised a rapid bsp PCR assay to detect LGT GBS colonisation in women of child bearing age. The PCR assay identified 62.5% of all vaginal and perianal positive culture GBS samples.  The specificity of the PCR assay was 89% while the positive and negative predictive values were 56.8% and 91.1% respectively.  This PCR assay using the current parameters is not an effective GBS detection assay but could be further optimised in the near future.  This PCR assay could be an effective test in the future with the development of an alternative DNA extraction method to InstaGene (BioRad).  However, this PCR assay if used in conjunction with the current culture method is able to detect a further 8.9% of women colonised with asymptomatic GBS.    Brisbane women aged between 26 to 35 years who are pregnant and who are attending public health care agencies are at greatest risk of being colonised with GBS.  No disparity was identified when ethnicity or social standing were assessed.  The overall results of this study demonstrate that the LGT GBS prevalence rate in Brisbane women is 26.2% but this rate was higher at 30.5% for women attending a Brisbane sexual health clinic and for pregnant women attending the Mater Mothers' antenatal clinic.  GBS serovar III has been identified as the dominant serovar in our population group and this strain has been reported as the major cause of GBS disease in neonates and infants aged to three months.  Disparity (11.1%) was reported when the incidence of adverse pregnancy outcomes amongst Aboriginal women was compared to non Aboriginal women.  From the outcomes of this study it has been suggested that Queensland adopt a screening based GBS preventative protocol.  It has also been suggested that an Australian wide GBS prevention strategy may further reduce the incidence of neonatal disease.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Group B Streptococcus</field><field name="subject">GBS neonatal disease</field><field name="subject">neonatal morbidity</field><field name="subject">neonatal mortality</field><field name="subject">serovar</field><field name="subject">PCR assay</field><field name="identifier">http://eprints.qut.edu.au/16462/</field><field name="validLink">True</field></doc><doc><field name="title">Computer vision applications on graphics processing units</field><field name="creator">Ohmer, Julius Fabian</field><field name="description">Over the last few years, commodity Graphics Processing Units (GPUs) have evolved from fixed graphics pipeline processors into more flexible and powerful data-parallel processors. These stream processors are capable of sustaining computation rates of greater than ten times that of a single-core CPU. GPUs are inexpensive and are becoming ubiquitous in a wide variety of computer architectures including desktop and laptop computers, PDAs and cell phones.    This research works investigates possible ways to use modern GPUs for real-time computer vision and pattern classification tasks. Special attention is paid to algorithms, where the power of the CPU is a limiting factor. This is in particular the case for real-time tracking algorithms on video streams, where many candidate regions must be evaluated at once to allow stable tracking of features. They impose a high computational burdon on sequential processing units such as the CPU.  The proposed implementation presented in this thesis is considering standard PC platforms rather than expensive special dedicated hardware to allow a broad variety of users to benefit from powerful computer vision applications. In particular, this thesis includes following topics:    1. First, we present a framework for computer vision on the GPU, which is used as a foundation for the implementation of computer vision methods.  2. We continue with the discussion of GPU-based implementation of Kernel Methods, including Support Vector Machines and Kernel PCA.  3. Finally, we propose GPU-accelerated implementations of two tracking algorithms. The first algorithm uses geometric templates in a gradient vector field. The second algorithm is a color-based approach in a particle filter framework. Both are able to track objects in a video stream.    This thesis concludes with a final discussion of the presented methods and will propose directions for further research work. It will also briefly present the features of the next generation of GPUs.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">graphics processing units (GPU)</field><field name="subject">computer vision applications</field><field name="identifier">http://eprints.qut.edu.au/16463/</field><field name="validLink">True</field></doc><doc><field name="title">Using a competing values framework to examine university culture</field><field name="creator">Sanderson, Donald Mark</field><field name="description">The presented dissertation reports the findings of an exploratory study that mapped the perceptions of stakeholders on the changing nature of the organisational culture, in terms of the corporatisation of higher education, in a single faculty from a large Australian university. The study used a mixed-method, case study approach and it tested the usefulness of an organisational culture measuring instrument based on the Competing Values Framework (Quinn &amp; McGrath, 1985; Quinn &amp; Rohrbaugh, 1981,  1983). The presented work argues that the institution of higher education can be viewed as being rudimentarily comprised of having two symbiotic cultural parts - a collegial and a mercantile part and that these parts form the corporation that is an institution of higher education. The generated hypothesis is that when the values of these two competing cultures are in a particular configuration of influence with each other, a university has its best opportunity to effectively attend to its core functions.  The research found that the relationship between the collegial and the mercantile parts in the study site's culture had shifted in favour of a mercantile culture and further research is needed to determine if that means the organisation is operating at an optimal effectiveness.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">case study</field><field name="subject">change</field><field name="subject">competing values framework</field><field name="subject">corporatisation</field><field name="subject">culture</field><field name="subject">higher education</field><field name="subject">organisation</field><field name="subject">mixed method</field><field name="subject">university</field><field name="identifier">http://eprints.qut.edu.au/16464/</field><field name="validLink">True</field></doc><doc><field name="title">Promoting self-management for patients with type 2 diabetes following a critical cardiac event</field><field name="creator">Wu, Chiung-Jung</field><field name="description">Type 2 diabetes is a global health problem. Evidence indicates that type 2 diabetes can lead to serious complications, such as a cardiac event, which usually require critical nursing care. Patients with type 2 diabetes and with a history of cardiac disease are at greater risk of a further cardiac event requiring readmission to hospital.
 
 
 
 Evidence indicates that improved diabetes management assists patients with type 2 diabetes to manage their condition efficiently, reduces risks of a further cardiac event, and therefore reduces hospitalisations. However, there is limited information found regarding a diabetes management program specifically for patients who have already had cardiac complications. Difficulties in developing patients' skills in managing and modifying their daily lives also present a challenge to coronary care staff. Therefore, there is a real need to develop a special diabetes management program for patients with diabetes who have experienced a critical cardiac event, which will be commenced in the Coronary Care Unit (CCU).
 
 
 
 The aim of this research is to gain a greater understanding of the characteristics, secondly to obtain in-depth understanding of needs and experiences of patients with type 2 diabetes hospitalised for a critical cardiac event. A further aim is to develop and pilot test a diabetes management program, specific to the patients with diabetes in the context of the CCU.
 
 
 
 The design of this research employed three studies: Study I was an exploratory study, which obtained patients' demographic and disease characteristics from the hospital records of all patients with diabetes admitted to the CCU of one public hospital between 1 January 2000 to 31 December 2003. Study II used a qualitative interpretative approach and aimed to gain an in-depth understanding of the perspectives of patients with type 2 diabetes who have experienced a critical cardiac event in managing their everyday lives with both diabetes and cardiac conditions. Study III included two parts. The first utilised the information from the first two studies and the literature (self-efficacy theory) to develop a diabetes self-management program specifically for patients with diabetes who have had a critical cardiac event. The second part pilot tested the newly-developed diabetes self-management program for patients with diabetes admitted to CCU following a critical cardiac event. The pilot study used a randomised controlled trial research design to evaluate the efficacy of the program.
 
 
 
 Study I collected data from one hospital's records retrospectively from 2000 to 2003. The results of Study I showed there were 233 (14.7%) patients admitted to CCU that had diabetes out of the total 1589 CCU admissions during the study period. More than 22% of CCU patients with diabetes were readmitted to hospital within 28 days, compared to 6% of CCU patients without diabetes. Patients with diabetes who had a longer CCU stay were more likely to be readmitted. These results indicate that a significant proportion of a CCU population had type 2 diabetes and is more likely to be readmitted to hospital.
 
 
 
 Study II used an interpretive approach comprising open-ended interviews to collect data from patients with type 2 diabetes experiencing a cardiac event who had a CCU admission in 2000-2003. The findings revealed that patients with diabetes who had a critical cardiac event experienced considerable feelings of hopelessness and fatigue. Patients also had concerns in the areas of self-confidence and confidence in health professionals. Patients indicated that greater self-confidence and confidence in health professionals would help their ability to manage their daily lives. Therefore, it is very important that intervention programs for these at-risk patients need to improve patients' confidence levels, and reduce their feelings of hopelessness and fatigue.
 
 
 
 The information gathered from Study I and Study II provided important insight into the development of an effective diabetes self-management specifically designed for patients with type 2 diabetes following a critical cardiac event, which is presented in Study III in this thesis. Study III also provided a preliminary evaluation of the newly developed program. The evaluation used a randomised controlled trial research design for the new program and the current educational program provided in the CCU. The results of the program indicate the feasibility of commencing the new diabetes self-management program in the CCU, and to be continued in wards or at home. The results also showed significant improvements in patients' knowledge in the experimental group, but not in other outcome variables (self-efficacy, vitality and mental health levels). However, as a small sample size was used in this pilot study, a larger study is needed to ensure adequate testing of the intervention. Future research is also recommended to incorporate the new diabetes self-management program into the current cardiac education program. Staff's further professional development in providing such a program also needs to be examined. Improvements in quality of care, and patients' quality of life are expected in the future.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">type 2 diabetes</field><field name="subject">critical cardiac event</field><field name="subject">coronary care unit</field><field name="subject">coronary heart disease</field><field name="subject">myocardial infarction</field><field name="subject">self-efficacy</field><field name="subject">health behaviour</field><field name="subject">diabetes self-management</field><field name="subject">retrospective</field><field name="subject">interpretative approach</field><field name="subject">randomised controlled trial</field><field name="identifier">http://eprints.qut.edu.au/16465/</field><field name="validLink">True</field></doc><doc><field name="title">Team role balance : investigating knowledge-building in a CSCL environment</field><field name="creator">Roberts, Alan</field><field name="description">Computer Supported Collaborative Learning (CSCL) is one approach that seemingly maps neatly to the notion of equipping learners for emergent knowledge-age work practice currently exemplified by Computer Supported Cooperative Work (CSCW) or Virtual Teams. However, the difficulty of achieving peer interaction in Computer Supported Collaborative Learning (CSCL) environments has proved to be a recurrent problem. Seemingly collaborative settings have been interpreted too narrowly referring only to positive phenomenon. There has been a tendency to focus on technology rather than social scaffolds. Little is known about the influence of students' personalities on online collaborative interaction and knowledge-building activity. Within collaborative team based contexts individuals demonstrate preferences towards certain activities. Such preferences and combinations of preferences may affect team knowledge-building activity both in terms of quality and efficiency. This thesis reports on the findings from a study that investigated if knowledge-building activity can be enhanced in tertiary education CSCL environments through the use of teams balanced by Team Role Preference.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">computer supported collaborative learning</field><field name="subject">teams</field><field name="subject">team role preference</field><field name="subject">knowledge-building</field><field name="subject">quality/effectiveness</field><field name="subject">efficiency</field><field name="identifier">http://eprints.qut.edu.au/16466/</field><field name="validLink">True</field></doc><doc><field name="title">Population phenology and natural enemies of paropsis atomaria Olivier (Coleoptera: Chrysomelidae) in South-East Queensland</field><field name="creator">Duffy, Michael Patrick</field><field name="description">Paropsis atomaria Olivier (Coleoptera: Chrysomelidae: Paropsini), is a major pest of commercially grown eucalypts in South-East Queensland. Current management of  paropsine beetles involves regular inspection and the application of chemical sprays if defoliation is severe. However, non-chemical control of plantation pests is highly desirable given the requirement to certify forest practices for sustainability, and community concerns over the use of pesticides. One way of reducing pesticide use is through conservation biological control, which requires detailed knowledge of the life history of the pest and its natural enemies. This thesis documents aspects of P. atomaria phenology, including life tables, sex ratios and damage estimates; identifies the predators, parasites, and egg and larval parasitoids of P. atomaria; and examines the ecology of the most promising natural enemy, Neopolycystus Girault sp. (Hymenoptera: Pteromalidae) in South-East Queensland.    P. atomaria adults are active from September until April and can complete up to four generations in a season. Field mortality between egg and fourth instar larvae is approximately 94%. A large proportion of this mortality can be attributed to natural enemies. The most abundant predators in eucalypt plantations were spiders, comprising 88% of all predators encountered.    Egg parasitoids exerted the greatest influence on P. atomaria populations, emerging from around 50% of all egg batches, and were responsible for mortality of almost one third of all eggs in the field. Only about one percent of larvae were parasitised in the field, in contrast to paropsine pests in temperate Australia, where egg parasitism rates are low and larval parasitism rates high.    Neopolycystus sp. was the only primary parasitoid reared from P. atomaria eggs, along with three hyperparasitoid species; Baeoanusia albifunicle Girault (Encyrtidae), Neblatticida sp. (Encyrtidae) and Aphaneromella sp. (Platygasteridae). This is the first record of B. albifunicle hyperparasitising Neopolycystus spp. B. albifunicle emerged from one-third of all parasitised egg batches and could pose a potential problem to the efficacy of Neopolycystus sp. as a biological control agent. However, within egg batches, hyperparasitoids rarely killed all Neopolycystus sp. with only 9% of hyperparasitised egg batches failing to produce any primary parasitoids. Total field mortality of P. atomaria through direct and indirect effects of parasitism by Neopolycystus sp. was 28%. The proportion of egg batches parasitised increased with exposure time in the field, but within-batch parasitism rate did not. In general, there was no significant correlation between parasitism rates and distance from landscape features (viz. water sources and native forest).</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Paropsis atomaria</field><field name="subject">Neopolycystus sp.</field><field name="subject">Eucalyptus cloeziana</field><field name="subject">parasitioids</field><field name="subject">natural enemies</field><field name="subject">habitat manipulation</field><field name="subject">conservation biological control</field><field name="identifier">http://eprints.qut.edu.au/16467/</field><field name="validLink">True</field></doc><doc><field name="title">Spatial perception and progressive addition lenses</field><field name="creator">Hendicott, Peter Leslie</field><field name="description">Progressive addition lenses (PALs) are an increasingly preferred mode for the correction of presbyopia, gaining an increased share of the prescription lens market.  Sales volumes are likely to increase over the next few years, given the increasing cohort of presbyopic patients in the population. This research investigated adaptation to PAL wear, investigating head movement parameters with and without progressive lenses in everyday visual tasks, and examined symptoms of spatial distortions and illusory movement in a crossover wearing trial of three PAL designs. Minimum displacement thresholds in the presence and absence of head movement were also investigated across the lens designs.    Experiment 1 investigated head movements in two common visual tasks, a wordprocessing copy task, and a visual search task designed to replicate a natural environment task such as looking for products on supermarket shelving. Head movement parameters derived from this experiment were used to set head movement amplitude and velocity in the third experiment investigating minimum displacement thresholds across three PAL designs. Head movements were recorded with a Polhemus Inside Track head movement monitoring system which allows real time six degrees of freedom measurement of head position. Head position in azimuth, elevation and roll was extracted from the head movement recorder output, and data for head movement angular extent, average velocity (amplitude/duration) and peak velocity were calculated for horizontal head movements Results of the first experiment indicate a task dependent effect on head movement peak and average velocity, with both median head movement average and peak velocity being faster in the copy task. Visual task and visual processing demands were also shown to affect the slope of the main sequence of head movement velocity on head movement amplitude, with steeper slope in the copy task. A steeper slope, indicating a faster head movement velocity for a given head movement amplitude, was found for head movements during the copy task than in the search task. Processing demands within the copy task were also shown to affect the main sequence slopes of velocity on amplitude, with flatter slopes associated with the need for head movement to bring gaze to a specific point. These findings indicate selective control over head movement velocity in response to differing visual processing demands.    In Experiment 2, parameters of head movement amplitude and velocity were assessed in a group of first time PAL wearers. Head movement amplitude, average and peak velocity were calculated from head movement recordings using the search task, as in Experiment 1. Head movements were recorded without PALs, on first wearing a PAL, and after one month of PAL wear to assess adaptation effects. In contrast to existing literature, PAL wear did not alter parameters of head movement amplitude and velocity in a group of first time wearers either on first wearing the lenses or after one month of wear: this is due to task related effects in this experiment compared to previous work. Task demand in this experiment may not have required wearers to use the progressive power corridor to accomplish identification of visual search targets, in contrast to previous studies where experimental conditions were designed to force subjects to use the progressive corridor. In Experiment 3, minimum displacement thresholds for random dot stimuli were measured in a repeated measures experimental design for a single vision lens as control, and three PAL designs. Thresholds were measured in central vision, and for two locations in the temporal peripheral field, 30&#176; temporal fixation and 10&#176; above and below the horizontal midline. Thresholds were determined with and without the subjects' head moving horizontally in an approximate sinusoidal movement at a frequency of about 0.7 Hz. Minimum displacement thresholds were not significantly affected by PAL design, although thresholds with PALs were higher than with a single vision lens control. Head movement significantly increased minimum displacement threshold across lens designs, by a factor of approximately 1.5 times. Results indicate that the local measures of minimum displacement threshold determined in this experiment are not sensitive to lens design differences. Sensitivity to motion with PAL lenses may be more a global than a localized response. For Experiment 4, symptoms of spatial distortion and illusory movement were investigated in a crossover wearing trial of three PAL designs, and related to optical characteristics of the lenses. Peripheral back vertex powers of the PALs were measured at two locations in the right temporal zone of the lenses, 15.6 mm temporal to the fitting cross, and 2.7 m above and below the horizontal to the fitting cross. These locations corresponded to the zones of the lenses through which minimum displacement thresholds were measured in the previous experiment. The effect of subjects' self movement on symptoms is able to discriminate between PAL designs, although subjective symptoms alone were not related to the lens design parameters studied. Subjects' preference for one PAL design over the other designs studied in this experiment is inversely related to the effect on subject movement on their symptoms of distortion. An optical parameter, blur strength, derived from the power vector components of the peripheral powers, may indicate preference for particular PAL designs, as higher blur strength values are associated with lower lens preference scores. Head movement amplitude and velocity are task specific, and are also influenced by visual processing demands within tasks. PALs do not affect head movement amplitude and velocity unless tasks are made demanding or performed in less natural situations designed to influence head movement behaviour. Both head movement and PALs have large effects on minimum displacement thresholds; these effects may be due in part to complexity of the subjects' task within the experiment. Minimum displacement thresholds however were not influenced by PAL design. The most sensitive indicator for subject's preference of PALs was the effect of subjects' self movement on their perception of symptoms, rather than the presence of actual symptoms. Blur strength should be further investigated for its role in PAL acceptance.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">progressive addition lenses</field><field name="subject">PAL</field><field name="subject">spatial perception</field><field name="subject">minimum displacement threshold</field><field name="subject">head movement</field><field name="identifier">http://eprints.qut.edu.au/16468/</field><field name="validLink">True</field></doc><doc><field name="title">Reculturing curriculum within a nursing context in Taiwan : an action research approach</field><field name="creator">Chien, Li-Yu</field><field name="description">The focus of this study is on curriculum change within a nursing institute in Taiwan where there is a growing demand for reform to nurse education in order to produce more competent practitioners. I conceptualised a framework to guide the transformation process in ways that were empowering, sustainable and generative. I argued that curriculum change also involves the beliefs, customs, attitudes or expectations of those who participate in the process: essentially it is a reculturing process. My conceptual framework included notions such as student-centredness, reculturing, collaborative practices and reflections, personal growth, and professional development. A plan of action was developed based on the notions contained in the conceptual framework and carried out within an Action Research methodology. Action Research provided the mechanism by which the collaborators explored and understood their conceptions of teaching and learning and then planned and implemented action to change the current situation, and evaluate and reflect on the transformations. Strategies such as personal practical theorising, focus group, critical debate, and collaborative reflection were used to bring about the curriculum change. The significance of this study lies in its practical contribution to all aspects of curriculum making including innovation, planning, implementation and ongoing review. Although information generated from this study is not generalisable, lessons learned from it may be utilised by other educational institutes with similar issues and similar contexts.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">curriculum change</field><field name="subject">reculturing</field><field name="subject">nurse education</field><field name="subject">Taiwan</field><field name="subject">action research</field><field name="subject">student-centredness</field><field name="subject">empowerment</field><field name="identifier">http://eprints.qut.edu.au/16469/</field><field name="validLink">True</field></doc><doc><field name="title">Exploration of elderly residents' care needs in a Taiwanese nursing home : an ethnographic study</field><field name="creator">Chuang, Yeu-Hui</field><field name="description">This study has explored the culture of nursing home life as experienced by elderly nursing home residents in Taiwan in order to understand, describe and interpret their care needs. In December 2006, the elderly represented 10% of the total population of Taiwan, and this proportion is predicted to increase steadily. In turn, this increase suggested that Taiwan would see ever greater numbers of elderly people with chronic illnesses and physical and mental disabilities. To care for these people, nursing homes have expanded rapidly throughout Taiwan. However, the quality of care provided in these nursing homes has become an urgent matter of concern. Though meeting the residents' care needs is essential for the provision of the best quality care, a review of the available literature shows that the care needs of the elderly residents within the nursing home context are poorly understood, both in Taiwan and internationally.    To address this gap in present understanding, a focused ethnographic approach, using participant observation, in-depth interviews and a review of documents, was undertaken between July 2005 and February 2006. The key participants were sixteen elderly residents who were 65 years old and over, had no cognitive impairment and had lived in the nursing home selected for the present study for at least six months.  Eight nurses, six nursing assistants, one private nursing assistant, one orderly, one physician's assistant and four family members were also interviewed, with questions put to them being based on the data generated from the observation and in-depth interviews with the elderly residents. All interviews were recorded on a digital recorder and transcribed verbatim. Following this, the data gathered from the in-depth interviews, the participant observation and the review of documents was sorted and indexed using the qualitative software program, NVivo7. A five-step analytic process, based on concepts discussed in previous literature, was used to trace the emerging themes.    Nine major care needs were identified by the elderly residents. These included basic functional care needs, emotional support care needs, economic care needs, psychological care needs, environmental care needs, social support care needs, professional care needs, religious care needs and preparation for death care needs.  Three themes of nursing home culture were generated; these were collective life, care rituals and embedded beliefs. The findings of the study indicate that the structure and culture of the nursing home contribute to several care needs remaining unmet. In addition, the results reveal that it is necessary to satisfy economic care needs before other care needs can be resolved.    These findings fill an important gap in nursing knowledge regarding the delivery of better quality care in nursing homes. They also provide relevant information to nursing practice, nursing education and Taiwanese long-term care policy-making, and provide a sound basis for future residential care research.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">care needs; culture; nursing home; aged care; long-term care; elderly residents; ethnography; focused ethnography; Taiwan</field><field name="identifier">http://eprints.qut.edu.au/16470/</field><field name="validLink">True</field></doc><doc><field name="title">A web-based programming environment for novice programmers</field><field name="creator">Truong, Nghi Khue Dinh</field><field name="description">Learning to program is acknowledged to be difficult; programming is a complex intellectual activity and cannot be learnt without practice. Research has shown that first year IT students presently struggle with setting up compilers, learning how to use a programming editor and understanding abstract programming concepts. Large introductory class sizes pose a great challenge for instructors in providing timely, individualised feedback and guidance for students when they do their practice. This research investigates the problems and identifies solutions. An interactive and constructive web-based programming environment is designed to help beginning students learn to program in high-level, object-oriented programming languages such as Java and C#. The environment eliminates common starting hurdles for novice programmers and gives them the opportunity to successfully produce working programs at the earliest stage of their study. The environment allows students to undertake programming exercises anytime, anywhere, by "filling in the gaps" of a partial computer program presented in a web page, and enables them to receive guidance in getting their programs to compile and run. Feedback on quality and correctness is provided through a program analysis framework. Students learn by doing, receiving feedback and reflecting - all through the web. A key novel aspect of the environment is its capability in supporting small &amp;quotfill in the gap" programming exercises. This type of exercise places a stronger emphasis on developing students' reading and code comprehension skills than the traditional approach of writing a complete program from scratch. It allows students to concentrate on critical dimensions of the problem to be solved and reduces the complexity of writing programs.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">computer programming</field><field name="subject">flexible delivery</field><field name="subject">web</field><field name="subject">tutoring system</field><field name="subject">on-line learning</field><field name="subject">feedback</field><field name="subject">fill in the gap</field><field name="subject">static analysis</field><field name="subject">cyclomatic complexity</field><field name="subject">automated testing</field><field name="subject">dynamic analysis</field><field name="subject">black box</field><field name="subject">white box</field><field name="subject">feedback</field><field name="subject">XML</field><field name="subject">assessment</field><field name="identifier">http://eprints.qut.edu.au/16471/</field><field name="validLink">True</field></doc><doc><field name="title">The efficiency of currency markets : studies of volatility and speed of adjustment</field><field name="creator">Boulter, Terry</field><field name="description">Whether or not currency markets may be regarded as efficient or not has been a hotly debated issue in the academic literature over recent decades. Economic theory would suggest that these markets should be efficient because they are apparently good examples of a perfectly competitive market structure. On the other hand, empirical tests of the efficient market hypothesis within these currency markets unequivocally find them to be inefficient. There is still no good explanation for this conundrum and as a result a fair amount of effort is still expended on refining the empirical studies of market efficiency, a task which is taken up in the four empirical studies that comprise this thesis.    Within efficient markets, prices are predicted to respond &amp;quotquickly" with the arrival of new information and the empirical work in the thesis focuses on these issues by identifying three key areas for research, namely, price adjustment and volatility, volatility and the &amp;quotnews", and the speed of price adjustment. In essence, the studies examine whether there is inefficient adjustment to news in terms of excessive volatility, whether or not news is actually the main driver of exchange rate volatility and whether or not &amp;quotquickly" can be measured empirically.    The empirical results reported within this thesis confirm that the Australian dollar has not been an excessively volatile currency, even though the level of volatility has been increasing; that the pattern of information flow explains a significant degree of the non constant variance in the returns of the world's most actively traded currencies, (i.e. information explains price innovation); that the reaction time to macroeconomic news occurs within seconds of a pre-scheduled announcement, and that the bulk of adjustment to fundamental value occurs within the hour. These findings are consistent with what would be expected within an efficient market.    The results reported within this thesis therefore suggest that the currency markets studied are efficient, at least for the sample periods of the data used in the studies. Exchange rates adjust rapidly with information arrival albeit not completely. It is also the case that a number of additional research questions emerge from this research. For example we know that volatility is not excessive and that it is increasing. What we do not know is the point at which increasing volatility becomes excessive. We know that exchange rates react quickly with the arrival of macroeconomic news, but we do not know precisely how long it takes for volatility to return to preannouncement levels, or why the reaction to news is inconsistent. We also do not know what type of information best explains volatility above that which is explained by the systematic dissemination of information or why full adjustment to fundamental value does not occur? Answers to these questions provide a future research agenda. Answers may provide insight that will help financial economists explain the apparent failure of the speculative efficient hypothesis.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">currency markets</field><field name="subject">currency volatility</field><field name="subject">exchange rates</field><field name="subject">macroeconomic news</field><field name="identifier">http://eprints.qut.edu.au/16472/</field><field name="validLink">True</field></doc><doc><field name="title">Taiwanese people with cancer and non Western medicine (NWM) use : a grounded theory study</field><field name="creator">Wang, Shou-Yu (Cindy)</field><field name="description">Because of the long and entrenched history of Chinese medicine in Taiwan, people have traditionally incorporated this knowledge into their health care. With the appearance and growing acceptance of Western medical practices, multiple medical approaches have become more and more popular. Yet, despite the strong foundations of Western medicine in the treatment of cancer in Taiwan, the use of Chinese medicine continues to be popular (Lin, 1992, p. 114). The focus of this research is the contextual construction of meanings about non Western medicine (NWM). The context for the study is Taiwan, the researcher's home country. The purpose of the research is to explore the motivations for, and the processes by which, Taiwanese people with cancer incorporate NWM into their cancer treatment journey. Utilising a grounded theory approach, this research sought to explore the social processes by which Taiwanese people with cancer come to use non Western medicine. Twenty four in depth interviews were undertaken in the study.    The findings of the study demonstrate that the interactions between people with cancer and their use of NWM are complex. Taken-for-grantedness emerges as the core category in the study. The core category situates the use of non Western medicine outside the institutionalised and regulated domains of health care. More specifically, the meanings attributed to NWM are embedded in the philosophical beliefs and social relationships that constitute the lives of the participants.   These findings suggest implications for our understanding of the co-existence of NWM and Western medicine by Taiwanese people with cancer and the social processes with which they engage.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">non Western medicine (NWM)</field><field name="subject">complementary and alternative medicine (CAM)</field><field name="subject">symbolic interactionism</field><field name="subject">grounded theory</field><field name="subject">cancer</field><field name="subject">Taiwan</field><field name="identifier">http://eprints.qut.edu.au/16473/</field><field name="validLink">True</field></doc><doc><field name="title">Processes for evaluating the optimum inter-modal terminal location</field><field name="creator">Yang, Jianfeng</field><field name="description">In 2001, Australia's annual freight movement load reached 310 billion million tonne-kilometres. By 2020, it is forecast to be 630 billion tonnes-kilometres, an expected rise of slightly over 100 percent of the current level. Due to accelerating freight movement demand in Australia, a rising need for efficient transport infrastructure can be expected. Terminals are a vital part of transport systems which affect the development of whole regions. Terminal location is therefore essential in evaluating the extent to which terminals play a positive role in shaping regional development.    Inter-modal freight transportation is defined as a system that carries freight from origin to destination by using two or more transportation modes. Inter-modal terminal location has great bearing on, and is influenced by, infrastructural efficiency. Terminal locations should optimize both the potential impacts of regional development and effects on transport development. Consequently, it is imperative to analyse the interaction of locations and effects in the process of optimizing terminal location.    This research aims to define the effects of terminal location on transportation by studying the different inter-modal system of the top Australia ports, and introducing the relationship between these effects and transport strategic modelling. Data on transport modelling elements will be investigated in four case studies, followed by data sensitivity analysis to assess the way in which terminal location affects transportation performance.    To examine the effects of terminal location factor on transportation, a number of key elements were selected by the Inter-modal Freight Transport and Regional Development Model and Strategic Modelling: Attractiveness, Location Decisions of Firms, Economic Activity, Shipping/Trip Decision, Destination Choice, Mode Choice, Route Choice, Link Loads, Link Times/Distances/Costs and Accessibility. Environmental issue of a terminal are an additional important consideration in freight movement, when presented as a cost of using the terminal.  The outcome of the case studies which make up this research is a statement of the main effects of the studied elements on terminal location and the potentially necessary improvements to the ports studied For example, 20 kilometres seems to be the radius of an inter-modal terminal catchment level and rail service in Victoria is therefore recommended to be increased to take into account environmental issues. This is augmented by two further studies of the In-land Port and Accessibility of the Port of Brisbane. In essence, this thesis is an attempt to make Australian transport and social services planners aware of the effects of factors relating to terminal location in the processes of evaluating the optimum terminal location.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">inter-modal terminal; location; port</field><field name="identifier">http://eprints.qut.edu.au/16474/</field><field name="validLink">True</field></doc><doc><field name="title">Design and implementation of a mobile wiki : mobile RikWik</field><field name="creator">Huang, Wei-Che (Darren)</field><field name="description">Wikis are a popular collaboration technology. They support the collaborative editing of web pages through a simple mark-up language. Mobile devices are becoming ubiquitous, powerful and affordable. Thus it is advantageous for people to get the benefits of wikis in a mobile setting. However, mobile computing leads to its own challenges such as limited screen size, bandwidth, memory and battery life; they also have intermittent connectivity due to the mobility and the coverage of network. I investigate how wikis can be made mobile; that is how wiki forms of collaborative editing can be achieved through mobile devices such as PDAs and smart phones. A prototype mobile wiki has been created using .NET, which addresses these issues and enables simple collaborative working whilst on and offline through smart mobile devices. A cut down wiki runs on the mobile device. This communicates with a main central wiki to cache pages for off line use. When sitting in a powered cradle eager, downloading and synchronization of pages is supported. During mobile operation, pages are cached lazily on demand to minimize power use and to save the limited and expensive bandwidth. On re-connection, offline edited as well as new pages are synchronized with the main wiki server. Finally a pluggable page rendering engine enables pages to be rendered in different ways to suit different sized screens.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">.NET</field><field name="subject">battery life</field><field name="subject">collaboration</field><field name="subject">collaborative editing</field><field name="subject">collaborative working</field><field name="subject">hoarding process</field><field name="subject">intermittent connectivity</field><field name="subject">limited screen size</field><field name="subject">mobile operation</field><field name="subject">mobile wiki</field><field name="subject">offline use</field><field name="subject">prototype</field><field name="subject">Wiki</field><field name="identifier">http://eprints.qut.edu.au/16475/</field><field name="validLink">True</field></doc><doc><field name="title">Understanding the health experiences of Taiwanese workers</field><field name="creator">Hsu, Tsui Hua</field><field name="description">This thesis attempt to uncover the qualitative different ways that Taiwanese workers experienced health. Workers' health is important to a country's economic, cultural and social development. Both Taiwanese government and health professionals acknowledgement the importance of health. A considerable amount of literature has been released over the past two decades in Taiwan around related issues. Most published research has reported investigation into occupational disease diagnosis, disease prevention, safety behaviours and health-related intervention for behaviour change. None has addressed the health experiences of workers.  To address this gap in knowledge and literature, phenomenographic research has been completed to identify and describe the ways in which Taiwanese workers in an industrial complex experience health. In-depth interview was undertaken with eighteen participants. The interview was tape-recorded and then transcribed verbatim. Data was collected in Mandarin or Taiwanese and analysed in Chinese. This avoids the loss or change of original meaning during the translation process. Significant quotations were then translated to English by the principal researcher. Discussions between the researcher and supervisor, and between researcher and another native English speaker who is be able to read Chinese were continuous through the analysis process to ensure that the English translation is as close possible as to the original meaning.    The outcomes of the research have been the identification of five conceptions of health which together represent understanding of the experience and the meaning of health. The five distinct conceptions are: health is absence of disease; health is a holistic view of the body function; health is a reward of doing 'good' deeds; health as living a healthy lifestyle; and health as a consequence of stress management. All conceptions combined constitute an outcome space that represents the referential and structural relationship between conceptions. The research outcomes contribute to an understanding of how a group of Taiwanese workers were aware of their health experience and have significant implications for health professionals in developing and conducting health intervention, for policy makers in planning occupational health policies, for describing health with a cultural context and for educators of health professionals. Furthermore, this research provides the basis for further research into specific aspects of health and its meaning in different work settings.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Taiwanese worker</field><field name="subject">health experience</field><field name="subject">phenomenography</field><field name="identifier">http://eprints.qut.edu.au/16476/</field><field name="validLink">True</field></doc><doc><field name="title">Portfolio selection and hedge funds : linearity, heteroscedasticity, autocorrelation and tail-risk</field><field name="creator">Bianchi, Robert John</field><field name="description">Portfolio selection has a long tradition in financial economics and plays an integral role in investment management. Portfolio selection provides the framework to determine optimal portfolio choice from a universe of available investments. However, the asset weightings from portfolio selection are optimal only if the empirical characteristics of asset returns do not violate the portfolio selection model assumptions. This thesis explores the empirical characteristics of traditional assets and hedge fund returns and examines their effects on the assumptions of linearity-in-the-mean testing and portfolio selection.    The encompassing theme of this thesis is the empirical interplay between traditional assets and hedge fund returns. Despite the paucity of hedge fund research, pension funds continue to increase their portfolio allocations to global hedge funds in an effort to pursue higher risk-adjusted returns. This thesis presents three empirical studies which provide positive insights into the relationships between traditional assets and hedge fund returns.    The first two empirical studies examine an emerging body of literature which suggests that the relationship between traditional assets and hedge fund returns is non-linear. For mean-variance investors, non-linear asset returns are problematic as they do not satisfy the assumption of linearity required for the covariance matrix in portfolio selection. To examine the linearity assumption as it relates to a mean-variance investor, a hypothesis test approach is employed which investigates the linearity-in-the-mean of traditional assets and hedge funds. The findings from the first two empirical studies reveal that conventional linearity-in-the-mean tests incorrectly conclude that asset returns are nonlinear. We demonstrate that the empirical characteristics of heteroscedasticity and autocorrelation in asset returns are the primary sources of test mis-specification in these linearity-in-the-mean hypothesis tests. To address this problem, an innovative approach is proposed to control heteroscedasticity and autocorrelation in the underlying tests and it is shown that traditional assets and hedge funds are indeed linear-in-the-mean.    The third and final study of this thesis explores traditional assets and hedge funds in a portfolio selection framework. Following the theme of the previous two studies, the effects of heteroscedasticity and autocorrelation are examined in the portfolio selection context. The characteristics of serial correlation in bond and hedge fund returns are shown to cause a downward bias in the second sample moment. This thesis proposes two methods to control for this effect and it is shown that autocorrelation induces an overallocation to bonds and hedge funds. Whilst heteroscedasticity cannot be directly examined in portfolio selection, empirical evidence suggests that heteroscedastic events (such as those that occurred in August 1998) translate into the empirical feature known as tail-risk. The effects of tail-risk are examined by comparing the portfolio decisions of mean-variance analysis (MVA) versus mean-conditional value at risk (M-CVaR) investors. The findings reveal that the volatility of returns in a MVA portfolio decreases when hedge funds are included in the investment opportunity set. However, the reduction in the volatility of portfolio returns comes at a cost of undesirable third and fourth moments. Furthermore, it is shown that investors with M-CVaR preferences exhibit a decreasing demand for hedge funds as their aversion for tail-risk increases.    The results of the thesis highlight the sensitivities of linearity tests and portfolio selection to the empirical features of heteroscedasticity, autocorrelation and tail-risk. This thesis contributes to the literature by providing refinements to these frameworks which allow improved inferences to be made when hedge funds are examined in linearity and portfolio selection settings.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">autocorrelation</field><field name="subject">conditional value at risk (CVaR)</field><field name="subject">heteroscedasticity</field><field name="subject">heteroscedasticity and autocorrelation consistent (HAC)</field><field name="subject">linearity</field><field name="subject">mean-conditional value at risk (M-CVaR)</field><field name="subject">mean-value at risk (M-VaR)</field><field name="subject">mean variance analysis (MVA)</field><field name="subject">modern portfolio theory (MPT)</field><field name="subject">portfolio selection</field><field name="subject">tail-risk</field><field name="subject">value at risk (VaR)</field><field name="identifier">http://eprints.qut.edu.au/16477/</field><field name="validLink">True</field></doc><doc><field name="title">Vibrational microspectroscopy of bacterial colonies</field><field name="creator">Goodwin, James Royce</field><field name="description">Vibrational spectroscopy, mainly infrared spectroscopy, has been applied to bacteria, yeast and archaea cells for many years, for example, for the purpose of developing a rapid method of identification. More recently microcolonies have been used for consistency with the preparation and culture protocols of traditional microbiological methods. Heterogeneity of microcolonies has not been well studied. Investigation of heterogeneity may provide detailed biochemical information leading to an understanding of how colonies grow and the link to the growth cycle.    Investigation of regions within bacterial colonies using FT-IR microspectroscopy was applied to two prokaryotes, the Gram-negative archaeon Halobacterium salinarium and the Gram-positive bacterium Bacillus stearothermophilus. Two-dimensional maps of the entire colony and point maps, spectra taken from key regions such as the periphery and centre of the colony, were acquired. The approximate size of the colonies ranged from 250-950 &#956;m.    The infrared data for the Gram-negative archaeon, H. salinarium supports that for the Gram-positive bacterium, B. stearothermophilus, despite the microorganisms being of different domains and Gram types. It was concluded that the periphery of the microcolony approximately equates to the exponential growth phase (and possibly the lag phase) where the younger cells reside, while the centre approximates to the death and stationary phases. However the spatial resolution proved to be a limiting factor, so Raman microspectroscopy was employed to address this.    Raman spectra across the diameter of microcolonies ranging from 100-300 &#956;m of the pigmented bacterial species Halobacterium salinarium revealed variations in the carotenoid bands. It was suggested that these variations correspond to growth rings, which relate to the growth cycle and the consolidation and migration phase of the cells. The carotenoid variation was rather clear mainly due to the enhanced spectral intensity due to resonance with the laser excitation source. Hence, pigmented bacterial colonies are ideal to study by Raman spectroscopy. The results of this particular aspect of the research are to be published in the Journal of Raman Spectroscopy [1]. In addition, a connection between the consolidation and migration phases and the phases of the growth cycle has been postulated as a novel hypothesis to link the periodic dynamics of the colony and the growth mechanisms at the cellular level.    The Raman microspectroscopic study was extended to non-pigmented bacterial colonies directly on the growth medium. This was a more difficult endeavour as the spectra taken do not have the resonance enhanced advantage of a pigmented bacterium. In addition the sampling volume can consist of variable amounts of growth medium thus decreasing the signal-to-noise ratio and reducing the accuracy of subsequent spectral calculations. However, this was overcome to a large extent by the use of confocal microscopy. The non-pigmented bacterial colonies investigated were Bacillus stearothermophilus and Bacillus subtilis. Analysis, by band area ratios and by chemometric approaches, of radial line map spectra of both Bacillus species revealed variation of nucleic acid concentration. The higher nucleic acid concentration is likely to be a result of cells in the exponential growth phase as rapid growth of new cells is occurring.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">vibrational spectroscopy</field><field name="subject">infrared spectroscopy</field><field name="subject">FT-IR microspectroscopy</field><field name="subject">Raman microspectroscopy</field><field name="subject">Raman spectroscopy</field><field name="identifier">http://eprints.qut.edu.au/16478/</field><field name="validLink">True</field></doc><doc><field name="title">Genetic stock structure and inferred migratory patterns of skipjack tuna (Katsuwonus pelamis) and yellowfin tuna (Thunnus albacares) in Sri Lankan waters</field><field name="creator">Dammannagoda Acharige, Sudath Terrence</field><field name="description">Tuna are the major marine fishery in Sri Lanka, and yellowfin tuna (YFT) (Thunnus  albacares) and skipjack tuna (SJT) (Katsuwonus pelamis) represent 94% of all tuna caught. The tuna catch in Sri Lanka has increased rapidly over recent years and this is true generally for the Indian Ocean. Tuna are a major animal protein source for 20 million people in Sri Lanka, while marine fisheries provide the main income source for most Sri Lankan coastal communities. While the importance of the fishery will require effective stock management practices to be employed, to date no genetic studies have been undertaken to assess wild stock structure in Sri Lankan waters as a basis for developing effective stock management practices for tuna in the future. This thesis undertook such a genetic analysis of Sri Lankan T. albacares and K. pelamis stocks.    Samples of both YFT and SJT were collected over four years (2001 - 2004) from seven fishing grounds around Sri Lanka, and also from the Laccadive and Maldive Islands in the western Indian Ocean. Partial mitochondrial DNA (mtDNA) ATPase 6 and 8 genes and nuclear DNA (nDNA) microsatellite variation were examined for relatively large samples of each species to document genetic diversity within and among sampled sites and hence to infer stock structure and dispersal behaviour.    Data for YFT showed significant genetic differentiation for mtDNA only among specific sites and hence provided some evidence for spatial genetic structure. Spatial Analysis of Molecular Variance (SAMOVA) analysis suggests that three geographically meaningful YFT groups are present. Specifically, one group comprising a single site on the Sri Lankan west coast, a second group comprising a single site on the east coast and a third group of remaining sites around Sri Lanka and the Maldive Islands. Patterns of variation at nDNA loci in contrast, indicate extensive contemporary gene flow among all sites and reflect very large population sizes. For SJT, both mtDNA and nDNA data showed high levels of genetic differentiation among all sampling sites and hence evidence for extensive spatial genetic heterogeneity. MtDNA data also indicated temporal variation within sites, among years. As for YFT, three distinct SJT groups were identified with SAMOVA; The Maldive Islands in the western Indian Ocean comprising one site, a second group comprising a single site on the east coast and a third group of remaining sites around Sri Lanka and the Laccadive Islands. The mtDNA data analyses indicated two divergent (M^ = 1.85% ) SJT clades were present among the samples at all sample sites. SJT nDNA results support the inference that multiple 'sub populations' co-exist at all sample sites, albeit in different frequencies. It appears that variation in the relative frequencies of each clade per site accounts for much of the observed genetic differentiation among sites while effective populations remain extremely large.    Based on combined data sets for management purposes therefore, there is no strong evidence in these data to indicate that more than a single YFT stock is present in Sri Lankan waters. For SJT however, evidence exists for two divergent clades that are admixed but not apparently interbreeding around Sri Lanka. The identity of spawning grounds of these two clades is currently unknown but is likely to be geographically distant from Sri Lanka. Spawning grounds of the two distinct SJT clades should be identified and conserved.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">tuna</field><field name="subject">skipjack tuna</field><field name="subject">yellowfin tuna</field><field name="subject">population genetics</field><field name="subject">population structure</field><field name="subject">migration</field><field name="subject">fisheries management</field><field name="subject">Sri Lanka</field><field name="subject">Maldives</field><field name="subject">Indian Ocean</field><field name="subject">demography</field><field name="identifier">http://eprints.qut.edu.au/16479/</field><field name="validLink">True</field></doc><doc><field name="title">The Chinese view of nature : tourism in China's scenic and historic interest areas</field><field name="creator">Han, Feng</field><field name="description">Tourism has greatly increased world wide in recent decades, especially in China.  Nature-dominated Scenic and Historic Interest Areas, representative of the Chinese philosophy of the 'oneness of nature and human beings', are the most popular tourism destinations in China. Tourism impacts in these areas have been receiving the attention of heritage landscape conservation. Management actions have largely been determined with an emphasis on natural values. This thesis maintains that values relating to nature are socially and culturally constructed, and that they dynamically change through history. By investigating the social and cultural structures underpinning values related to nature, a macro-history method has been applied to explore the traditional Chinese View of nature from traditional Chinese philosophies and landscape cultures. An instrumental case study method has been applied to explore the contemporary Chinese values of nature. The relationships between traditional values and contemporary values have been identified. It was found that the traditional Chinese values still have a profound influence today, although many aspects have been distorted. Historic high culture in natural areas has been replaced by mass tourism culture and Western values. The research also found that today's values are more socially and politically contested. It has been revealed that there are deep social, cultural, economic and political roots underlying heritage conservation management actions. Changing and contested values have been interpreted from these perspectives. The values inherent in the Chinese View of nature, such as holistic philosophical perspectives, sophisticated Chinese landscape languages, and evolving living landscapes, have been identified. The contributions of these values to relevant theories of environmental philosophy, cultural landscape, national park tourism and heritage conservation have been identified by this research. The implications for multi-cultural dialogues in heritage landscape conservation have been addressed.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">value</field><field name="subject">nature</field><field name="subject">culture</field><field name="subject">scenic and historic interest area</field><field name="subject">landscape</field><field name="subject">tourism</field><field name="subject">authenticity</field><field name="subject">cultural landscape</field><field name="subject">heritage landscape</field><field name="subject">conservation</field><field name="subject">world heritage</field><field name="subject">China</field><field name="identifier">http://eprints.qut.edu.au/16480/</field><field name="validLink">True</field></doc><doc><field name="title">Molecular regulation of calvarial suture morphogenesis and human craniofacial diversity</field><field name="creator">Coussens, Anna Kathleen</field><field name="description">This body of work is concerned with the genetics of craniofacial morphology and specifically with that of the cranial sutures which form fibrous articulations between the calvarial bones. The premature fusion of these sutures, known as craniosynostosis, is a common developmental abnormality and has been extensively utilised here as a tool through which to study the genetics of suture morphogenesis and craniofacial diversity.    Investigations began with a search for polymorphisms associated with normal variation in human craniofacial characteristics. Denaturing High-Performance Liquid chromatography was used to identify polymorphisms in two genes causative for  craniosynostosis by analysing DNA from a large cohort of individuals from four  ethnogeographic populations. A single nucleotide polymorphism in fibroblast growth factor receptor 1 was identified as being associated with variation in the cephalic index, a common measure of cranial shape.    To further, and specifically, investigate the molecular processes of suture morphogenesis gene expression was compared between unfused and prematurely fusing/fused suture tissues isolated from patients with craniosynostosis. Two approaches, both utilising Affymetrix gene expression microarrays, were used to identify genes differentially expressed during premature suture fusion. The first was a novel method which utilised the observation that explant cells from both fused and unfused suture tissue, cultured in minimal medium, produce a gene expression profile characteristic of minimally differentiated osteoblastic cells. Consequently, gene expression was compared between prematurely fused suture tissues and their corresponding in vitro de-differentiated cells. In addition to those genes known to be involved in suture morphogenesis, a large number of novel genes were identified which were up-regulated in the differentiated in vivo state and are thus implicated in premature suture fusion and in vivo osteoblast differentiation.    The second microarray study involved an extensive analysis of 16 suture tissues and compared gene expression between unfused (n=9) and fusing/fused sutures (n=7).  Again, both known genes and a substantially large number of novel genes were identified as being differentially expressed. Some of these novel genes included retinol binding protein 4 (RBP4), glypican 3 (GPC3), C1q tumour necrosis factor 3 (C1QTNF3), and WNT inhibitory factor 1 (WIF1). The known functions of these genes are suggestive of potential roles in suture morphogenesis. Realtime quantitative RT PCR (QRT-PCR) was used to verify the differential expression patterns observed for 11 genes and Western blot analysis and confocal microscopy was used to investigate the protein expression for 3 genes of interest. RBP4 was found to be localised on the ectocranial surface of unfused sutures and in cells lining the osteogenic fronts while GPC3 was localised to suture mesenchyme of unfused sutures.    A comparison between each unfused suture (coronal, sagittal, metopic, and lambdoid) demonstrated that gene expression profiles are suture-specific which, based on the identification of differentially expressed genes, suggests possible molecular bases for the differential timing of normal fusion and the response of each suture to different craniosynostosis mutations. One observation of particular interest was the presence of cartilage in unfused lambdoid sutures, suggesting a role for chondrogenesis in posterior skull sutures which have generally been thought to develop by intramembranous ossification without a cartilage precursor.    Finally, the effects of common media supplements used in in vitro experiments to stimulate differentiation of calvarial suture-derived cells were investigated with respect to their ability to induce in vivo-like gene expression. The response to standard differentiation medium (ascorbic acid + &#946;-glycerophosphate) with and without dexamethasone was measured by both mineralisation and matrix formation assays and QRT-PCR of genes identified in the above described microarray studies. Both media induced collagen matrix and bone nodule formation indicative of differentiating osteoblasts. However, the genes expression profiles induced by both media differed and neither recapitulated the levels and profiles of gene expression observed in vivo for cells isolated from both fused and unfused suture tissues. This study has implications for translating results from in vitro work to the in vivo situation. Significantly, the dedifferentiation microarray study identified differentially expressed genes whose products may be considered candidates as more appropriate osteogenic supplements that may be used during in vitro experiments to better induce in vivo-like osteoblast   differentiation.    This study has made a substantial contribution to the identification of novel genes and pathways involved in controlling human suture morphogenesis and craniofacial diversity. The results from this research will stimulate new areas of inquiry which will one day aid in the development of better diagnostics and therapeutics for craniosynostosis, and other craniofacial and more general skeletal abnormalities.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">craniosynostosis</field><field name="subject">suture morphogenesis</field><field name="subject">skull growth</field><field name="subject">osteoblast differentiation</field><field name="subject">de-differentiation</field><field name="subject">premature suture fusion</field><field name="subject">microarray</field><field name="subject">craniofacial diversity</field><field name="subject">cranial morphology</field><field name="subject">SNP</field><field name="subject">fibroblast growth factor</field><field name="subject">Wnt signalling</field><field name="subject">ephrin/Eph signalling</field><field name="subject">RBP4</field><field name="subject">GPC3</field><field name="subject">C1QTNF3</field><field name="subject">WIF1</field><field name="subject">LEF1</field><field name="subject">SATB2</field><field name="subject">RARRES1</field><field name="identifier">http://eprints.qut.edu.au/16481/</field><field name="validLink">True</field></doc><doc><field name="title">Getting smarter music : a role for reflection in self-directed music learning</field><field name="creator">Lebler, Don</field><field name="description">Conservatoires all over the world are re-examining their educational roles and practices in a changing cultural and economic context, including re-evaluating their function as sites of relevant learning. This dissertation by publication contributes to this re-examination by investigating understandings of assessment, evaluative reflection, the relationship between know-how and knowledge, autonomous learning, community of practice and the student experience of these pedagogies in one Queensland conservatorium.
 
 
 
 The study is presented in the form of a synopsis and five publications, with additional data that will form the basis of further post-doctoral publication. It is focused on non-traditional pedagogical processes operating within a bachelor of popular music program, processes that have been intuited by the academic teacher who is also the author of this dissertation. What these processes have in common is the philosophical rejection of teacher-led pedagogy and an insistence upon, and scaffolding of, self-directed student action and reflection. The aim of the dissertation, in keeping with the rationale for a professional doctorate, is to subject this approach to systematic theoretical and empirical scrutiny, and thereby to further refine and strengthen the practices in terms of their capacity to engage young people in self-directed approaches to quality music making.
 
 
 
 John Biggs's presage/process/product learning model (1999) provides a structure for this systematic evaluation of the pedagogical work. The study understands the learning characteristics that students bring to the program, combined with the structures and pedagogical approaches in place in the program, to be the key presage elements; the learning activities (including assessment as learning) that occur within the program are the key process elements; the key products are the learning outcomes for the students and the ongoing development of the program and pedagogical approaches informed by reflection on empirical data including data collected as part of this research.
 
 
 
 The study demonstrates the significance of recognising and valuing presage and process elements that enable students to perform from the basis of their intuitive know how while being recorded, and then apply their knowledge-based critical reflection skills to an appraisal of their own work and the work of their peers while hearing the recording played back. While not displacing the teacher as mentor and critical friend, this moves responsibility for learning to the student as a self-monitoring, strategic decision-maker about the nature and quality of their learning products. The program requirement that students write meaningfully about the process appears to encourage the embracing of both conscious and unconscious ways of knowing and doing.
 
 
 
 As a documentation of this type of teaching, the study presents an argument for a broader incorporation of student-led pedagogy into higher education in general and
 
 conservatoria in particular. It concludes that aspects of education that enhance students' abilities to learn, including self- and peer assessment, self-directed learning, reflective practice, and both independent and collaborative work that incorporates program-wide learning, are likely to enhance integrated creative practice. This project has made it possible to disseminate a scholarly engagement with such processes through publication in academic and professional contexts.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">learning</field><field name="subject">music-learning</field><field name="subject">self-directed learning</field><field name="subject">scaffolded learning</field><field name="subject">assessment</field><field name="subject">self assessment</field><field name="subject">peer assessment</field><field name="subject">criteria-referenced assessment</field><field name="subject">assessment standards</field><field name="subject">knowledge</field><field name="subject">know-how</field><field name="subject">reflection</field><field name="subject">critical reflection</field><field name="subject">collaboration</field><field name="subject">collaborative learning</field><field name="subject">peer learning</field><field name="subject">peer teaching</field><field name="identifier">http://eprints.qut.edu.au/16482/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis, characterisation and application of organoclays</field><field name="creator">Xi, Yunfei</field><field name="description">This thesis focuses on the synthesis and characterisation of organoclays. X-ray diffraction has been used to study the changes in the basal spacings of montmorillonite clay and surfactant-intercalated organoclays. Variation in the d-spacing was found to be a step function of the surfactant concentration.    Three different molecular environments for surfactant octadecyltrimethylammonium bromide (ODTMA) within the surface-modified montmorillonite are proposed upon the basis of their different decomposition temperatures. High-resolution thermogravimetric analysis (HRTG) shows that the thermal decomposition of  montmorillonite modified with ODTMA takes place in four steps attributing to dehydration of adsorbed water, dehydration of water hydrating metal cations, loss of surfactant and the loss of OH units respectively. In addition, it has shown that the decomposition procedure of DODMA and TOMA modified clays are very different from that of ODTMA modified ones. The surfactant decomposition takes place in several steps in the DODMA and TOMA modified clays while for ODTMA modified clays, it shows only one step for the decomposition of surfactant. Also TG was proved to be a useful tool to estimate the amount of surfactant within the organoclays.    A model is proposed in which, up to 0.4 CEC, a surfactant monolayer is formed between the montmorillonite clay layers; up to 0.8 CEC, a lateral-bilayer arrangement is formed; and above 1.5 CEC, a pseudotrimolecular layer is formed, with excess surfactant adsorbed on the clay surface. While for dimethyldioctadecylammonium bromide (DODMA) and trioctadecylmethylammonium bromide (TOMA) modified clays, since the larger sizes of the surfactants, some layers of montmorillonite are kept unaltered because of steric effects. The configurations of surfactant within these organoclays usually take paraffin type layers. Thermal analysis also provides an indication of the thermal stability of the organoclay as shown by different starting decomposition temperatures.    FTIR was used as a guide to determine the phase state of the organoclay interlayers as determined from the CH asymmetric stretching vibration of the surfactants to provide more information on surfactant configurations. It was used to study the changes in the spectra of the surfactant ODTMA upon intercalation into a sodium montmorillonite.  Surfaces of montmorillonites were modified using ultrasonic and hydrothermal methods through the intercalation and adsorption of the cationic surfactant ODTMA. Changes in the surfaces and structure were characterized using electron microscopy. The ultrasonic preparation method results in a higher surfactant concentration within the montmorillonite interlayer when compared with that from the hydrothermal method. Both XRD patterns and TEM images demonstrate that SWy-2-Namontmorillonite contains superlayers. TEM images of organoclays prepared at high surfactant concentrations show alternate basal spacings between neighboring layers. SEM images show that modification with surfactant will reduce the clay particle aggregation. Organoclays prepared at low surfactant concentration display curved flakes, whereas they become flat with increasing intercalated surfactant.    Fundamentally this thesis has increased the knowledge base of the structural and morphological properties of organo-montmorillonite clays. The configurations of surfactant in the organoclays have been further investigated and three different molecular environments for surfactant ODTMA within the surface-modified montmorillonite are proposed upon the basis of their different decomposition temperatures. Changes in the spectra of the surfactant upon intercalation into clay have been investigated in details. Novel surfactant-modified montmorillonite results in the formation of new nanophases with the potential for the removal of organic contaminants from aqueous media and for the removal of hydrocarbon spills on roads.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">clay</field><field name="subject">organo-clay</field><field name="subject">montmorillonite</field><field name="subject">smectite</field><field name="subject">bentonite</field><field name="subject">isomorphic substitution</field><field name="subject">basal spacing</field><field name="subject">surfactant</field><field name="subject">cation exchange</field><field name="subject">intercalation</field><field name="subject">thermal decomposition</field><field name="subject">dehydration</field><field name="subject">dehydroxylation</field><field name="subject">infrared spectroscopy</field><field name="subject">Fourier transform infrared spectroscopy</field><field name="subject">x-ray diffraction</field><field name="subject">thermogravimetric analysis</field><field name="subject">high-resolution thermogravimetric analysis</field><field name="subject">scanning electron microscopy</field><field name="subject">transmission electron microscopy</field><field name="subject">morphology</field><field name="subject">organic contaminants</field><field name="subject">oil spills</field><field name="subject">sorbents</field><field name="identifier">http://eprints.qut.edu.au/16483/</field><field name="validLink">True</field></doc><doc><field name="title">Technicalities of ageing in place : a case study of the integration of residential care services through the use of information technology (IT) in the changing context of care</field><field name="creator">Ibrahim, Rahimah</field><field name="description">Through a case study about the impact of IT adoption in a residential aged care organisation, this thesis examines the increasing pressure for service integration as mainstreamed through reform policies. Specifically, the research investigates the role of IT in facilitating the 1997 aged care reform agenda of 'ageing in place' focusing on the levels of transformation from the policy context to the organisational/management context, and to the context of service provision by care staff.  A single embedded case study (Yin, 1993) is used in order to meet the general objective to capture the dynamics of the impact of ageing in place in the three social contexts. The research is informed by social constructionism, a theoretical framework that emphasises the significance and effects of language in shaping social realities (Ainsworth, 2001; Hosking, 1999). The framework, therefore, justifies the qualitative analysis of both written (i.e., policy documents) and spoken (i.e., interviews with staff) texts to address meaning in relation to context.  Changing technologies can result in altered societal structures (Betz, 2003) at all levels, from the very complex to the very basic. As such, it is important to understand a few basic premises of technology. First, technology is a human invention to improve the well-being of society (Ayres, 1996). Consequently, technological inventions that improve the quality of life are seen by people as a necessity for modern living. In the case of ageing, modernisation and technological advances effectively resulted in people becoming healthier and living longer (Department of Health and Aged Care [DHAC], 2000). Second, technology is a human means to control nature (Betz, 2003). As such, technological advances can be seen as a modernising process of predicting and regulating the effects of the trends existing in the environment, such as ageing. Ageing in the twenty first century presents a challenge to government's development policies because ageing is depicted as a steady force with a long-term economic impact (Johnson, 1999).  Third, a technology becomes powerful when it is sponsored by the market (Betz, 2003; Hughes, 1983). Unless a technology is backed by business, it lacks the influence on a large scale. Fourth, technology is used to enable change. By using IT, governments, business and the community are co-operating through a paradigm similar to the business sector. As a result, the service environment is shifting towards more business-like approaches. To sustain the changes brought by a different paradigm and modes of operation, the rhetoric of technology is employed.  Therefore, the purpose of the study is to investigate the use of IT in processes of organisational adaptations to reform, which requires the examination of: a) specific meaning of IT as used in long-term care policies for older people since the last structural reform, b) the rationale behind the introduction of a new IT system into a residential care organisation, and c) the meaning of IT as articulated by care staff who have experienced a change in technology.  The first paper represents a rhetorical analysis at the macro or policy level.  There is a significant influence of a global political actor in developing proactive strategies on ageing, which results in a new, multi-organisational approach in delivering government-subsidised services, such as residential care. Three key institutional texts were selected to represent international to local policy development since the time ageing became a global concern. Since then, ageing is also viewed as a human rights issue. Using Burke's pentad, an analytic framework to analyse rhetoric in texts (Stillar, 1998), these institutional texts are seen to employ the rhetoric of 'technology for sustainability' to justify changes to policy approaches that seek long-term viability. Technology, in the name of sustainable development ensures support for economic growth, which balances the long-term effects of population ageing.  The existence of a global force, such as population ageing, allows the intervening powers of the UN in mainstreaming ageing into development policies. Accordingly, it initiates corresponding actions at national (Australian Commonwealth Government) and state (Queensland Government) levels. IT is a medium of communication, knowledge transfer, and standard practice at these levels of actions.    The second paper represents a qualitative analysis at the meso or organisational level. This paper explores the cogent rationale in the introduction of a computer-based, care documentation system in a large residential aged care organisation.  Twenty two staff, from every level of the organisation, were interviewed to get an insight into the role of IT in substantive changes to organisational structure and modes of service provision. Responses from staff indicate external and internal influence that pressured the organisation to change. In the bid to sustain the future of aged care, the industry is changing through the introduction of new structure of service delivery. The Aged Care Structural Reform instigated a shift towards sustainable service provision that is consumer-driven, with a fixed cost compliance mechanism and performance criteria that are tied to funding. Facing the requirement for evidence to corroborate funding, a residential care organisation changed its structure of service delivery by introducing a new strategic direction. IT is part of this new strategic direction, planning, and operations of a changed service environment.    The third paper represents a qualitative analysis at the micro or individual level to examine the impact of IT at frontline service delivery. This study is also based on interviews with twenty-two staff, across the organisational structure; however, this time the focus is more on staff who are involved in providing direct care to older residents at the organisation. The reason behind this is that IT has always been a management tool which handles management priorities such as financial planning and performance monitoring. The themes arising from the interviews indicate discord at the level of service delivery from the introduction of a new technical system. It also points to the idea that staff generally refer to ethical ideas and future promise of the new system.    In summary, these three papers attached to this thesis support the notion that the meaning of technology is socially constructed. First, technology in the aged care sector has particular reference to improving or enhancing the well-being of older people, and in this case, the provision of high quality services that fulfil the needs of older people. Second, IT has an important role in meeting the evidence-based requirement, such as in the use of information in manipulating the use of resources required for the ageing population. Third, the meaning of IT is conceived from the context requiring its use such as the need to use resource efficiently to ensure long-term sustainability, which were emphasised in the last reform. Fourth, IT is used to enable structural changes in organisations to implement generic practices originated from the business sector, requiring the use of strong rhetoric such as balance and future. The limit of this case study is that these dimensions of technology can only be applied to the specific context of aged care and is not generalisable to other political contexts.  However, the strength of the study rests on the macro-, meso- and micro-analysis of the meaning of technology. Therefore, future studies should investigate and compare the dimensions of technology in other contexts.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">residential aged care</field><field name="subject">service integration</field><field name="subject">reform</field><field name="subject">Aged Care Structural Reform 1997</field><field name="subject">information technology (IT)</field><field name="subject">technological advances</field><field name="subject">rhetoric of technology</field><field name="subject">rhetorical analysis</field><field name="subject">Burke&#146;s pentad</field><field name="subject">sustainability</field><field name="subject">ageing in place</field><field name="subject">policy development</field><field name="subject">organisational context</field><field name="subject">service delivery</field><field name="subject">global to local</field><field name="subject">glocal</field><field name="subject">social constructionism</field><field name="subject">qualitative analysis</field><field name="identifier">http://eprints.qut.edu.au/16484/</field><field name="validLink">True</field></doc><doc><field name="title">White writing black : issues of authorship and authenticity in non-indigenous representations of Australian Aboriginal fictional characters</field><field name="creator">Miley, Linda</field><field name="description">This creative practice-led thesis is in two parts - a novella entitled Leaning into the Light and an exegesis dealing with issues for creative writers who are non-Indigenous engaging with Indigenous characters and inter-cultural relationships. The novella is based on a woman's tale of a cross cultural friendship and is set in a Queensland Cape York Aboriginal community over a period of fifteen years.  Leaning into the Light is for the most part set in the late 1960s, and as such tracks some of the social and personal cost of colonisation through its depiction of Indigenous and non-Indigenous relationships within a Christian run mission. In short, Leaning into the Light creates an imaginary space of intercultural relationships that is nevertheless grounded in a particular experience of a 'real' place and time where Indigenous and non-Indigenous subjectivities collide and communicate.    The exegesis is principally concerned with issues of non-Indigenous representation of indigeneity, an area of enquiry and scholarship that is being increasingly theorized and debated in contemporary cultural and literary studies. In this field, two questions raised by Fee (in Ashcroft, Griffiths and Tiffin, 1995) are key concerns in the exegesis.  How do we determine who is a member of the Aboriginal minority group, and can majority members speak for this minority?  The intensification of interest around these issues follows a period of debate in the 1990s which in turn was spawned by the &amp;quotunprecedented politicisation of {Australian} history" (Collins and Davis, 2004, p.5) following the important Mabo decision which overturned the &amp;quotnation's founding doctrine of terra nullius" (ibid, p.2). These debates questioned whether or not non-Aboriginal authors could legitimately include Aboriginal themes and characters in their work (Huggins, 1994; Wheatley, 1994, Griffiths, et al in Tiffin and Lawson, 1994), and covered important political and ethical considerations, at the heart of which were issues of representation and authenticity. Moreover, there were concerns about non-Indigenous authors competing for important symbolic and publishing space with Indigenous authors. In the writing of Leaning into the Light, these issues became pivotal to the representation of character and situation and as such constitute the key points of analysis in the exegesis.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">creative writing</field><field name="subject">non-indigenous authors</field><field name="subject">indigenous fiction</field><field name="identifier">http://eprints.qut.edu.au/16485/</field><field name="validLink">True</field></doc><doc><field name="title">Information security management in Australian universities : an exploratory analysis</field><field name="creator">Lane, Tim</field><field name="description">Australian Universities increasingly rely on Information Technology (IT) systems for essential business operations, including administration, teaching, learning and research. Applying information security to university IT systems is strategically important to maintaining overall business continuity in universities. However, the process of effectively implementing information security management in the university sector is challenging for security practitioners. University environments consist of a cultural mix of academic freedoms, student needs and compliance mandates. Consequently, unique and divergent demands are placed on securing and accessing university IT systems. This research undertook a qualitative based exploratory analysis of information security management in Australian universities. The aims and objectives of the research (represented as the research questions) were to determine:    1) What is the current status of information security management practices in the Australian university sector?  2) What are the key issues and influencing factors surrounding the effectiveness of information security management practices?  3) How could improvements in information security management be achieved?    The findings from the research led to a comprehensive and insightful examination of the current status, issues and challenges facing information security practitioners in Australian universities. The research findings culminated in the development of a Security Practitioner's Management Model. An essential aim of the model is to assist security practitioners to successfully implement and progress information security in the Australian university environment. The research improves current understanding of information security issues and reinforces the pertinence of information security management as a strategically important business function for Australian universities.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">information security</field><field name="subject">management</field><field name="subject">culture of compliance</field><field name="identifier">http://eprints.qut.edu.au/16486/</field><field name="validLink">True</field></doc><doc><field name="title">Identification and characterization of novel candidates for a vaccine against chlamydial genital tract infection</field><field name="creator">Barker, Christopher Jon</field><field name="description">Chlamydia trachomatis is a human pathogen of the genital tract and ocular epithelium. It is an obligate intracellular parasite with a unique biphasic development cycle. C.trachomatis infection is the most common bacterial sexually transmitted disease in industrialized nations. Its ability to cause chronic disease makes it a serious economic burden and health threat to developed and developing countries. Although treatable, approximately 70% of C.trachomatis infections are asymptomatic, potentially leading to the development of chronic sequelae. Furthermore, chlamydial genital tract infection has been associated with an increased risk of cervical cancer and human immunodeficiency virus infection. Consequently, the development of an efficacious vaccine is the most convenient, potentially reliable and cost effective option to control chlamydial infection and disease complications.
 
 
 
 Anti-chlamydial protective immunity is essentially mediated by a T helper, type 1 (Th1), response that is dependent upon the presentation of antigen via major histocompatibility (MHC) class II molecules. While antibody secreting cells are not critical components of the primary effector response, they have been shown to be important for clearance of re-infection. Thus an ideal vaccine would be one capable of inducing both a strong Th1 T cell response and a strong mucosal antibody response. Currently there are very few efficacious vaccine candidates that have been identified and characterized. More specifically, there is only a limited number of known T cell antigens processed and presented by the human leukocyte antigen (HLA) class II molecules. This type of antigen is going to be essential to the development of an efficacious chlamydial vaccine. 
 
 
 
 In this study we have identified a number of unique vaccine candidates using a novel in silico approach. In an attempt to overcome HLA polymorphism the whole chlamydial genome was screened for proteins containing epitopes predicted to bind multiple HLA class II molecules (i.e. predicted &#8216;promiscuous&#8217; T cell epitopes). A wide range of HLA class II molecules were used in this screen to identify vaccine antigens that could potentially offer broad and ethnically balanced population coverage. This analysis identified a number of novel targets and was validated by the identification of a known chlamydial T cell epitope.
 
 
 
 A selection of these target proteins was cloned, expressed and purified. Recombinant protein was screened against serum samples from patients with both acute and chronic chlamydial infections. Two novel targets, hypothetical protein CT425 and ribonucleotide reductase small chain protein (NrdB) were identified as being immunoreactive.
 
 
 
 The in vivo protective efficacy of NrdB was analyzed using a mouse model. CD4+ T cells were harvested from NrdB immunized mice and adoptively transferred to na&#239;ve mice, which were subsequently infected at the genital site. NrdB immunization was found to confer a CD4+ T cell driven degree of protection similar to that seen with CD4+ T cells primed from a live challenge. The adjuvants and route of immunization used ensured immunological responses were initiated at both the systemic and local sites of infection. Immunization elicited a predominant Th1 response with primed T cells producing high levels of interferon gamma, an essential requirement for the development of an efficacious chlamydial vaccine. Furthermore, high titres of antigen specific IgG and IgA were produced following immunization, with sera derived antibodies demonstrating neutralization properties. NrdB is a highly conserved chlamydial protein with an essential role in the replication of chlamydiae and could play a central role in a multi-subunit vaccine against chlamydial genital tract infections.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">chlamydia trachomatis</field><field name="subject">sexually transmitted disease</field><field name="subject">chlamydial genital tract infection</field><field name="subject">anti-chlamydial protective immunity</field><field name="subject">vaccines</field><field name="identifier">http://eprints.qut.edu.au/16487/</field><field name="validLink">True</field></doc><doc><field name="title">Development of an integrated model for assessment of operational risks in rail track</field><field name="creator">Reddy, Venkatarami</field><field name="description">In recent years there has been continuous increase of axle loads, tonnage, train speed, and train length which has increased both the productivity in the rail sector and the risk of rail breaks and derailments. Rail operating risks have been increasing due to the increased number of axle passes, sharper curves, wear-out of rails and wheels, inadequate rail-wheel grinding and poor lubrication and maintenance. Rolling contact fatigue (RCF) and wear are significant problems for railway companies. In 2000, the Hatfield accident in the UK killed 4 people, injured 34 people and led to the cost of &#163; 733 million (AUD$ 1.73 billion) for repairs and compensation. In 1977, the Granville train disaster in Australia killed 83 people and injured 213 people. These accidents were related to rolling contact fatigue, wear and poor maintenance.    Studies on rail wear and lubrication, rolling contact fatigue and inspection and rail grinding analyse and assess the asset condition to take corrective and preventive measures for maintaining reliability and safety of rail track. Such measures can reduce the operational risks and the costs by early detection and prevention of rail failures, rail breaks and derailments. Studies have so far been carried out in isolation and have failed to provide a practical solution to a complex problem such as rail-wheel wearfatigue-lubrication-grinding-inspection for cost effective maintenance decisions. Therefore, there is a need to develop integrated economic models to predict expected total cost and operational risks and to make informed decisions on rail track maintenance.    The major challenges to rail infrastructure and rolling stock operators are to:  1. keep rolling contact fatigue and rail-wheel wear under controllable limits,  2. strike a balance between rail grinding and rail lubrication, and  3. take commercial decisions on grinding intervals, inspection intervals, lubrication placements, preventive maintenance and rail replacements.    This research addresses the development and analysis of an integrated model for assessment of operational risks in rail track. Most significantly, it deals with problems associated with higher axle loads; wear; rolling contact fatigue; rail defects leading to early rail replacements; and rail breaks and derailments. The contribution of this research includes the development of:    failure models with non-homogenous Poisson process and estimation of parameters.  economic models and analysis of costs due to grinding, risks, downtime, inspection and replacement of rails for 23, 12, 18 and 9 Million Gross Tonnes (MGT) of traffic through curve radius 0-300, 300-450, 450-600 and 600-800 m; and application of results from this investigation to maintenance and replacement decisions of rails. Cost savings per meter per year are:    * 4.58% with 12 MGT intervals compared to 23 MGT intervals for 0-300 m  * 9.63% with 12 MGT intervals compared to 23 MGT intervals for 300-450 m  * 15.80% with 12 MGT intervals compared to 23 MGT intervals for 450-600 m  * 12.29% with 12 MGT intervals compared to 23 MGT intervals for 600-800 m.     a lubrication model for optimal lubrication strategies. It includes modelling and economic analysis of rail wear, rail-wheel lubrication for various types of lubricators. Cost effectiveness of the lubricator is modelled, considering the number of curves and the total length of curves it lubricates. Cost saving per lubricator per year for the same curve length and under the same curve radius is:    * 17% for solar wayside lubricators compared to standard wayside lubricators.   simulation model for analysis of lubrication effectiveness. Cost savings per meter per year for:  * 12 MGT grinding interval is 3 times for 0-450 m and 2 times for 450-600 m curve radius with lubrication compared to without lubrication.  * 23 MGT grinding interval is 7 times for 0-450 m and 4 times for 450-600 m curve radius with lubrication compared to without lubrication.   a relative performance model, total curve and segment model.   an inspection model for cost effective rail inspection intervals. Cost savings per year for same track length, curves and MGT of traffic:  * 27% of total maintenance costs with two inspections, compared to one inspection considering risk due to rail breaks and derailments.   a risk priority number by combining probability of occurrence, probability of detection and consequences due to rail defects, rail breaks and derailments.   integrated model combining decisions on grinding interval, lubrication strategies, inspection intervals, rectification strategies and replacement of rails.  Cost saving per meter per year for 12 MGT is:  * 5.41% of total maintenance costs with two inspections, compared to one inspection considering risk due to rail breaks and derailments.  * 45.06% of total maintenance costs with lubrication for two inspections, compared to without lubrication.  Cost saving per meter per year for 23 MGT is:  * 5.61% of total maintenance costs with two inspections, compared to one inspection considering risk due to rail breaks and derailments.  * 68.68% of total maintenance costs with lubrication for two inspections, per year compared to no lubrication.    The thesis concludes with a brief summary of the contributions that it makes to this field and the scope for future research in wear-fatigue-lubrication-grinding-inspection for maintenance of rail infrastructure.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">rail tracks</field><field name="subject">rail operating risks</field><field name="subject">rail wear</field><field name="subject">derailments</field><field name="identifier">http://eprints.qut.edu.au/16488/</field><field name="validLink">True</field></doc><doc><field name="title">Immersive virtual reality learning environment : learning decision-making skills in a virtual reality-enhanced learning environment</field><field name="creator">Yahaya, Ros Aizan</field><field name="description">New advances in computer programming and more powerful technology have opened up new opportunities for learning though immersive virtual reality simulations. This research highlighted the importance of the role of a lecturer in fostering learning in a technology rich learning environment. Undergraduate business studies students worked collectively to try resolve a problem depicted through an immersive simulation involving a burning factory. The simulation provided a rich personal experience that enabled students with lecturer support to generate effective strategies to address the problem.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">activity theory</field><field name="subject">blended learning</field><field name="subject">immersive virtual reality</field><field name="subject">authentic learning environment</field><field name="subject">constructivist learning style</field><field name="subject">situated cognition</field><field name="subject">cognitive apprenticeship</field><field name="subject">technology education</field><field name="subject">business education</field><field name="subject">university teaching</field><field name="subject">ICT</field><field name="identifier">http://eprints.qut.edu.au/16489/</field><field name="validLink">True</field></doc><doc><field name="title">Mapping and modelling the invasion dynamics of Senna obtusifolia at different levels of scale in Australia</field><field name="creator">Dunlop, Elizabeth A.</field><field name="description">The invasion of natural environments by alien species is a significant threat to the ecological integrity of these systems. Senna obtusifolia is an aggressive invasive weed recently introduced to Australia that is having significant impacts on grassland ecosystems on the Cape York Peninsula. Currently the species is inadequately managed and so range expansion continues. The invasion potential of S. obtusifolia in Australia remains unknown, as does much about its behaviour and management in natural systems. This project undertakes extensive mapping and modelling of the current and future distributions and the invasion dynamics of S. obtusifolia in Australia to facilitate early detection of outbreak populations and the development of appropriate management strategies.    The mapping and modelling of S. obtusifolia was conducted at three different scales: continental, landscape and local (population).  To address these spatial scales, eco-climatic modelling, remote sensing analysis, field experimentation and creation of a model of seed fate was undertaken.    Using the climatic preferences of S. obtusifolia displayed internationally, an eco-climatic model (using CLIMEX software) ascertained that S. obtusifolia has a very large invasive potential in Australia. The predicted geographic distribution comprised the entire eastern and northern Australian coastlines, with spread further inland being largely restricted by a lack of moisture. The regional distribution of S. obtusifolia was not successfully delineated using remote sensing technology. Despite possessing favourable traits for detection by remote sensors, poor data quality and inappropriate image scales prevented the weed from being distinguished from other vegetation by multi-spectral satellite imagery and aerial photography. However, the results indicated that refining the data and the techniques used, single S. obtusifolia populations may be detectable in the future.    Investigation of the invasion dynamics of S. obtusifolia at the local scale involved multiple field surveys and manipulative experiments during 2002-2005. Field work indicated that little variation in population characteristics (e.g. stem density, soil seed reserve, seed production) existed within populations, but there was variability across populations and between years: the variation between years was very significant. The vegetation type adjacent to the weed population did not affect population attributes; however less competitive, more open and disturbed environments may better facilitate the invasion. The compartment model of seed fate reflecting S. obtusifolia population dynamics demonstrated that change in annual rainfall was unlikely to explain the variation evident between populations and years. Instead, the rate at which dormancy is broken in seeds and the intensity and regularity of fire provided a better explanation of the weed's population dynamics. Early detection of invaders and the prediction of likely sites of invasion provide the most effective means of preventing future invasions.  How best to achieve these goals still remains largely unknown. The process undertaken in this study was a relatively quick and reliable method for assessing the seriousness of S. obtusifolia, predicting future outbreaks and for providing clues to long term management. The appropriate use of fire, maintaining high interspecific competition and shade, as well reducing the rate at which dormancy is broken in seeds are all possible methods of managing S. obtusifolia.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">competition</field><field name="subject">CLIMEX</field><field name="subject">early detection</field><field name="subject">eco-climatic modelling</field><field name="subject">invasive species</field><field name="subject">population dynamics</field><field name="subject">remote sensing</field><field name="subject">scale</field><field name="subject">seed fate model</field><field name="subject">weed management</field><field name="identifier">http://eprints.qut.edu.au/16490/</field><field name="validLink">True</field></doc><doc><field name="title">Genetic structuring among naturally isolated dune lake populations : a microcosm of evolutionary processes on oceanic islands</field><field name="creator">Duffy, Angela</field><field name="description">Oceanic islands have been used as model systems for studies of evolution and speciation as the range of island sizes coupled with their known geological chronosequence make them ideal systems for the study of spatial and temporal variations in species diversity and distributions. These processes also occur on continental islands and mainland habitats but features of oceanic islands, notably their clearly delimited boundaries, natural isolation and simple geological composition make them more amenable to study.    The perched dune lakes of Fraser Island, Australia share many of the properties of oceanic islands. The naturally isolated formation of the perched lakes, clearly delimited boundaries of the freshwater habitat and phase difference compared to the surrounding, terrestrial environment have significant implications for the biota these lakes support. Inhabitants of the perched dune lakes consist of the aquatic and semi-aquatic descendents of colonisers that were able to traverse a land barrier and survive in the oligotrophic, acidic waters over subsequent generations. Barriers to ongoing gene flow among lake populations, are however likely to be different for species with different life history characteristics. I therefore sought to assess the effects of three different life history characteristics on post-colonisation interpopulation gene flow.    A representative species was selected to represent one of each of the following life history characteristics:  *	Aquatic species confined to lake for entire life cycle - freshwater shrimp Caridina indistincta.  *	Semi-aquatic species capable of terrestrial dispersal - freshwater turtle  Emydura krefftii.  *	Semi-aquatic species capable of aerial dispersal - odonate Orthetrum  Boumiera.    137-250 individuals were sampled per species across six lakes separated by 1-6km.  Regions of the mitochondrial genome were targeted and molecular screening methods developed and employed to assess the relative levels of post-colonisation gene flow among lake populations.    Parsimony analysis of the 25 unique haplotypes identified in the species with no apparent inter-lake dispersal mechanism, the freshwater shrimp Caridina indistincta, demonstrated that there was no sharing of derived haplotypes among lake populations. Star shaped genealogies were identified in four lake populations indicative of a population expansion and mismatch distribution analysis confirmed a recent population expansion estimated to have occurred no more than 200,000 years ago. This demonstrates that each of the perched dune lakes was colonised by  C.indistincta soon after their inception but that no ongoing gene flow among lake populations has occurred.    The population genetic structure of the species assessed which is capable of terrestrial dispersal suggests that although this species of freshwater turtle, Emydura krefftii, is capable of overland dispersal, gene flow among lake populations is limited. Even at the small spatial scale examined in this study, E.krefftii populations displayed a pattern of isolation by distance (r=0.854, p&amp;lt0.03). Nested clade analysis also suggested a pattern of restricted gene flow with some long distance dispersal in recent times with long distance dispersal and a possible range expansion occurring historically.    The species examined in this study that displayed the most extensive gene flow among lake populations was the dragonfly Orthetrum boumiera. No relationship was found between genetic and geographic distance (r= -0.0852, p&amp;gt0.05) and nested clade analysis could not identify a geographical association among haplotypes, indicative of panmixia. While larval life stages of this species are fully aquatic, the winged adult stages of this species appear to be connecting seemingly isolated lake populations, at least at the spatial scale examined here.    The results of this study have demonstrated that these perched dune lakes provide 'island like' models for recent biogeographic processes. The pattern of colonisation and subsequent diversification identified in these populations takes the form of insitu 'genetic radiations' with those populations that are isolated forming monophyletic clades endemic to a single lake. The genetic diversity and endemism identified in this study has occurred over much smaller temporal (&amp;lt500,000 years) and spatial (&amp;lt6.5km) scales than in studies of oceanic island fauna. However, the mode of formation of the perched dune lakes and the implications that their natural isolation and abiotic genesis have for the evolution of colonisers of these unique habitats has resulted in them being analogous to true oceanic islands.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">perched dune lake</field><field name="subject">Fraser Island</field><field name="subject">dispersal</field><field name="subject">Caridina indistincta</field><field name="subject">Emydura krefftii</field><field name="subject">Orthetrum boumiera</field><field name="subject">population genetics</field><field name="subject">oceanic island</field><field name="subject">island biogeography</field><field name="identifier">http://eprints.qut.edu.au/16491/</field><field name="validLink">True</field></doc><doc><field name="title">Biomass burning : particle emissions, characteristics, and airborne measurements</field><field name="creator">Wardoyo, Arinto Yudi</field><field name="description">Biomass burning started to attract attention since the last decade because of its impacts on the atmosphere and the environmental air quality, as well as significant potential effects on human health and global climate change. Knowledge of particle emission characteristics from biomass burning is crucially important for the quantitative assessment of the potential impacts. This thesis presents the results of study aimed towards comprehensive characterization of particle emissions from biomass burning. The study was conducted both under controlled laboratory conditions, to quantify the particle size distribution and emission factors by taking into account various factors which may affect the particle characteristics, and in the field, to investigate biomass burning processes in the real life situations and to examine vertical profile of particles in the atmosphere. To simulate different environmental conditions, a new technique has been developed for investigating particle emissions from biomass burning in the laboratory. As biomass burning may occur in a field at various wind speeds and burning rates, the technique was designed to allow adjustment of the flow rates of the air introduced into the chamber, in order to control burning under different conditions. In addition, the technique design has enabled alteration of the high particle concentrations, allowing conducting measurements with the instrumentations that had the upper concentration limits exciding the concentrations characteristic to the biomass burning.  The technique was applied to characterize particle emissions from burning of several tree species common to Australian forests. The aerosol particles were characterized in terms of size distribution and emission factors, such as PM2.5 particle mass emission factor and particle number emission factor, under various burning conditions. The characteristics of particles over a range of burning phases (e.g., ignition, flaming, and smoldering) were also investigated. The results showed that particle characteristics depend on the type of tree, part of tree, and the burning rate. In particular, fast burning of the wood samples produced particles with the CMD of 60 nm during the ignition phase and 30 nm for the rest of the burning process.  Slow burning of the wood samples produced large particles with the CMD of 120 nm, 60 nm and 40 nm for the ignition, flaming and smoldering phases, respectively. The CMD of particles emitted by burning the leaves and branches was found to be 50 nm for the flaming phase and 30 nm for the smoldering phase, under fast burning conditions. Under slow burning conditions, the CMD of particles was found to be between 100 to 200 nm for the ignition and flaming phase, and 50 nm for the smoldering phase.    For fast burning, the average particle number emission factors were between 3.3 to 5.7 x 1015 particles/kg for wood and 0.5 to 6.9 x 1015 particles/kg for leaves and branches.  The PM2.5 emission factors were between 140 to 210 mg/kg for wood and 450 to 4700 mg/kg for leaves and branches. For slow burning conditions, the average particle number emission factors were between 2.8 to 44.8 x 1013 particles/kg for wood and 0.5 to 9.3 x 1013 particles/kg for leaves and branches, and the PM2.5 emissions factors were between 120 to 480 mg/kg for wood and 3300 to 4900 mg/kg for leaves and branches.    The field measurements were conducted to investigate particle emissions from biomass burning in the Northern Territory of Australia over dry seasons.  The results of field studies revealed that diameters of particles in ambient air emissions were within the size range observed during laboratory investigations.  The laboratory measurements found that the particles released during the controlled burning were of a diameter between 30 and 210 nm, depending on the burning conditions. Under fast burning conditions, smaller particles were produced with a diameter in the range of 30 to 60 nm, whilst larger particles, with a diameter between 60 nm and 210 nm, were produced during slow burning. The airborne field measurements of biomass particles found that most of the particles measured under the boundary layer had a CMD of (83 &#177; 13) nm during the early dry season (EDS), and (127 &#177; 6) nm during the late dry season (LDS). The characteristics of ambient particles were found to be significantly different at the EDS and the LDS due to several factors including moisture content of vegetation, location of fires related to the flight paths, intensity of fires, and burned areas. Specifically, the investigations of the vertical profiles of particles in the atmosphere have revealed significant differences in the particle properties during early dry season and late dry season. The characteristics of particle size distribution played a significant role in these differences.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">biomass burning</field><field name="subject">emission factors</field><field name="subject">ultrafine particles</field><field name="subject">particle number emission</field><field name="subject">particle size distribution</field><field name="subject">particle vertical profile</field><field name="subject">Queensland trees</field><field name="subject">Northern Territory of Australia</field><field name="subject">particle number concentration</field><field name="subject">Northern Territory Australia</field><field name="subject">airborne measurements</field><field name="subject">vertical profile</field><field name="identifier">http://eprints.qut.edu.au/16492/</field><field name="validLink">True</field></doc><doc><field name="title">Collaboration in clinical education : development, implementation and evaluation of an innovative model of clinical education for undergraduate nursing students</field><field name="creator">Nash, Robyn Elizabeth</field><field name="description">Introduction  The purpose of this study was to enhance the prac experience of undergraduate nursing students and registered nursing staff. An innovative model of clinical education, the Clinical Education Unit (CEU) model was developed, implemented and evaluated. Background to the study  Clinical education is a vital component of the undergraduate nursing curriculum. 'Real world' practice provides students with the opportunity to develop the knowledge, attitudes and skills needed to function effectively as a registered nurse. Despite the commitment of universities to produce competent graduates, there has continued debate regarding the preparedness of new graduates for practice as registered nurses.  This has focussed continued attention on the adequacy of students' clinical education and, in particular, on the models used for clinical facilitation/supervision.  There is little published evidence that clearly demonstrates the effectiveness of any of the current models of clinical education or that any particular model is better than any other in achieving quality outcomes (Wellard, Williams and Bethune 2000; Clare, White, Edwards and Van Loon 2002). Hence, as recommended in the recent National Review of Nurse Education (2002), ongoing evaluation of nursing curricula and teaching practice, including clinical education, is clearly warranted. Methods  The study utilised action research methodology to examine the effects of the Clinical Education Unit (CEU) on the quality of clinical prac as experienced by undergraduate nursing students and registered nurses working with the students in wards where they were placed for their practicums. It was undertaken in two iterations or phases: Phase 1 - Development, implementation and initial evaluation of an innovative model of clinical education (the CEU model) and Phase 2 - Refinement and re-evaluation of the CEU model of clinical education. Using focus group discussions and survey questionnaires, qualitative and quantitative data were collected from undergraduate nursing students and clinical nursing staff in conjunction with each iteration of the study.    Results  Phase 1 results indicated that the CEU model was evaluated more positively by students and registered nurses than were the non-CEU models that were used for comparison. This result was demonstrated in the comments of students and registered nurses with regard to the respective models of clinical education and supported by their ratings of the quality of clinical experience through the QPE-Phase questionnaires. A similar trend was found in the results from Phase 2.  The CEU-2 model was again evaluated more positively by students and registered nurses than were the non-CEU models that were used for comparison. Conclusion In summary, the results of this study indicate that the CEU model had a positive impact on the prac experience of students and registered nurses. In both phases of the study, students and registered nurses in wards where the CEU model was being used evaluated the prac experience more positively than did students and registered nurses in wards where non-CEU models were being used.  Two key factors were found to be important in achieving this outcome: the collaborative nature of the CEU model and nursing staff ownership of students' clinical education. These factors provided an operating framework which enabled the development of positive learning environments in the wards where students were placed for prac. Equally important were arrangements for the supervision of students' practice which involved local clinical facilitation and the explicit inclusion of other nursing staff in the ward. Further, continued support from the university to allow the clinical facilitators to take a supernumary role when facilitating students, to provide staff development for clinical education and to support staff on a day-to-day basis during the prac was also important, if not essential. It is proposed that these factors, acting synergistically, promoted enhanced access to learning opportunities for students and improved learning outcomes for students and staff.  The study makes an important contribution to nursing education by providing evidence that can inform future developments in the area of undergraduate clinical education. It has potential benefits for nursing education not only in the local context, but within the international arena as well.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">models of clinical education</field><field name="subject">clinical learning environment</field><field name="subject">clinical supervision</field><field name="subject">clinical placement</field><field name="subject">clinical learning outcomes</field><field name="subject">quality of clinical experience and undergraduate students</field><field name="identifier">http://eprints.qut.edu.au/16493/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis, characterisation and invitro evaluation of PLLA-co-succinic anhydride networks</field><field name="creator">George, Karina Anne</field><field name="description">The biocompatibility and the in vivo degradation of poly(L-lactide), (PLLA)- based materials has prompted much interest in the development of these materials into scaffolds for tissue engineering applications. PLLA-based polymers have been available for use in craniomaxillofacial surgery since 1991. Usually, a plate or sheet of the polymer is placed in or over a defect in the bone. Ideally the bone will use the polymer as a support to repair the defect and as the polymer degrades, the bone will continually remodel, so that the loss of mass and mechanical strength of the polymer correlates with the increase in the mass and strength of the new bone. However, this is an ideal situation, and is not always observed in practice.    The aim of this work is to develop PLLA-based materials that should encourage bone growth onto the material and allow control over the rate of degradation. PLLA-co-succinic anhydride networks were synthesised and the mineralisation and degradation of these materials were evaluated in vitro. The synthesis of these networks, involved the polymerisation of 4-arm star PLLA polymers, which were coupled through their end groups with succinic anhydride.    The low molecular weight star PLLA polymers were synthesised using calcium hydride and pentaerythritol as initiator and co-initiator respectively. Calcium hydride was preferred to stannous octoate in this study as there is concern over the release of tin-containing when the polymer is implanted. As only very limited studies have been directed into the polymerisation and resulting polymers formed using calcium hydride, this was a major focus of the study. The identification of hydrogen in the reaction tubes was evidence that calcium alkoxide, formed from the reaction of  pentaerythritol and calcium hydride, is the actual initiating species for the ring opening polymerisation. In situ FT-Raman spectroscopy was used as a tool to monitor the reaction process and was found to be a convenient and reliable method for obtaining information about the polymerisation kinetics. Analysis of the FTRaman kinetic curves, along with analysis of products by GPC, polarimetry and NMR spectroscopy showed that the polymerisation was 'quasi-living' depending on the ratio of pentaerythritol and calcium hydride in the system. Furthermore, both the degree of transesterification and racemisation of polymers synthesised in optimised reactions were low.    The PLLA-co-succinic anhydride networks were synthesised by coupling of hydroxyl-terminated PLLA star polymers with succinic anhydride (one-pot reaction) and by coupling hydroxyl-terminated PLLA stars with succinic anhydride-terminated PLLA star polymers (two-pot reaction), using a carbodiimide, EDC to mediate the esterification. The one-pot reaction produced polymers with high gel fractions and high conversion of functional groups in the gel, whereas the gel fraction and conversion of functional groups was lower in the two-pot reaction. For the networks synthesised in the one-pot reaction, the molecular weight between crosslinks was controlled by the length of the PLLA polymer arms. The networks synthesised were characterised by FTIR-ATR spectroscopy, SEM, contact angle and by swelling.    The extent of mineralisation of the PLLA-co-succinic anhydride networks in simulated body fluid (SBF) after 14 days was greater than the mineral deposition on the high molecular weight PLLA reference polymer. The degradation of the networks was carried out under accelerated conditions in 0.1 M NaOH at 37 degrees Celsius. All networks degraded much more slowly than the high molecular weight linear PLLA reference sample. The rate of degradation was found to be dependent on the crystallinity of the polymer chains, with the more crystalline networks degrading at a faster rate, while the location of the degradation, surface or bulk, was controlled by the crosslink density, showing that the degradation is 'tuneable'.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">craniomaxillofacial surgery</field><field name="subject">poly(L-lactide)</field><field name="subject">(PLLA)- based materials</field><field name="identifier">http://eprints.qut.edu.au/16494/</field><field name="validLink">True</field></doc><doc><field name="title">Dendritic cell mRNA delivery strategies for ovarian cancer immunotherapy</field><field name="creator">Maxwell, Tammy Joy</field><field name="description">Ovarian cancer, with the highest mortality rate amongst gynaecological malignancies in Australia, is the eighth most common cancer and the fifth cause of cancer-related deaths in women.  Currently, five-year survival for women diagnosed with ovarian cancer is only 40 % and despite many patients experiencing remission, approximately 80 % of them will relapse due to residual micrometastasis.  The limited impact of standard therapies on the prognosis for recurrent chemotherapy-resistant disease and the need to identify less toxic alternatives has motivated the development of strategies to combat the aggressive and life-threatening burden of ovarian cancer.  A novel therapy against cancer utilises dendritic cells (DC), potent antigen presenting cells, to deliver tumour antigens to the immune system for the stimulation of cytotoxic T-lymphocyte (CTL) responses. DC immunotherapy has been used for the treatment of patients with ovarian cancer; however, clinical responses after the injection of antigen-loaded DC have been disappointing.  Therefore, the identification of additional tumour associated antigens (TAA) is required.  A TAA highly expressed in ovarian cancer cells, CA125, is a candidate target for DC-based immunotherapy.  Initially, CTL responses to CA125 were studied in the context of HLA-A*0201.  CD8+ T-cell responses specific for CA125 peptides (with high affinity for the MHC class I) were generated from cultures initiated with peptide-loaded monocyte-derived DC (Mo-DC).  To expand the evaluation of T-cell recognition of CA125 to non-HLA-A*0201 individuals, messenger RNA (mRNA) was investigated as an antigen-loading vehicle.  RNA encodes for the repertoire of epitopes presented by the TAA, potentially inducing immune responses in the context of multiple MHC class I and II molecules to known/unknown antigens.  One focus of this study was to investigate a novel mRNA transfection system utilising mannan for the delivery of mRNA into DC.  Initially the immunomodulating effect of mannan was examined in terms of DC activation.  Mannan induced the phenotypic and functional maturation of immature Mo-DC in vitro.  Next, the ability of oxidised mannan (OxM) linked to mRNA was investigated for its capacity to deliver enhanced green fluorescent protein (EGFP) mRNA into DC.  We observed high transfection efficiencies in the murine and in human DC systems using low mRNA concentrations, in the absence of significant cell viability impairment.  Interestingly, upon mRNA delivery via the OxM-PEI complex, DC maturation was induced to considerably higher levels as compared with that achieved with electroporation and non-transfected controls, this was measured by phenotype (CD83) and IL-12 secretion.  Within this study, OxM-PEI did not deliver TAA encoding mRNA into DC for the stimulation of CTL.  In summary, mannan is a novel strategy to deliver mRNA and a strong maturation signal simultaneously to human Mo-DC.  The functional capacity of this system requires further investigation before it can be considered for clinical use. Electroporation has evolved as a superior method for mRNA delivery into DC as reported in the literature.  Therefore, a comprehensive study was performed encompassing the critical issues associated with transfection efficiency, in order to standardise an electroporation protocol for use in DC immunotherapy schedules.  EGFP was used as a model antigen to optimise mRNA uptake by Mo-DC by monitoring the expression of the reporter gene by FACS analysis.  Influenza matrix protein 1 mRNA was, then, utilised as a model antigen for MHC class I restricted antigen presentation, for confirmation of the optimised loading parameters.  The efficiency of this delivery system was assessed using CA125 mRNA in stimulating antigen-specific T-cell responses in PBMC of healthy individuals.  CD4+ and CD8+ antigen-specific T-cell responses were generated recognising CA125 mRNA loaded Mo-DC and also ovarian cancer cell lines endogenously expressing CA125. This study has identified CA125 specific T-cell responses in healthy donors, allowing further investigation into the potential for its use as a candidate TAA in ovarian cancer immunotherapy.  Furthermore, the use of Mo-DC transfected with mRNA encoding TAA is a promising strategy for the delivery of TAA in the generation of antigen-specific T-cell responses.  In summary, the results gained from this PhD thesis should be taken into consideration when designing future DC immunotherapy strategies to combat one of the leading causes of cancer mortality in women, ovarian cancer.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">antigen</field><field name="subject">cancer</field><field name="subject">cytotoxic t-lymphocytes</field><field name="subject">dendritic cells</field><field name="subject">immunotherapy</field><field name="subject">ovarian cancer</field><field name="subject">RNA</field><field name="identifier">http://eprints.qut.edu.au/16495/</field><field name="validLink">True</field></doc><doc><field name="title">Formatting and Change in East Asian Television Industries: Media Globalization and Regional Dynamics</field><field name="creator">Lim, Wei Ling Tania Patricia</field><field name="description">Television is increasingly both global and local. Those television industries discussed in this thesis transact in an extensive neo-network of flows in talents, financing, and the latest forms of popular culture. These cities attempt to become media capitals but their status waxes and wanes, depending on their success in exporting their Asian media productions. What do marital arts dramas, interactive game-shows, children's animation and teenage idol soap operas from East Asian television industries have in common? Through the systematic use of TV formatting strategies, these television genres have become the focus for indigenous cultural entrepreneurs located in the East Asian cities of Hong Kong, Singapore and Taipei to turn their local TV programmes into tradable culture.    This thesis is a re-consideration of the impact of media globalisation on Asian television that re-imagines a new global media order. It suggests that there is a growing shift in perception and trade among once-peripheral television industries that they may be slowly de-centring Hollywood's dominance by inserting East Asian popular entertainment into familiar formats or cultural spaces through embracing global yet local cultures of production.    While TV formats like Survivor, Millionaire, Big Brother and American Idol have become profitable and powerful franchises globally, in East Asia, the size of TV format trade is actually eclipsed by the regional trade in East Asian popular cultural commodities from martial arts novels and films, manga and romantic fiction, to popular music. These commodities have become the source of remaking local television culture into tradable cultures as local TV programmes use formatting practices to circulate within their region. The many faces of formatting in television are explored through four case studies - from Hong Kong (TVB's Heaven Sword and Dragon Sabre), Singapore (Robert Chua Productions' Everyone Wins, Peach Blossom Media's Tomato Twins) and Taipei (Comic Ritz Production's Meteor Garden). Conceptualised as Asian media productions, these TV programmes are sites for examining individual agency, the network flows of popular culture and structural changes of their respective broadcasting fields.    This thesis argues that TV formatting practices can become a currency for neo-networked media producers to create a medium of cultural exchange that sets up the possibility for a common market for cultural trade in East Asia. However, the ease with which TV formatting practices and re-sale of TV programmes are copied lower barriers for competition and often this tends toward over production. Over-exposure kills many new genres of production and discourages investment in the research and development component of creating TV formats for trade. Change in East Asian television industries is also aided by media conglomeration, global access through satellite TV, the Internet and increasingly digital entertainment, media de-regulation and pro-development policies.    A number of factors and conditions that accompany the rise of TV formatting in East Asia (such as the role of independents vis-a-vis big local players, the emergence of copyright issues and marketing celebrities) contribute to the innovations that result from adapting formatting practices to local contexts, and suggest how each city's television industry attempts to address the rise of tradable cultural commodities that are increasingly made for pan-Asian consumption.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">circuit of cultural production</field><field name="subject">East Asian popular culture</field><field name="subject">television industries</field><field name="subject">field of broadcasting</field><field name="subject">formatting</field><field name="subject">local knowledge</field><field name="subject">media capitals</field><field name="subject">neo-networks</field><field name="subject">regional dynamics</field><field name="subject">tv formats</field><field name="subject">martial arts dramas</field><field name="subject">teenage idol soap operas</field><field name="subject">game-shows</field><field name="identifier">http://eprints.qut.edu.au/16496/</field><field name="validLink">True</field></doc><doc><field name="title">Disturbance monitoring in distributed power systems</field><field name="creator">Glickman, Mark</field><field name="description">Power system generators are interconnected in a distributed network to allow sharing of power. If one of the generators cannot meet the power demand, spare power is diverted from neighbouring generators. However, this approach also allows for propagation of electric disturbances. An oscillation arising from a disturbance at a given generator site will affect the normal operation of neighbouring generators and might cause them to fail. Hours of production time will be lost in the time it takes to restart the power plant. If the disturbance is detected early, appropriate control measures can be applied to ensure system stability. The aim of this study is to improve existing algorithms that estimate the oscillation parameters from acquired generator data to detect potentially dangerous power system disturbances.    When disturbances occur in power systems (due to load changes or faults), damped oscillations (or &amp;quotmodes") are created. Modes which are heavily damped die out quickly and pose no threat to system stability. Lightly damped modes, by contrast, die out slowly and are more problematic. Of more concern still are &amp;quotnegatively damped" modes which grow exponentially with time and can ultimately cause the power system to fail. Widespread blackouts are then possible. To avert power system failures it is necessary to monitor the damping of the oscillating modes. This thesis proposes a number of damping estimation algorithms for this task. If the damping is found to be very small or even negative, then additional damping needs to be introduced via appropriate control strategies.    This thesis presents a number of new algorithms for estimating the damping of modal oscillations in power systems. The first of these algorithms uses multiple orthogonal sliding windows along with least-squares techniques to estimate the modal damping. This algorithm produces results which are superior to those of earlier sliding window algorithms (that use only one pair of sliding windows to estimate the damping). The second algorithm uses a different modification of the standard sliding window damping estimation algorithm - the algorithm exploits the fact that the Signal to Noise Ratio (SNR) within the Fourier transform of practical power system signals is typically constant across a wide frequency range. Accordingly, damping estimates are obtained at a range of frequencies and then averaged. The third algorithm applied to power system analysis is based on optimal estimation theory. It is computationally efficient and gives optimal accuracy, at least for modes which are well separated in frequency.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">distributed power system</field><field name="subject">power system disturbance</field><field name="subject">power system oscillation</field><field name="subject">white noise</field><field name="subject">coloured noise</field><field name="subject">damping factor</field><field name="subject">mean-square error</field><field name="subject">Cramer-Rao bound</field><field name="subject">orthogonal windows</field><field name="subject">least-squares techniques</field><field name="subject">spectral averaging</field><field name="subject">optimal estimation theory</field><field name="subject">Prony analysis</field><field name="identifier">http://eprints.qut.edu.au/16497/</field><field name="validLink">True</field></doc><doc><field name="title">Jinx infinity and the conundrum of myth</field><field name="creator">Cameron, Donna Maree</field><field name="description">The myth, Echo and Narcissus, is retold in a modern context in my play Jinx Infinity.  The accompanying exegesis examines the techniques I employed in writing this piece with reference also to two other plays I have written from myth. This exploration seeks to determine the fine balance between focusing or relying on the myth and the actuality of writing a dramatic text to be performed on stage by actors in front of a live audience. I was able to divide the results from the examination of my writing process into a ten-step guideline or template. The question of balance is addressed throughout the guidelines but becomes particularly vital in the final step, when the playwright is advised to forget the myth in order to ensure the established principles of playwriting are adhered to. If these principals are present and the essence of the ancient myth is inherent, then the final product should be a successful play containing a universal theme that will translate through the ages.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">playwriting</field><field name="subject">myth</field><field name="subject">Narcissus</field><field name="subject">Echo</field><field name="subject">translation</field><field name="subject">adaptation</field><field name="subject">technique</field><field name="identifier">http://eprints.qut.edu.au/16498/</field><field name="validLink">True</field></doc><doc><field name="title">Aristophanes to Fo : conventions of political satire in Western theatre</field><field name="creator">Guy, Bette Margaret</field><field name="description">Aristophanes to Fo is a study of the principal comedic conventions of Aristophanes' political satire and their relationship to contemporary political satire. A template of these principal conventions is tabulated. This is then compared to, and contrasted with, conventions used in subsequent plays in the genre of political satire, including one written as the practice component of this exegesis. This process determines the influence of Aristophanic conventions on political satire from 4th century BCE Greece to the modern era. There is an analytical emphasis on three 20th century plays as case studies and on my play, Soft Murder, which is case study number four.    At the core of the research is the hypothesis that Aristophanic comedic conventions are still relevant to the genre of political satire in contemporary theatre. To retain relevance the genre should be a discourse on a situation or event that has social as well as political meaning to its audience and its presentation should have entertainment value for the culture of the time. Soft Murder is a fundamental part of this process and is written concurrently with the research component.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Aristophanes</field><field name="subject">comedic conventions</field><field name="subject">Dario Fo</field><field name="subject">political satire</field><field name="subject">war propaganda</field><field name="identifier">http://eprints.qut.edu.au/16499/</field><field name="validLink">True</field></doc><doc><field name="title">Modelling passenger mode choice behaviour using computer aided stated preference data</field><field name="creator">Khan, Omer Ahmed</field><field name="description">Redland Shire Council (RSC) has recently completed the preparation of Integrated Local Transport Plan (ILTP) and started its implementation and monitoring program. One of the major thrusts of the ILTP is to reduce the car dependency in the Shire and increase the shares of sustainable environmental-friendly travelling modes, such as walking, cycling and public transport. To achieve these objectives, a mathematical model is needed that is capable of modelling and forecasting the travelling mode choice behaviour in the multi modal environment of Redland Shire. Further, the model can be employed in testing the elasticity of various level-of-service attributes, under a virtual travel environment, as proposed in the ILTP, and estimating the demand for the new travelling alternatives to private car, namely the bus on busway, walking on walkway and cycling on cycleway. The research estimated various nested logit models for different trip lengths and trip purposes, using the data from a stated preference (SP) survey conducted in the Shire. A unique computer assisted personal interviewing (CAPI) instrument was designed, using both the motorised (bus on busway) and non-motorised travelling modes (walking on walkway and cycling on cycleway) in the SP choice set. Additionally, a unique set of access modes for bus on busway was also generated, containing hypothetical modes, such as secure park and ride facilities and kiss and ride drop-off zones at the busway stations, walkway and cycleway facilities to access the busway stations and a frequent and integrated feeder bus network within the Shire. Hence, this study created a totally new virtual travel environment for the population of Redland Shire, in order to record their perceived observations under these scenarios and develop the mode choice models.    From the final model estimation results, it was found that the travel behaviour forecasted for regional trip-makers is considerably different from that of local trip-makers. The regional travellers for work, for instance, were found not to perceive the non-motorised modes as valid alternatives to car, possibly due to longer trip lengths. The value of time (VoT) determined for local work trip-makers (16.50 A$/hr) was also found to be higher than that of regional work trip-makers (11.70 A$/hr).    From the survey analysis, a big part of the targeted population was found to be car captives, who are not likely to switch from cars to public transport; even if a more efficient transit infrastructure is implemented. In the past, the models have been generally calibrated using the mode choice survey data only, while that of the captive users were ignored. This yields a knowledge gap in capturing the complete travel behaviour of a region, since the question of what particular biases can be involved with each model estimation parameter by the captives remain unresolved. In this research, various statistical analyses were performed on the car captive users' data by categorising them into various trip characteristics and household parameters, in order to infer the relative influence of the car captive population on the travel behaviour of the study area. The outcomes of the research can assist the policy makers in solving the strategic issues of transit planning, including the future development of a busway corridor, with an efficient transit access mode network. The research findings can also be utilised in evaluating the feasibility of developing walkways and cycleways in the Shire, along with appraising the relative influence of car captive users on the travel behaviour forecasts for the study area.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">mode choice modelling; stated preference survey; CAPI; captive analysis; busway; walkway; cycleway; access modes</field><field name="identifier">http://eprints.qut.edu.au/16500/</field><field name="validLink">True</field></doc><doc><field name="title">Separated fathers : generativity, grief, and mental health</field><field name="creator">McKeering, Helen Margaret</field><field name="description">Mental health disorders are highest among adults who are separated and divorced, with 23% of men in this group reporting a mental illness. Separated men are more likely to commit suicide compared with married men. In Australia, there are over 53,100 divorces per annum, involving almost 50,000 children. To date, little research has been conducted on the mental health of separated men who are fathers.    Aims: Using a pilot qualitative study, parenting and health issues reported by 23 south-east Queensland separated fathers were examined. The pilot study informed the selection of correlates and measurements for the quantitative study. The aims of the subsequent quantitative study of 80 Queensland separated fathers were to examine: (1) how postseparation stressors, conflict with the ex-partner, access to children, and generativity impact on fathers' grief; and (2) how grief impacts on the mental health of separated fathers.    Model: Variables correlating with separated fathers' grief and mental health were entered into the health model proposed by Bartholomew, Parcel, and Kok (1995). Generativity (caring for others and providing support for the next generation) was a key construct in this research.    Results: Results of grief analyses, as measured by the Separated Fathers Grief Scale, indicated that the more generative a separated father, and the fewer and less intense the stressors in his life, the less his grief. A grieving father's access to his children and his perception of his financial insecurity correlated with alcohol abuse, conflict with his expartner and stressors in his life. Parenting concerns were the predominant factor affecting conflict with the ex-partner and stressors for separated fathers. Results indicate that a generative father with a positive perception of his financial security and few stressors had low levels of depression anxiety and stress, unless he was unable to resolve his grief over separation from his children.    Implications for Public Health: For separated fathers, findings that increased generativity serves as a preventive for grief and mental health problems, support the potential benefit of educational programs utilising an adult developmental approach. Social and legislative changes are required to ensure that: fathering is given equal importance to mothering; consensual rather than adversarial legal processes are promoted; and equitable maintenance and financial planning strategies are promoted to increase the financial security of all separated parents and their children.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">separated fathers</field><field name="subject">generativity</field><field name="subject">stressors</field><field name="subject">conflict</field><field name="subject">access</field><field name="subject">grief</field><field name="subject">depression</field><field name="subject">mental health</field><field name="identifier">http://eprints.qut.edu.au/16501/</field><field name="validLink">True</field></doc><doc><field name="title">Translation of small-plot scale pollutant build-up and wash-off measurements to urban catchment scale</field><field name="creator">Egodawatta, Prasanna Kumarasiri</field><field name="description">Accurate and reliable estimations are the most important factors for the development of efficient stormwater pollutant mitigation strategies. Modelling is the primary tool used for such estimations. The general architecture of typical modelling approaches is to replicate pollutant processes along with hydrologic processes on catchment surfaces. However, due to the lack of understanding of these pollutant processes and the underlying physical parameters, the estimations are subjected to gross errors. Furthermore, the essential requirement of model calibration leads to significant data and resource requirements. This underlines the necessity for simplified and robust stormwater pollutant estimation procedures.    The research described in this thesis primarily details the extensive knowledge developed on pollutant build-up and wash-off processes. Knowledge on both build-up and wash-off were generated by in-depth field investigations conducted on residential road and roof surfaces. Additionally, the research describes the use of a rainfall simulator as a tool in urban water quality research. The rainfall simulator was used to collect runoff samples from small-plot surfaces. The use of a rainfall simulator reduced the number of variables which are common to pollutant wash-off.    Pollutant build-up on road and roof surfaces was found to be rapid during the initial time period and the rate reduced when the antecedent dry days increase becoming asymptote to a constant value. However, build-up on roofs was gradual when compared to road surfaces where the build-up on the first two days was 66% of the total build-up. Though the variations were different, it was possible to develop a common replication equation in the form of a power function for build-up for the two surface types with a as a multiplication coefficient and b as a power coefficient. However, the values for the two build-up equation coefficients, a, and b were different in each case. It was understood that the power coefficient b varies only with the surface type. The multiplication coefficient varies with a range of parameters including land-use and traffic volume. Additionally, the build-up observed on road surfaces was highly dynamic. It was found that pollutant re-distribution occurs with finer particles being removed from the surface thus allowing coarser particles to build up. This process results in changes to the particle size composition of build-up.  However, little evidence was noted of re-distribution of pollutants on roof surfaces.  Furthermore, the particulate pollutants in both road and roof surfaces were high in adsorption capacity. More than 50% of the road and more than 60% of the roof surface particulates were finer than 100 &#956;m which increases the capacity to adsorb other pollutants such as heavy metals and hydrocarbons. In addition, the samples contained a significant amount of DOC which would enhance the solubility of other pollutants.    The wash-off investigations on road and roof surfaces showed a high concentration of solid pollutants during the initial part of events. This confirmed the occurrence of the 'first flush' phenomenon. The observed wash-off patterns for road and roof surfaces were able to be mathematically replicated using an exponential equation. The exponential equation proposed is a modified version of an equation proposed in past research. The modification was primarily in terms of an additional parameter referred to as the 'capacity factor' (CF). CF defines the rainfall's ability to mobilise solid pollutants from a given surface. It was noted that CF varies with rainfall intensity, particle size distribution and surface characteristics. Additional to the mathematical replication of wash-off, analysis further focused on understanding the physical processes governing wash-off. For this, both particle size distribution and physicochemical parameters of wash-off pollutants were analysed. It was noted that there is little variation in the particle size distribution of particulates in wash-off with rainfall intensity and duration. This suggested that particle size is not an influential parameter in wash-off. It is hypothesised that the particulate density and adhesion to road surfaces are the primary criteria that govern wash-off. Additionally, significantly high pollutant contribution from roof surfaces was noted. This justifies the significance of roof surfaces as an urban pollutant source particularly in the case of first flush.    This dissertation further describes a procedure to translate the knowledge created on pollutant build-up and wash-off processes using small-plots to urban catchment scale.  This leads to a simple and robust urban water quality estimation tool. Due to its basic architecture, the estimation tool is referred to as a 'translation procedure'. It is designed to operate without a calibration process which would require a large amount of data. This is done by using the pollutant nature of the catchment in terms of buildup and wash-off processes as the basis of measurements. Therefore, the translation procedure is an extension of the current estimation techniques which are typically complex and resource consuming. The use of a translation procedure is simple and based on the graphical estimation of parameters and tabular form of calculations. The translation procedure developed is particularly accurate in estimating water quality in the initial part of runoff events.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">stormwater quality modelling</field><field name="subject">pollutant build-up</field><field name="subject">pollutant wash-off</field><field name="subject">urban water quality</field><field name="subject">rainfall simulation</field><field name="identifier">http://eprints.qut.edu.au/16502/</field><field name="validLink">True</field></doc><doc><field name="title">Towards a precise understanding of service properties</field><field name="creator">O'Sullivan, Justin James</field><field name="description">This thesis addresses the question of what would be a domain independent taxonomy that is capable of representing the non-functional properties of conventional, electronic and web services. We cover all forms of services, as we prefer not to make any distinction between the three forms. Conventional service descriptions, such as newspaper advertisements, are rich in detail, and it is this richness that we wish to make available to electronic and web service descriptions. In a conventional service context, when we ask a service provider for details, perhaps by phoning the service provider, we are seeking ways to assist with decision making. It is this same decision making or reasoning that we wish to be available to electronic services. Historically, services have always been distinguished according to some criteria of a service requestor. Examples are price, payment alternatives, availability and security. We are motivated to ensure that the criteria used to evaluate conventional services are also available for electronic and web services. We believe that the ability to richly and accurately describe services has significant applicability in the areas of electronic service discovery, dynamic service composition, service comparison, service optimisation, and service management. In particular, the increased level of descriptive depth will also facilitate more thorough decision-making by a service requestor. Whilst we acknowledge the importance of service functionality, this thesis is primarily concerned with the non-functional properties of services. A service is not a function alone. It is a function performed on your behalf at a cost. And the cost is not just some monetary price; it is a whole collection of limitations. This thesis is all about these. We believe that to accurately represent any service, a description requires information relating to both the functionality and the associated constraints. We consider these constraints over the functionality of the service to be non-functional properties. We believe that a service description is only complete once the non-functional aspects are also expressed. We undertook a significant analysis of services from numerous domains. From our analysis we compiled the non-functional properties into a series of 80 conceptual models that we have categorised according to availability (both temporal and locative), payment, price, discounts, obligations, rights, penalties, trust, security, and quality. Our motivation is to provide a theoretical basis for automated service discovery, comparison, selection, and substitution. The need to describe a service is analogous with labelling for goods or products. Product labelling occurs for the safety and benefit of purchasers. Why is the same labelling not afforded for the benefit of service requestors?</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">non-functional properties</field><field name="subject">service description</field><field name="subject">web services</field><field name="subject">service taxonomy</field><field name="subject">service semantics</field><field name="identifier">http://eprints.qut.edu.au/16503/</field><field name="validLink">True</field></doc><doc><field name="title">Auditory localisation : contributions of sound location and semantic spatial cues</field><field name="creator">Yao, Norikazu</field><field name="description">In open skill sports and other tasks, decision-making can be as important as physical performance. Whereas many studies have investigated visual perception there is little research on auditory perception as one aspect of decision making. Auditory localisation studies have almost exclusively focussed on underlying processes, such as interaural time difference and interaural level difference. It is not known, however, whether semantic spatial information contained in the sound is actually used, and whether it assists pure auditory localisation. The aim of this study was to investigate the effect on auditory localisation of spatial semantic information. In Experiment One, this was explored by measuring whole body orientation to the words &amp;quotLeft", &amp;quotRight", &amp;quotBack", &amp;quotFront" and &amp;quotYes", as well as a tone, each presented from left right, front and back locations. Experiment Two explored the effect of the four spatial semantic words presented either from their matching locations, or from a position rotated 20 degrees anticlockwise. In both experiments there were two conditions, with subjects required to face the position indicated by the sound location, or the meaning of the word. Movements of the head were recorded in three dimensions with a Polhemus Fastrak system, and were analysed with a custom program. Ten young adult volunteers participated in each experiment. Reaction time, movement time, initial rotation direction, rotation direction at peak velocity, and the accuracy of the final position were the dependent measures. The results confirmed previous reports of confusions between front and back locations, that is, errors about the interaural axis. Unlike previous studies, many more back-to-front than front-toback errors was made. The experiments provided some evidence for a spatial Stroop interference effect, that is, an effect on performance of conflicting information provided by the irrelevant dimension of the stimulus, but only for reaction time and initial movement direction, and only in the Word condition. The results are interpreted using a model of the processes needed to respond to the stimulus and produce an orienting movement. They suggest that there is an asymmetric interference effect in which auditory localisation can interfere with localisation based on semantic content of words, but not the reverse. In addition, final accuracy was unaffected by any interference, suggesting that these effects are restricted to the initial stages of response selection.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">auditory localization</field><field name="subject">spatial Stroop effect</field><field name="subject">stimulus response compatibility</field><field name="subject">semantic processing</field><field name="subject">information processing</field><field name="subject">response selection</field><field name="subject">reaction time</field><field name="subject">orienting</field><field name="identifier">http://eprints.qut.edu.au/16504/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis of polycaprolactone polymers for bone tissue repair</field><field name="creator">Colwell, John Michael</field><field name="description">Polycaprolactone (PCL) is a biodegradable synthetic polymer that is currently used in a number of biomedical applications.  A number of concerns have been raised over the toxicity of initiators commonly employed for the synthesis of PCL.  Therefore, more biocompatible initiators have been studied.  The biocompatibility of PCL, itself, is adequate; however, improved bioactivity is desirable for several applications.  Copolymerisation, and incorporation of bioactive fillers can both be used as ways of enhancing the bioactivity of PCL.  Therefore, the global objective of this project was to enhance the bioactivity of PCL by copolymerisation of PCL with poly(ethylene glycol) (PEG) using a biocompatible calcium-based initiator.  This calcium-initiator was expected to leave potentially bioactive calcium-initiator residues in the synthesised copolymers.  A study of the ring-opening polymerisation of epsilon-caprolactone (CL) in the presence of a poly(ethylene glycol) (PEG) / calcium hydride (CaH2) co-initiation system was performed.  Polymerisation kinetics were monitored by following the degree of conversion of CL by Fourier transform-Raman (FT-Raman) spectroscopy and 1H nuclear magnetic resonance spectroscopy (NMR).  Resultant PCL-b-PEG-b-PCL (PCL/PEG/PCL) triblock copolymers were analysed by NMR and gel permeation chromatography (GPC). The observed rates of polymerisation for the synthesis of PCL/PEG/PCL triblock copolymers using the PEG / CaH2 co-initiator were much lower than expected.  1H NMR and Raman microspectroscopy analysis showed that the concentration of the active calcium-PEG alkoxide was much lower than the initial feed concentration of PEG.  Even so, the molecular weight of PCL/PEG/PCL triblock copolymers could be predicted from the CL : PEG feed ratio.  This was found to be due to a fast reversible transfer process.    Inductively coupled plasma-atomic emission spectroscopy (ICP-AES) analysis of solutions containing acid digested, pure PCL/PEG/PCL copolymers showed calcium concentrations at equal to or greater than 77 % of the calcium feed concentration.  These calcium-initiator residues were isolated and their structures confirmed by Fourier transform infrared-attenuated total reflectance spectroscopy (FTIR-ATR).  They were found to be a mixture of calcium hydroxide (Ca(OH)2) and calcium carbonate (CaCO3).    The effect of calcium-initiator residues on the in vitro mineralisation of PCL/PEG/PCL triblock copolymers, as well as the same effect on a model calcium-salt-doped PCL homopolymer system, was studied by immersion in simulated body fluid (SBF).  In the model studied, PCL homopolymer was doped with low concentrations (0.2 - 2 w / w % Ca) of Ca(OH)2, or CaCO3.  Results from the model study showed calcium phosphate (CaP) mineral deposition on Ca(OH)2-doped PCL, and not on CaCO3-doped PCL.  This was attributed to the higher solubility of Ca(OH)2, compared to CaCO3.  Minimal CaP deposition was observed on PCL/PEG/PCL triblock copolymers.  This was attributed to the low Ca(OH)2 concentration in these samples.  For all mineralised samples in the SBF studies, the formation of carbonated HAP was observed.    Overall, the synthesis of PCL/PEG/PCL copolymers using the PEG / CaH2 co-initiator was found to be a suitable method for preparing reproducible materials.  The calcium-based initiator was also found to have potential for increasing the bioactivity of PCL-based materials.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">bone tissue repair</field><field name="subject">polycaprolactone</field><field name="identifier">http://eprints.qut.edu.au/16505/</field><field name="validLink">True</field></doc><doc><field name="title">Expansion methods applied to distributions and risk measurement in financial markets</field><field name="creator">Marumo, Kohei</field><field name="description">Obtaining the distribution of the profit and loss (PL) of a portfolio is a key problem in market risk measurement. However, existing methods, such as those based on the Normal distribution, and historical simulation methods, which use empirical distribution of risk factors, face difficulties in dealing with at least one of the following three problems: describing the distributional properties of risk factors appropriately (description problem); deriving distributions of risk factors with time horizon longer than one day (time aggregation problem); and deriving the distribution of the PL given the distributional properties of the risk factors (risk aggregation problem).    Here, we show that expansion methods can provide reasonable solutions to all three problems. Expansion methods approximate a probability density function by a sum of orthogonal polynomials multiplied by an associated weight function. One of the most important advantages of expansion methods is that they only require moments of the target distribution up to some order to obtain an approximation. Therefore they have the potential to be applied in a wide range of situations, including in attempts to solve the three problems listed above. On the other hand, it is also known that expansions lack robustness: they often exhibit unignorable negative density and their approximation quality can be extremely poor. This limits applications of expansion methods in existing studies.    In this thesis, we firstly develop techniques to provide robustness, with which expansion methods result in a practical approximation quality in a wider range of examples than investigated to date. Specifically, we investigate three techniques: standardisation, use of Laguerre expansion and optimisation. Standardisation applies expansion methods to a variable which is transformed so that its first and second moments are the same as those of the weight function. Use of Laguerre expansions applies those expansions to a risk factor so that heavy tails can be captured better. Optimisation considers expansions with coefficients of polynomials optimised so that the difference between the approximation and the target distribution is minimised with respect to mean integrated squared error. We show, by numerical examples using data sets of stock index returns and log differences of implied volatility, and GARCH models, that expansions with our techniques are more robust than conventional expansion methods. As such, marginal distributions of risk factors can be approximated by expansion methods. This solves a part of the description problem: the information on the marginal distributions of risk factors can be summarised by their moments. Then we show that the dependence structure among risk factors can be summarised in terms of their cross-moments. This solves the other part of the description problem. We also use the fact that moments of risk factors can be aggregated using their moments and cross-moments, to show that expansion methods can be applied to both the time and risk aggregation problems. Furthermore, we introduce expansion methods for multivariate distributions, which can also be used to approximate conditional expectations and copula densities by rational functions.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">conditional expectations; copulas; hermite polynomials; Laguerre; polynomials; orthogonal expansion; risk aggregation</field><field name="identifier">http://eprints.qut.edu.au/16506/</field><field name="validLink">True</field></doc><doc><field name="title">Digital evidence : representation and assurance</field><field name="creator">Schatz, Bradley Lawrence</field><field name="description">The field of digital forensics is concerned with finding and presenting evidence sourced from digital devices, such as computers and mobile phones. The complexity of such digital evidence is constantly increasing, as is the volume of data which might contain evidence. Current approaches to interpreting and assuring digital evidence rely implicitly on the use of tools and representations made by experts in addressing the concerns of juries and courts. Current forensics tools are best characterised as not easily verifiable, lacking in ease of interoperability, and burdensome on human process.  The tool-centric focus of current digital forensics practise impedes access to and transparency of the information represented within digital evidence as much as it assists, by nature of the tight binding between a particular tool and the information that it conveys. We hypothesise that a general and formal representational approach will benefit digital forensics by enabling higher degrees of machine interpretation, facilitating improvements in tool interoperability and validation. Additionally, such an approach will increase human readability.  This dissertation summarises research which examines at a fundamental level the nature of digital evidence and digital investigation, in order that improved techniques which address investigation efficiency and assurance of evidence might be identified. The work follows three themes related to this: representation, analysis techniques, and information assurance.  The first set of results describes the application of a general purpose representational formalism towards representing diverse information implicit in event based evidence, as well as domain knowledge, and investigator hypotheses. This representational approach is used as the foundation of a novel analysis technique which uses a knowledge based approach to correlate related events into higher level events, which correspond to situations of forensic interest. The second set of results explores how digital forensic acquisition tools scale and interoperate, while assuring evidence quality. An improved architecture is proposed for storing digital evidence, analysis results and investigation documentation in a manner that supports arbitrary composition into a larger corpus of evidence.  The final set of results focus on assuring the reliability of evidence. In particular, these results focus on assuring that timestamps, which are pervasive in digital evidence, can be reliably interpreted to a real world time. Empirical results are presented which demonstrate how simple assumptions cannot be made about computer clock behaviour. A novel analysis technique for inferring the temporal behaviour of a computer clock is proposed and evaluated.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">digital evidence</field><field name="subject">computer based electronic evidence</field><field name="subject">digital forensics</field><field name="subject">computer forensics</field><field name="subject">forensic computing</field><field name="subject">evidence provenance</field><field name="subject">evidence representation</field><field name="subject">knowledge representation</field><field name="identifier">http://eprints.qut.edu.au/16507/</field><field name="validLink">True</field></doc><doc><field name="title">Good governance implementation and international allignment : the case of regional governments in Indonesia</field><field name="creator">Mardiasmo, Diaswati</field><field name="description">The purpose of this study is to analyse the level of good governance understanding implementation in Indonesia regional governments, identify impeding variables to good governance implementation, and evaluate the extent of international good governance standards alignment. The influence of economic and political transition, decentralisation and regional autonomy regime, bureaucracy culture, and political history is analysed to reflect the degree of good governance implementation and level of convergence to international good governance standards. The methodological approach involves a triangulation of in-depth interview, document analysis, and International Good Governance Standard comparison. Findings from the study reflect disparities in good governance understanding and implementation between Indonesia regional governments, nine main impeding variables to good governance implementation including bureaucratic culture and political history, and a positive response to convergence towards international good governance standard alignment. Findings also act as an in depth study and analysis of current Indonesia regional government situation, resulting in inputs and recommendations geared towards public policy development and good governance implementation guidelines.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">good governance</field><field name="subject">Indonesia</field><field name="subject">Indonesia regional government</field><field name="subject">impeding variables</field><field name="subject">International Good Governance Standards</field><field name="subject">triangulation methodology</field><field name="subject">in-depth interviews</field><field name="subject">document analysis</field><field name="subject">international standard comparison</field><field name="subject">decentralisation</field><field name="subject">regional autonomy</field><field name="subject">bureaucracy culture</field><field name="subject">political history</field><field name="subject">disparity</field><field name="subject">convergence</field><field name="subject">divergence</field><field name="subject">public policy</field><field name="subject">implementation guidelines</field><field name="identifier">http://eprints.qut.edu.au/16508/</field><field name="validLink">True</field></doc><doc><field name="title">Health innovation adoption : the role of attitudes, control, and risk appraisal</field><field name="creator">O'Connor, Erin Leigh</field><field name="description">Three studies were conducted to examine the role of psychosocial factors in the prediction of health innovation uptake.  A health innovation is a device, treatment or altered food product intended to improve the health of an individual or group and considered new by the population of interest.  Health innovations may be used to address current health problems in individuals but also play a key role in preventative health efforts.  Encouraging individuals to adopt appropriate health innovations is often an important strategy in improving the general health and minimising the social cost of illness of a population.  The current program of research examined the influence of predictors from the Theory of Planned Behaviour (TPB; Ajzen, 1991), the Technology Acceptance Model (TAM; Davis, 1989; Davis, Bagozzi, &amp; Warshaw, 1989), and risk technology literature (Fischhoff, Slovic, Lichtenstein, Read, &amp; Combs, 1978; Slovic, 1987; Slovic, Fischhoff, &amp; Lichtenstein, 1980) on health innovation decision-making.  Additionally, the study examined the background factors of previous experience with the innovation, age, and gender.  Guided by the overall conceptualisations of change presented in the Stages of Change Model (Prochaska &amp; DiClemente, 1984; Prochaska &amp; Velicer, 1997) and the Innovation Decision Model (Rogers, 1958, 2003), the three studies aimed to examine the role of the proposed predictors for a number of different innovations at various stages of diffusion.  Study 1 (N = 358) employed a correlational design to predict people's intentions and willingness to use the four health innovations of functional foods, vitamin supplements, alternative therapies and pedometers. Participants completed questionnaires based on the TPB examining attitude (favourability towards the innovation), subjective norms (pressure from others for innovation uptake) and perceived behavioural control (PBC; sense of control over adopting the innovation).  In addition, participants completed items assessing the constructs of usefulness of the innovation and ease of use of the innovation from the TAM and familiarity of risks and dread of risks associated with the innovation, adapted from the risk literature.  Background factors, such as previous innovation use and age and gender of the participants, were also examined.  The underlying behavioural, normative, and control belief constructs of the TPB were examined to differentiate between those participants who reported that they were intending to or willing to adopt the health innovation and those who were not intending to or willing to adopt the health innovation.  Overall, the results of Study 1 supported the TPB constructs, perceived usefulness from the TAM, and risk familiarity. Study 2 (N = 102) utilized an experimental design where usefulness of the four innovations examined in Study 1 and the familiarity of risks associated with them were manipulated in a 2 x 2 scenario based study.  As in Study 1, participants completed measures of the TPB factors, an assessment of the dread of risk and reported background factors such as previous innovation use, and their age and gender.  Participants read reports of 'recent research' that contained information about the innovations' usefulness in relation to health benefit and familiarity of risk in comparison to traditional health products.  As in Study 1, people's intentions and willingness to use the health innovations were examined, as was a third outcome measure; participant predicted future use of each innovation.  The results of Study 2 provided support for the TPB constructs of attitude and subjective norms. The study also provided limited support for the TAM factor of usefulness, as well as for the risk dimensions of familiarity of risks and dread of risks.  The TPB construct of PBC and the background factors of age and gender were not supported.  Study 3 (N = 116) employed a 2 x 2 between-subjects design where usefulness and dread of risks were manipulated for a previously unavailable health innovation, calcium enriched mints.  Study 3 also involved a within-subjects measurement of two behaviour measures (estimated consumption, and a diary recorded measure of consumption) over three time periods.  Intention was retained as a third uptake measure of innovation uptake.  Participants were presented with manipulated information about the usefulness and dread of risks associated with calcium enriched mints.  Study 3 examined the role of the manipulated constructs, the TPB factors, familiarity of risk, and demographics in the prediction of the enriched mints uptake.  The design of this study addressed limitations identified in the literature and mirrored a number of authentic health innovation uptake situations.  The results of Study 3 strongly supported the role of attitude and subjective norms as influential predictors of intention to consume the calcium enriched mints, and intention as a predictor of estimated and diary recorded measures of consumption.  The study offered limited support for the risk factors of familiarity of risks and dread of risks and did not support the TAM construct of usefulness as a predictor of calcium enriched mint uptake.  Taken together, the results of this research provided strong support for the role of the TPB factors of attitude and subjective norms, but not PBC, as predictors of health innovation intentions and willingness.  The results also supported the role of intention as a predictor of health innovation adoption behaviour.  Limited support was found for the risk dimensions of familiarity of risks and dread of risks, suggesting that another conceptualisation of risk may be more appropriate for health innovation decision-making.  The results found little support for the TAM variables of usefulness and ease of use, or the influence of demographic characteristics of age and gender.  These findings indicate that the general decision-making model of the TPB, with the exception of the role of PBC, provides a useful framework to understand people's health innovation decision-making.  Given the limited support for PBC in the prediction of intentions and behaviour in this context, the Theory of Reasoned Action (Fishbein &amp; Ajzen, 1975), with some consideration of risk factors, may be an appropriate approach to adopt to facilitate an understanding the factors underlying people's decision to use innovations designed to improve their health.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">theory of planned behaviour</field><field name="subject">technology acceptance model</field><field name="subject">risk</field><field name="subject">health innovation</field><field name="identifier">http://eprints.qut.edu.au/16509/</field><field name="validLink">True</field></doc><doc><field name="title">Landing site selection for UAV forced landings using machine vision</field><field name="creator">Fitzgerald, Daniel Liam</field><field name="description">A forced landing for an Unmanned Aerial Vehicle (UAV) is required if there is an emergency on board that requires the aircraft to land immediately. Piloted aircraft in the same scenario have a human on board that is able to engage in the complex decision making process involved in the choice of a suitable landing location. If UAVs are to ever fly routinely in civilian airspace, then it is argued that the problem of finding a safe landing location for a forced landing is an important unresolved problem that must be addressed.    This thesis presents the results of an investigation into the feasibility of using machine vision techniques to locate candidate landing sites for an autonomous UAV forced landing. The approach taken involves the segmentation of the image into areas that are large enough and free of obstacles; classification of the surface types of these areas; incorporating slope information from readily available digital terrain databases; and finally fusing these maps together using a high level set of simple linguistic fuzzy rules to create a final candidate landing site map. All techniques were evaluated on actual flight data collected from a Cessna 172 flying in South East Queensland.    It was shown that the use of existing segmentation approaches from the literature did not provide the outputs required for this problem in the airborne images encountered in the gathered dataset. A simple method was then developed and tested that provided suitably sized landing areas that were free of obstacles and large enough to land. The advantage of this novel approach was that these areas could be extracted from the image directly without solving the difficult task of segmenting the entire image into the individual homogenous objects.    A number of neural network classification approaches were tested with the surface types of candidate landing site regions extracted from the aerial images. A number of novel techniques were developed through experimentation with the classifiers that greatly improved upon the classification accuracy of the standard approaches considered. These novel techniques included: automatic generation of suitable output subclasses based on generic output classes of the classifier; an optimisation process for generating the best set of input features for the classifier based on an automated analysis of the feature space; the use of a multi-stage classification approach; and the generation of confidence measures based on the outputs of the neural network classifiers. The final classification result of the system performs significantly better than a human test pilot's classification interpretation of the dataset samples.    In summary, the algorithms were able to locate candidate landing site areas that were free of obstacles 92.3 &#177;2.6% (99% confidence in the result) of the time, with free obstacle candidate landing site areas that were large enough to land in missed only 5.3 &#177;2.2% (99% confidence in the result) of the time.    The neural network classification networks developed were able to classify the surface type of the candidate landing site areas to an accuracy of 93.9 &#177;3.7% (99% confidence in the result) for areas labelled as Very Certain. The overall surface type classification accuracy for the system (includes all candidate landing sites) was 91.95 &#177;4.2% (99% confidence in the result). These results were considered to be an excellent result as a human test pilot subject was only able to classify the same data set to an accuracy of 77.24 %.    The thesis concludes that the techniques developed showed considerable promise and could be used immediately to enhance the safety of UAV operations. Recommendations include the testing of algorithms over a wider range of datasets and improvements to the surface type classification approach that incorporates contextual information in the image to further improve the classification accuracy.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Unmanned Arial Vehicle (UAV)</field><field name="subject">UAV forced landing</field><field name="subject">UAV emergency landing</field><field name="subject">safe landing site selection</field><field name="subject">aerial robotics</field><field name="subject">image segmentation</field><field name="subject">image classification</field><field name="subject">Artificial Neural Network (ANN)</field><field name="subject">UAV civilian airspace integration</field><field name="identifier">http://eprints.qut.edu.au/16510/</field><field name="validLink">True</field></doc><doc><field name="title">Rewarding inventive ingenuity through patent ownership as part of the Australian innovation strategy</field><field name="creator">Eliades, Dimitrios George</field><field name="description">The government has indicated that innovation fosters economic growth and is essential to maintaining a competitive position in international markets. Patents are the preferred mechanism by which the Australian Government and other governments encourage their nationals to protect their innovations.    The question of the entitlement was raised in several cases in the Federal Court of  Australia where there has been a failure to name all of the inventors on a patent grant (non-joinder) or where persons were mis-named as inventors, who were not and consequently have no interest in a grant (rnis-joinder). In both cases, parties who were not themselves daiming an entitlement to the invention, brought objections based on a number of grounds, including entitlement.    The results have been the revocation of the patent in the case on the non-joinder of an inventor and in the case of mis-joinder, the preliminary view of a judge of the Federal Court has been, that the patent would be invalid through lack of entitlement. The result is that competitors are permitted to 'exploit' the invention, as the subject matter is not protected by a patent.    The implications are far reaching, For example, where a research team in collaboration with another develops an invention but omits the inventive contribution of even one member of one team or includes a person who has not made an inventive contribution in the patent grant, the patent will be invalid. In these circumstances, the author considers that the result produces a disincentive to innovate.    Consideration of this area in other jurisdictions reveals that the U.S. and the U.K. have recognised this as an unsatisfactory state of affairs. As a result, Congress in the U.S. made provision in their Patent Code in the early 1950's, that in the case of error or mistake giving rise to a non-joinder or mis-joinder of inventors, the patent would not be invalid but could be rectified by the Director of Patents and Trade Marks (the 'Director'). In the U.K., the Comptroller has powers to deal with a wide variety of cases involving entitlement to ownership of a patent. The situations include but are not limited to cases where some but not all of the persons entitled to the grant have been granted the patent, i.e. non-joinder, or where a person entitled to be granted a patent, has been granted a patent together with a person who is not entitled, i.e. mis-joinder. The thesis will focus on the non-joinder and mis-joinder of inventors, but the U.K. provision addresses a wider field of parties entitled, whether entitled as inventors or on some other basis. In addition, the U.K. and Germany have made provision restricting the persons who are able to challenge a patent on entitlement grounds. This is restricted to those persons having an interest in the patent, rather than open to any person, as is the case in Australia.    The Australian decisions have been determined on historic cases dating back to the 17th century. It is timely to consider amendments which will overcome revocation of patents under Australian law, for what is essentially a matter between the persons interested. These amendments will accordingly encourage innovation, particularly in an environment where intellectual property has taken on greater importance and where the identification of the inventor has become more complex as collaborations in research become more common.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">patents</field><field name="subject">ownership</field><field name="subject">joint ownership</field><field name="subject">inventor</field><field name="subject">innovation</field><field name="subject">entitlement</field><field name="subject">revocation</field><field name="subject">Patents Act 1990 (Cth) s 138(3)(a)</field><field name="subject">rationale of patents</field><field name="subject">collaborative research</field><field name="subject">Stack</field><field name="subject">non-joinder</field><field name="subject">Conor</field><field name="subject">mis-joinder</field><field name="subject">water meter assembly</field><field name="subject">Patents Act 1990 (Cth) s 15(1)</field><field name="subject">Patents Act 1977 (U.K.) s 37</field><field name="subject">error or mistake</field><field name="subject">exploitation by co-owners</field><field name="identifier">http://eprints.qut.edu.au/16511/</field><field name="validLink">True</field></doc><doc><field name="title">Online communities of practice and their role in the professional development of teachers</field><field name="creator">Duncan-Howell, Jennifer</field><field name="description">Teachers are required to constantly change their pedagogy throughout their career, either in response to new theoretical approaches or new technological innovations. It is a profession that is characterised by dynamism and constantly strives to advance its practices to improve outcomes in student learning. However, current professional development programs are seen to be failing to meet the needs of the teachers, students and education policy.    Research has shown (Huberman, 1995; Richardson, 1990), there has been little discernible change in teaching practice from current professional development programs, thus an alternative solution is needed.  The premise underlying this study is that the use of online communities of practice may present a solution to the failure of current professional development programs in effecting change to teaching practice.  Thus it is the intention of this thesis to investigate if online communities of practice can realise this potential.    The research was conducted within the paradigm of qualitative analysis.  The study was conducted as a multiple explanatory case study also known as a collective case study (Yin, 2003) and this approach reflects the current shift in trends of research in education.  As Richardson (1994) stated, it has shifted &amp;quotfrom a focus on effective behaviours toward the hermeneutic purpose of understanding how teachers make sense of teaching and learning" (p. 5).  The approach used in this thesis provided insights into the value of online communities as authentic contexts for supporting professional development particularly in relation to relationships, communication and collaboration between teachers around professional inquiry, problem solving and emotional aspects of teaching.    The results of the study show that online communities of practice are a valuable source of continuous professional development for teachers. They have the ability to provide support as teachers accommodate the constant changes and the need to acquire new skills and knowledge. The strength of this method of PD lies in its ability to be self-sustaining and generative. Teachers have access to authentic, relevant and flexible learning that is not constrained by time and can be accessed according to members needs.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Communities of Practice</field><field name="subject">Online Communities of Practice</field><field name="subject">ICT</field><field name="subject">teacher change</field><field name="subject">professional development</field><field name="subject">professional communication</field><field name="identifier">http://eprints.qut.edu.au/16512/</field><field name="validLink">True</field></doc><doc><field name="title">Measurements of the distribution and behaviour of Beryllium-7 in the natural environment</field><field name="creator">Doering, Che</field><field name="description">Beryllium-7 is a cosmogenic radionuclide produced in the atmosphere through the spallation of nitrogen and oxygen nuclei by cosmic-ray-produced neutrons and protons. It is carried in the atmosphere attached to aerosols and is deposited on land and ocean surfaces by wet and dry deposition processes. Beryllium-7 decays by electron capture to lithium-7 and has a half-life of approximately 53 days. It is a potentially useful radionuclide for studying different natural processes.    This thesis presents a collection of scientific papers on the occurrence of beryllium-7 in the natural environment, particularly in the Southeast Queensland region of Australia. It shows the results of experimental measurements and discusses their implications. Overall, this thesis contributes to advancing our understanding of the distribution and behaviour of beryllium-7 in the natural environment and provides a foundation for the development of nuclear techniques for the evaluation of environmental problems.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">beryllium-7</field><field name="subject">environment</field><field name="subject">environmental radioactivity</field><field name="subject">radionuclide</field><field name="subject">cosmogenic</field><field name="subject">cosmic-rays</field><field name="subject">atmosphere</field><field name="subject">deposition</field><field name="subject">soil</field><field name="subject">surface air</field><field name="subject">atmospheric transport</field><field name="subject">erosion</field><field name="subject">depositional flux</field><field name="subject">areal activity density</field><field name="subject">Brisbane</field><field name="subject">southeast Queensland</field><field name="subject">Australia</field><field name="identifier">http://eprints.qut.edu.au/16513/</field><field name="validLink">True</field></doc><doc><field name="title">A contextual measure of teacher efficacy for teaching primary school students who have ESL</field><field name="creator">Tangen, Donna Jean</field><field name="description">The current research utilised a modified cyclical model of tracking teachers' efficacy beliefs from their source through to their implementation in teaching strategies. Key inclusions to the model were four factors (personal efficacy, teaching efficacy, classroom management efficacy and outcome efficacy) of teacher efficacy and four contextual considerations (culture load, learning load, language load and cognitive load) in relation to teaching students who have ESL. Data were collected through three studies, ultilising both qualitative methodologies (focus groups, hypothetical teaching scenarios) and a quantitative methodology (researcher-generated survey). Results revealed a two-factor model of teacher efficacy (not a four-factor model) with the two factors being personal efficacy (general teaching abilities) and teaching efficacy (overcoming environmental factors such as home life). Culture load and language load were significant contextual considerations given to teaching students who have ESL. Results of the research suggested that specific teacher training needs to focus on how to adapt curriculum to meet the needs of a diverse group of learners, emphasising in particular why chosen strategies should be used. More training is needed which involves learning how to include parents and other community members as valuable resources in the learning processes of the classroom.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">cyclical model of teacher efficacy</field><field name="subject">English as a second language (ESL)</field><field name="subject">ESL contextual considerations</field><field name="subject">sources of efficacy beliefs</field><field name="subject">teacher efficacy</field><field name="subject">teaching strategies</field><field name="identifier">http://eprints.qut.edu.au/16514/</field><field name="validLink">True</field></doc><doc><field name="title">Investigating the relationship between market values and accounting numbers for 30 selected Australian listed companies</field><field name="creator">Clout, Victoria Jane</field><field name="description">In capital market research (CMR) studies of the value relevance of accounting numbers are founded upon the concept that, in equilibrium, the book values are equal to or have some long-term relationship with the market value and that market returns are related to book returns.    This thesis seeks to resolve a gap in the CMR by examining 30 selected individual firms listed on the Australian stock market during the period 1950 to 2004, using equilibrium correction modelling techniques. Even these limited prior works used cross-sectional techniques rather than the long-run, time-series, analysis used in this study. Moreover, dynamic analysis in the CMR has tended to focus on indexes or portfolio data rather than using firm-specific case study data of the type modelled here. No prior research has taken this approach using Australian data.    The results of this thesis indicated that an equilibrium correction relationship between market values and book values for firms listed on the Australian Stock Exchange (ASX) could be determined by using accounting and macroeconomic regressors. The findings of the thesis were consistent with the literature in terms of the variables suggested and important in the firm's valuation from the three main approaches, the analysts (industry) approach, the finance and accounting theory (textbook) approach and the CMR literature approach. The earnings, dividends and book value variables are significant in their relationships with the firm's market values. The models constructed were typically more informative and had an increased forecasting performance compared with the a priori models tested, based on theory and the literature.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">capital market research; value relevance; dynamic modelling equilibrium correction; error correction models; forecasting; sufficiency</field><field name="identifier">http://eprints.qut.edu.au/16515/</field><field name="validLink">True</field></doc><doc><field name="title">Opioid-taking self-efficacy in Taiwanese Outpatients with cancer pain</field><field name="creator">Liang, Shu-Yuan</field><field name="description">Despite the fact that as many as 80-90% of patients with cancer pain can be effectively treated using pharmacological therapies and other advanced approaches, 31% to 85% of cancer patients in Taiwan still experience varying levels of pain. Pain is one of the symptoms that patients fear most; it overwhelms all aspects of patients' lives and creates a sense of uncertainly and hopelessness. Pain control is, therefore, a high priority in the treatment of cancer patients. Pharmacological therapy is the cornerstone of cancer pain management. With the current trend toward outpatient care, many patients are being required to assume greater responsibility for self-management of prescribed analgesics at home to deal with the variable and complex nature of cancer pain and side effects of opioids. Patients however, have misconceptions regarding analgesics and a series of difficulties when attempting to put a pain management regimen into practice.    This research addressed the hypothesis that self-efficacy beliefs might play an important role in analgesic adherence and pain experience in Taiwanese outpatients with cancer. The purpose of this study was to develop a scale to measure the self-efficacy expectations relating to opioid-taking in Taiwanese outpatients with cancer. Another purpose was to explore how opioid-taking self-efficacy and beliefs about opioid analgesics contribute to patients' analgesic adherence and pain experience in Taiwanese outpatients with cancer.    In the first stage semi-structured interviews were conducted to collect data from a purposeful sample (n=10) of oncology outpatients from two teaching hospitals in the Taipei area of Taiwan. The purpose of this phase was to identify behaviours and situational impediments associated with analgesic taking. Findings from this phase were used to develop a scale to measure opioid-taking self-efficacy. In the second stage a pilot test with a convenience sample (n=30) was conducted to test the validity and reliability of the new scale and to identify the feasibility of using the scale in a cross-sectional survey. In the third stage a cross-sectional survey was undertaken (n=92) to describe pain experiences, analgesic adherence, beliefs about opioid analgesics, and opioid-taking self-efficacy in Taiwanese outpatients with cancer and to explore how opioid-taking self-efficacy and beliefs about opioid analgesics contributed to analgesic adherence and pain experience.    Results of this study highlight an important issue - under-treatment of cancer pain in this group of Taiwanese outpatients. As well, low adherence rates to opioid analgesics in cancer outpatients arose as an important issue in this study. A range of misconceptions about using opioids for pain was also common amongst the sample. Despite these misconceptions, patients reported being moderately confident in their ability to perform self-management behaviours related to their prescribed opioid-taking. Results of this research supported the notion that patients' self-efficacy in relation to taking their prescribed opioid regimen was a significant independent predictor of patients' adherence behaviour and pain relief, but not of pain severity. Beliefs about opioid analgesics were also an independent predictor of patients' adherence, but not of pain relief or pain severity. In addition, findings from this study provided support for the validity and reliability of the opioid-taking self-efficacy scale. Results suggested there is a need for systematic assessment of beliefs affecting patients' opioid adherence behaviours for cancer pain control, including perceived personal self-efficacy and beliefs about opioid analgesics. Educational programs that focus on overcoming patients' misconceptions (beliefs) about taking opioid analgesics may be particularly beneficial. In addition, this study advocates that conducting self-efficacy-enhancing interventions may improve medication adherence for patients and therefore pain relief. More research is needed to demonstrate the construct validity of the self-efficacy scale and to evaluate self-efficacy enhancing interventions in cancer pain management.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">decision making</field><field name="subject">analgesic-taking self-management</field><field name="subject">self-efficacy</field><field name="subject">confidence</field><field name="subject">cancer pain</field><field name="subject">pain management</field><field name="identifier">http://eprints.qut.edu.au/16516/</field><field name="validLink">True</field></doc><doc><field name="title">A theoretical evaluation and empirical investigation into explanations for the escalation of commitment phenomenon in the particular organisational contexts of Expo 86 and Expo 88</field><field name="creator">Donohue, Kerry John</field><field name="description">Escalation of commitment to failing investments is considered to be representative of biased forms of decision-making which may result in unproductive consequences. Decision makers adopt investment courses of action in initial conditions of uncertainty, which subsequently appear to lead to failure. When confronted with the prospect of their decisions producing losses, they commit decision errors thus escalating their commitment to their original courses of action.
 
 
 
 Several theories with rational and irrational antecedents have been developed in the literature to explain the escalation phenomenon. Fundamental theoretical differences are associated with the origin of the concept. Escalation of commitment was conceived in the decision theory context of the problem of resource allocation under uncertainty conditions.
 
 
 
 This thesis describes the resource allocation problem in order to identify and explain associated characteristics. Explanations of these characteristics reveal several problems: there are no decision rules available to handle uncertainty; decision makers consistently violate the requirements for rationality and rational economic decision making; individual utility maximization is divorced from the business objective of profit maximisation and also involves taking increased risks when there is an expectation that investment losses will be recovered; there are several criteria for and methods of investment evaluation which are computationally and analytically difficult to apply; and whether a decision error has been made is indeterminate with some investment projects whose success or failure cannot be determined until after project completion. These problems lead to the conclusion that the determination of the success or failure of an investment decision may depend on the valuation methodology selected. In this respect it is argued that investment decisions undertaken in public organisations should be evaluated using methodologies developed to measure social benefits and costs because calculations of private rates of return provide misleading assessments.
 
 
 
 Research on the escalation phenomenon is dominated by a psychological perspective, which obtains its findings from extensive investigation of individuals in controlled experimental laboratory conditions. The experimental research has identified personal pre-dispositional, social and situational influences, which contribute to escalation and de-escalation of commitment. The major research focus has resulted in two theoretical explanations for escalation of commitment. These derive from descriptive cognitive motivational theories concerned with expectancy, that encourage rational decision making and dissonance, which in turn produce irrational self justification based decisions. An alternative research focus favours explanations from prospect theory. Research, critical of the psychological explanations favours rational explanations derived from the normative theory of expected utility, which encourages individual self-interested behaviour.
 
 
 
 This thesis is concerned with explaining escalation of commitment in organisations. This necessarily involves adopting an interdisciplinary perspective. This thesis examines two world expositions, Expo 86 and Expo 88. World expositions are unusual government events whose principal purpose is to celebrate human achievements. Expo 86 was held to celebrate Vancouver&#8217;s centenary. Expo 88 was held to celebrate Australia&#8217;s bicentennial. They were not designed for their potential profitability. To justify the expenditures involved other objectives are attached to the celebratory purpose. These usually are associated with urban renewal and economic development. They are unorthodox investment projects. They involve long lead times of capital expenditure followed by short operating periods of six months or less, after which time most of the capital improvements are either disposed of or demolished.
 
 
 
 Expo 86 incurred significant financial losses and was considered an escalation prototype. It became a case study used to develop a generalized theoretical model of escalation. The model specifies how initially formulated rational decisions are replaced progressively by decisions based on self-justification, which escalate commitment. Escalation is reinforced by psychological pre-dispositional, social and structural influences. The model is an extension of research findings from individual laboratory experiments.
 
 
 
 The thesis identifies several plausible alternative theoretical explanations for escalation in organisations. These involve emotional commitment, social influences to conform to group norms, the possibilities for deviating from rational decision making principles in the presence of uncertainly and the agency theory problem which involves individuals pursuing their own rational self interests which are contrary to the objectives of an organisation.
 
 
 
 Expo 86 was directly linked to urban renewal objectives. The economic project and urban planning studies of Expo 86 concluded that the event successfully achieved the urban development objectives using social cost benefit analysis as the criterion of evaluation. These objectives were rationally conceived and executed. As a result of the examination, the thesis explores the problems associated with investment projects having multiple objectives, looks at how rational explanations can be accommodated in the theoretical model and questions whether calculations of accounting negative rates of return should be the criteria for evaluation and the determinant of whether Expo 86 qualified as a prototypical example of escalation in organisations.
 
 
 
 The analysis of Expo 88 reinforced these concerns. A longitudinal dimension was adopted in the case study. This enabled the origins of the event to be explored, the objectives to be identified and the project to be evaluated using various private and public investment criteria. Expo 88 qualified as a failed private investment project on all but one of the financial investment criteria employed. The evaluation of Expo 88 as a public investment project produced social benefits and economic impacts in excess of social costs.
 
 
 
 Expo 88 was conceived by influential individuals who promoted the initiative for an exposition on the basis that its staging would be publicly and personally beneficial. The project was associated with multiple objectives other than its celebratory purpose that included tourism development and urban renewal from which the public was expected to benefit and which promoters believed justified the event. The principal decision makers were not directly influenced by profitability considerations because information had been provided during the planning phase, which indicated that the project would produce financial losses. Because of public pronouncements it became politically necessary to include the profitability of the project as an objective. Various costly and deceptive measures were adopted in order to generate an impression of profitability. At the same time success was promoted publicly and successfully, not in terms of its profitability, but in terms of attendance figures.
 
 
 
 As a result of the analyses, the theoretical model was modified by incorporating rational motives into the original structure. Decision makers were driven by rational motives over the life of the projects. In the case of Expo 88 these rational motives derived from agency theory relationships and the pursuit of objectives concerned with economic development, celebration and political recognition.
 
 
 
 The thesis concludes with a discussion of the contributions and limitations of the research. The contributions involve modifications to the theoretical model to reflect the importance of rational motives in the decision making process, generalisation of the causes of escalation in organisations in various contingent circumstances and the impact that multiple project objectives and methodological problems concerned with evaluation criteria have on theory development. The major limitation relates to the selection of public organisations engaged in unorthodox investment projects as inappropriate representatives to examine the escalation phenomenon.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">management science</field><field name="subject">escalation of commitment</field><field name="subject">evaluation methodology</field><field name="subject">utility theory</field><field name="subject">theoretical modelling</field><field name="identifier">http://eprints.qut.edu.au/16517/</field><field name="validLink">True</field></doc><doc><field name="title">Design, maintenance and methodology for analysing longitudinal social surveys, including applications</field><field name="creator">Domrow, Nathan Craig</field><field name="description">This thesis describes the design, maintenance and statistical analysis involved in undertaking a Longitudinal Survey.  A longitudinal survey (or study) obtains observations or responses from individuals over several times over a defined period. This enables the direct study of changes in an individual's response over time. In particular, it distinguishes an individual's change over time from the baseline differences among individuals within the initial panel (or cohort). This is not possible in a cross-sectional study. As such, longitudinal surveys give correlated responses within individuals. Longitudinal studies therefore require different considerations for sample design and selection and analysis from standard cross-sectional studies.  This thesis looks at the methodology for analysing social surveys. Most social surveys comprise of variables described as categorical variables.  This thesis outlines the process of sample design and selection, interviewing and analysis for a longitudinal study. Emphasis is given to categorical response data typical of a survey.  Included in this thesis are examples relating to the Goodna Longitudinal Survey and the Longitudinal Survey of Immigrants to Australia (LSIA). Analysis in this thesis also utilises data collected from these surveys. The Goodna Longitudinal Survey was conducted by the Queensland Office of Economic and Statistical Research (a portfolio office within Queensland Treasury) and began in 2002. It ran for two years whereby two waves of responses were collected.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">bayesian</field><field name="subject">benchmarking</field><field name="subject">correlation</field><field name="subject">cross sectional surveys</field><field name="subject">data analysis</field><field name="subject">generalized estimating equations</field><field name="subject">imputation</field><field name="subject">longitudinal surveys</field><field name="subject">missing data</field><field name="subject">sample size</field><field name="subject">standard error</field><field name="subject">survey design</field><field name="subject">survey methodology</field><field name="subject">weighting</field><field name="identifier">http://eprints.qut.edu.au/16518/</field><field name="validLink">True</field></doc><doc><field name="title">The phenomenon of preschool children's spirituality</field><field name="creator">Giesenberg, Anna</field><field name="description">Spirituality is discussed as seen in literature from the disciplines of psychology, religion, education, nursing, politics and philosophy. Special emphasis is placed on how spirituality is viewed in regard to young children. From the disciplines mentioned, an overall definition of spirituality - at least for adults - is derived: &amp;quotSpirituality is an innate ability to show awareness or consciousness of the surrounding world shown through wonder, a sense of compassion, and love towards this world and everything in it, and for some people a relationship with a transcendent being, who can also be immanent in the individual." Findings are described from a field study of 12 months duration where 56 children, aged 3-7 years, from 4 different early childhood settings were followed on a fortnightly basis. The children were able to express aspects of spirituality in their play, discussions and artwork, such as paintings and drawings. The children were asked to paint and draw their experiences of selected pieces of chamber music, of a beautiful day, of love, and of dreams. In addition children were observed in their interactions with peers. The data were analysed using a combination of Grounded Theory methodology and Phenomenology. The main finding is that young children &amp;quotlive in" their spirituality, and that young children are very aware of their surroundings and are able to express abstract concepts such as love, beauty, wonder and compassion. Young children's spirituality differs from adults in one major aspect: that they do not express a relationship with a transcendent being. It appears that spirituality may be innate as described by Montessori (1949), Hegel (1807) and Descartes (in Luria &amp; Vygotsky, 1998).    Suggestions for dealing with young children and their spirituality are made for the early childhood educator. Suggestions for further studies related to young children's spirituality are also made.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">preschool</field><field name="subject">child spirituality</field><field name="identifier">http://eprints.qut.edu.au/16519/</field><field name="validLink">True</field></doc><doc><field name="title">Learning for liberation : values, actions and structures for social transformation through Aboriginal communities</field><field name="creator">Hockey, Neil Edward</field><field name="description">Negative perceptions of being Aboriginal persist and policies such as self-determination are generally perceived to have failed despite many texts to the contrary. This thesis examines assumptions and presuppositions within contemporary writings and practices, determining in the process, conditions seeming necessary for decolonising ways of living and research. Much closer attention is required not only to developing better understandings, but especially to articulating explanations via the reality of deep structures, their powers and causal mechanisms underpinning social life generally and in particular, the lived experience of oppressed communities. Neo-Nietzscheanism and post-structuralism tend to see reality as merely constructed.    Maximising movements of solidarity with the oppressed must express the freedom of everyone in any particular place. The thesis begins by exploring the nature and significance of philosophical underlabouring (clearing the ground) for decolonisation as self-emancipation. It then engages with issues of value, truth and power by means of establishing a critical realist dialogue between two sets of writings. Key works by Australian (Japanangka West, Yolnju) Maori (Tuhiwai Smith) and American (Moonhawk Alford, Taiaiake Alfred) First Nations thinkers in modernity's colonial context are retroductively analysed in order to suggest what must be the case (in terms of being and becoming) for decolonisation to be possible. Works by philosophers currently establishing and applying Bhaskarian transcendental dialectical critical realist and/or meta-Realist principles of self-emancipation are critiqued in relation to their compatibility with decolonisation. Terms of reference within this dialogue are then supplemented from within writings by a range of others (Fanon, Said, Otto and Levinas), selected for their perceived significance in developing a dialectical praxis of personal and social transformation through spirit within the domain of strengthening community and protecting children.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Aboriginal communities</field><field name="subject">child protection</field><field name="subject">decolonising research</field><field name="subject">self-emancipation</field><field name="subject">critical realism</field><field name="subject">spirituality</field><field name="subject">Bhaskar</field><field name="identifier">http://eprints.qut.edu.au/16520/</field><field name="validLink">True</field></doc><doc><field name="title">Bioinformatic prediction of conserved promoters across multiple whole genomes of Chlamydia</field><field name="creator">Grech, Brian James</field><field name="description">The genome sequencing projects have generated a wealth of genomic data and the analysis of this data has provided many interesting findings. However, genome wide analysis of bacteria for promoters has lagged behind, because it has been difficult to accurately predict the promoters with so much background noise that are found in bacterial genomes. One approach to overcome this problem is to predict phylogenetically conserved promoters across multiple genomes of different bacteria, thus filtering out many of the false positives, which are predicted by the current methods. However, there are no programmes capable of doing this. Therefore, the work presented in this thesis has developed a position weight matrix (PWM) based programme called Multiscan that predicts conserved promoters across multiple bacterial genomes. Since Chlamydia is one of the most sequenced bacterial genera and has a high level of conservation of genes and large-scale conservation of gene order between species, Multiscan was developed and tested on Chlamydia. When Multiscan analysed a genome wide dataset of equivalent non-coding regions (NCRs) upstream of genes, from Chlamydia trachomatis, Chlamydia pneumoniae and Chlamydia caviae for &#963;66 promoters that are phylogenetically conserved, Multiscan predicted 42 promoters. Since only one of the 42 promoters predicted by Multiscan had previously available biological data to confirm its prediction, an additional subset of 10 of the remaining 41 &#963;66 promoters were analysed in C. trachomatis by mapping the 5' end of the transcripts. The primer extension assay synthesised cDNA products of the correct length for seven of the 10 genes chosen. When the performance of Multiscan was compared to one of the accepted method for genome wide prediction of promoters in bacteria, the &amp;quotstandard PWM method", Multiscan predicted 32 more promoters than the &amp;quotstandard PWM method" in Chlamydia. Furthermore, the promoters predicted by Multiscan were up to three more mismatches from the Escherichia coli &#963;70 consensus sequence than the promoters predicted by the standard PWM method. Although Multiscan predicted 42 promoters that were well conserved across the three chlamydial species, the analysis was unable to identify the 14 known &#963;66 promoters in C. trachomatis. These promoters were missed (1) because they were dissimilar to the E. coli &#963;70 consensus sequence and/or (2) because the promoters were poorly conserved across the three chlamydial species. To address the second possibility, the 14 false negatives were analysed by another phylogenetic footprinting method. Fourteen sets of equivalent NCRs located upstream of the homologous genes from the three chlamydiae were aligned with the computer programme Clustal W and the alignment analysed &amp;quotby eye" for evidence of phylogenetic footprints containing the 14 false negatives. The analysis identified that seven of the 14 false negatives were poorly conserved across the chlamydial species. Analysis of two of the seven promoters that could not be footprinted, the promoters of ltuA and ltuB, by mapping the transcriptional start sites in C. caviae, confirmed their poor conservation across C. trachomatis and C. caviae. This analysis showed that substantial differences exist in chlamydial &#963;66 promoters from equivalent NCRs upstream of genes. This study has developed a new computer programme for genome wide prediction of promoters that are phylogenetically conserved and has shown the value of this programme by identifying seven new well conserved promoters and seven candidate poorly conserved promoters in Chlamydia.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">algorithm</field><field name="subject">bioinformatic</field><field name="subject">Chlamydia</field><field name="subject">comparative genomics</field><field name="subject">gene expression regulation</field><field name="subject">phylogenetic footprinting</field><field name="subject">phylogeny</field><field name="subject">promoter</field><field name="subject">sigma factor</field><field name="subject">transcription</field><field name="subject">transcription factor</field><field name="subject">transcription start site</field><field name="identifier">http://eprints.qut.edu.au/16521/</field><field name="validLink">True</field></doc><doc><field name="title">Parents' management of childhood fever</field><field name="creator">Walsh, Anne Majella</field><field name="description">Despite decades of research about educational interventions to correct parents' childhood fever management their knowledge remains poor and practices continue to be based on beliefs about harmful outcomes. The purpose of this thesis was to 1) identify Australian parents' fever management knowledge, attitudes, practices and methods of learning to manage fever and 2) undertake a theoretical exploration of the determinants of parents' intentions to reduce fever using the Theory of Planned Behavior (TPB). Two studies were undertaken: a qualitative study with 15 parents; and survey of 401 Queensland parents with a child aged between 6 months and 5 years.    Parents determine childhood fever through behavioural changes they have learnt to associate with fever. Few were aware of the immunological beneficial effects associated with fever and most believed fever harmful causing febrile convulsions and brain damage. To prevent harm they monitored temperatures, used antipyretics, dressed children in light clothing and sponged them with tepid, cool or cold water.    Despite believing antipyretics harmful most parents reduced temperatures of 38.3 degrees Celsius &#177; 0.6 degrees Celsius with antipyretics, alternating two antipyretics when fever was not reduced or returned. In addition to temperature reduction antipyretics were used to reduce distress or general unwellness and pain or discomfort. Multiple factors were used to determine antipyretic dosage including temperature, irritability and illness severity. Over one-third of parents had overdosed their child with too frequent antipyretic administration; more frequently with ibuprofen than paracetamol, 12:1.    Fever management information was learnt from numerous sources. Doctors were the most frequently reported followed by personal experience. With the variety of information sources nearly half received conflicting information about how to manage fever increasing concerns and creating uncertainty about how to best care for their child. Despite this many believed they knew how to manage fever.    Some parents' practices changed over time as a result of either positive or negative experiences with fever indicating more positive or negative attitudes toward fever.  Positive experiences reduced antipyretic and medical service use; negative ones had the adverse effect with increase in antipyretic use including alternating antipyretics and double dosing with one antipyretic. Child medication behaviours also influenced attitudes and practice intentions. Parents of children who readily took antipyretics had more negative attitudes and intended to reduce their child's next fever with antipyretics. Negative attitudes were a significant determinant of fever management intentions.    Parents' practices were strongly influenced by their perception that doctors and partners expected them to reduce fever. This expectation from partners is understandable; from doctors it is not and indicates doctors' propensity to recommend reducing fever. There is an urgent need to identify doctors' fever management beliefs and rationales for practice recommendations. Parents also learn to manage fever from nurses and pharmacists; their beliefs and management rationales must also be determined and addressed.    There is an urgent need to educate parents about evidence-based fever management and reduce their unnecessary antipyretic use. They must be encouraged to delay antipyretic administration using them to reduce pain rather than fever. Findings from this thesis have identified the determinants of parents' intentions to reduce fever; negative attitudes and normative influences and positive child medication behaviours. Future studies should examine the efficiency and cost effectiveness of fever management educational programs for parents using different presentation methods in multiple settings.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">childhood illness; child nursing; community care</field><field name="subject">decision making; evidence-based practice; fever; focus groups; general paediatrics; health education; information needs; instrument development; literature review; medications; medication management; parental attitudes; parenting; public health nursing; s</field><field name="identifier">http://eprints.qut.edu.au/16522/</field><field name="validLink">True</field></doc><doc><field name="title">The impact of pain on the quality of life of people with multiple sclerosis</field><field name="creator">Douglas, Clint</field><field name="description">This thesis was concerned with determining the scope, nature and impact of pain on quality of life (QOL) among a community-based sample of people with multiple sclerosis (MS). An analysis of the research literature on pain in MS reveals that pain is a significant problem which has historically been underinvestigated and is currently poorly understood. The vast majority of the published literature consists of prevalence studies, descriptive research and clinical reports. Where available, empirical data are often limited by methodological and analytical problems such that substantive conclusions about the scope and nature of MS-related pain remain unclear. Among the most fundamental issues is the extent to which pain is problematic in a population which is already impaired by other physical disabilities. Little is known about how pain contributes to MS-related disability, distress and QOL. Moreover, research examining the psychosocial aspects of MS-related pain is noticeably absent. It is clear that there are substantial gaps in the literature and that many basic questions about the scope, nature and impact of pain problems among individuals with MS remain unanswered. Thus the primary aim of this study was to begin to fill some of these gaps by systematically investigating the following research questions: (1) What is the prevalence and nature of pain experienced by people with MS? (2) What is the impact of pain on the QOL of people with MS, over and above the impact of disability itself? (3) To what extent do physical and psychosocial factors influence adjustment to chronic pain in people with MS? (4) What meaning is given to the pain experience by people with MS?    The present study utilised a multimethod research design involving cross-sectional postal survey, structured in-person pain interviews and focus groups. Survey respondents were a 219-person sample recruited from the Queensland MS Society membership database via systematic random sampling. All participants completed a piloted questionnaire containing questions about their demographic and clinical characteristics, validated measures of QOL and MS-related disability, and a question on whether or not they had experienced clinically significant pain in the previous two weeks. Respondents who reported pain then completed face-to-face structured pain interviews assessing pain characteristics (viz. intensity, quality, location, extent and duration), pain-related beliefs and coping strategies, and pain management techniques used. Four focus groups were also conducted that included 32 people with MS living in the community. Study participants were a purposive sample drawn from four MS support groups located in the South-East Queensland region.    Pain was found to be common with some 67.1% of the sample reporting pain during the two weeks preceding the study. Comprehensive pain assessment revealed that a substantial subset of these individuals experience chronic pain conditions characterised by moderate-to-severe pain intensity. Pain prevalence and intensity were found to be strongly correlated with QOL: physical health, psychological health, level of independence and global QOL were more likely to be impaired among people with MS when pain was present, and the extent of impairment was associated with the intensity of pain. Moreover, these relationships remained significant even after statistically controlling for multiple demographic and clinical covariates associated with self-reported QOL. Pain-related beliefs and coping strategies were also associated with and explained a significant proportion of the variance in adjustment to pain among people with MS, over and above that accomplished by demographic and MS-related variables and pain intensity. Finally, qualitative data analysis revealed four broad conceptualisations of the experience of chronic MS-related pain including: pain is pervasive, nobody understands, I'm fine, and always a factor in the equation. These findings suggest that for people with MS, pain is an important source of distress and disability over and above that caused by neurological impairments. These data also lead to the hypothesis that recognition and effective treatment of pain would improve the QOL of people with MS, irrespective of their level of neurologic disability. Although correlational, the findings provide support for a biopsychosocial model of pain and adjustment to pain in people with MS.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">multiple sclerosis</field><field name="subject">MS</field><field name="subject">chronic pain</field><field name="subject">disability-related pain</field><field name="subject">quality of life</field><field name="subject">biopsychosocial model</field><field name="subject">pain beliefs</field><field name="subject">pain coping</field><field name="identifier">http://eprints.qut.edu.au/16523/</field><field name="validLink">True</field></doc><doc><field name="title">Teacher reaction to and understanding of a task-based, embedded syllabus</field><field name="creator">Sparks, Candice Leah</field><field name="description">This thesis investigates where the Years 4-10 Queensland French Syllabus is receiving support, by investigating groups of teachers with shared characteristics. In doing so, it aims to shed some light on why teachers have not embraced this new syllabus. Specific issues pertaining to the syllabus are investigated, such as the use of task-based instruction as the chosen methodology and of embedded content, as well as contextual issues, such as employment sector and levels taught. Teachers' reactions to change have also been investigated in relation to the introduction of this syllabus. In addition to this, the process involved in acceptance of an innovation has been explored which led to an examination of teacher understanding of the current syllabus. This study is divided into five chapters. Chapter one outlines the syllabus and context, as well as hypotheses for this study and rationale. Chapter two is a literature review which brings together previous research and links it to the current study. The chosen methodology is covered by chapter three, with chapter four being a detailed explanation of results received from the data collection. The final chapter, chapter five, discusses these results and the implications of these findings.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">task-based instruction</field><field name="subject">embeddedness</field><field name="subject">Queensland French syllabus</field><field name="subject">French teaching</field><field name="subject">teacher understanding</field><field name="subject">learner centredness</field><field name="subject">teacher role</field><field name="subject">teacher change</field><field name="identifier">http://eprints.qut.edu.au/16524/</field><field name="validLink">True</field></doc><doc><field name="title">EFL and ESL teacher values and integrated use of technology in universities in the Asia-Pacific region</field><field name="creator">Boulter, Carmen Henriette</field><field name="description">Educators who teach international students English as a second language (ESL) or  English speakers teaching English as a foreign language (EFL) in universities in non-  English speaking countries in the Asia-Pacific region are often challenged to develop culturally appropriate curriculum for a diverse group of learners. Prompted by educational policy over the past two decades, the technological infrastructure in most universities throughout the world has advanced. Innovative tools for language learning have been developed for computer-assisted instruction. The purpose of the present study was to assess to what extent teachers use multimedia in EFL/ESL university classrooms in relation to the theoretical underpinnings of constructivism as well as Rogers' (1995) theory of diffusion of innovations and adopter categories.  Further, the study aimed to ascertain what factors contribute to or discourage teachers' use of multimedia in tertiary level English language teaching classrooms. A mixed- method research design was used and both quantitative and qualitative data were collected. One hundred and seventy-nine English-language teachers from five universities in the Asia-Pacific region were interviewed and data were collected on their use of multimedia. Complex relationships were found among teacher-held educational and cultural values, teaching experience, formal computer professional learning, nationality, institution, region, age, gender, and collaboration with colleagues. Results showed that even with adequate access to hardware, software, technical support and computer professional learning, most teachers in the study made limited use of multimedia in the EFL/ESL classroom. As well, the results indicated that teachers in all three universities in Taiwan used multimedia in the EFL/ESL classroom less than teachers in Australia and in Thailand. Teachers who endorsed constructivist teaching methodologies tended to use multimedia more. Also, teachers with fewer than ten years teaching experience tended to use technology in teaching more. Data showed the use of integrated technology by teachers usually diminished as teachers got older. However, results showed that teachers who engaged in professional learning tended to use multimedia more regardless of age. Future directions in technology integration and recommendations for creating and sustaining a culture of technology at educational institutions are offered. Suggestions for professional development to encourage the integrated use of technology in English language teaching programs are outlined.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">EFL</field><field name="subject">ESL</field><field name="subject">culture of technology</field><field name="subject">technology-enhanced language learning</field><field name="subject">computer-assisted language learning (CALL)</field><field name="subject">multimedia in language teaching</field><field name="subject">learning styles</field><field name="subject">multiple intelligences</field><field name="subject">second language acquisition</field><field name="subject">computer-assisted instruction</field><field name="subject">CAI</field><field name="subject">social constructivism</field><field name="subject">cultural constructivism</field><field name="identifier">http://eprints.qut.edu.au/16525/</field><field name="validLink">True</field></doc><doc><field name="title">Changing relations in landscape planning discourse</field><field name="creator">Lawson, Gillian Mary</field><field name="description">With the increasing development of relations of consumption between discipline knowledge and students, educators face many pressures. One of these pressures is the emotional response of students to their learning experiences and the weight given to their evaluation of teaching by universities. This study emerged from the polarised nature of student responses to one particular area of study in landscape architecture, the integrative discourse of Landscape Planning. While some students found this subject highly rewarding, others found it highly confronting. Thus the main aims of this study are to describe how the students, teacher and institution construct this discourse and to propose a way to rethink these differences in student responses from a teacher's perspective.
 
 
 
 Firstly, the context of the study is outlined. The changing nature of higher education in Australian society frames the research problem of student-teacher struggles in Landscape Planning, a domain of knowledge in landscape architecture that is situated in a an enterprise university in Queensland. It describes some of the educational issues associated with Boyer's scholarship of integration, contemporary trans-disciplinary workplaces and legitimate knowledge chosen by the institution [Design], discipline [Landscape Architecture], teacher [Landscape Planning] and students [useful and relevant knowledge] as appropriate in a fourth year classroom setting.
 
 
 
 Secondly, the conceptual framework is described to establish the point of departure for the study. This study uses the work of Basil Bernstein, Harvey Sacks and Kenneth Burke to explore the changing nature of knowledge relations in Landscape Planning. Unconventionally perhaps, it begins by proposing a new concept called the 'decision space' formed from the conceptual spaces of multiple participants in an activity and developed from notions of creativity, conceptual boundaries and knowledge translation. It argues that it is in the 'decision space' that this inquiry is most likely to discover new knowledge about student-teacher struggles in Landscape Planning. It outlines an educational sociological view of the 'decision space' using Bernstein's concepts of the underlying pedagogic device, pedagogic discourse, pedagogic context, recontextualising field and most importantly the pedagogic code comprising two relative scales of classification and framing. It introduces an ethnomethodological view of knowledge boundaries that construct the 'decision space' using Sacks' concepts of context-boundedness and indexicality in people's talk. It also makes a link to a rhetorical view of knowledge choices in the 'decision space' using Burke's concepts of symbolic human action, motive and persuasion in people's speeches, art and texts. 
 
 
 
 Thirdly, the study is divided methodologically into three parts: knowledge relations in official and curriculum texts, knowledge choices in student drawings and knowledge troubles in student talk. Knowledge relations in official texts are investigated using two relative scales of classification and framing for Landscape Planning and its adjacent pedagogic contexts including Advanced Construction and Practice 1 and 2 and Advanced Landscape Design 1 and 2. The official texts that described unit objectives and content in each context reveal that Landscape Planning is positioned in the landscape architecture course in Queensland as an intermediary discourse between the strongly classified and strongly framed discourse of Advanced Construction and Practice and the weakly classified and weakly framed discourse of Advanced Landscape Design. This seems to intensify the need for students in their professional year to access and adapt to new pedagogic rules, apparently not experienced previously. A further subjective reflection of my own week 1 unit information as curriculum text using classification and framing relations is included to explain what characterised the rationale, aim, objectives, teaching programme, assessment practice and assessment criteria in Landscape Planning. It suggests that the knowledge relations in my teaching practice mirror the weakly classified and strongly framed discourse of the official text for this unit, that is that students were expected to transcend knowledge boundaries but also be able to produce specific forms of communication in the unit.
 
 
 
 Knowledge choices in student drawings in Landscape Planning are described using a new sociological method of visual interpretation. It is comprised of four steps: (a) setting up a framing scale using the social semiotic approach of Kress and van Leeuwen (2005) (contact gaze, social distance, angle of viewpoint, modality, analytical structure and symbolic processes) combined with the pentadic approach of Burke (1969) (act, scene, agency, purpose); (b) setting up a classification scale using the concept of agent from the pentad of Burke (1969) combined with how the relationship between 'I' the producer and 'you' the viewer is constructed in each drawing, like a sequence in a conversation according to Sacks (1992a); (c) coding student drawings according to these two relative scales and (d) assessing any shifts along the scales from the start to the end of the semester. This approach shows that there is some potential in assessing student drawings as rhetorical 'texts' and identifying a range of student orientations to knowledge. The drawings are initially spread across the four philosophical orientations when students begin Landscape Planning and while some shift, others do not shift their orientation during the semester. By the end of the semester in 2003, eight out of ten student drawings were characterised by weak classification of knowledge boundaries and weak framing of the space for knowledge choices. In 2004, nine out of twenty-one drawings exhibited the same orientation by the end of the semester. Thus there is a changing pattern, complex though it may be, of student orientations to knowledge acquired through studying Landscape Planning prior to graduating as landscape architects.
 
 
 
 Knowledge troubles in student talk are identified using conversation markers in student utterances such as 'I don't know', 'I think', 'before' and 'now' and the categorisation of sequences of talk according to what is knowable and who knows about Landscape Planning. Student talk suggests that students have a diverse set of affective responses to Landscape Planning, with some students able to recognise the new rules of the pedagogic code but not able to produce appropriate texts as learning outcomes. This suggests a sense of discontinuity where students dispute what is expected of them in terms of transcending knowledge boundaries and what is to be produced in terms of specific forms of communication. The study went further to describe a language of legitimation of knowledge in Landscape Planning based on how students viewed its scope, scale, new concepts and other related contexts and who students viewed as influential in their selection of legitimate knowledge in Landscape Planning. It is the language of legitimation that constructs the 'decision space'.
 
 
 
 Thus in relation to the main aims of the study, I now know from unit texts that the knowledge relations in my curriculum design align closely with those of the official objectives and required content for Landscape Planning. I can see that this unit is uniquely positioned in terms of its hidden rules between landscape construction and landscape design. From student drawings, I acknowledge that students make a range of knowledge choices based on different philosophical orientations from a pragmatic to a mystical view of reality and that my curriculum design allows space for student choice and a shift in student orientations to knowledge. From student talk, I understand what students believe to be the points of contention in what to learn and who to learn from in Landscape Planning. These findings have led me to construct a new set of pedagogic code modalities to balance the diverse expectations of students and the contemporary requirements of institutions, disciplines and professions in the changing context of higher education. Further work is needed to test these ideas with other teachers as researchers in other pedagogic contexts.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">landscape planning</field><field name="subject">landscape architecture</field><field name="subject">scholarship of integration</field><field name="subject">recontextualisation</field><field name="subject">pedagogic discourse</field><field name="subject">dramatism</field><field name="subject">indexicality</field><field name="identifier">http://eprints.qut.edu.au/16526/</field><field name="validLink">True</field></doc><doc><field name="title">Unstable acts : a practitioner's case study of the poetics of postdramatic theatre and intermediality</field><field name="creator">Fenton, David Raymond</field><field name="description">This practice-led research enquiry examines the form and experience of postdramatic theatre and intermediality. Through three practice-led enquiry cycles, the performance, Unstable Acts, was created. The study was designed to introduce the practitioner to a new process of practice within a postmodern aesthetic and to investigate the theory and practice of intermedial performance. Accordingly, Unstable Acts generated moments of praxis concerning postdramatic theatre and intermediality. By analysing this praxis an increasingly complex understanding of de-representational performance, the liminal experience, percipience, reflection and intermediality in postdramatic theatre was developed.    In responding to Unstable Acts, the study proposes a working model for the poetics of postdramatic theatre which places intermediality as a formal recurrence of the postdramatic form. The model also proposes that the postdramaturgical strategy of de-representational performance is a central stylistic quality of postdramatic form, and that the liminal experience is central to the postdramatic theatre experience. Connecting de-representation and liminality through queer theory, the model contends that reflection is an important aspect of both the form and experience of postdramatic theatre.    In so doing, the study provides a clearer understanding for theorists and practitioners of the poetics of postdramatic theatre and the position of intermediality in postdramatic practice.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">anxiety</field><field name="subject">conceptual</field><field name="subject">contemporary</field><field name="subject">cyborg</field><field name="subject">de-representation</field><field name="subject">digital</field><field name="subject">form</field><field name="subject">hybridity</field><field name="subject">identity</field><field name="subject">impotentiality</field><field name="subject">intermediality</field><field name="subject">interpretation</field><field name="subject">juxtaposition</field><field name="subject">liminality</field><field name="subject">mediatised</field><field name="subject">mediatized</field><field name="subject">mimesis</field><field name="subject">open</field><field name="subject">percipience</field><field name="subject">performance</field><field name="subject">practice-led</field><field name="subject">postdramatic</field><field name="subject">postdramaturgy</field><field name="subject">potentiality</field><field name="subject">queer</field><field name="subject">reflection</field><field name="subject">representation</field><field name="subject">theatre</field><field name="subject">virtual</field><field name="identifier">http://eprints.qut.edu.au/16527/</field><field name="validLink">True</field></doc><doc><field name="title">They didn't ask the question...An inquiry into the learning experiences of students with spina bifida and hydrocephalus</field><field name="creator">Rissman, Barbara Murray</field><field name="description">The researcher has a daughter who was born with an encephalocele and her neuropsychological assessment indicates a Nonverbal Learning Disability (NLD). The difficulties of the educational experiences that emerged over time, mainly because her learning profile was not understood, prompted reflection on the consequences for other students who present with this profile. A concern for the long-term implications for students and parents of the frequent misunderstandings of the NLD has inspired this study.    A review of the literature suggested a need to raise educator awareness about the subtle but disabling nature of the NLD syndrome. This study explored the perceptions of teachers, teacher aides and parents involved with 5 students who showed hallmark signs of an NLD. The theoretical foundation rests in the understanding that a student's learning experiences are influenced by past and present school experiences, the attitudes of peers, and parental expectations.    The purpose of this thesis is to help parents, teachers and others appreciate the school experiences of children at Level 1 risk of developing an NLD, those with a hydrocephalic condition. It does not purport to offer ultimate solutions or to contribute to diagnosis but rather to act as a starting point for a body of theory to guide development of suitable learning environments for such children. Of further importance is emphasis on the need for similar studies to be conducted into the learning experiences of other children who demonstrate specific syndromes or mosaic forms of those syndromes.    Naturalistic Inquiry methodology was used to explore the educational experiences of five students who attended different Australian schools. After completion of all interviews, psychological testing assessed general intelligence and the NLD status of each student. All students were found to be severely learning disabled and all were high on the NLD parameter. Educators generally did not reveal understanding of the NLD syndrome &amp;quotNonverbal, what is it? So is it a visual ..." Some teachers devised innovative strategies to help the student cope in class while others expressed frustration ... if the traditional instruction &amp;quotdoesn't work either, what does?" What stood out was an absence of understanding about nonverbal deficits. Frustration about poor organisation, decision making, task completion and problem-solving was expressed and a mixture of concern and criticism was levelled at social incompetence. Students who could not work independently were perceived by some teachers and aides as &amp;quotlazy" or &amp;quotmolly-coddled" and problems with everyday living skills were sometimes blamed on the student's family.    Findings revealed a compelling need to raise educator awareness about the range of cognitive, learning and social problems associated with shunted hydrocephalus and spina bifida. They also highlighted a need for teachers to question &amp;quotWhy can't this student do things one would expect they could do" and demand answers that explicate the serious difficulties being experienced.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">nonverbal learning disability</field><field name="subject">NLD</field><field name="subject">NLD profile</field><field name="subject">spina bifida</field><field name="subject">hydrocephalus</field><field name="subject">shunted hydrocephalus</field><field name="subject">teacher</field><field name="subject">aide</field><field name="subject">parent</field><field name="subject">student</field><field name="subject">educator</field><field name="subject">Education Queensland</field><field name="subject">acquired brain injury</field><field name="subject">ABI</field><field name="subject">assets</field><field name="subject">deficits</field><field name="subject">strengths</field><field name="subject">weaknesses</field><field name="subject">perception</field><field name="subject">phenotype</field><field name="subject">psychological</field><field name="subject">psychometric</field><field name="subject">assessment</field><field name="identifier">http://eprints.qut.edu.au/16528/</field><field name="validLink">True</field></doc><doc><field name="title">Schooling attention deficit hyperactivity disorders</field><field name="creator">Graham, Linda Jayne</field><field name="description">This thesis effects a (dis)ordered look as a disordered construct. A Thesis by Publication format has been employed, where instead of a traditional linear argument: A + B = Conclusion, this work follows a cartographical route - instead of traditional thesis chapters, there are scholarly journal articles. Whilst related, these papers each concentrate on different threads of the problem that we currently call &amp;quotAttention Deficit Hyperactivity Disorder". Connected by short linking summaries, they constitute a cartographic survey utilising Foucault's (1977; 2003b) notion of a discursive/technological grid to examine &amp;quotADHD" as a discursive formation and schooling as a system of formation of &amp;quotdisorderly" objects.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">attention deficit hyperactivity disorder</field><field name="subject">ADHD</field><field name="subject">Foucault</field><field name="subject">education systems</field><field name="identifier">http://eprints.qut.edu.au/16529/</field><field name="validLink">True</field></doc><doc><field name="title">Process modelling and control of pulse gas metal arc welding of aluminum</field><field name="creator">Posinasetti, Praveen</field><field name="description">Recent developments in materials and material joining [specifically Aluminum and Pulse Gas Metal Arc Welding (GMAW-P) technology] have increased the scope and extent of their areas of application. However, stern market demand for the improved weld quality necessitates the need for automation of the welding processes. As a result, improvements in the process parameter feedback, sensing and control, are necessary to successfully develop the automated control technology for the welding processes. Hence, several aspects of the GMAW-P process have been investigated in this study in order to improve its control techniques.
 
 
 
 Welding was conducted on 6XXX aluminium, using 1.2 mm diameter 4047 aluminum electrode and argon shielding gas. An extensive collection of high speed camera pictures were taken over a wide range of pulse parameters and wire feed rates using a xenon shadowgraph setup to improve understanding of the physics of GMAW-P process. Current and voltage signals were recorded concurrently too. 
 
 
 
 This investigation explores the effects of different process parameters namely pulsing parameters (Peak current (IP), Base Current (IB), Peak time (TP), Base Time (TB)) and wire feed rate on metal transfer phenomena in GMAW-P. Number of drops per pulse, arc length and droplet diameter were measured for aluminium electrodes by high speed videography. The pulsing parameters and wire feed rate were varied to investigate their effect on the metal transfer behaviour. Analysis showed that transition between the different metal transfer modes is strongly influenced by the electrode extension. Lower electrode extension reduced the number of droplets detached per pulse, while at higher electrode extension, spray mode is observed due to increased influence of the resistance heating.
 
 
 
 Analysis of the current and voltage signals were correlated with the high speed films. A simple derivative filter was used to detect the sudden changes in voltage difference associated with metal transfer during GMAW-P. The chosen feature for detection is the mean value of the weld current and voltage. A new algorithm for the real time monitoring and classification of different metal transfer modes in GMAW-P has been developed using voltage and current signals. The performance of the algorithm is assessed using experimental data. The results obtained from the algorithm show that it is possible to detect changes in metal transfer modes automatically and on-line.
 
 
 
 Arc stability in the GMAW-P has a close relationship with the regularity of metal transfer, which depends on several physical quantities (like voltage, current, materials, etc.) related to the growth and transfer of the metal droplet. Arc state in GMAW-P can be assessed quantitatively in terms of number of drops per pulse, droplet diameter and arc length. In order to assess the arc state in GMAW-P quantitatively, statistical and neural network models for number of drops/pulse, droplet diameter and arc length were developed using different waveform factors extracted from the current waveform of GMAW-P. To validate the models, estimated results were compared to the actual values of the number of drops per pulse, droplet diameter and arc length, observed during several welding conditions.
 
 
 
 Determination of stable one drop per pulse (ODPP) parametric zone containing all the combinations of peak current (IP), base current (IB), peak time (TP), and base time (TB) that results in stable operation of GMAW-P, is one of the biggest challenges in GMAW-P. A new parametric model to identify the stable ODPP condition in aluminium which also considers the influence of the background conditions and wire feed has been proposed.
 
 
 
 Finally, a synergic control algorithm for GMAW-P process has been proposed. Synergic algorithm proposed in this work uses the sensing and prediction techniques to analyse state of the arc and correct the pulsing parameters for achieving the stable ODPP. First arc state is estimated using the signal processing techniques and statistical methods to detect the occurrence of short circuit, unstable ODPP or multiple drops per pulse (MDPP) in GMAW-P system. If the arc state is not stable ODPP, then parametric model and genetic algorithm (GA) is used to assess the deviation of the existing pulsing parameters from the stable operation of GMAW-P process and automatically adjust pulsing parameters to achieve stable ODPP.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">aluminum</field><field name="subject">GMAW-P</field><field name="subject">statistical modelling</field><field name="subject">genetic algorithm</field><field name="identifier">http://eprints.qut.edu.au/16530/</field><field name="validLink">True</field></doc><doc><field name="title">Modelling of fluid flow in multiple axial groove water lubricated bearings using computational fluid dynamics</field><field name="creator">Tanamal, Tan Kong Hong Ryan</field><field name="description">Extensive research has been conducted in the area of journal bearings over many years for various operating conditions and geometry, effects of different types of lubricants (oil and water), different numbers (zero, one and three) and positions of grooves and the flow of lubricant between the shaft and bearing. One area of research has been developing methods to minimize the experimental time and cost of predicting the performance of journal bearings operating over a wide variety of conditions. This has led to numerical methods being developed and utilised for this purpose. Numerical methods are an important foundation for the development of Computational Fluid Dynamics (CFD). CFD method has proved to be a very useful tool in this research field.    This project uses a CFD (specifically FLUENT) approach to simulate the fluid flow in a water lubricated journal bearing with equal spaced axial grooves. Water is fed into the bearing from one end. The lubricant is subjected to a velocity induced flow, as the shaft rotates and a pressure induced flow, as the water is pumped from one end of the bearing to the other. CFD software is used to simulate the fluid flow phenomenon that occurs during the process. Different parameters such as eccentricity ratio, number of grooves and groove orientation to the load line were examined. Lubricant pressure and velocity profiles were obtained and compared with available theoretical and experimental results.    Two dimensional studies showed that the predicted maximum pressure and load carrying capacity from CFD were similar to the results from theoretical calculations. A small percentage difference (1.78% - 3.76%) between experimental and theoretical results was found. The pressure distribution in the lubricant shows that grooves decrease the pressure and load carrying capacity of the bearing. Swirl or turbulence does occur in the groove is affected by the viscosity of the lubricant. Three dimensional studies show that the pressure drops linearly from one end of the bearing to the other for no groove, concentric and three grooves cases. As the eccentricity increases, for one groove cases, the shape of the pressure profile changes to parabolic shape at positive region while the other pressure profiles drop linearly. The magnitude of the velocity it the bearing gap increased from 0.8 m/s to about 2.9 m/s when the shaft speed increased from zero to 5.5 m/s for a concentric and no groove case, similar changes were noted for all other cases.    An interesting observation occurs when implementing the pressure profiles along the bearing. At cases such as zero and one groove condition and e  = 0.4 and 0.6, lubricant flow back is observed at both inlet and outlet i.e. at certain area of the inlet, lubricant flowed out of the bearing against the supply pressure, a similar situation occurred at the exit of the bearing.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">computational fluid dynamics</field><field name="subject">CFD</field><field name="subject">journal bearings</field><field name="identifier">http://eprints.qut.edu.au/16531/</field><field name="validLink">True</field></doc><doc><field name="title">Socioeconomic position and utilisation of preventive health services among adults in the general population</field><field name="creator">Zhang, Jianzhen (Jenny)</field><field name="description">Background: International research has shown that socioeconomically disadvantaged groups experience significantly higher mortality and morbidity rates than other groups. Both cardiovascular disease (CVD) and diabetes are major contributors to Australia's burden of disease, and individuals from lower socioeconomic groups are more likely to be affected by both, and to have worse prognoses and outcomes. There is substantial research evidence that a range of preventive activities can reduce the morbidity and mortality associated with these conditions. Research in countries with good access to primary health care services has demonstrated that socioeconomically disadvantaged groups tend to have higher levels of medical consultations, but make less use of preventive care and screening services. This fact contributes to their poorer health outcomes, as diagnosis will typically occur later than for more advantaged individuals, thus leading to a poorer prognosis. However, to date, there has been little research on the differential utilisation of preventive health services for CVD and diabetes by different socioeconomic groups in Australia. To understand socioeconomic influences on the use of preventive health services, a comprehensive review of the literature of determinants of health service utilisation was conducted and a number of explanations for this relationship considered. It was proposed that the following factors are likely to be important in this relationship: differences in the perception of the availability of, and accessibility to health care, attitudes and beliefs toward preventive health care, having a regular source of care, perception of interpersonal care from general practitioners, and social support. A number of theoretical models were also reviewed; in particular, the Andersen Behavioural Model of Health Service Research Utilisation. Aims: This doctoral research program has described the relationship between socioeconomic position (SEP) and utilisation of preventive health services in relation to CVD and diabetes. It aims to improve the understanding of the determinants of uptake and utilisation of preventive health services in general practice by different socioeconomic groups in Australia. Methods: The study was conducted in Brisbane Australia, in 2004, using a cross-sectional design and a self-administered mailed survey for data collection. A sample of adults aged 25-64 years was selected randomly from the Brisbane Electoral Roll. A conceptual model incorporating a range of relevant socio-demographic, risk-factor and behavioural variables in the relationship between SEP and GP-based use of preventive health services was used to develop a self-administered questionnaire. The questionnaire was pilot-tested and then reviewed by a panel of international experts. A new self-administered questionnaire, the Health Service Utilisation Questionnaire (HSUQ), was developed. It included 79 items: 12 socio-demographic items; 10 items assessing health status, disease conditions and smoking status; 20 items assessing use of health services; and 37 items assessing the factors that might affect use of health services utilisation. The HSUQ was then mailed to 800 randomly selected survey participants. The survey response rate was 65.6 per cent. After exclusion of those patients with cardiovascular diseases and diabetes, the final sample size was 381, consisting of 155 males and 226 females. Socioeconomic indicators were individual education level and family income. Blood pressure, blood cholesterol and blood glucose check-ups by general practitioners (GPs) were used as the major outcome variables. Nine scales and two dichotomous variables that measure those potential factors were derived following Principal Component Analysis and reliability testing. The data were analysed separately by gender, and adjusted for age and each of the socioeconomic indicators. Statistical description, bivariate analysis and multivariable modelling in SPSS were applied for the data analysis. Results: The survey results were suggestive of socioeconomically disadvantaged people being less likely than more advantaged people to utilise preventive health services for CVD and diabetes. For males, the low socioeconomic groups recorded the least use of preventive health services among the three education and income groups, including blood cholesterol and blood glucose check-ups, while the high socioeconomic group recorded the greatest use of preventive health services. There was no apparent relationship between education level and blood pressure check-up, while individuals from low-income families were less likely to go for a blood pressure check-up. For females, most of the results suggested that the low socioeconomic groups were less likely than the high socioeconomic groups to have blood cholesterol and blood glucose check-ups. However, this was not the case for blood pressure check-ups. The results showed that the low and middle socioeconomic groups were more likely than the high socioeconomic groups to have BP check-ups. However, the low socioeconomic groups were still less likely than the middle socioeconomic groups to have a blood pressure check-up. Overall, there was a similar pattern between education and income and the use of GP-based preventive health services among both males and females.    The findings from the examination of the mediating factors between SEP and the GP-based use of preventive health services suggested that socioeconomically disadvantaged adults (both low level of education and low income) are more concerned about transport and travel time to health care, and accessibility to health care in terms of finding a GP who bulk bills, the cost of seeing a GP and having a choice of GP. They are also less likely to have a regular place of care and social support. These potential factors are likely to result in a lesser use of preventive health services than their high-SEP counterparts. In addition, the findings also suggested that respondents with a low level of education have less-positive attitudes towards health care, and that those from low-income families do not have a regular care provider and are less likely to visit their GP for a preventive check-up in relation to CVD and diabetes in Australia. Conclusions: Strategies for reducing socioeconomic health inequalities are partly associated with changing social and economic policies, empowering individuals, strengthening social and family networks, and improving the equity of the health care system. Strategies have been recommended for implementation in general practice that are directed at targeting the needs of disadvantaged groups; for example, providing longer consultation time and actively offering information on preventive care. Implementation of health promotion programs is needed in disadvantaged areas to keep the community informed about the availability of health services and to make health services more accessible. The health care system needs to be geographically accessible through improvements to the transport system. In addition, improving access to a regular source of primary health care is likely to be an important step in encouraging low-SEP individuals to use preventive health services.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">utilisation</field><field name="subject">blood pressure check-up</field><field name="subject">blood cholesterol check-up blood glucose check-up</field><field name="subject">determinants</field><field name="subject">development of questionnaire</field><field name="subject">mail survey</field><field name="identifier">http://eprints.qut.edu.au/16532/</field><field name="validLink">True</field></doc><doc><field name="title">Quantifying the effect of exercise on total energy expenditure in obese women</field><field name="creator">Colley, Rachel Christine</field><field name="description">The prevalence of obesity continues to increase despite considerable research and innovation regarding treatment and management strategies. When completed as prescribed, exercise training is associated with numerous health benefits and predictable levels of weight loss. However, under free-living conditions the benefits of exercise are less consistent, suggesting that non-adherence and/or a compensatory response in non-exercise activity thermogenesis (NEAT) may be occurring. The accurate quantification of all components of total energy expenditure (TEE), including TEE itself, was imperative to elucidate the primary research question relating to the impact of exercise on TEE. In addition, the measurement of changes in body composition and the response to prescribed exercise were assessed in methodological and pilot investigations. Following this extensive background, the primary research question relating to the effect of exercise on levels of TEE and the associated implications of such a compensatory response could be more rigorously investigated.    The first study investigated the variability in isotopic equilibrium time under field conditions, and the impact of this variability on estimates of total body water (TBW) and body composition when using the deuterium dilution technique. Following the collection of a fasting baseline urine sample, 10 women and 10 men were dosed with deuterium oxide (0.05g/kg body weight). Urine samples were collected every hour for 8 hours. The samples were analysed using isotope ratio mass spectrometry and time to equilibration was determined using three commonly employed data analysis approaches. Isotopic equilibrium was reached by 50, 80 and 100% of participants at 4, 6 and 8 h, respectively. The mean group equilibration times determined using the three different plateau determination methods were 4.8 &#177; 1.5, 3.8 &#177; 0.8, and 4.9 &#177;1.4 h, respectively. Isotopic enrichment, TBW, and percent body fat estimates differed between early sampling times (3-5 h), but not later sampling times (5-8 h). Therefore, sampling &lt; 6 hours post dose compared to sampling &#8805; 6 hours resulted in greater relative measurement error in TBW and body composition estimates. Although differences in equilibration time were apparent between the three plateau determination approaches, sampling at 6 hours or later may decrease the likelihood of error in body composition estimates resultant from incomplete isotopic equilibration in a small proportion of individuals.    In the second study, the aim was to measure the self-paced walking (SPW) speed of adults ranging in body size from normal to obese. The utility of heart rate monitors to estimate the energy cost of walking was also investigated. Twenty-nine participants (12 normal-weight, 17 overweight or obese) completed two outdoor walking tests to determine their SPW speed. A walking treadmill test with stages below, at, and above the SPW speed was completed to compare the energy expenditure estimates of the Polar S610 and WM42 heart rate monitors with that from indirect calorimetry. The average SPW speed was 1.7 &#177; 0.1 m*sec-1, which was equivalent to an exercise intensity of 48.6 &#177; 9.4 %VO2max (61.0 &#177; 7.1 %HRmax). There was no difference in the energy expenditure estimation between indirect calorimetry (4.7 &#177; 0.7 kcal*kg*-1*h-1), the S610 (4.8 &#177; 1.3 kcal*kg*-1*h-1) and the WM42 (4.8 &#177; 1.6 kcal*kg*-1*h-1).  It was concluded that the heart rate monitors provided reasonable energy expenditure estimates at the group level. However considerable error was evident at the individual level, explained in part by exercise heart rate and fitness level, suggesting that an individualised calibration should be performed where possible. An additional finding from this study was that 145 to 215 minutes of SPW per week, dependent upon the level of adiposity, is required to meet the current American College of Sports Medicine (ACSM) guidelines for health of 1000 kcal*wk-1.    The purpose of the third study was to establish the level of adherence to a specific exercise prescription (1500 kcal*wk-1) by objectively quantifying unsupervised exercise energy expenditure (ExEE) in a group of obese women. The 16-wk lifestyle intervention consisted of weekly meetings with research staff, combined with promotion of increased ExEE (1500 kcal*wk-1) and a decreased dietary intake (-500 kcal*d-1). Twenty-nine obese females (Body Mass Index = 36.8 &#177; 5.0 kg*m2, Body Fat = 49.6 &#177; 3.7 %) from a hospital-based lifestyle intervention were included in the analysis. ExEE was estimated and monitored weekly using heart rate monitoring. Body composition was measured before and after the intervention by dual-energy x-ray absorptiometry (DXA). Results indicated free-living adherence to the exercise prescription was modest and variable, with 14% of participants achieving the 1500 kcal*wk-1. The average weekly ExEE (768 kcal*wk-1) represented 51.2% of the total amount prescribed. ExEE was correlated with changes in body weight (r = 0.65, p &lt; 0.001) and fat mass (r = 0.65, p = 0.0002). Achievement of a 5% weight loss target was dependent on an ExEE level of 1000 kcal*wk-1 (p &amp;lt0.001). Exercise 'adherers' (&gt; 000 kcal*wk-1) lost more weight (-9.9 vs. -4.1 kg), more fat mass (-6.8 vs. -3.0 kg), and more waist circumference (-9.8 vs. -5.6 cm) when compared to 'non-adherers' (&lt; 1000 kcal*wk-1). The results suggest that the extent of supervision and monitoring influenced exercise adherence rates. The variability in adherence highlights the importance of objective monitoring of ExEE. Identification of individuals not complying with program targets may enable intervention staff to provide additional support or make individualised adjustments to the exercise prescription.    The fourth study investigated issues relating to the management and interpretation of  accelerometry data when the device is to be used to monitor levels of daily physical activity. Given the high between-individual variability in accelerometry output for a given walking speed, the use of a more individualised approach to the data management has been suggested. In addition, accelerometry was used to compare daily physical activity patterns between a supervised and unsupervised exercise prescription of the same dose (1500 kcal*wk-1) in overweight and obese women. Total energy expenditure, activity energy expenditure, and vector magnitude increased significantly during the intervention. Time spent in very low intensity movement decreased from baseline to the intervention (p &lt; 0.01) in both the supervised (-18.6 min*d-1) and unsupervised (-68.5 min*d-1) group, whereas time spent in high and vigorous intensity movement increased significantly from baseline to the intervention (p &lt; 0.05 and p &lt; 0.0001, respectively). The increase in vigorous movement was significantly greater in the supervised group when compared to the unsupervised group (+11.5 vs. +5.4 min*d-1, p &lt; 0.05). Time spent above three different moderate-intensity walking thresholds increased from baseline to the intervention (p &lt; 0.0001). The threshold determination approach significantly affected the resultant outcomes (p &lt; 0.0001) such that the standard threshold was significantly different to both group-specific and individualised approaches. Significant differences were also noted in accelerometer output between treadmill and overground walking (p &lt; 0.0001). A positive finding of this study was that two different interventions aimed at increasing physical activity levels in a group of sedentary and obese women were successful in gaining modest increases in overall daily movement. The change observed appears to be a replacement of sedentary movement with more vigorous physical activity. Collectively, the differences observed between threshold determination approaches, as well as between treadmill and overground walking, highlight the need for standardised approaches to accelerometry data management and analysis. In addition, the findings suggest that obese women may benefit from a certain degree of exercise supervision to ensure compliance, however, strategies to encourage these women to continue with the exercise on their own without supervision are essential to making a sustainable long-term change to their lifestyles.    The final study aimed to assess whether obese women compensate for structured exercise by decreasing their NEAT and thereby impeding weight loss. Thirteen participants were prescribed 1500 kcal*wk-1 of exercise through a structured walking program (4 week supervised followed by 4 weeks unsupervised). The energy expenditure of the walks was quantified using individually-calibrated Polar F4 heart rate monitors. The DLW technique was used to measure TEE. Accelerometry measures were also collected throughout and represented an alternative method of quantifying changes in total daily movement patterns resultant from an increase in energy expenditure through exercise. Compliance with the exercise program was excellent, with the average compliance being 94% over the 8-week intervention. The adoption of moderate-intensity exercise in this group of obese women resulted in a 12% decrease in TEE (p = 0.01) and a 67% decrease in NEAT (p &lt; 0.05). No significant change was observed in resting metabolic rate from baseline to the  postintervention time-point. Compensation was significantly correlated with dietary report bias (r= -0.84, p = 0.001), body image (r = 0.75, p &lt; 0.01), and bodily pain (r = -0.65, p &lt; 0.05). A linear regression model including dietary reporting bias and the pain score explained 78% of the variation in &#916;TEE. Compensators were therefore less likely to underreport their dietary intake, less likely to be self-aware of their obese state, and more likely to be experiencing pain in their daily life. Self-reported dietary intake decreased significantly during the intervention (p = 0.01) with specific decreases noted in fat and carbohydrate intake. The consequence of compensation was evidenced by a lack of significant change in body weight, body composition, or blood lipids (p &gt; 0.05). However, positive outcomes of the study included improvement in the SF-36 scores of general health (p &lt; 0.05) and maintenance of exercise program adherence into the unsupervised phase of the intervention. Qualitative data collected via interview indicated that 85% of participants experienced increased energy and positive feedback from peers during the intervention. This study confirms that exercise prescription needs to be prescribed with an individualised approach that takes into account level of adiposity. The goal of exercise prescription for the obese should therefore be to determine the intensity and modality of exercise that does not activate compensatory behaviours, as this may in turn negate the beneficial effects of the additional energy expenditure of exercise.    This study confirms that during the initial phase of an exercise-based weight loss intervention, the majority of obese women compensated for some, if not all, the energy cost of the exercise sessions by reducing NEAT. Whether this compensatory behaviour continues beyond the first month of an exercise program, particularly after training adaptations in cardiorespiratory fitness are realised, cannot be discerned from the current study. However these results do provide a rationale for why the magnitude of weight loss achieved is often less than predicted during exercise interventions. Further research is required to examine the temporal pattern of compensation in NEAT, and the relationship between the time courses of NEAT compensation relative to physical fitness improvements. The results from this thesis support the use of activity monitors such as accelerometers during weight loss interventions to track NEAT and provide objective feedback regarding compensatory behaviours to clinicians and the obese individuals.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">physical activity</field><field name="subject">exercise energy expenditure</field><field name="subject">non-exercise activity thermogenesis</field><field name="subject">NEAT</field><field name="subject">exercise adherence</field><field name="subject">body composition</field><field name="subject">accelerometry</field><field name="subject">heart rate monitoring</field><field name="subject">deuterium dilution</field><field name="subject">lifestyle interventions</field><field name="identifier">http://eprints.qut.edu.au/16533/</field><field name="validLink">True</field></doc><doc><field name="title">Sustainable housing for residential-industrial neighbourhoods in Malaysia : a study on the elements of indoor environmental quality improvements</field><field name="creator">Zakaria, Rozana</field><field name="description">Economic development brings about urbanisation which may result in rapid housing expansion. The health and well-being of communities is often not considered as a priority of urbanisation with the pressure for developing better economies. Sustainability principles in housing developments are perceived to be able to enhance and to improve the quality of living. The approach to sustainability can, however, be interpreted and prioritised differently. Many developing countries such as Malaysia are depending upon industrialisation for the development of their economies. Continuing urbanisation and industrialisation in these countries indirectly creates tensions between the need for a better built environment, and the push for economic growth. One specific phenomena in Malaysia is the introduction of the mixed-use urban neighbourhood, whereby residential development is netsled within the industrial establishments. On one hand, this helps to create job opportunities and improve the local economy. On the other, it creates concerns in the relations to the house planning, and to the well-being of the residents. These have potential exposures to industrial activities that are associated with environmental problems, such as, poor air quality, local temperature increases, and excessive noise levels. This research applied the current international trends of sustainability practices in housing development in searching for the most appropriate strategies for developing sustainable residential-industrial neighborhoods. Cross reference to other countries strategies and experiences can be adaptation for Malaysian conditions. A residential-industrial community in the city of Pasir Gudang Johor, Malaysia, has been selected as a case study in order to examine the perceived problems of indoor environmental quality in such environments. The result of a questionnaire survey and in-situ measurement indicates that they are facing indoor environmental problems. A set of recommendations for housing guidelines which are tailored for local Malaysians conditions have been identified, and have potential for improving the housing development guidelines and policies for mixed-use community living. Comprehensive strategies will need to be developed to achieve housing development sustainability goals. The development of Master Planned Communities (MPC's) is suggested to be appropriate mechanism to developing planning controls. This will ensure the improvement of indoor environmental quality of living in residential-industrial housing developments in Malaysia. It is anticipated that this research will make a positive contribution to developing decision-making procedures that are appropriate to achieving the goals of sustainable housing development in relation to mixed-used residential housing, It is also expected that this research will assist in establishment of a unified national sustainable housing strategy, and in the rationalised adoption of a master planned community approach.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">industrialisation</field><field name="subject">indoor air quality</field><field name="subject">indoor environment quality</field><field name="subject">master planned community</field><field name="subject">mixed-use urban development</field><field name="subject">neighbourhoods</field><field name="subject">planning development</field><field name="subject">residential-industrial</field><field name="subject">sustainable living</field><field name="subject">sustainable development</field><field name="subject">sustainable principles</field><field name="identifier">http://eprints.qut.edu.au/16534/</field><field name="validLink">True</field></doc><doc><field name="title">Conceptualizing complex meaning systems : the case of management fads</field><field name="creator">Corfield, Wendy Lea</field><field name="description">The thesis is an attempt to apply complex systems thinking to the problem of meaning. It is in two parts. Part 1, Chapter 1 introduces the research agenda and overviews the thesis. Chapter 2 establishes the value of adopting a systems approach to the problem of meaning.  The next chapter introduces key concepts of complex systems theory as they apply to sociocultural phenomena, and the last chapter in Part 1 reviews three theories of complex meaning systems (Donald Campbell, Jay Lemke, and Paul Cilliers) from which a preliminary model and agenda for theorising complex meaning systems is proposed. Part 2 of the thesis investigates the phenomena of management fads, applying the models of complex meaning systems formulated in Part 1. No primary empirical work is attempted; rather an analytical engagement is conducted using secondary literature on what we know about such fads. The literature, both primary and secondary, is reviewed and critiqued. The final chapters exemplify the problem of meaning using the theory building and agenda setting from Part 1. The concluding chapter reflects on the adequacy of a complex systems approach to meaning, critiques the process of the thesis and comments upon its contribution.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">meaning</field><field name="subject">philosophy</field><field name="subject">complex systems</field><field name="subject">management fads</field><field name="subject">management gurus</field><field name="subject">decision making</field><field name="subject">emergence</field><field name="subject">epistemology</field><field name="subject">ontology</field><field name="identifier">http://eprints.qut.edu.au/16535/</field><field name="validLink">True</field></doc><doc><field name="title">The impact of work-family conflict on working women in Taiwan : the effects of organizational support</field><field name="creator">Lu, Yu-Ying</field><field name="description">A cross-sectional survey was undertaken to examine the impact of organizational support on work-family conflict experienced by Taiwanese working women. A stress model of work and family interference was applied in the Taiwanese context; the current study examined whether the results of western studies of work-family conflict can be generalised to the Taiwanese population. The enactment of the Gender Equality of Employment Law in Taiwan in 2002 was a further impetus for the research. The study examined the effects of organizational family-friendly policies and cultural support of family responsibilities on work-family conflict and well-being.    Women (aged between 15 and 64 years) in paid employment working in three public universities in northern Taiwan formed the sample population for this research. Stratified random sampling by occupation was used to enhance representativeness. The total sample consisted of 441 participants, made up of 288 general staff and 153 academic staff. The data was collected with several tested and widely used instruments (including the Family-Friendly Policies Usage and Satisfaction Questionnaires, Work-Family Culture Questionnaire, Work-Family Conflict Scale, Job Satisfaction Questionnaire, Family Satisfaction Questionnaire, Perceived Stress Scale, and Physical Symptoms Inventory). Descriptive analysis was used to examine demographic variables and all the measures; correlation analysis was used to examine the relationships between selected research variables; T-test, chi-square test and one-way ANOVA were used to characterize the differences between groups.  Hierarchical multiple regression was performed to test the research hypotheses.    The findings showed that work-family conflict was strongly linked with lower job and family satisfaction, greater stress and more severe physical ailments. Implementing family-friendly policies and creating a supportive work environment can help working women to manage their work-family conflict and improve their health outcomes. A supportive organizational culture has been confirmed by this research as important in preventing the negative consequences of work-family conflict. However, such conflict did not predict the levels of physical symptoms. Employer-supported dependant care policies were not associated with the level of work-family conflict. In addition, organizational cultural support did not predict the usage of family-friendly policies. This study has provided evidence that some relationships could be generalised, across western and Chinese societies, between organizational support and work-family conflict, and between work-family conflict and an individual's well-being, although specificities within each cultural remain and require different methods of assessment.    In conclusion, a western theoretical model of work-family conflict was found to be acceptable and feasible to implement within the Taiwanese population, since the majority of the hypotheses were supported. This research provided valuable information for healthcare professionals, policy makers and organizations, presenting ways to help working women to manage the conflicting demands of work and family roles better.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">working women</field><field name="subject">work-family conflict</field><field name="subject">family-friendly policies</field><field name="subject">leave policies</field><field name="subject">flexible work arrangements</field><field name="subject">employer-supported dependant care</field><field name="subject">organizational culture</field><field name="subject">well-being</field><field name="subject">job satisfaction</field><field name="subject">family satisfaction</field><field name="subject">psychological stress</field><field name="subject">physical symptoms</field><field name="subject">Taiwan</field><field name="identifier">http://eprints.qut.edu.au/16536/</field><field name="validLink">True</field></doc><doc><field name="title">Seismic response of building fa&#231;ade system with energy absorbing connections</field><field name="creator">Hareer, Rahila Wardak</field><field name="description">Facades are popular in modern buildings and are made of different materials such as pre-cast concrete, glass, aluminium, granite or marble and steel. During recent times seismic activity in densely populated areas has resulted in damage and a consequent loss of life. There were many types of building failure, including failure of building facade systems. Facade systems are highly vulnerable and fail more frequently than the buildings themselves with significant devastating effects. During an earthquake building frames suffer large interstorey drifts, causing racking of the building facade systems. The facade systems may not be able to cater for such large deformations and this can result in either functional or total failure at the facade connections or damage by pounding (impact) with adjacent facade panels. Fa&#231;ade failure and collapse can cause serious damage to buildings and injury to people in the vicinity. Moreover, facade represent between 10- 20 % or more of the total building cost depending on the size and importance of the facility and facade material (Facades1980).  Considering the cost and safety issues, the importance of a well designed facade system on a building needs to be emphasised. In modern buildings, energy absorbing passive damping devices are very commonly used for energy absorption in order to manage the vibration response of multistorey buildings in an earthquake event. A number of manufactured dampers such as Viscoelastic and viscous, friction and yielding dampers are available. These dampers use a range of materials and designs in order to achieve diverse levels of damping and stiffness.    This thesis is an investigation of the seismic behaviour of building facade systems and studies the effects of facade and connection properties on this response. The objectives with energy absorbing connections of the study are to determine and control facade distortions and to establish the required connection properties. Finite Element techniques have been used for modelling and analysis of the building frame, facade and connections. Time history analyses under earthquake loadings were carried out to determine the system response in terms of inter-storey drifts, facade distortions, differential displacement between facades and frames and the axial force in horizontal connections. Connection properties with respect to stiffness and energy absorption capability (or damping) have been modelled and varied to obtain the desired response. Findings illustrate the influence of these connection properties on system response and show that it is possible to control facade distortions to within acceptable limits. They also demonstrate that energy absorbing connections are able to reduce inter-storey drifts and mitigate the detrimental seismic effects on the entire building facade system.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">earthquake</field><field name="subject">facades</field><field name="subject">buildings</field><field name="subject">time histories</field><field name="subject">connection</field><field name="subject">stiffness</field><field name="subject">damping</field><field name="subject">inter-storey drift</field><field name="subject">distortion</field><field name="subject">finite element</field><field name="identifier">http://eprints.qut.edu.au/16537/</field><field name="validLink">True</field></doc><doc><field name="title">Vibration characteristics of steel-deck composite floor systems under human excitation</field><field name="creator">De Silva, Sandun S.</field><field name="description">Steel-deck composite floor systems are being increasingly used in high-rise building construction, especially in Australia, as they are economical and easy to construct.
 
 These composite floor systems use high strength materials to achieve longer spans and are thus slender. As a result, they are vulnerable to vibration induced under service loads. These floors are normally designed using static methods which will not reveal the true behaviour and miss the dynamic amplifications resulting in inappropriate designs, which ultimately cause vibration and discomfort to occupants.
 
 At present there is no adequate design guidance to address the vibration in these composite floors, due to a lack of research information, resulting in wasteful post event retrofits.
 
 
 
 To address this gap in knowledge, a comprehensive research project is presented in this thesis, which investigated the dynamic performance of composite floors under various human induced loads. A popular type of composite floor system was selected for this investigation and subjected to load models representing different human activities. These load models have variable parameters such as load intensity, activity type (contact ratio), activity frequency and damping and are applied as pattern loads to capture the maximum responses in terms of deflections and accelerations.
 
 Computer models calibrated against experimental results are used in the analysis to generate the required information. The dynamic responses of deflections and accelerations are compared with the serviceability deflection limits and human comfort levels (of accelerations) to assess these floor types.
 
 
 
 This thesis also treats the use of visco-elastic (VE) dampers to mitigate excessive vibrations in steel-deck composite floors. VE damper properties have been presented and their performances in reducing the excessive vibrations have been assessed this thesis.
 
 
 
 The results identified possible occupancies under different loading conditions that can be used in planning, design and evaluation. The findings can also be used to plan retrofitting measures in problematic floor systems.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">floor vibration</field><field name="subject">human perceptibility</field><field name="subject">finite element modelling</field><field name="subject">composite floors</field><field name="subject">human-induced loads</field><field name="subject">pattern loading</field><field name="subject">damping</field><field name="subject">dynamic amplifications</field><field name="subject">accelerations</field><field name="subject">visco-elastic dampers</field><field name="identifier">http://eprints.qut.edu.au/16538/</field><field name="validLink">True</field></doc><doc><field name="title">Development of a novel rep-inducible tomato leaf curl virus expression system</field><field name="creator">Williams, Brett Robert</field><field name="description">Pathogen-derived resistance (PDR) strategies, particularly those based on post-transcriptional gene silencing, have been used with great success for the generation of transgenic plants with resistance to RNA viruses. In contrast, a suitable strategy for transgenic resistance to ssDNA plant viruses, including those viruses belonging to the Geminiviridae, has remained elusive. Further, there is no convincing evidence that either post-transcriptional gene silencing, or pathogen-derived resistance in general, would be broadly applicable to ssDNA plant viruses. Researchers at QUT have been developing a novel resistance strategy against ssDNA viruses based on virus-activated expression of a stably integrated suicide gene. The strategy, based on InPAct (In Plant Activation) technology, relies on a &amp;quotsplit" suicide gene cassette being arranged in such a way that expression of a lethal ribonuclease (barnase) is dependent on the virus-encoded replication-associated protein (Rep). Upon infection, Rep mediates the release of the construct resulting in the reconstitution of a transcribable and translatable episomal suicide gene expression cassette. The research for this PhD describes the development of an InPAct vector designed to confer resistance to Tomato leaf curl begomovirus (ToLCV), a major cause of disease in Solanaceous crops in the tropics and subtropics.    ToLCV-based InPAct vectors were constructed based upon two ToLCV isolates from Australia and North Vietnam. Prior to the generation of InPAct cassettes, the entire ToLCV-[Au] and ToLCV-Vie intergenic regions (IRs) were embedded within the castorbean catalase intron of a &#946;-glucuronidase expression vector to determine the effect of the IR upon transcript processing. Using transient reporter gene assays in tobacco NT-1 cells, it was demonstrated that the ToLCV IRs both contained cryptic intron splice sites which interfered with efficient transcript processing and GUS expression. A series of truncations to the IRs were subsequently made to identify the potential cryptic intron splice sites and/or interfering sequences in both the ToLCV-[Au] and ToLCV-Vie IRs. The final truncated IRs, which were used in the construction the InPAct cassettes, comprised approximately 100 bp and appeared to contain all the necessary cis-acting elements required for efficient rolling circle replication (RCR). Using histochemical GUS assays and Southern analyses, the InPAct cassettes were shown to be activated and replicated only in the presence of the cognate viral Rep. GUS expression levels were shown to be further enhanced in the presence of the ToLCV replication-enhancer protein (REn) and by the addition of the Tobacco yellow dwarf mastrevirus origin of second strand synthesis into the cassette. Under these conditions, Rep-activated GUS expression from the InPAct vectors was found to reach levels similar to that of the benchmark CaMV 35S promoter. Fifteen independent transgenic lines containing the ToLCV-[Au] and -Vie InPAct-GUS cassettes were generated by Agrobacterium-mediated transformation of tobacco leaf discs. Using agroinfiltration and histochemical assays, Rep-mediated activation of the InPAct cassettes and subsequent GUS expression was demonstrated in 11 out of the 15 lines tested; six of which showed expression levels equivalent to, or higher than, that obtained using a CaMV 35S promoter control. Evidence for activation of the integrated InPAct cassettes at the molecular level was provided by Southern analyses, with showed both linear and open circular forms of the replicating InPAct episome in genomic DNA extracted from infiltrated leaf tissue. Following the demonstration of Rep-activatable reporter gene expression and episomal replication of the ToLCV-based InPAct-GUS vectors using transient and stable tobacco transformation assays, new ToLCV-based InPAct vectors were designed to express the lethal RNase, barnase, in an attempt to generate virus resistant plants. Although transient assays in NT-1 cells demonstrated some &amp;quotleaky" expression of barnase from the InPAct vectors, the level of barnase-mediated cell death from the InPAct vectors was found to be significantly increased in the presence of the cognate Rep and REn. Thirteen independently transformed tobacco lines containing the ToLCV-[Au] InPAct-barnase cassette were generated by Agrobacterium-mediated transformation of tobacco leaf discs. However, agroinfiltration of these plants with ToLCV Rep and REn failed to activate a barnase response. Subsequent molecular analyses on two transgenic lines revealed that both contained mutations in the barnase-coding gene in a region known to encode the active site. These mutations were presumed to result from the leaky barnase expression during initial stages of the Agrobacterium transformation which would favour the selection of barnase mutant InPAct plants. To overcome the problems associated with leaky expression of barnase, a barstar-expression cassette was included in the ToLCV-[Au] InPAct-barnase cassette. Transient assays in non-transgenic tobacco leaves demonstrated that the basal levels of barstar expressed from the modified InPAct vector were sufficient to negate the effects of leaky barnase expression. Importantly, however, the level of barnase expression in the presence of Rep and REn was shown to be sufficient to overcome the basal levels of barstar. Seventeen independently transformed lines were generated with the ToLCV-[Au] InPAct-barnase/barstar cassette, and analysis of one line revealed the presence of an uncorrupted barnase-coding region. Using transient agroinfiltration assays, seven of the transgenic lines showed varying levels of cognate Rep and REn-activated, barnase-induced cell death.    Fifteen transgenic lines were challenged with ToLCV-[Au] by injection of recombinant Agrobacteria containing an infectious ToLCV clone. Unfortunately, all lines displayed typical ToLCV symptoms and tested positive for virus by PCR at 28 days post-inoculation. The inability of the InPAct cassette to confer resistance to ToLCV may have been due to one or a combination of factors, including (i) a delay in barnase-induced cell death, (ii) homology-dependent silencing of the integrated cassette, (iii) generally low-level, Rep-activated barnase expression or (iv) excessive virus load due to the artifical method of inoculation.   This study details the first report of a ToLCV-based InPAct system for Rep-induced transgene expression in planta. Despite failing to generate ToLCV-resistant plants, the research findings will provide a solid foundation to develop a more effective InPAct vector and ultimately assist in the generation of transgenic plants with resistance to ToLCV and potentially other ssDNA plant viruses, particularly the begomoviruses.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">pathogen-derived resistance (PDR)</field><field name="subject">tomato leaf curl virus</field><field name="subject">replication-association protein (Rep)</field><field name="subject">begomoviruses</field><field name="identifier">http://eprints.qut.edu.au/16539/</field><field name="validLink">True</field></doc><doc><field name="title">Detection and identification of potyviruses and geminiviruses in Vietnam</field><field name="creator">Ha, Cuong Viet</field><field name="description">Prior to the commencement of this project, few plant viruses had been identified from Vietnam despite virus-like symptoms being commonly observed on many crops and weeds. In limited surveys in the late 1990's, preliminary evidence was obtained indicating that potyviruses and geminiviruses were causing significant diseases. As a result, this study was aimed at developing generic PCR-based methods for the rapid detection of viruses belonging to viruses in the families Potyviridae and Geminiviridae in plant samples collected from Vietnam, and to characterise the viruses at the molecular level.    Novel degenerate PCR primers were developed for the identification of begomoviruses. Using these primers, 17 begomoviruses species infecting seven crop and nine weed species in Vietnam were identified and characterised. Sequence analyses showed that ten of the viruses (six monopartite and four bipartite) were new species. Of the seven previously characterized begomoviruses, five were identified in Vietnam for the first time. Additionally, eight DNA-&#223; and three nanovirus-like DNA-1 molecules were also found associated with the monopartite viruses. Five of the DNA-&#946; molecules were putatively novel.    Two novel bipartite begomoviruses, named Corchorus yellow vein virus (CoYVV) and Corchorus golden mosaic virus (CoGMV), were isolated from jute plants. Analysis of these viruses showed that they were more similar to New World begomoviruses than to viruses from the Old World. This was based on the absence of an AV2 open reading frame, the presence of an N-terminal PWRLMAGT motif in the coat protein and phylogenetic analysis of the DNA A and DNA B nucleotide and deduced amino acid sequences. This is the first known occurrence of Old World viruses bearing features of New World viruses, and their presence in Vietnam suggests the presence of a &amp;quotNew World" virus in the Old World prior to Gondwana separation. Other interesting features relating to begomoviruses identified in Vietnam were; (i) the detection of several recombination events, particularly between the newly identified Tomato yellow leaf curl Vietnam virus (TYLCVNV), and the previously characterised, Tomato leaf curl Vietnam virus (ToLCVV), (ii) the identification of new natural hosts of Sida leaf curl virus (SiLCV), Papaya leaf curl China virus (PaLCuCNV) and Alternanthera yellow vein virus (AlYVV), (iii) the first report of variation in the geminivirus stem-loop nonanucleotide sequence (CoGMV sequence was TATTATTAC rather than TAATATTAC) and (iv) the first report of  different stem sequences in the stem-loop structure of two genomic components from a bipartite begomovirus, Kudzu mosaic virus (KuMV). The sequence and phylogenetic analyses of the begomoviruses and begomovirus-associated DNAs identified in this study suggested that South East Asia, and Vietnam in particular, may be a centre of begomovirus diversity.    Two pairs of degenerate primers, designed in the CI gene (CIFor/CIRev) and HC-Pro gene (HPFo/HPRev), were developed for the detection of viruses in the genus Potyvirus. Using these primers, three novel potyviruses from Vietnam were detected, namely Telosma mosaic virus (TelMV) infecting telosma (Telosma cordata), Peace lily mosaic virus (PeLMV) infecting peace lily (Spathiphyllum patinii) and Wild tomato mosaic virus (WTMV) infecting wild tomato (Solanum torvum). The fragments amplified by the two sets of primers enabled additional PCR and complete genomic sequencing of these three viruses and a Banana bract mosaic virus (BBrMV) isolate from the Philippines. All four viruses shared genomic features typical of potyviruses. Sequence comparisons and phylogenetic analyses indicated that WTMV was most closely related to Chilli veinal mottle virus (ChiVMV) and Pepper veinal mottle virus (PVMV) while PeLMV, TelMV were related to different extents with members of the BCMV subgroup.   The incidence of potyviruses infecting plants in Vietnam was investigated using the potyvirus-specific primers. Fifty two virus isolates from 13 distinct potyvirus species infecting a broad range of crops were identified in Vietnam by PCR and sequence analysis of the 3' region of the genome. The viruses were Bean common mosaic virus (BCMV), Potato virus Y (PVY),  Sugarcane mosaic virus (SCMV), Sorghum mosaic virus (SrMV), Chilli veinal mottle virus (ChiVMV), Zucchini yellow mosaic virus (ZYMV), Leek yellow stripe virus (LYMV), Shallot yellow stripe virus (SYSV), Onion yellow dwarf virus (OYDV), Turnip mosaic virus (TuMV), Dasheen mosaic virus (DsMV), Sweet potato feathery mottle virus (SPFMV) and a novel potyvirus infecting chilli, which was tentatively named Chilli ringspot virus (ChiRSV). With the exception of BCMV and PVY, this is first report of these viruses in Vietnam. Further, rabbit bell (Crotalaria anagyroides) and typhonia (Typhonium trilobatum) were identified as new natural hosts of the Peanut stunt virus (PStV) strain of BCMV and of DsMV, respectively. Sequence and phylogenetic analyses, based on the nucleotide sequence of the entire CP-coding region of all 52 virus isolates, revealed considerable variability in BCMV, SCMV, PVY, ZYMV and DsMV. The phylogenetic analyses also suggested the possible presence of ancestral groups of BCMV, SCMV and ZYMV in Vietnam.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">ssDNA viruses</field><field name="subject">geminiviridae</field><field name="subject">begomovirus</field><field name="subject">ssDNA satellites</field><field name="subject">begomovirus-associated DNA &#946;</field><field name="subject">begomovirus-associated DNA 1</field><field name="subject">ssRNA viruses</field><field name="subject">potyviridae</field><field name="subject">potyvirus</field><field name="subject">degenerate primer</field><field name="subject">nanovirus</field><field name="subject">Vietnam</field><field name="identifier">http://eprints.qut.edu.au/16540/</field><field name="validLink">True</field></doc><doc><field name="title">Effectiveness of a specific infection control education program for Taiwanese nursing students</field><field name="creator">Wu, Chia Jung</field><field name="description">The purpose of the study  The purpose of this research project was to develop and test an educational program for preparing Taiwanese nursing students for clinical practice.    Study background  The SARS outbreak revealed that health care professionals were ill-prepared for coping with the disease epidemic in terms of the rapid transmission of the infection, the high mortality and morbidity rate among health care workers, and the significant impacts on the public and health care personnel. Frontline nurses were the group at highest risk of becoming infected, as they are the health care personally that provide direct health care to infected patients. However, to date the ability of Taiwanese frontline nurses to respond to such a disease epidemic has not been examined.    Study design  This research project incorporated a three phase design, presented in the form of two separate studies. A small qualitative exploratory study was undertaken to validate the assumptions emerging from international literature regarding the preparedness nurses in managing an infection outbreak. The information gained was used to construct an infection control education program (Study I). A quasi-experimental design, using pre- and post-tests and experimental and control groups was then used to test the effectiveness of the education intervention (Study II).    Participants  A purposive sampling technique was used in the qualitative exploratory study, whereby six Taiwanese nurses who had provided direct nursing care to patients with SARS were interviewed. A convenience sampling approach was utilised in the quantitative study, which aimed to test the effectiveness of educational intervention. This, second study, had 175 participants in total, 80 in the experimental group and 95 in the control group. All participants were enrolled in the first semester of their fourth year in a five-year nursing program in two selected junior nursing colleges.    The education intervention  The purpose-designed standard and additional precautions (SnAP) program was the intervention. The experimental group received a SnAP program which consisted of 16 hours of classes over 16 weeks. The control group received a conventional education program.    Data collection and instrument  Data were collected at three time points during the study (baseline, four months, six month) using validated instrument. The reliability and validity of the instrument was established in a pilot study with a Taiwanese population prior to the present study.    Data analysis  t-tests and chi-square analyses were performed to assess any differences across demographic variables and baseline outcome variables between the experimental and control groups. Two-way repeated measures ANOVAs were used to examine the scores of the intervention and control groups across three time points.    Results  The data revealed that, at six months following the education program, there was a statistically significant improvement in the knowledge (F [2,180] =13.53, p=0.001) and confidence (F [2,94] =4.88, p= 0.01) of infection precautions in the intervention group compared to the control group. Also, the means of knowledge and confidence in intervention group showed a consistently increased across three time points; whereas, the mean of confidence relating infection control management in the control group resulted a drop at time 3. Although the application skills relating to infection control procedures did not show a statistically significant change during this period (F [2, 174] = 2.54, p=0.081), there were minor improvements in these scores at the six-month follow-up assessment.    Conclusion  The SnAP program had a positive impact on Taiwanese nursing students' readiness for clinical placement and potential outbreak of disease epidemics. Participation increased their knowledge about infection control precautions, their ability to properly use these specific precautions, and their confidence in solving infection-related issues in clinical practice.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">infection control</field><field name="subject">standard and additional precautions</field><field name="subject">infection control precautions</field><field name="subject">severe acute respiratory syndrome (SARS)</field><field name="subject">infection control education program</field><field name="subject">nursing curriculum</field><field name="subject">nursing education</field><field name="identifier">http://eprints.qut.edu.au/16541/</field><field name="validLink">True</field></doc><doc><field name="title">Development of soil-eps mixes for geotechnical applications</field><field name="creator">Illuri, Hema Kumar</field><field name="description">Global concern about the environmental impacts of waste disposal and stringent implementation of environmental laws lead to numerous research on recycled materials. Increased awareness about the inherent engineering values of waste materials, lack of landfill sites and strong demand for construction materials have encouraged research on composite materials, which are either fully or partly made of recycled materials. This trend is particularly strong in transportation and geotechnical projects, where huge quantities of raw materials are normally consumed.    Owing to the low mass-to-volume ratio, disposal of Expanded Polystyrene (EPS) is a major problem. In addition, EPS recycling methods are expensive, labour intensive and energy demanding. Hence, this thesis is focused on the development of a new soil composite made by mixing recycled EPS with expansive clays. Given the high cost of damage to various buildings, structures and pavements caused by the unpredictable ground movements associated with expansive soils, it has been considered prudent to try and develop a new method of soil modification using recycled EPS beads as a swell-shrink modifier and desiccation crack controller. The innovative application of recycled EPS as a soil modifier will minimise the quantity of waste EPS destined to the landfill considerably.    An extensive experimental investigation has been carried out using laboratory reconstituted expansive soils - to represent varied plasticity indices - consisting of fine sand and sodium bentonite. Three soils notated as SB16, SB24 and SB32 representing 16%, 24% and 32% of bentonite contents respectively were tested with four EPS contents of 0.0%, 0.3%, 0.6% and 0.9%. The tests performed include compaction, free swell, swell pressure, shrinkage, desiccation, shear strength and hydraulic conductivity. All the tests have been performed at the respective maximum dry unit weight and optimum moisture content of the mixes. It has been observed that by mixing of recycled EPS beads with the reconstituted soil, a lightweight geomaterial is produced with improved engineering properties in terms of dry unit weight, swelling, shrinkage and desiccation.    The EPS addition depends on the moulding moisture content of the soil. With increasing moisture content, additional EPS can be added. Also, there is a reduction in dry unit weight with the addition of EPS. Furthermore, the reduction of swell-shrink potential and desiccation cracking in soils, for example, is related to the partial replacement of soil particles as well as the elasticity of the EPS beads. There is a reduction in shear strength with the addition of EPS to soils. However, mixing of chemical stabilisers along with EPS can enhance the strength in addition to improved overall properties.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">expanded polystyrene</field><field name="subject">EPS</field><field name="subject">expansive soil</field><field name="subject">recycled materials</field><field name="subject">swelling</field><field name="subject">shrinkage</field><field name="subject">desiccation</field><field name="subject">cracking</field><field name="subject">soil stabilisation</field><field name="subject">soil replacement</field><field name="identifier">http://eprints.qut.edu.au/16542/</field><field name="validLink">True</field></doc><doc><field name="title">The internationalization process of entrepreneurial SMEs in high technology niche market segments</field><field name="creator">Cruz-Carreon, Gilbert</field><field name="description">This study seeks to make a theoretical contribution to the rapidly growing field of  International Entrepreneurship by investigating the process of internationalization of Small and Medium Enterprises (SMEs). Bell, McNaughton, Young &amp; Crick, (2003) emphasized the need for researchers to re-conceptualize their thinking on the internationalization process of smaller firms.    While there has been substantial research done on the small business internationalization and how the participation of these firms in the global economy has fuelled economic growth in a number of countries (Audretsch &amp; Thurik, 2003; Acs, Randall Morck, Shraver &amp; Yeung, 1997; Storey, 1994; Alam &amp; Pacher, 2003), there is tangible evidence that SMEs in Australia are not keeping up with global trends. Studies conducted on Australian firms allude to the following reasons for their constrained presence in international markets: (i) geographic and psychic distance; (ii) costs disadvantage; (iii) overdependence on inward FDI from large foreign multinationals; (iv) a history of inward-looking and narrowly focussed economic development policies of the Australian government. These factors had the combined effect of imbalanced economic growth which was particularly detrimental to the small business sector (Australian Trade Commission, 2002; Maitland &amp; Nicholas, 2002; Alam &amp; Pacher, 2003).    Despite the identified obstacles, some Australian SMEs have succeeded in penetrating international markets. This study involved a preliminary qualitative investigation of selected Australian SMEs and their unique internationalization process. Evidence from the case study based investigation will indicate that the respondent firms have leveraged on entrepreneurial qualities to overcome the obstacles and enhance their success in international markets. As such, the internationalization process for these selected firms is seen as an extension of and integral to their entrepreneurial behaviour.    Using the lenses provided by relevant facets of the entrepreneurship, internationalization and strategy scholarly fields, this exploratory qualitative study, while building the foundation for further empirical research into the internationalization process of SMEs, can serve as a guide to researchers for ascertaining future directions in this emergent field. The findings from the study are intended to contribute to a body of knowledge encompassing the cross-border operations of SMEs. The research also has value from a practical perspective as Australian SMEs can draw from this body of knowledge as they pursue opportunities internationally.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">internationalization</field><field name="subject">entrepreneurship</field><field name="subject">small business</field><field name="subject">resource based view</field><field name="subject">psychic proximity</field><field name="subject">networks</field><field name="subject">entrepreneurial motivation</field><field name="subject">opportunity recognition</field><field name="subject">high technology</field><field name="subject">niche market</field><field name="subject">social construction</field><field name="identifier">http://eprints.qut.edu.au/16543/</field><field name="validLink">True</field></doc><doc><field name="title">From sandstone to sandpit : a study of a community playgroup in a university</field><field name="creator">Lewis, Patricia Anne</field><field name="description">This thesis examines the establishment and maintenance of an early childhood playgroup project in an Australian university setting. It examines the playing out of the intention of a university to create a collaborative partnership with an early childhood playgroup initiative within a higher education policy climate actively promoting such endeavours. The study documents the struggle to establish the playgroup project, elaborating the conditions that enabled and/or constrained its inclusion into a university setting. To do so, it investigates the contextual and relational issues that sustained or impeded the operationalisation of the playgroup project, identifying the stakeholders and the parts they played in supporting the initiative. The aim of the study is to generate new knowledge of a little-researched area, namely that of partnerships between universities and the community in the area of early childhood education.    The study is underpinned by the feminist theoretical work of Dorothy Smith (1987), and so takes the everyday world as problematic, using this standpoint as an analytic framework through which to observe and understand women's lives as they worked to establish the playgroup project in the university setting. Additionally the work of Marilyn Strathern (1997) concerning the audit culture of universities was used to enhance Smith's epistemological approach. The data collection methods for the study were in-depth interviews, participant observations and document analysis. In-depth, unstructured interviews were conducted with seventeen women involved with the playgroup project. The sample comprised ten playgroup parents, four women from the Centre for Human Services, and three lecturers from the Child and Family Studies section of the School for Human Services. Additionally participant observations were completed and recorded as field notes. The majority of these took place in the playgroup rooms. The collection and examination of documentation associated with the playgroup project focused on significant documents ranging from emails and parking permits, to government and university policy imperatives. These documents were analysed as texts mediating the playgroup initiative.    Findings detailed the conditions that enabled and/or constrained the inclusion of the playgroup project into a university setting. It was found the playgroup project was enabled by: government and university policies encouraging university and community partnership; a genuine intention on behalf of the university to promote partnerships with the community; thematics in the discourse of early childhood education promoting the profession's caring nature; and, committed people who worked to ensure the continuation of the playgroup project. It was found that the playgroup project was constrained by: government and university policies promoting research agendas; a partnership that was not collaborative in nature; disagreements about decision-making and leadership within the playgroups; the hierarchical nature of the university; and, differing notions of work and play that made the playgroups difficult to sustain.    The study identified factors that enabled and/or constrained a specific community and university partnership in relation to early childhood education. In doing so it begins to fill a gap in the literature in this area. Findings from this study may be used to inform early childhood professionals and academics by expanding their awareness of the issues involved in undertaking a partnership such as this one. The implications that flow from the study included the need for greater understanding of the anthropology of the university and its systemic organisation, a formal contract for the partnership specifying the obligations of each party and outlining expectations, and the inclusion of committed people, prepared to work toward genuine collaborative partnerships.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">audit culture</field><field name="subject">childcare</field><field name="subject">community</field><field name="subject">early childhood</field><field name="subject">feminist</field><field name="subject">institutional ethnography</field><field name="subject">partnership</field><field name="subject">performativity</field><field name="subject">playgroup</field><field name="subject">university</field><field name="identifier">http://eprints.qut.edu.au/16544/</field><field name="validLink">True</field></doc><doc><field name="title">A framework for the dynamic coordination of services</field><field name="creator">Lawrence, Ian Rae</field><field name="description">Web services is a relatively recent initiative that aims to promote program-toprogram interaction across the Internet, but while web services is based on a set of  XML standards, new standards continue to emerge and existing standards to evolve.  Also, web services relies on Remote Procedure Call (RPC) for communication and is thus influenced by the semantics of RPC. In this research, we investigated the juxtaposition of RPC with Generative Communications (GC). GC is a communication paradigm where messages exist independently of the sender and receiver and are stored in a network accessible buffer called a &amp;quotspace": this leads to interactions which are inherently decoupled (in time and space). Also, messages are addressed to recipients by their content, rather than by network addresses, opening up the possibility for one-to-many interactions. These aspects are a marked departure from the RPC paradigm and introduce two main implications: 1) GC messages can be intercepted when in-transit between participants thus introducing the opportunity for mediation and 2) GC can be used as the basis for the aggregation of simple services into more complex ensembles.    In this research, we explored these possibilities by creating proof-of-concept prototypes in three areas. 1) Mediation - GC based mediation was used to intercede between clients and services to allow a client using one protocol to interact with a service using a different protocol. For example, a GC based client interacting with a SOAP service (leading to backward compatibility). 2) Location services - a location service is a GC based service that performs a similar function to a UDDI registry but can be treated as just another service rather than part of an architecture. 3) Aggregation - a workflow design was used as the basis of an aggregated service using GC as the means by which the aggregation elements interact. We concluded that GC provides a natural platform for mediation, location services and aggregation and that these aspects could be combined to produce a holistic service environment.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">web services</field><field name="subject">generative communications</field><field name="subject">service aggregation</field><field name="identifier">http://eprints.qut.edu.au/16545/</field><field name="validLink">True</field></doc><doc><field name="title">Developing security services for network architectures</field><field name="creator">Tham, Kevin Wen Kaye</field><field name="description">In the last 15 years, the adoption of enterprise level data networks had increased dramatically. This is mainly due to reasons, such as better use of IT resources, and even better coordination between departments and business units. These great demands have fuelled the push for better and faster connectivity to and from these networks, and even within the networks. We have moved from the slow 10Mbps to 1Gbps connectivity for end-point connections and moved from copper-based ISDN to fibre-linked connections for enterprise connections to the Internet. We now even include wireless network technologies in the mix, because of the greater convenience it offers.    Such rapid progress is accompanied by ramifications, especially if not all aspects of networking technologies are improved linearly. Since the 1960s and 1970s, the only form of security had been along the line of authentication and authorisation. This is because of the widely used mainframes in that era. When the Internet and, ultimately, the wide-spread use of the Internet influxed in the 1980s, network security was born, and it was not until the late 1980s that saw the first Internet Worm that caused damage to information and systems on the Internet. Fast forward to today, and we see that although we have come a long way in terms of connectivity (connect to anywhere, and anytime, from anywhere else), the proposed use of network security and network security methods have not improved very much. Microsoft Windows XP recently switched from using their own authentication method, to the use of Kerberos, which was last revised 10 years ago.    This thesis describes the many problems we face in the world of network security today, and proposes several new methods for future implementation, and to a certain extend, modification to current standards to encompass future developments. Discussion will include a proposed overview of what a secure network architecture should include, and this will lead into several aspects that can be improved on. All problems identified in this thesis have proposed solutions, except for one. The critical flaw found in the standard IEEE802.11 wireless technology was discovered during the course of this research. This flaw is explained and covered in great detail, and also, an explanation is given as to why this critical flaw is not fixable.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">secure network architecture</field><field name="subject">security services</field><field name="subject">protocols</field><field name="subject">denial-of-service</field><field name="subject">network security</field><field name="subject">worm</field><field name="subject">denial-of-service</field><field name="identifier">http://eprints.qut.edu.au/16546/</field><field name="validLink">True</field></doc><doc><field name="title">The attraction of sloppy nonsense: resolving cognitive estrangement in Stargate through the technologising of mythology</field><field name="creator">Whitelaw, Sandra</field><field name="description">The thesis consists of the novel, Stargate Atlantis: Exogenesis (Whitelaw and Christensen, 2006a) and an accompanying exegesis.
 
 The novel is a stand-alone tie-in novel based on the television series Stargate Atlantis (Wright and Glassner), a spin-off series of Stargate SG-1 (Wright and Cooper) derived from the movie Stargate (Devlin and Emmerich, 1994). Set towards the end of the second season, Stargate Atlantis: Exogenesis begins with the discovery of life pods containing the original builders of Atlantis, the Ancients. The mind of one of these Ancients, Ea, escapes the pod and possesses Dr. Carson Beckett. After learning what has transpired in the 10,000 years since her confinement, the traumatised Ea releases an exogenesis machine to destroy Atlantis. Ea dies, leaving Beckett with sufficient of her memories to reveal that a second machine, on the planet Polrusso, could counter the effects of the first device. When the Atlantis team travel to Polrusso, what they discover has staggering implications not only for the future of Atlantis but for all life in the Pegasus Galaxy.
 
 The exegesis argues that both science and science fiction narrate the dissolution of ontological structures, resulting in cognitive estrangement. Fallacy writers engage in the same process and use the same themes and tools as science fiction writers to resolve cognitive estrangement: they technologise mythology. Consequently, the distinction between fact and fiction, history and myth, is blurred.
 
 The exegesis discusses cognitive estrangement, mythology, the process of technologising mythology and its function as a novum that facilitates the resolution of cognitive estrangement in both fallacy and science fiction narratives. These concepts are then considered in three Stargate tie-in novels, with particular reference to the creative work, Stargate Atlantis: Exogenesis.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">technologising mythology</field><field name="subject">cognitive estrangement</field><field name="subject">verisimilitude</field><field name="subject">fallacy</field><field name="subject">ontology</field><field name="subject">Stargate SG-1</field><field name="subject">Stargate Atlantis</field><field name="subject">media tie-ins</field><field name="subject">media novels</field><field name="subject">mythology</field><field name="subject">science fiction television</field><field name="subject">SF</field><field name="subject">genre television</field><field name="subject">alien gods</field><field name="subject">extraterrestrial gods</field><field name="subject">cults</field><field name="subject">familiarisation</field><field name="subject">defamiliarisation</field><field name="subject">refamiliarisation</field><field name="subject">Lovecraft</field><field name="subject">Velikovsky</field><field name="subject">Hubbard</field><field name="subject">von Daniken</field><field name="subject">Sitchin</field><field name="subject">Campbell</field><field name="subject">Devlin</field><field name="subject">Emmerich</field><field name="identifier">http://eprints.qut.edu.au/16547/</field><field name="validLink">True</field></doc><doc><field name="title">Identification of viral-based replicating vectors suitable for the development of a sugarcane bioreactor</field><field name="creator">Pirlo, Steven Dominic</field><field name="description">The circular, single-stranded (ss) DNA genomes of plant viruses in the families Geminiviridae and Nanoviridae are replicated within the nucleus of a host cell by a mechanism called rolling circle replication (RCR). Although this process relies almost exclusively on the replication machinery of the host cell, initiation occurs via the interaction of the viral replication initiation protein (Rep) with regulatory DNA sequences within the viral genome. The use of a virus-based episomal amplification technology as a plant bioreactor platform exploits the process of Rep-mediated RCR for the high-level amplification of virus-based episomes in plants and subsequent expression of heterologous proteins; such an approach offers advantages over existing gene expression technologies. This PhD thesis describes research towards the development of a virus-based episomal amplification system for use in sugarcane. Such a crop is ideally suited for a plant bioreactor system due to the efficient high-level production of plant biomass and the existence of established production, harvesting and processing infrastructure.    In order to rapidly assess the potential of a virus-based episomal amplification system in sugarcane, a transient assay system was established. Sugarcane callus was identified as the most suitable cell preparation; providing rapid cell regeneration, uniform experimental samples and upon isolation, total DNA suitable for Southern analysis. This assay system once established, proved effective in rapidly identifying virus-based episomes capable of undergoing RCR within sugarcane host cells.    This transient assay system was then used to test the functionality of a virus-based episomal amplification system based on the ssDNA virus, Banana bunchy top virus (BBTV) in sugarcane. BBTV-based episomal amplification vectors were constructed with a reporter gene expression cassette flanked by two copies of the BBTV regulatory DNA sequences. The episomal amplification vectors were bombarded into sugarcane and banana host cells in various combinations and evidence of RCR was assessed through Southern blot analysis. RCR products were identified in banana host cells bombarded with the BBTV-based episomal amplification vectors in combination with vectors encoding BBTV Master-Rep (M Rep). RCR products were not identified within sugarcane cells bombarded with the same construct combinations.    Integrated InPAct (In Plant Activation) episomal vectors based on BBTV were then employed to confirm the transient results, in addition, the functionality of an InPAct vector based on an alternate virus, Tobacco yellow dwarf virus (TYDV) was also assessed. InPAct vectors based on BBTV were constructed with an untranslatable expression cassette for integration within the sugarcane genome. Transient experiments were performed to assess the ability of BBTV M-Rep and TYDV Rep to initiate RCR of their respective InPAct vectors. Visual observation of GFP expression indicated that BBTV M-Rep was capable of initiating RCR of the BBTVbased InPAct vectors within banana host cells but no evidence was observed in sugarcane host cells. TYDV Rep was capable of initiating RCR of the TYDV-based InPAct vector within sugarcane host cells with a 100-fold increase in the number of fluorescent foci compared to cells bombarded with the TYDV InPAct vector alone. The BBTV-based InPAct vector was stably integrated within the sugarcane genome and the ability for BBTV M-Rep to initiate episome formation and RCR was assessed by Southern blot analysis. Evidence of BBTV M-Rep mediated RCR was not detected within the transgenic sugarcane bombarded with BBTV M-Rep. Transgenic sugarcane containing the TYDV-based InPAct vectors was assessed for the ability to be activated by TYDV Rep and undergo RCR. Southern blot analysis demonstrated that TYDV Rep was capable of recognising the integrated TYDVbased InPAct vector and RCR was detected within the transgenic sugarcane.    The observation that episomal vectors based on TYDV were functional within sugarcane host cells and BBTV-based vectors were not, was unexpected. It had been hypothesised that an episomal vector based on a monocot-infecting virus would replicate in an alternate monocot host, while an episomal vector based on a dicot infecting virus would not. Virus replication is thought to be host-specific however most host range studies have been conducted with full length infectious clones and not deconstructed virus-based episomes. The implication that viral Reps may be functional in plant cells of non-host species was then investigated. The ability for viral Reps to recognise their cognate IR and initiate RCR of virus-based episomes in different host cells was assessed through cross-replication experiments. Four ssDNA plant viruses; BBTV, TYDV, Chloris striate mosaic virus (CSMV) and Tomato leaf curl virus - Australia (ToLCV-Au) were assessed via Southern blot analysis for their ability to initiate both autonomous replication of infectious clones and episomal amplification within three different plant hosts; tobacco, sugarcane and banana.    Results from cross replication studies indicated a complex interaction between viral and host replication components. BBTV infectious clones and episomal vectors were restricted to replication within banana host cells providing a clear indication that episomal amplification vectors based on BBTV are restricted to Musa spp.  BBTV M-Rep was unable to recognise the viral regulatory DNA sequences of the other three ssDNA viruses. TYDV infectious clones and episomal vectors were capable of replicating within all three host cells tested, indicating that TYDV is capable of undergoing RCR within a broad range of plant hosts. TYDV Rep was also capable of recognising the viral regulatory DNA sequences of both CSMV and BBTV given favourable conditions within specific plant hosts. Replication of the CSMV infectious clone was not detected in any of the three host cells, although fidelity of this clone requires further confirmation. CSMV episomal vectors were functional within banana host cells only, indicating that although closely related to TYDV, episomal amplification vectors based on CSMV have a restricted host range.  CSMV Rep could not initiate RCR of episomal amplification vectors containing the viral regulatory DNA regions of the other three viruses in any of the plant host cells. ToLCV-Au infectious clones were capable of replicating within banana and tobacco host cells. Episomal amplification vectors based on ToLCV-Au extended the host range to sugarcane. ToLCV-Au Rep was unable to recognise the viral regulatory  DNA sequences of the other three viruses in any of the plant host cells. The ability for a viral Rep to recognise its own cognate regulatory DNA sequences within alternate plant host cells is variable. Episomal amplification vectors based on TYDV and ToLCV-Au appear to be the most suitable for the further development of a virusbased bioreactor system in sugarcane.    This study details the initial steps taken towards the development of a virus-based episomal amplification system in sugarcane. In doing so, fundamental knowledge into the mechanisms involved in Rep recognition of viral regulatory DNA sequences has been gathered. These research findings will provide a solid foundation for the further development of a sugarcane-based bioreactor.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">bioreactor; episomal; amplification; rolling circle replication; replication initiation protein; replication accessory protein; TYDV; BBTV; ToLCV-Au; CSMV; ssDNA plant virus</field><field name="identifier">http://eprints.qut.edu.au/16548/</field><field name="validLink">True</field></doc><doc><field name="title">Novel modulators of cell growth and migration</field><field name="creator">Van Lonkhuyzen, Derek Robert</field><field name="description">Recent observations have demonstrated that Insulin-like Growth Factors (IGFs) are able to form complexes with the extracellular matrix protein Vitronectin (VN). These complexes of VN:IGFBP:IGF-I significantly enhance the proliferation and migration of various cell lines including skin and corneal epithelial cells, as well as primary cells derived from human skin and corneal tissue. These enhanced effects arise from co- activation of the IGF-binding type-1 IGF receptor (IGF-1R) as well as activation of the VN-binding &#945;v-integrins. Further studies suggest that these complexes can replace the requirement for serum in the ex vivo expansion of cells. In order to translate the VN:IGFBP:IGF-I technology into techniques for the improved culture of cells, we have designed, expressed and purified synthetic chimeric molecules, consisting of various domains of VN and mature IGF-I, using a baculovirus based expression system. The recombinant VN:IGF-I (rVN:IGF-I) chimeras were secreted into conditioned media of transfected Sf9 insect cells. Purification of the chimeras was achieved via methods including heparin-sepharose chromatography, Q-sepharose ion-exchange chromatography and Ni2+-NTA affinity chromatography. The rVN:IGF-I chimeras were detectable by Western blot analysis using a poly-clonal anti-VN antibody. Functional characterisation studies indicate that the chimeras promote cellular growth and migration to a similar extent as the VN:IGFBP:IGF-I complexes at 10x and 30x molar ratios. Additionally, function blocking antibodies directed to the IGF-1R and the VN binding &#945;v-integrin were able to abolish this effect indicating that co-activation of these receptors is critical to the migratory effect of the chimeras. A functional chimera may lead to the development of cell culture techniques and methodologies that are devoid of xenogeneic or allogeneic support systems, thus paving the way to approved tissue engineering therapeutics that incorporate ex vivo expanded adult stem and progenitor cells.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Insulin-like Growth Factors (IGFs)</field><field name="subject">Vitronectin (VN)</field><field name="subject">cell growth</field><field name="identifier">http://eprints.qut.edu.au/16549/</field><field name="validLink">True</field></doc><doc><field name="title">The whole world shook: shifts in ethnic, national and heroic identities in children's fiction about 9/11</field><field name="creator">Lampert, Jo Ann</field><field name="description">Like many other cataclysmic events September 11, a day now popularly believed to have 'changed the world', has become a topic taken up by children's writers.  This thesis, titled The Whole World Shook: Ethnic, National and Heroic Identities in Children's Fiction About 9/11, examines how cultural identities are constructed within fictional texts for young people written about the attacks on the Twin Towers.  It identifies three significant identity categories encoded in 9/11 books for children: ethnic identities, national identities, and heroic identities.  The thesis argues that the identities formed within the selected children's texts are in flux, privileging performances of identities that are contingent on post-9/11 politics. This study is located within the field of children's literature criticism, which supports the understanding that children's books, like all texts, play a role in the production of identities. Children's literature is highly significant both in its pedagogical intent (to instruct and induct children into cultural practices and beliefs) and in its obscurity (in making the complex simple enough for children, and from sometimes intentionally shying away from difficult things).  This literary criticism informed the study that the texts, if they were to be written at all, would be complex, varied and most likely as ambiguous and contradictory as the responses to the attacks on New York themselves. The theoretical framework for this thesis draws on a range of critical theories including literary theory, cultural studies, studies of performativity and postmodernism.  This critical framework informs the approach by providing ways for: (i) understanding how political and ideological work is performed in children's literature; (ii) interrogating the constructed nature of cultural identities; (iii) developing a nuanced methodology for carrying out a close textual analysis. The textual analysis examines a representative sample of children's texts about 9/11, including picture books, young adult fiction, and a selection of DC Comics.  Each chapter focuses on a different though related identity category.  Chapter Four examines the performance of ethnic identities and race politics within a sample of picture books and young adult fiction; Chapter Five analyses the construction of collective, national identities in another set of texts; and Chapter Six does analytic work on a third set of texts, demonstrating the strategic performance of particular kinds of heroic identities.  I argue that performances of cultural identities constructed in these texts draw on familiar versions of identities as well as contribute to new ones.  These textual constructions can be seen as offering some certainties in increasingly uncertain times.  The study finds, in its sample of books a co-mingling of xenophobia and tolerance; a binaried competition between good and evil and global harmony and national insularity; and a lauding of both the commonplace hero and the super-human.  Being a recent corpus of texts about 9/11, these texts provide information on the kinds of 'selves' that appear to be privileged in the West since 2001. The thesis concludes that the shifting identities evident in texts that are being produced for children about 9/11 offer implicit and explicit accounts of what constitute good citizenship, loyalty to nation and community, and desirable attributes in a Western post-9/11 context. This thesis makes an original contribution to the field of children's literature by providing a focussed and sustained analysis of how texts for children about 9/11 contribute to formations of identity in these complex times of cultural unease and global unrest.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">9/11</field><field name="subject">children&#146;s literature</field><field name="subject">fiction</field><field name="subject">cultural identity</field><field name="subject">postmodernism</field><field name="subject">ethnicity</field><field name="subject">national identity</field><field name="subject">heroism</field><field name="subject">terrorism</field><field name="identifier">http://eprints.qut.edu.au/16550/</field><field name="validLink">True</field></doc><doc><field name="title">Promoting better weaning practice in PICU : the development, implementation and evaluation of guidelines for weaning children from mechanical ventilation</field><field name="creator">Keogh, Samantha Jane</field><field name="description">Introduction: Weaning from mechanical ventilation is defined as the gradual reduction of mechanical support, and replacing this support with spontaneous ventilation. It is a complex process involving assessing the patient's readiness to wean, optimising factors that can impede the process, selecting the most appropriate weaning mode and continually assessing the patient's progress. In paediatric intensive care the clinician must also account for the unique physiological and psychosocial needs of the child.    Aim: The aim of the study was to explore the need for, and impact, of guidelines for weaning children from mechanical ventilation on patient outcomes and staff practice.    Method: The study was multi-dimensional using the Model for Improvement as the conceptual framework and decided into four phases.    Phase one: A survey of Australian PICUs in 2000 revealed that over 2500 children were ventilated over a 12 month-period, with a potential population of 625 children experiencing difficulties with weaning from mechanical ventilation. No guidelines for weaning children from mechanical ventilation were identified at the time. Standardising the approach to weaning had proven successful with the adult population.    Phase two: Collaborative guidelines for weaning, based on available evidence and expert opinion, were drawn up, validated by a panel of experts and safely piloted.    Phase three: The guidelines were then tested using a time series design over two years on a PICU at a tertiary referral children's facility. Results demonstrated that total ventilation time, weaning duration and length of stay were not significantly improved in the experimental group. However, quality indicators were slightly improved and a survival analysis also showed a slightly reduced probability of long term ventilated patients remaining ventilated. Results also demonstrated a reduction in the fluctuation of outcome variables over time indicating improved consistency in weaning due to the guidelines    Phase four: A qualitative analysis of focus group interviews with staff about the impact of guidelines on their practice generated themes, centred on practice development, framework, relationships and challenges. Few previous studies have investigated the perceptions of staff regarding use of practice guidelines. This study identified that staff viewed the use of weaning guidelines favourably and perceived that their implementation improved patient outcomes.    Weaning is a relatively neglected area of intensive care because much of the initial focus of management is resuscitation and stabilisation. This study has demonstrated the positive impact that standardised and collaborative practice can have on patient outcome and clinical practice.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Mechanical Ventilation</field><field name="subject">Weaning</field><field name="subject">Paediatrics</field><field name="subject">Children</field><field name="subject">Intensive Care</field><field name="subject">Guidelines</field><field name="identifier">http://eprints.qut.edu.au/16551/</field><field name="validLink">True</field></doc><doc><field name="title">Defining anterior posterior dissociation patterns in electroencephalographic comodulation in Chronic Fatigue Syndrome and depression</field><field name="creator">Lorensen, Tamara Dawn</field><field name="description">This is a study of quantitative electroencephalographic (QEEG) comodulation analysis, which is used to assist in identifying regional brain patterns associated with Chronic Fatigue Syndrome (CFS) compared to an EEG normative database.  Further, this study investigates EEG patterns in depression which is found to be a highly comorbid condition to CFS.  The QEEG comodulation analysis examines spatial-temporal cross-correlation of spectral estimates in the individual resting dominant frequency band.  A pattern shown by Sterman and Kaiser (2001) and referred to as the Anterior Posterior Dissociation (APD) discloses a significant reduction in shared functional modulation between frontal and centro-parietal areas of the cortex.  Conversely, depressed patients have not shown this pattern of activity but have disclosed a pattern of frontal Hypercomodulation localized to bilateral pre-frontal and frontal cortex.  This research investigates these comodulation patterns to determine whether they exist reliably in these populations of interest and whether a clear distinction between two highly comorbid conditions can be made using this metric.
 
 
 
 Sixteen CFS sufferers and 16 depressed participants, diagnosed by physicians and a psychiatrist respectively were involved in QEEG data collection procedures.  Nineteen-channel cap recordings were collected in five conditions: eyes-closed, eyes open, reading task-one, math computations task-two, and a second eyes-closed baseline.
 
 
 
 Five of the 16 CFS patients showed a clear Anterior Posterior Dissociation pattern for the eyes-closed resting dominant frequency.  However, 11 participants did not show this pattern of dysregulation.  Examination of the mean 8-12 Hz band spectral magnitudes across three cortical regions (frontal, central and parietal) indicated a trend of higher overall alpha levels in the parietal region in CFS patients who showed the APD pattern compared to those who did not show this pattern.  All participants who showed the APD pattern were free of medication, while the majority of those absent of this pattern were using antidepressant medications.  For the depressed group, all of which were medication free, 100 % of the depressed group showed a frontal Hypercomodulation pattern.  Furthermore, examination of the mean 8-12 Hz band spectral magnitudes across three cortical regions disclosed a trend of high frontal alpha and a left/right asymmetry of greater voltages in the left frontal cortex.
 
 
 
 Although these samples are small, it is suggested that this method of evaluating the disorder of CFS holds promise.  The fact that this pattern is not consistently represented in the CFS sample could be explained by the possibility of subtypes of CFS, or perhaps comorbid conditions.  Further, the use of antidepressant medications may mask the pattern by altering the temporal characteristics of the EEG.  This study, however, was able to demonstrate that the QEEG was able to parse out the regional cerebral brain differences between CFS and depressed group.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Quantitative EEG</field><field name="subject">Chronic Fatigue Syndrome</field><field name="subject">Depression</field><field name="subject">EEG Normative Databases</field><field name="identifier">http://eprints.qut.edu.au/16552/</field><field name="validLink">False</field></doc><doc><field name="title">Dialogues with the prototype</field><field name="creator">Denaro, Chris</field><field name="description">This exegesis traces a path through the production of an animated work, and discusses the evolution of an individual production workflow that refigures the industrial animation process of prototyping.
 
 
 
 By incorporating spontaneity within the animation workflow, the creative output of the project focusses on the development of a series of non-narrative, process-driven temporal constructions that fuse form and process.
 
 
 
 The creative work occupies 75% of this Masters project, and the exegesis 25% (7500 Words)</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">creative practitioner</field><field name="subject">reflective practitioner</field><field name="subject">spontaneity</field><field name="subject">animation</field><field name="subject">motion graphics</field><field name="subject">prototype</field><field name="subject">process-driven animation</field><field name="subject">practice-led</field><field name="subject">anthropomorphism</field><field name="subject">blobject</field><field name="subject">creative commons</field><field name="subject">reflection in action</field><field name="subject">surprise</field><field name="subject">Schon</field><field name="subject">Scrivener</field><field name="subject">Kentridge.</field><field name="identifier">http://eprints.qut.edu.au/16553/</field><field name="validLink">False</field></doc><doc><field name="title">'Should I stay or should I go?' : Retirement age triggers of sworn members of the Queensland Police Service entitled to access voluntary retirement at age fifty-five</field><field name="creator">Marcus, Benjamin Roland Derek</field><field name="description">At the time this study was conducted, Queensland police officers were offered a five year age range in which retirement was possible. These officers were permitted to retire from age 55 and were forced to retire at age 60. The Queensland Police Service had previously identified that only 13% of all police officers were staying in their employment until the mandatory retirement age of 60. Retirement of these officers at the earliest possible opportunity presented a considerable loss of human resource investment. This study was undertaken to investigate some possible triggers influencing the decision to retire.    Three specific research questions associated with the retirement intentions of Queensland police officers of the baby-boomer generation were formulated and subsequently investigated. These questions were:    * How do the demographic characteristics of individual police officers relate to their retirement intentions?  * What are the triggers that are associated with the retirement age intentions of baby-boomer police officers in Queensland? and,  * How are these triggers associated with officers' intentions to retire earlier or later?    While considerable work had been previously done on retirement triggers, the issue of police retirement triggers is under-researched. The situation was further compounded by the fact that the major study of police retirement was American, with retirement in that system based on years of service, and not age as in Australia. A list of possible retirement triggers was compiled from the literature and then focus groups of Queensland police officers were used to discuss some aspects of these possible retirement triggers and generate others that were specific to the Queensland Police Service. The study obtained the views of 641 members of the cohort through a questionnaire and utilised a quantitative research methodology to achieve findings.    Demographic aspects showed little overall influence on an officer's retirement age decision. The demographic items that did have a direct association with retirement intentions were gender, length of service, and the method of admission to the organisation. Female officers, officers with the greatest length of service and those admitted to the organisation as Cadets were more likely to seek earlier retirement, that is retirement at or soon after age fifty-five. Whilst not conclusive, the education level of the individual indicated a trend towards later retirement for those with higher levels of education. Importantly, operational status, shift worker status, rank, and qualification for promotion had no association with the retirement decision.    A factor analysis of the questionnaire items used in the study identified five factors, of which four contributed significantly to a police officer's retirement timing decision at the later end of the retirement window spectrum. These factors were 'appropriateness', 'worth and belonging', 'influences and relationships' and 'financial' issues. A fifth factor 'flexibility' was also determined but found to have no statistical significance.    Three recommendations were made from this study: the formation of a Queensland Police Service alumni; the adoption of a n employment re-engagement policy called 'procruiting'; and the introduction of an assisted retirement education package for exiting members.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">police</field><field name="subject">retirement</field><field name="subject">triggers</field><field name="subject">intentions</field><field name="subject">baby-boomer</field><field name="subject">transition</field><field name="subject">voluntary</field><field name="subject">mandatory</field><field name="subject">police recruiting</field><field name="subject">procruiting</field><field name="identifier">http://eprints.qut.edu.au/16554/</field><field name="validLink">True</field></doc><doc><field name="title">Injured or abused children less than one year of age: are they the same sub-population?</field><field name="creator">Pratt, Jan</field><field name="description">Children less than one year of age are a vulnerable population. Injury, and child abuse and neglect (child maltreatment) are causes of morbidity and mortality in this population. The literature suggests that the family characteristics of both sub-populations are similar and they may be the same sub-population (Peterson and Brown 1994).    Large scale studies have revealed that there are multiple risk markers that are predictive of child abuse and neglect (Browne 1995, Sidebotham et al. 2001, 2002). There is mixed evidence as to whether home visiting can have an impact on preventing injury and child abuse and neglect.    This study aims to show that children who are injured and maltreated are the same sub-population. The study also examines the impact of child, family and societal risk markers on the likelihood of a child presenting for an injury or child maltreatment, and the effect of home visiting on the outcomes of injury and/or child maltreatment.    This study is a retrospective cohort study using administrative data from three administrative data systems. The data from these systems were merged as part of a work project and de-identified. The de-identified data set contained data at an individual child level and formed the study sample. There were 11,821 children in the sample who lived within the Royal Children's Hospital Health Service District. Variables included demographic data, family characteristics, service contacts which included injury and Child Advocacy Service contacts (a proxy for child maltreatment).      The main results of the study indicate there is a small cross-over of the sub-populations and these children are an extremely at-risk sub-population with a very high prevalence of risk markers. The research found that for children less than one year of age the 4.1% of the study sample presented for an injury contact and 1.1% of the study sample has a Child Advocacy Service (CAS) contact. There was 5.17% of the injury sub-population, compared to 0.93% of the non-injured population who had a CAS contact. Nineteen percent (19 %) of children who had a CAS contact also had an injury contact. The study also found that sole parents, mothers with an intellectual disability, and mothers who live in temporary/rental housing are predictors of injury and child maltreatment. Another finding is that an injury contact is a significant predictor of child maltreatment. A child who had an injury was 9 times more likely to attend for a CAS contact than a non-injured child (AOR 9.087 significant at 95% confidence interval (CI), (4.863-17.073).  The introduction of home visiting into the model was examined and it was found that more than one home visit has the potential to reduce the likelihood of a child having child maltreatment contact if the mother is a sole parent, less than 20 years of age, abused as a child, lives in a family violence situation, has a mental health problem, is intellectual disabled or uses illicit substances. Whilst the results show a reduction, the impact clinically would be that home visiting as a single strategy will not prevent a CAS contact.    The service implications of the study revealed that, there is a high usage of Department of Emergency Medicine (DEM) of Triage Category 4 and 5 clients. This presents an opportunity to look at alterative service model for these clients. Not all CAS clients were seen by the Primary Care Program, this also presents an opportunity to develop a pathway back to preventative health care services for this vulnerable group. The practice implications are that further research is required to identify the decision making process within DEM for injury presentation to identiy the indicators that DEM staff use to make a referral to the CAS. The identification of risk by Child Health Nurses requires further research to identify if the low occurrence of family risk variables in the study sample is a result of interview skills or data recording.    The study has identified that there is a cross-over sub-population of injured and maltreated children. The research findings will provide information not previously available in the Australian context. At a service level the findings provide data to improve practice and service delivery.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">maltreatment</field><field name="subject">physical abuse</field><field name="subject">emotional abuse</field><field name="subject">sexual abuse</field><field name="subject">neglect</field><field name="identifier">http://eprints.qut.edu.au/16555/</field><field name="validLink">True</field></doc><doc><field name="title">An intuitive motion-based input model for mobile devices</field><field name="creator">Richards, Mark Andrew</field><field name="description">Traditional methods of input on mobile devices are cumbersome and difficult to use.  Devices have become smaller, while their operating systems have become more complex, to the extent that they are approaching the level of functionality found on desktop computer operating systems.  The buttons and toggle-sticks currently employed by mobile devices are a relatively poor replacement for the keyboard and mouse style user interfaces used on their desktop computer counterparts.  For example, when looking at a screen image on a device, we should be able to move the device to the left to indicate we wish the image to be panned in the same direction.
 
 
 
 This research investigates a new input model based on the natural hand motions and reactions of users.  The model developed by this work uses the generic embedded video cameras available on almost all current-generation mobile devices to determine how the device is being moved and maps this movement to an appropriate action.
 
 
 
 Surveys using mobile devices were undertaken to determine both the appropriateness and efficacy of such a model as well as to collect the foundational data with which to build the model.  Direct mappings between motions and inputs were achieved by analysing users' motions and reactions in response to different tasks.
 
 
 
 Upon the framework being completed, a proof of concept was created upon the Windows Mobile Platform. This proof of concept leverages both DirectShow and Direct3D to track objects in the video stream, maps these objects to a three-dimensional plane, and determines device movements from this data.
 
 
 
 This input model holds the promise of being a simpler and more intuitive method for users to interact with their mobile devices, and has the added advantage that no hardware additions or modifications are required the existing mobile devices.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Input Model</field><field name="subject">Human&#150;Computer Interface</field><field name="subject">Mobile Device</field><field name="subject">User Interface</field><field name="subject">Input Devices</field><field name="subject">Interaction Styles</field><field name="subject">Automated Survey</field><field name="subject">DirectX Mobile</field><field name="subject">DirectShow</field><field name="subject">Windows Mobile</field><field name="subject">Computer Vision</field><field name="subject">Image Processing</field><field name="subject">Edge Detection</field><field name="subject">Object Detection</field><field name="subject">Motion Tracking</field><field name="subject">Scene Analysis</field><field name="subject">Human Movement</field><field name="subject">ARToolkit</field><field name="subject">Augmented Reality</field><field name="identifier">http://eprints.qut.edu.au/16556/</field><field name="validLink">True</field></doc><doc><field name="title">Executive stock option disclosures by Australian listed companies: an assessment of their nature, extent and association with governance characteristics</field><field name="creator">Nelson, Jodie Elizabeth</field><field name="description">This thesis investigates statutory executive stock option (ESO) disclosures by Australian listed companies, and their nature, extent and association with governance characteristics. The study is motivated by the limited prior Australian studies that find evidence of low levels of compliance with ESO disclosures (Nelson and Percy, 2005), and by the changes in Australia's regulatory environment over the financial years 2001 to 2004. Arising from these motivations, three research questions are addressed: 1) what is the nature and extent of compliance with ESO disclosures in annual reports and does it change over time?, 2) how does corporate governance influence compliance with ESO disclosures?, and 3) what other factors influence compliance with ESO disclosures? Based on prior research and an application of agency theory, the research questions are addressed by systematically evaluating ESO disclosure compliance, and by modelling and testing the governance and other factors associated with companies' disclosure practices over the 2001 to 2004 study period.    Within the agency framework, it is argued that effective governance mechanisms mitigate agency costs by decreasing information asymmetry through increased disclosure. Hence it is predicted that internal governance mechanisms, including the effectiveness of the board of directors, the effectiveness of the audit committee, the existence of a compensation committee, and management incentives are associated with the level of compliance with ESO disclosures. In addition, external governance mechanisms are predicted to influence compliance with ESO disclosures. Specifically, it is predicted that firms responded positively to the increased media and regulatory scrutiny on financial reporting practices as a result of major corporate collapses in Australia and the United States. Furthermore, it is predicted that regulatory intervention, in the form of new and comprehensive ESO disclosure requirements, as well as the authoritative guidance on valuing options and active enforcement efforts by ASIC, have contributed to increased levels of compliance.    Using a combination of univariate and multivariate procedures, compliance and governance characteristics are tested over the financial years 2001 to 2004, to capture the changes in compliance over time and to examine the hypothesised relationships. The results of this thesis indicate that Australian companies do not fully comply with ESO disclosure requirements. Nevertheless, the results show that overall compliance has increased progressively from 2001 to 2004, suggesting that the increased scrutiny of companies' financial reporting practices following major corporate collapses has motivated companies to increase compliance. Notably, compliance has increased after the introduction of new and more comprehensive disclosure requirements for ESOs, as well as increased authoritative guidance and enforcement efforts by ASIC. However, despite the overall evidence of improvement in compliance levels, the results continue to reveal management's reluctance to disclose ESO information that may be considered sensitive (for example, price and value-related information).    The multivariate results indicate that firms with a larger board of directors and a larger audit committee are more likely to encourage greater levels of compliance with ESO disclosures. However, a larger board of directors appears to take a holistic approach to monitoring company activities by encouraging higher overall compliance rather than focusing on specific, sensitive disclosures. Where a less independent Chairperson is present, the firm is more likely to disclose more sensitive information only, indicating a substitution effect whereby firms mitigate the agency problems associated with this lack of independence by increasing sensitive disclosures. Also, where the Chief Executive Officer's remuneration is relatively larger, companies are less forthcoming about ESO information. With respect to the influence of external corporate governance, the findings indicate that companies identified as poor performers by the Australian Shareholders' Association (a measure of external governance) exhibit lower levels of overall compliance, but not compliance with sensitive disclosures. This latter finding suggests that poorly performing firms provide similar levels of sensitive and important information as other firms, possibly to direct attention away from the low performance of the company.    Consistent with prior disclosure research, other factors associated with compliance include leverage, where firms that are more highly leveraged disclose more sensitive information in an effort to become more transparent to creditors, thus reducing their monitoring costs. The use of a Big 4 auditor (a proxy for auditor quality) is associated with overall compliance, which indicates that external auditors primarily ensure that the financial report as a whole is compliant with the regulations, rather than identifying sensitive disclosures in detail, particularly where these disclosures may not have a material effect. Lastly, performance (as measured by profit or lossmaking status) is negatively associated with compliance.    By investigating in detail the nature and extent of compliance with ESO disclosures over time and its relation to governance characteristics, the findings of this study demonstrate that while companies appear to lack full compliance with ESO disclosures, compliance has increased over time with active regulatory enforcement and assistance and comprehensive disclosure requirements. Of particular interest, is that the nature of compliance illustrates the very low levels of compliance with important, but sensitive, components of the required ESO disclosures. Importantly, the adoption of stronger governance structures appears to enhance compliance with ESO disclosures, including sensitive disclosures. Therefore, the findings of this study have important implications for corporate regulators, standard setters, financial statement preparers, shareholders and other users of financial reports with an interest in ESOs.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">executive stock option</field><field name="subject">ESO disclosures</field><field name="identifier">http://eprints.qut.edu.au/16557/</field><field name="validLink">True</field></doc><doc><field name="title">Editing the independent, digital feature film, mosaic</field><field name="creator">McMillan, Matthew Christopher</field><field name="description">The production of the independent, digital feature film titled Mosaic was performed on a very low budget. The design and implementation of the post-production of the film required consideration of budgetary constraints, and solutions to these constraints that would still allow the creative freedom of the editor and the director.    The technical design was based around digital filmmaking technology. The choice of this technology influenced how the editor was able to address aesthetic and technical challenges.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">feature film</field><field name="subject">independent</field><field name="subject">low-budget</field><field name="subject">film editing</field><field name="subject">post-production</field><field name="subject">montage</field><field name="subject">digital filmmaking</field><field name="subject">high definition</field><field name="subject">HD-CAM</field><field name="subject">DV-CAM</field><field name="subject">Mini-DV</field><field name="subject">Avid</field><field name="subject">Xpress Pro</field><field name="subject">Media Composer</field><field name="subject">Adrenaline</field><field name="subject">DS|HD.</field><field name="identifier">http://eprints.qut.edu.au/16558/</field><field name="validLink">True</field></doc><doc><field name="title">Design and implementation of a multi-stage, object-oriented programming language</field><field name="creator">Neverov, Gregory Michael</field><field name="description">Multi-stage programming is a valuable technique for improving the performance of computer programs through run-time optimization. Current implementations of multi-stage programming do not support run-time type introspection, which is a significant feature of modern object-oriented platforms such as Java and C#. This is unfortunate because many programs that use type introspection in these languages could be improved with multi-staging programming.    The aim of this research is to investigate the interaction between multi-stage programming and object-oriented type introspection. This is done by the invention of a new programming language that is a multi-stage extension to C#. The language is capable of expressing traditional multi-stage programs as well as a new style of multi-stage programs that incorporate type introspection, most notably polytypic algorithms such as object serialization. A compiler for the language is implemented and freely available. The language is significant because it is the first object-oriented, multi-stage language; the first attempt to combine type introspection with multi-stage programming; and the first exploration of polytypic programming in a multi-stage context.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">programming languages</field><field name="subject">multi-stage programming</field><field name="subject">object-oriented programming</field><field name="subject">meta programming</field><field name="subject">run-time code generation</field><field name="subject">polytypic programming</field><field name="subject">type systems</field><field name="identifier">http://eprints.qut.edu.au/16559/</field><field name="validLink">True</field></doc><doc><field name="title">Improved acetabular cementing techniques</field><field name="creator">Smith, Bjorn Nicholas</field><field name="description">The most common cause for revision total hip replacement surgey is aseptic loosening of the acetabular component. This thesis explores the effect of three techniques to improve the depth and quality of cemented acetabular component fixation in primary total hip replacement. This may have beneficial effects on the longevity of cemented acetabular components and reduce the rate of revision surgery for aseptic loosening.  Aims: 1. Determine the effect of the rim cutter on cement pressure during cup insertion. 2. Examine the effect of the rim cutter on cement penetration distance. 3. Evaluate the effect of bone grafting of the acetabular notch. 4. Determine the effect of iliac suction during cement pressurisation. 5. Compare the behaviour of bone cement with Play Dough&#61650;.  Materials and Methods: 1. Sawbones hemi pelvis models were fitted with pressure transducers at the rim and apex of the acetabulum. Peak pressure was measured upon insertion of cups with different flange sizes and when the acetabulum was prepared with the rim cutter. 2. Foam cavities were used to measure the depth of cement penetration when the same cups and rim cutter were used. 3. Hemi pelvis models were modified to simulate bone grafting of the acetabular notch. Again, pressure sensors were mounted at the apex and rim of the acetabulum. Intra-acetabular cement pressure was compared with native acetabulae. 4. A back bleeding model of the acetabulum was fitted with a suction catheter. The effect on cement penetration into cancellous bone was measured compared with no suction. 5. Play Dough&#61650; pressurisation and penetration into hemi pelvises and foam was compared to bone cement. Results: 1. Significant increase in peak apex and rim pressures when flanged cup inserted into an acetabulum prepared with the rim cutter compared with both flanged and unflanged cups alone. 2. Significant increase in cement penetration at the rim of the acetabulum when rim cutter used and flanged cup inserted when compared with flanged and unflanged cups alone. 3. Significant increase in intra-acetabular pressure when cement pressurised in presence of simulated acetabular notch bone grafting compared with normal acetabulae. 4. Significant increase in cement penetration distance when suction used compared with no suction. 5. Significant differences in the flow characteristics between bone cement and Play Dough&#61650;.  Conclusion: The authors recommend preparation of the acetabular rim with the rim cutter and bone grafting of the acetabular notch to improve the depth and uniformity of the cement mantle in cemented primary THA. Play Dough&#61650; at room temperature is not a suitable substitute for bone cement in in-vitro cementing studies.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">hip</field><field name="subject">acetabulum</field><field name="subject">cement</field><field name="subject">flanged</field><field name="subject">cup</field><field name="subject">rim cutter</field><field name="subject">suction</field><field name="subject">pressurisation</field><field name="subject">bone graft</field><field name="subject">acetabular notch</field><field name="subject">arthroplasty</field><field name="subject">penetration</field><field name="subject">play dough</field><field name="identifier">http://eprints.qut.edu.au/16560/</field><field name="validLink">True</field></doc><doc><field name="title">The synthesis and characterisation of azoporphyrins : the porphyrin analogues of azobenzene</field><field name="creator">Esdaile, Louisa Jane</field><field name="description">Due to the prevalence of porphyrins and their derivatives in Nature, there is a wide interest in the synthesis, design and exploitation of their properties. Their electron delocalisation, and the ease with which the electronic system can be perturbed and manipulated, have meant that porphyrins have been investigated for applications in many avenues. Conjugated, multiporphyrin oligomers have been studied as light-harvesting system mimics, molecular wires and sensors. It has been predicted that the azo-linkage should enable superior porphyrin-to-porphyrin interaction. Preparation of an azo-linked bis(porphyrin) was approached by reacting protected hydrazines with bromoporphyrins. A series of mono- and bis-substituted porphyrinoids including novel diiminoporphodimethenes was synthesised using palladium-catalysed reactions, and spectroscopic, structural and redox properties of these products were investigated. The manner in which a bis-substituted product evolved from a mono-activated starting material was studied. The synthesis of these products was refined to produce each product selectively. These products display interesting redox properties, and several of them exhibit greatly red-shifted absorption spectra. The palladium-catalysed synthesis of primary and secondary aminoporphyrins, as well as a hydroxyporphyrin, from the reaction of bromoporphyrins with unsubstituted hydrazine was discovered and investigated. The synthesis of these products was optimised to yield each novel porphyrinoid selectively. Some of the electronic and structural properties of these products were studied, and the unique bis(porphyrin)secondary amine exhibited excitonic coupling between the macrocycles.    A porphyrin dyad with an azo-linkage was isolated, and its synthesis was optimised, initially using palladium-catalysed homocoupling of aminoporphyrins, and then using copper catalysis. The synthesis of this "azoporphyrin" was optimised to obtain the desired dimers in high yields and the properties of these dimers were studied and contrasted with those of other conjugated porphyrin dimers. The absorption spectra exhibited greatly split Soret bands and intense, red-shifted Q-bands, while cyclic voltammetry showed a decrease in the HOMO-LUMO gap, indicative of extremely efficient porphyrin-porphyrin interaction. Two crystal structures of azoporphyrins were obtained, and the dihedral angle and the distance between the mean planes of the macrocycles were also significantly smaller than those found for the analogous (E)-ethene-linked dimers. A series of novel "head-to-tail" porphyrin dyads was also isolated and characterised, and these exhibited interesting spectral features, including very broad and red-shifted Q-bands and split Soret bands in their absorption spectra.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">porphyrin</field><field name="subject">amination</field><field name="subject">palladium-catalysis</field><field name="subject">copper-catalysis</field><field name="subject">chemistry</field><field name="subject">azoporphyrin</field><field name="subject">aminoporphyrin</field><field name="subject">diiminoporphodimethene</field><field name="subject">hydroxyporphyrin</field><field name="subject">synthesis</field><field name="identifier">http://eprints.qut.edu.au/16561/</field><field name="validLink">True</field></doc><doc><field name="title">Discharge information and the self-reported health of women following a hysterectomy</field><field name="creator">Warden, Sandra Elizabeth</field><field name="description">Aim:
 The aim of this study was to develop a targeted health information package for women to use specifically as a reference during their return to health following a hysterectomy and to subsequently test its usefulness.
 
 Method:
 A quasi-experimental design measured the effectiveness of this package in improving the health and satisfaction outcomes of women compared to those who received the standard information. Women undergoing a hysterectomy for benign reasons who were between the ages of 20 and 60 years were included. There were 55 participants recruited into the control group and 44 into the intervention group. Participants completed a self-administered questionnaire both prior to and 14-16 weeks post-surgery.
 
 Results:
 The study found that there were no statistically significant differences between the two groups for their self-reported health, the time taken to return to usual activities and the number of symptoms experienced after surgery. Clinical improvements, however, were noted in the intervention group.
 
 A statistically significant difference was found between the groups for the amount written information that they would have preferred for their recovery (X2 8.26 df2 p=0.011). Ninety percent (90%) of the women who received the intervention wanted the same amount of written information to take home whilst 40% of the control group would have preferred more written information. This indicated a positive effect from the intervention. An unexpected finding in this study was that almost 40% of both groups wanted more verbal information and discussion prior to discharge.
 
 Conclusion:
 A valuable aspect of this study was its usefulness in identifying the clinical importance of discussion as part of the discharge process. These findings will be important for health professionals to utilise in their clinical practice for women undergoing a hysterectomy.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">discharge information</field><field name="subject">health outcomes</field><field name="subject">hysterectomy</field><field name="subject">intervention</field><field name="subject">quasi-experimental</field><field name="identifier">http://eprints.qut.edu.au/16562/</field><field name="validLink">True</field></doc><doc><field name="title">Property market forecasts and their valuation implications: a study of the Brisbane central business district office market</field><field name="creator">Cowley, Mervyn Wellesley</field><field name="description">Property market forecasts play a crucial role in modern real estate valuation methodologies and, consequently, flawed forecasts can have adverse impacts on the accuracy of valuations.  This thesis identifies property industry inconsistencies in the formulation and application of office rent forecasts adopted in discounted cash flow (DCF) studies used to assess the value of commercial properties and the viability of proposed projects.  Existing research on commercial property cycles and office property market modelling is examined in order to identify the dominant market drivers adopted by researchers.  Forecasting techniques are also explored towards specifying space and rent models for the Brisbane CBD office market using the perceived dominant drivers as explanatory variables.  Surveys of property valuers and developers are undertaken to underpin the selection of these variables.  The implications of varying rent forecasts applied in DCF based valuation assessments are tested through the use of a case study involving four Brisbane office buildings.  Innovative research is conducted through adopting geographic information system supported land use and historical valuation studies to delineate market precincts within the Brisbane CBD.  The rent model is then re-estimated using precinct based office rent data to allow the generation of forecasts for the individual precincts.  Out-of-sample accuracy test results for the precinct forecasts are compared with the results produced by the model specified using whole-of-city data.    The literature reviews, surveys and model testing determine a relatively consistent range of dominant explanatory variables applicable to office markets.  The case study, in a local context, confirms that varying forecasts do have a significant impact on property valuations.   Tests of the forecast results generated by the Brisbane CBD model provide some evidence that more plausible office rent forecasts stem from the use of market models as compared with solely applying professional judgement based forecasts.  Subject to data availability limitations, the precinct based rent model is found to produce rent forecasts superior to those generated by the whole-of-city model.  Finally, the thesis makes a range of industry recommendations towards enhancing forecasts and recommendations are also made for potential future research projects.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">property market forecasts</field><field name="subject">econometric models</field><field name="subject">office buildings</field><field name="subject">market dynamics</field><field name="subject">regression analysis</field><field name="subject">explanatory variables</field><field name="subject">rent growth forecasts</field><field name="subject">space supply</field><field name="subject">discounted cash flows</field><field name="identifier">http://eprints.qut.edu.au/16563/</field><field name="validLink">True</field></doc><doc><field name="title">Investigation into the proteolytic activity in chronic wound fluid and development of a remediation strategy</field><field name="creator">Rayment, Erin Alexis</field><field name="description">Chronic ulcers are an important and costly medical issue, causing their sufferers a large amount of pain, immobility and decreased quality of life. The common pathology in these chronic wounds is often characterised by excessive proteolytic activity, leading to the degradation of both the extracellular matrix, as well as key factors critical to the ulcer's ability to heal. As matrix metalloproteinases (MMPs), a large family of zinc-dependent endopeptidases, have been shown to have increased activity in chronic wound fluid (CWF), it was hypothesised that this specific proteolytic activity was directly related to an ulcer's chronic nature. Although previous studies have identified elevated proteases in CWF, many have reported contradictory results and therefore the precise levels and species of MMPs in CWF are poorly understood. The studies reported herein demonstrate that MMP activity is significantly elevated in CWF compared with acute wound fluid (AWF). In particular, these studies demonstrate that this proteolytic activity can be specifically attributed to MMPs and not another class of proteases present in wound healing. Furthermore, it is shown that MMP-9 is the predominant protease responsible for matrix degradation by CWF and is an indicator of the clinical status of the wound itself. Moreover, MMP-9 can be inhibited with the bisphosphonate alendronate, in the form of a sodium salt, a functionalised analogue, and also tethered to a synthetic biocompatible hydrogel compromised of aqueous poly (2-hydroxy methacrylate) PHEMA synthesised in the presence of poly(ethylene glycol) (PEG). Together, these results highlight the potential use of a tethered MMP inhibitor as an improved ulcer treatment to inhibit protease activity in the wound fluid, while still allowing MMPs to remain active in the wound bed where they perform vital roles in the activation of growth-promoting agents and immune system regulation.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">wound healing</field><field name="subject">chronic ulcer</field><field name="subject">hydrogel</field><field name="subject">matrix metalloproteinase</field><field name="subject">gelatinase</field><field name="subject">zymography</field><field name="subject">protease inhibition</field><field name="subject">wound dressing</field><field name="subject">biomaterials</field><field name="subject">tissue engineering</field><field name="identifier">http://eprints.qut.edu.au/16564/</field><field name="validLink">True</field></doc><doc><field name="title">Development of a limit state design methodology for railway track</field><field name="creator">Leong, Jeffrey</field><field name="description">The research presented in this thesis is aimed at developing a limit state design methodology for railway track for recommendation to Standards Australia's next revision of the 'Permanent way materials: prestressed concrete sleepers' code (AS1085.14, 2003).    There is widespread suspicion that the railway track, particularly concrete sleepers, have untapped reserves of strength that has potential engineering and economic advantages for track owners. Through quantifying the effects of train speed, wheel impact loadings and distribution of vehicle loads, track engineers would be able to design railway track more accurately and hence uncover the reserves of strengths in railway track.    To achieve this improvement a comprehensive set of wheel/rail impact measurements has been collected over a one year period to establish a distribution of track loadings. The wheel/rail impact data collected showed a logarithmically linear distribution which shows that impact forces are randomly occurring events. The linearity of the data also allows for wheel/rail impact forces to be forecasted allowing for a more rational risk based design of the railway track.    To help with an investigation of the influence of changes to train operation on the wheel/rail impact force distributions, development of a new dynamic track computer model capable of simulating the complex interaction between the train and track was completed within this research. The model known as DTRACK (Dynamic analysis of rail TRACK) was benchmarked against other dynamic models and field data to validate its outputs.    The field measurements and DTRACK simulations became the basis for development of a limit state design methodology for railway track (risk based approach) for railway track in place of an allowable limit state (compliance based) approach. This new approach will allow track owners to assess the track capacity based on more realistic loads and is expected to allow an increase in the capacity of existing track infrastructure which will allow railways to be more commercially competitive and viable.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">railways</field><field name="subject">railway track</field><field name="subject">sleepers</field><field name="subject">train speed</field><field name="subject">impact loading</field><field name="subject">computer model</field><field name="identifier">http://eprints.qut.edu.au/16565/</field><field name="validLink">True</field></doc><doc><field name="title">E-recruitment: the effectiveness of the internet as a recruitment source</field><field name="creator">Marr, Erica R.</field><field name="description">The present study has made a comparative assessment of recruitment source effectiveness. The study is based on the pre-hire measures of the quantity and quality of applicants, with a specific focus on e-recruitment. A nine year longitudinal study was employed over a period of pre-internet and post-internet use by a large organisation which enabled the exploration of changes in applicant data. Recruitment source effects were assessed through two perspectives: applicant and organisational. The relationship between source and applicant was explored in terms of key job and organisational attributes communicated to attract quality applicants, and their subsequent intention to pursue the job. The research was designed with two studies to capture the two perspectives. Applicant perspectives were assessed through the distribution of a survey to real applicants of the organisation. Organisational perspectives were captured through interviews with Human Resource Practitioners of eight mid- to large-size organisations. Results indicated that the quality of applicants generated by e-recruitment is equivalent to or less than that of other sources, therefore it is not the most effective recruitment source. Furthermore, recruitment sources had some effect on applicant intentions to pursue the job, but this relationship was not mediated by applicant perspectives. In terms of source information, job attributes were considered more important than organisational attributes in attracting quality applicants from both perspectives. Overall, the research has provided evidence to support the need for organisations to develop a recruitment strategy which incorporates a diverse range of sources to reach quality applicants in the desired target market.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">recruitment; recruitment source; realistic information; person-job; person-organisation; internet recruitment; e-recruitment</field><field name="identifier">http://eprints.qut.edu.au/16566/</field><field name="validLink">True</field></doc><doc><field name="title">The biology of the grassland Melomys (Melomys burtoni) (Rodentia: Muridae) in far north Queensland sugarcane crops</field><field name="creator">Dyer, Brendan Charles</field><field name="description">Melomys burtoni and M. cervinipes naturally occur in habitats adjacent to sugarcane crops in north Queensland, have been trapped within sugarcane crops, and are potentially damaging to sugarcane crops.  However, little is known about their biology and pest status in sugarcane crops and this information is needed by the industry for the development of a sustainable pest management programme for these rodents.  Field studies were undertaken between Tully and Innisfail in far north Queensland, to determine the extent to which either or both Melomys species inhabit sugarcane crops and to examine the biology of Melomys within the crop.  Field diagnostic approaches were developed which, when blind tested using molecular techniques, proved 100% accurate in-field discrimination of the two Melomys species.  Based on field trapping, M. cervinipes proved to be rare in sugarcane and should not be regarded as a pest by the industry.  In contrast, M. burtoni were recorded in significant numbers within cane, were found to feed on cane and, in crop stage 5 (canopy closure to harvest) were responsible for damage to ~5% of stalks.  Melomys burtoni were found to colonise sugarcane at the later stages of crop development than the other major sugarcane rodent, Rattus sordidus.  The highest proportion of M. burtoni reproduction and juvenile recruitment also occurs in the later stages of crop development.  The late colonisation of the crop by M. burtoni means that the Integrated Pest Management (IPM) strategy already in place for R. sordidus is not directly transferable to M. burtoni.  If an effective IPM strategy is to be developed, further research is required to examine the population dynamics and dispersal of M. burtoni populations between the crop and the adjacent habitats within the sugarcane production system of far north Queensland.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">grassland Melomys</field><field name="subject">Melomys burtoni</field><field name="subject">sugarcane crops</field><field name="subject">pests</field><field name="subject">Queensland</field><field name="identifier">http://eprints.qut.edu.au/16567/</field><field name="validLink">True</field></doc><doc><field name="title">Web of institutionalised legitimacy : building a model of legitimacy as a raison d'etre for public relations practice</field><field name="creator">Bartlett, Jennifer Lea</field><field name="description">This research responds to calls for the establishment of an overriding rationale, or  raison d'&#234;tre, for public relations practice. Several scholars are suggesting that the  construct of legitimacy provides an overarching rationale that would link public  relations practice across organisations, industries and countries (Boyd, 2000&#894;  Massey, 2001&#894; Metzler, 1995, 2001&#894; van Ruler &amp; Vercic, 2005&#894; Vercic, van Ruler,  Butschi, &amp; Flodin, 2001). However, existing public relations studies using legitimacy  have focused on the communicative aspects, with little emphasis on long term and  societal level effects for organisations. In seeking to accommodate these challenges,  the central research question of this thesis is:  Does legitimacy provide a rationale for public relations practice, and if so, in  what ways?  This study draws on institutional theory, with its central imperative of  legitimacy, to address this question. Institutional theory considers the relationship  between organisations and environments from a social constructionist perspective.  Institutions created through the social construction of reality are based on shared,  rational myths of legitimacy which drive organisational and social action, and with  which organisations need to demonstrate compliance through their organisational  ceremonies or practices. These two central contributors to legitimacy -- rational  myths and ceremonies -- provide the framework guiding the study. The study was  conducted around issues about the corporate social responsibility (CSR) of the four  major Australian banks.  In order to consider relationships between public relations practice and  legitimacy as an institutional concept, Giddens' theory of structuration is used as a  theoretical apparatus to straddle the rational myths of legitimacy at the level of  institution, with public relations practice related to ceremonies at the level of action.  'Structuring moments' identified in media coverage provide sites of microanalysis  of the intense social construction of rational myths of legitimacy that include  organisations and publics. Through these theoretical devices, a number of guiding  research questions shape the study:  RQ i): What is learned about the social construction of rational myths about  legitimacy by studying media coverage about CSR in Australian banking?  RQ ii): What is learned about legitimacy by studying public relations  practices in relation to media coverage about CSR in Australia banking?  A longitudinal, qualitative, case study approach was taken to explore the  research questions in this study. As legitimacy was viewed as a process of ongoing  social construction, a temporal bracketing strategy (Langley, 1999) was used to  examine the relationships between the level of institution and of action over the six  year period of the study. Media coverage, annual and social impact reports, and  interviews were used as sources of data to examine the institutionalisation of  corporate social responsibility in the Australian banking industry.  The findings of the study show that there is a dynamic relationship between  public relations and legitimacy at both theoretical and practical levels. Through the  duality of structure lens, theoretically public relations can be conceived as agency  and legitimacy as structure. The influence of these two dynamically interrelated  levels of agency and structure is both constituted by human agency and is the  medium of the institutions (Sewell, 1992). Public relations practices, therefore, can  be seen as human agency that both shapes and is shaped by legitimacy. If legitimacy  represents a dominant concept of organisational success, it is also a rationale for  public relations practice as an act of human agency that seeks to create alignment  between organisations and publics in their environment.  As such, public relations practices are not just activities. Rather, public  relations practices constitute a central resource that organisations can access to exert  power to create and manage their legitimacy within the broader environment. Public  relations practices, therefore, are resources because they are embedded within the  deep structures of society that influence organisational practice, but also are actions  that allow the organisation to shape those structural arrangements. This process takes place within webs of communication and relationships between organisations and  publics that form institutionalised legitimacy.  This study also found that public relations practice is a balance between the  demands of time and space. The traditional focus of public relations studies has been  on incidents of compressed time and space, such as crises and campaigns. This study  suggests that expanded periods of time and space are also integral to how and why  public relations make a contribution as, over time, there were shifts to the  institutional arrangements that guide public relations practices. This suggests that  there is a compression of time and space as organisations and publics communicate  in their relationship and an expansion of time and space to shift frames of social  structures and legitimacy. It is through this juxtaposition of time and space, and  across dual levels of structure, that legitimacy provides a rationale for public  relations practices.  The conclusions of this research make a major contribution to public relations  theory by building a model for considering how legitimacy provides a raison d'&#234;tre  for public relations practices. As such, the model developed in this research provides  a theoretical framework of how public relations practices contribute to organisational  legitimacy at a societal level. The study also provides deeper insights to the role of  public relations practices in managing organisational legitimacy at the level of  action. In doing so, it addresses theoretical and methodological issues of the  conflation of publics and environment.  A number of opportunities for further research are presented by this study in  understanding drivers of public relations practices and the role of inspection forums  in processes of legitimacy. For practice, there are implications of taking a longer  term perspective to considering the role of public relations practices, its impact on  organisational success and, therefore, how it is evaluated.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Public relations</field><field name="subject">legitimacy</field><field name="subject">institutional theory</field><field name="subject">corporate social responsibility</field><field name="subject">Australian banking</field><field name="identifier">http://eprints.qut.edu.au/16568/</field><field name="validLink">True</field></doc><doc><field name="title">30 years on from Kangan: an analysis of the current policy position of TAFE Queensland</field><field name="creator">McMillan, Gregory Neil</field><field name="description">Within Australia, Vocational Education and Training (VET) encompasses the  Technical and Further Education (TAFE) sector, private providers, community  education and training, and work-based training. Additionally, some VET activities  are embedded within the secondary school and university sectors. As the major  provider of Government-funded vocational education and training, TAFE has  undergone significant change since its establishment in the 1970's. Historically,  TAFE has provided broader education and social opportunities for individuals  beyond a narrower focus on the achievement of training outcomes for economic  benefits. However, shifts in policy direction in 1980's and 1990's have seen the  delineation between broader education and economic outcomes becoming less  distinct. While this is perhaps true of all education sectors, it has potentially  impacted more on TAFE than any other sector. This thesis investigated these  impacts within the context of TAFE's social service and economic utility roles. This  was undertaken by analysing seven seminal Commonwealth and Queensland  documents and by analysing the findings of interviews with six senior executives  within Queensland's Department of Employment and Training and TAFE. The key  findings of this thesis indicate that TAFE Queensland continues to perform a number  of functions or activities that can be associated with a social service role. However,  the findings also indicate that, for TAFE Queensland, there has been a shift towards  an economic utility role. Since the Kangan Report (1974), TAFE's role has become  more focussed on meeting Queensland's economic and industry needs within a broad  view that Australia needs a flexible workforce, qualified to industry standards of  competence and able to compete in a globalised world.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Australia</field><field name="subject">policy</field><field name="subject">vocational education and training</field><field name="subject">TAFE</field><field name="subject">social service and economic utility roles</field><field name="subject">globalisation</field><field name="subject">economic rationalism</field><field name="subject">managerialism</field><field name="subject">human capital theory</field><field name="subject">case study</field><field name="subject">content analysis</field><field name="subject">constant comparative method.</field><field name="identifier">http://eprints.qut.edu.au/16569/</field><field name="validLink">True</field></doc><doc><field name="title">Development of an asset management model for effective safety equipment compliance in the Queensland electrical supply industry</field><field name="creator">Hart, Timothy Scott</field><field name="description">The aim of this research project is to investigate and implement an effective equipment  safety compliance system within the Queensland electrical entity ENERGEX and to  influence Australian testing practices. The implementation of this work has facilitated the  development of an Asset Management model for safety equipment and instrumentation  to achieve compliance and effective management of $20M of assets.  The work involved six projects to assist in the development of department ENERGEX -  RedEquip compliance system.  * Development of an Asset Management System to record test results, frequency, test  method.  * Redevelopment of Queensland Code for safety Equipment between ENERGEX and  Ergon Energy  * Portable Earthing Testing requirements and techniques  * HV fibreglass stick testing to IEC 60855 and specific ENERGEX and Powerlink test  criteria.  * EWP testing to comply to AS 1418.10 - 2004 Cranes Elevating work platforms which  have dramatically changed the EWP test methods.  * Pole Leakage detector requirements  The work has resulted in ENERGEX -RedEquip becoming an industry leader in safety  equipment compliance testing.  The thesis presents many findings based on the projects undertaken. The findings have  resulted in major changes to testing frequencies of equipment and proposed new test  methods. The major theme to this work was Safety and Testing, to align the two and  provide a system that would satisfy the Queensland Electrical Safety Act 2002. The  thesis is based on the individual work undertaken by the author to support this overall  theme. The Asset management and Inspection Testing document project are  fundamental in establishing the systems to manage safety compliance for ENERGEX.  The other projects were a selection of individual equipment issues to demonstrate the  complexity of equipment testing that need to be resolved.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Energex</field><field name="subject">electrical safety</field><field name="subject">safety equipment</field><field name="subject">Queensland electrical supply</field><field name="identifier">http://eprints.qut.edu.au/16570/</field><field name="validLink">True</field></doc><doc><field name="title">Computing with meaning by operationalising socio-cognitive semantics</field><field name="creator">McArthur, Robert James</field><field name="description">This thesis is motivated by the desire to provide technological solutions to enhance human  awareness in information processing tasks. The need is pressing. Paradoxically, as information  piles up people become less and less aware due to perceived scarce cognitive resources.  As a consequence, specialisations become ever more specialised, projects and individuals in  organisations become ever more insular. Technology can enhance awareness by informing  the individual about what is happening outside their speciality. Systems which can assist  people in these ways need to make sense of human communication. The computer system  must know about what it is that it is processing; it must follow a socio-cognitive framework  and reason with it. It must compute with meanings not symbolic surface structures.  The hypothesis of the thesis is that knowledge potentially useful for enhancing awareness  can be derived from interactions between people using computational models based on  socio-cognitive semantics. The goals are whether an appreciable approximation of conceptual  spaces can be realised through semantic spaces, and whether such semantic spaces can  develop representations of meaning which have the potential to enhance the awareness of  users? The two thesis questions are how well the socio-cognitive framework of G&#168;ardenfors  could be brought into operational reality, and if a bridge can be made, then what practical  issues can be involved?  The theory of conceptual spaces of Peter G&#168;ardenfors is combined with methods from  cognitive science for creating geometric spaces to represent meaning. Hyperspace Analogue  to Language and Latent Semantic Analysis are used as exemplars of the cognitive science  algorithms. The algorithms are modified by a variety of syntactic processing schemes to  overcome a paucity of data and hence lack of expressivity in representations of meaning:  part-of-speech tagging, index expressions and anaphora resolution are effected and incorporated  into the semantic space.  The practical element of the thesis consists of five case studies. These are developed in  two parts: studies describing how meaning changes and evolves in semantic spaces, and studies  describing semantic space applications featuring knowledge discovery. These studies are  in a variety of domains with a variety of data: online communities of interest using a mailing  list, a health-based mailing list, organisational blogs, "hallway chatter", and organisational  email. The data is real world utterances that provide the situational factors that cognitive  systems need to answer queries and provide context. The amounts of data are significantly less than previously used by semantic space methods, hence the need for syntactic assistance.  The particular problems examined in the case studies are corporate expertise management,  social network discovery, tracking ebbs and flows of topics, and noticing the change in a  person's sense-of-self over time. These are significantly different to those usually examined  using semantic spaces.  The key differentiator of this work stems from its focus on the geometrically-based computational  realisation of meaning. This thesis takes semantic spaces out of the closet and into  real-world information technology applications, with a roadtest in real life.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">computing</field><field name="subject">semantics</field><field name="identifier">http://eprints.qut.edu.au/16571/</field><field name="validLink">True</field></doc><doc><field name="title">Establishing the human perspective of the information society</field><field name="creator">Partridge, Helen L.</field><field name="description">The digital divide is a core issue of the information society. It refers to the division
 
 between those who have access to, or are comfortable using, information and
 
 communication technology (ICT) (the "haves") and those who do not have access
 
 to, or are not comfortable using ICT (the "have-nots"). The digital divide is a complex
 
 phenomenon. The majority of studies to date have examined the digital divide from
 
 a socio-economic perspective. These studies have identified income, education and
 
 employment as the key factors in determining the division between the "haves" and
 
 the "have-nots". Very little research has explore the psychological, social or cultural
 
 factors that contribute to digital inequality in community. The current study filled this
 
 gap by using Bandura's social cognitive theory (SCT) to examine the psychological
 
 barriers that prevent individuals from integrating ICT into their everyday lives.
 
 SCT postulates that a person will act according to their perceived capabilities and
 
 the anticipated consequences of their actions. Four studies have explored the digital
 
 divide using SCT. Because of limitations in the research design these studies have
 
 shed only limited light onto current understanding of digital inequality in community.
 
 The current research was the first study exploring the digital divide that (i)
 
 incorporated both socio-economic and socio-cognitive factors, (ii) used a community
 
 context that ensured the recruitment of participants who represented the full
 
 spectrum of the general population, and (iii) was conducted in both the US and
 
 Australia. Data was gathered via self administered questionnaires in two
 
 communities: Brisbane, Australia and San Jose, USA. Completed questionnaires
 
 were obtained from 330 and 398 participants from the US and Australia,
 
 respectively.
 
 Hierarchical regression analysis was used to explore the research question: what
 
 influence do socio-cognitive factors have in predicting internet use by members of
 
 the general population when the effects of socio-economic factors are controlled?
 
 The results of this analysis revealed that attitudes do matter. The US study found
 
 that socio-economic factors were not statistically significant predictors of internet
 
 use. The only factor that found to be a significant predictor of use was internet self
 
 efficacy. In short individuals with higher levels of internet self efficacy reported
 
 higher levels of internet use. Unlike the US study, the Australian study found that by
 
 themselves several socio-economic factors predicted internet use. In order of
 
 importance these were age, gender, income and ethnicity. However, the study also revealed that when socio-economic factors are controlled for, and socio-cognitive
 
 variables included into the analysis, it is the socio-cognitive and not the socioeconomic
 
 variables that are the dominant (in fact the only!) predictors of internet
 
 use.
 
 The research illustrated that the digital divide involves more than just the availability
 
 of resources and funds to access those resources. It incorporates the internal forces
 
 of an individual that motivates to them to use or integrate ICT into their lives. The
 
 digital divide is not just about ICT such as computers and the internet. It is about
 
 people. As such, the key to solving the issue of digital inequality is not going to be
 
 found with corporate or government funds providing physical access to technology.
 
 Instead, the key to solving digital inequality is inside the individual person. The
 
 alternative view of the digital divide presented in this research is by no means
 
 intended to minimise the role played by socio-economic factors. Indeed, the socioeconomic
 
 perspective has helped shed light on a very real social issue. What this
 
 research has done is suggest that the digital divide is more complex and more
 
 involved than has been imagined, and that further and different research is required
 
 if genuine insights and real steps are going to be made in establishing an
 
 information society for all.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">information society</field><field name="subject">information literacy</field><field name="subject">digital divide</field><field name="subject">social cognitive theory</field><field name="subject">psychology</field><field name="subject">haves</field><field name="subject">have-nots</field><field name="subject">self-efficacy</field><field name="subject">survey method</field><field name="subject">internet</field><field name="subject">Australia</field><field name="subject">USA</field><field name="identifier">http://eprints.qut.edu.au/16572/</field><field name="validLink">True</field></doc><doc><field name="title">Molecular cloning and characterisation of potential Fusarium resistance genes in banana (Musa acuminata ssp. Malaccensis)</field><field name="creator">Echeverria, Santy Peraza</field><field name="description">Banana is the most important fruit crop in the world but ironically one of the crops least studied. This fruit constitutes a major staple food for millions of people in developing countries and also it is considered the highest selling fruit in the world market making this crop a very important export commodity for the producing countries. At the present time, one of the most significant constraints of banana production that causes significant economical losses are fungal diseases. Among these, Panama disease, also known as Fusarium wilt has been the most catastrophic. Panama disease is caused by the soil-borne fungus Fusarium oxysporum formae specialis (f.sp) cubense (FOC), which infects susceptible bananas through the roots causing a lethal vascular wilt. To date, the race 4 of this pathogen represents the most serious threat to banana production worldwide since most of the commercial cultivars are highly susceptible to this pathogen. Introduction of FOC resistance into commercial cultivars by conventional breeding has been difficult because edible bananas are sterile polyploids without seeds. Genetic transformation of banana, which has already been established in various laboratories around the world has the potential to solve this problem by transferring a FOC race 4 resistance gene into susceptible banana cultivars (eg. Cavendish cultivars). However, a FOC resistant (R) gene has not been isolated. Genes that confer resistance to Fusarium oxysporum have been isolated from tomato and melon using a map-based positional cloning approach. The tomato I2 and melon Fom-2 genes belong to the non-Toll/interleukin like receptors (TIR) subclass of nucleotide-binding site and leucine-rich repeat (NBS-LRR) R genes. These genes confer resistance only to certain races of F. oxysporum in their corresponding plant families limiting their use in other plant families. The fact that these two Fusarium resistance genes share the same basic non-TIR-NBS-LRR structure suggests a similar Fusarium resistance mechanism is shared between the families Solanaceae and Cucurbitaceae. This observation opens the possibility to find similar Fusarium resistance genes in other plant families including the Musaceae.  A remarkable discovery of a population of the wild banana Musa acuminata subspecies (ssp.) malaccensis segregating for FOC race 4 resistance was made by Dr. Ivan Buddenhagen (University of California, Davis) in Southeast Asia. Research carried out at Queensland Department of Primary Industries (Australia) using this plant material has demonstrated that a single dominant gene is involved in FOC race 4 resistance (Dr. Mike Smith, unpublished results). Tissue-culture plantlets of this FOC race 4 segregating population were kindly provided to the Plant Biotechnology Program (Queensland University of Technology) by Dr. Mike Smith to be used in our research. This population holds the potential to assist in the isolation of a FOC race 4 resistance gene and other potential Fusarium resistance genes. The overall aims of this research were to isolate and characterise resistance gene candidates of the NBS-type from M. acuminata ssp. malaccensis and to identify and characterise potential Fusarium resistance genes using a combination of bioinformatics and gene expression analysis.
 
 Chapter 4 describes the isolation by degenerate PCR of five different classes of NBS sequences from banana (Musa acuminata ssp malaccensis) designated as resistance gene candidates (RGCs). Deduced amino acid sequences of the RGCs revealed the typical motifs present in the majority of known plant NBS-LRR resistance genes. Structural and phylogenetic analyses showed that the banana RGCs are related to non-TIR subclass of NBS sequences. The copy number of each class was estimated by Southern hybridisation and each RGC was found to be in low copy number. The expression of the RGCs was assessed by RT-PCR in leaf and root tissues of plants resistant or susceptible to Fusarium oxysporum f. sp. cubense (FOC) race 4. Four classes showed a constitutive expression profile whereas no expression was detected for one class in either tissue. Interestingly, a transcriptional polymorphism was found for RGC2 whose expression correlated with resistance to FOC race 4 suggesting a possible role of this gene in resistance to this devastating FOC race. Moreover, RGC2 along with RGC5 showed significant sequence similarity to the Fusarium resistance gene I2 from tomato and were chosen for further characterisation. The NBS sequences isolated in this study represent a valuable source of information that could be used to assist the cloning of functional R genes in banana.
 
 Chapter 5 describes the isolation and characterisation of the full open reading frame (ORF) of RGC2 and RGC5 cDNAs. The ORFs of these two banana RGCs were predicted to encode proteins that showed the typical structure of non-TIR-NBS-LRR resistance proteins. Homology searches using the entire ORF of RGC2 and RGC5 revealed significant sequence similarity to the Fusarium resistance gene I2 from tomato. Interestingly, the phylogenetic analysis showed that RGC2 and RGC5 were grouped within the same phylogenetic clade, along with the Fusarium resistance genes l2 and Fom-2. These findings suggest that the banana RGC2 and RGC5 are potential resistance gene candidates that could be associated with Fusarium resistance. The case of RGC2 is more remarkable because its expression was correlated to FOC race 4 resistance (Chapter 4). As a first step to test whether RGC2 has a role in FOC race 4 resistance, different expression constructs were made with the ORF of this sequence. One of the constructs contains a RGC2 putative promoter region that was successfully cloned in this work. These constructs will be used to transform susceptible banana plants that can then be challenged with FOC race 4 to assess whether resistance has been acquired by genetic complementation.
 
 The results of this thesis provide interesting insights about the structure, expression and phylogeny of two potential Fusarium resistance genes in banana, and provide a rational starting point for their functional characterisation. The information generated in this thesis may lead to the identification of a Fusarium resistance gene in banana in further studies and may also assist the cloning of Fusarium resistance genes in other plant species.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">banana</field><field name="subject">Musa acuminata ssp. malaccensis</field><field name="subject">Fusarium oxysporum f. sp. cubense race 4</field><field name="subject">Panama disease</field><field name="subject">disease resistance gene candidates</field><field name="subject">nucleotide binding site</field><field name="identifier">http://eprints.qut.edu.au/16573/</field><field name="validLink">True</field></doc><doc><field name="title">Unlearning in the workplace : a mixed methods study</field><field name="creator">Becker, Karen Louise</field><field name="description">Contemporary organisations face a raft of challenges in coping with competing demands and rapidly changing environments. With these demands and changes comes the need for those within the organisation to be adequately skilled to meet these challenges both now and into the future. There is a growing concern that the rate of change is such that learning will not be sufficient and that individuals will need to be skilled in unlearning or letting go of past practice and behaviour.    This research investigated individual unlearning as it applies in the workplace, and enabled the development of a process model of unlearning that provides specific indication of factors affecting unlearning during times of change.    In particular, this thesis highlights the critical importance of elements of a more personal and affective nature; often referred to as "soft" issues. Six key factors at the level of the individual were identified as impacting unlearning; positive prior outlook, individual inertia, feelings and expectations, positive experience and informal support, understanding the need for change, and assessment of the new way.    Two factors emerged from the organisational level that also impact unlearning; organisational support and training and history of organisational change. Many change efforts will fail because of lack of attention to individuals, how they unlearn and the level of feelings and expectations that accompany change. This research demonstrates that organisations must provide resources and education to provide both those in supervisory roles and those impacted by change with the necessary skills to unlearn and to embrace change at an individual level.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">unlearning</field><field name="subject">learning</field><field name="subject">adult learning</field><field name="subject">organisational learning</field><field name="subject">workplace learning</field><field name="subject">resistance to change</field><field name="subject">change</field><field name="subject">organisational change</field><field name="subject">innovation</field><field name="subject">individual inertia</field><field name="subject">organisational culture</field><field name="subject">organisational memory</field><field name="subject">explicit knowledge</field><field name="subject">tacit knowledge</field><field name="subject">frames of reference</field><field name="subject">transitions</field><field name="identifier">http://eprints.qut.edu.au/16574/</field><field name="validLink">True</field></doc><doc><field name="title">Success in the protean career : a predictive study of professional artists and tertiary arts graduates</field><field name="creator">Bridgstock, Ruth Sarah</field><field name="description">In the shift to a globalised creative economy where innovation and creativity are increasingly prized, many studies have documented direct and indirect social and economic benefits of the arts. In addition, arts workers have been argued to possess capabilities which are of great benefit both within and outside the arts, including (in addition to creativity) problem solving abilities, emotional intelligence, and team working skills (ARC Centre of Excellence for Creative Industries and Innovation, 2007).  However, the labour force characteristics of professional artists in Australia and elsewhere belie their importance. The average earnings of workers in the arts sector are consistently less than other workers with similar educational backgrounds, and their rates of unemployment and underemployment are much higher (Australian Bureau of Statistics, 2005; Caves, 2000; Throsby &amp; Hollister, 2003). Graduating students in the arts appear to experience similar employment challenges and exhibit similar patterns of work to artists in general. Many eventually obtain work unrelated to the arts or go back to university to complete further tertiary study in fields unrelated to arts (Graduate Careers Council of Australia, 2005a).  Recent developments in career development theory have involved discussion of the rise of boundaryless careers amongst knowledge workers. Boundaryless careers are characterised by non-linear career progression occurring outside the bounds of a single organisation or field (Arthur &amp; Rousseau, 1996a, 1996b). The protean career is an extreme form of the boundaryless career, where the careerist also possesses strong internal career motivations and criteria for success (Baruch, 2004; Hall, 2004; Hall &amp; Mirvis, 1996). It involves a psychological contract with one's self rather than an organisation or organisations. The boundaryless and protean career literature suggests competencies and dispositions for career self-management and career success, but to date there has been minimal empirical work investigating the predictive value of these competencies and dispositions to career success in the boundaryless or protean career. This program of research employed competencies and dispositions from boundaryless and protean career theory to predict career success in professional artists and tertiary arts graduates. These competencies and dispositions were placed into context using individual and contextual career development influences suggested by the Systems Theory Framework of career development (McMahon &amp; Patton, 1995; Patton &amp; McMahon, 1999, 2006a). Four substantive studies were conducted, using online surveys with professional artists and tertiary arts students / graduates, which were preceded by a pilot study for measure development.  A largely quantitative approach to the program of research was preferred, in the interests of generalisability of findings. However, at the time of data collection, there were no quantitative measures available which addressed the constructs of interest. Brief scales of Career Management Competence based on the Australian Blueprint for Career Development (Haines, Scott, &amp; Lincoln, 2003), Protean Career Success Orientation based on the underlying dispositions for career success suggested by protean career theory, and Career Development Influences based on the Systems Theory Framework of career development (McMahon &amp; Patton, 1995; Patton &amp; McMahon, 1999, 2006a) were constructed and validated via a process of pilot testing and exploratory factor analyses. This process was followed by confirmatory factor analyses with data collected from two samples: 310 professional artists, and 218 graduating arts students who participated at time 1 (i.e., at the point of undergraduate course completion in October, 2005). Confirmatory factor analyses via Structural Equation Modelling conducted in Study 1 revealed that the scales would benefit from some respecification, and so modifications were made to the measures to enhance their validity and reliability. The three scales modified and validated in Study 1 were then used in Studies 3 and 4 as potential predictors of career success for the two groups of artists under investigation, along with relevant sociodemographic variables.  The aim of the Study 2 was to explore the construct of career success in the two groups of artists studied. Each participant responded to an open-ended question asking them to define career success. The responses for professional artists were content analysed using emergent coding with two coders. The codebook was later applied to the arts students' definitions. The majority of the themes could be grouped into four main categories: internal definitions; financial recognition definitions; contribution definitions; and non-financial recognition definitions. Only one third of the definition themes in the professional artists' and arts graduates' definitions of career success were categorised as relating to financial recognition. Responses within the financial recognition category also indicated that many of the artists aspired only to a regular subsistence level of arts income (although a small number of the arts graduates did aspire to fame and fortune).  The second section of the study investigated the statistical relationships between the five different measures of career success for each career success definitional category and overall. The professional artists' and arts graduates' surveys contained several measures of career success, including total earnings over the previous 12 months, arts earnings over the previous 12 months, 1-6 self-rated total employability, 1-6 self-rated arts employability, and 1-6 self-rated self-defined career success. All of the measures were found to be statistically related to one another, but a very strong statistical relationship was identified between each employability measure and its corresponding earnings measure for both of the samples. Consequently, it was decided to include only the earnings measures (earnings from arts, and earnings overall) and the self-defined career success rating measure in the later studies.  Study 3 used the career development constructs validated in Study 1, sociodemographic variables, and the career success measures explored in Study 2 via Classification and Regression Tree (CART - Breiman, Friedman, Olshen, &amp; Stone, 1984) style decision trees with v-fold crossvalidation pruning using the 1 SE rule. CART decision trees are a nonparametric analysis technique which can be used as an alternative to OLS or hierarchical regression in the case of data which violates parametric statistical assumptions.  The three optimal decision trees for total earnings, arts earnings and self defined career success ratings explained a large proportion of the variance in their respective target variables (R2 between 0.49 and 0.68). The Career building subscale of the Career Management Competence scale, pertaining to the ability to manage the external aspects of a career, was the most consistent predictor of all three career success measures (and was the strongest predictor for two of the three trees), indicating the importance of the artists' abilities to secure work and build the external aspects of a career. Other important predictors included the Self management subscale of the Career Management Competence scale, Protean Career Success Orientation, length of time working in the arts, and the positive role of interpersonal influences, skills and abilities, and interests and beliefs from the Career Development Influences scale. Slightly different patterns of predictors were found for the three different career success measures.  Study 4 also involved the career development constructs validated in Study 1, sociodemographic variables, and the career success measures explored in Study 2 via CART style decision trees. This study used a prospective repeated measures design where the data for the attribute variables were gathered at the point of undergraduate course completion, and the target variables were measured one year later. Data from a total of 122 arts students were used, as 122 of the 218 students who responded to the survey at time 1 (October 2005) also responded at time 2 (October 2006).  The resulting optimal decision trees had R2 values of between 0.33 and 0.46. The values were lower than those for the professional artists' decision trees, and the trees themselves were smaller, but the R2 values nonetheless indicated that the arts students' trees possessed satisfactory explanatory power. The arts graduates' Career building scores at time 1 were strongly predictive of all three career success measures at time 2, a similar finding to the professional artists' trees. A further similarity between the trees for the two samples was the strong statistical relationship between Career building, Self management, and Protean Career Success Orientation. However, the most important variable in the total earnings tree was arts discipline category. Technical / design arts graduates consistently earned more overall than arts graduates from other disciplines. Other key predictors in the arts graduates' trees were work experience in arts prior to course completion, positive interpersonal influences, and the positive influence of skills and abilities and interests and beliefs on career development.  The research program findings represent significant contributions to existing knowledge about artists' career development and success, and also the transition from higher education to the world of work, with specific reference to arts and creative industries programs. It also has implications for theory relating to career success and protean / boundaryless careers.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Career success</field><field name="subject">protean career</field><field name="subject">boundaryless career</field><field name="subject">career development</field><field name="subject">career transition</field><field name="subject">school to work transition</field><field name="subject">university to work transition</field><field name="subject">work experience</field><field name="subject">higher education</field><field name="subject">career self-management</field><field name="subject">career management</field><field name="subject">career education</field><field name="subject">artists</field><field name="subject">arts graduates</field><field name="subject">creative industries</field><field name="subject">creative workforce</field><field name="subject">graduate attributes</field><field name="subject">employability</field><field name="subject">generic skills</field><field name="subject">transferable skills</field><field name="subject">scale development</field><field name="subject">confirmatory factor analysis</field><field name="subject">structural equation modelling</field><field name="subject">content analysis</field><field name="subject">decision tree</field><field name="subject">regression tree</field><field name="subject">CART</field><field name="identifier">http://eprints.qut.edu.au/16575/</field><field name="validLink">True</field></doc><doc><field name="title">A cost effective grassland management strategy to reduce the number of bird strikes at the Brisbane airport</field><field name="creator">Thomson, Belinda</field><field name="description">In an era of acute concern about airline safety, bird strikes are still one of the major hazards to aviation worldwide. The severity of the problem is such that it is mandatory in all developed countries to include bird management as part of airport safety management programs. In Australia, there are approximately 500 bird aircraft strikes per year (Bailey 2000). Brisbane airport has a relatively high occurrence of strikes, with an average of 77 recorded every year (2002-2004).    Given the severity of the problem, a variety of techniques have been employed by airports to reduce bird strikes. Scare devices, repellents, continuous patrols for bird hazing, use of raptors to clear airspace of birds and depredation are used by many airports. Even given the diversity of control methods available, it is accepted that habitat management is the most effective long term way to control birds in and around the airport space. Experimental studies have shown that habitat manipulation and active scaring measures (shooting, scaring etc), can reduce bird numbers to an acceptable level.    The current study investigated bird populations in six major vegetation habitat types identified within the operational and surrounding areas of Brisbane airport. In order to determine areas where greater bird control and management should be focused, bird abundance, distribution, and activity were recorded and habitats that pose the greatest bird strike risk to aircraft were identified. Secondly, species with high hazard potential were identified and ranked according to their hazard potential to aircraft.    This study also investigated the effectiveness of different vegetation management options to reduce bird species abundance within operational areas of Brisbane airport. Four different management options were compared. Each management option was assessed for grass structural complexity and potential food resources available to hazardous bird species.    Analysis of recorded data showed that of the habitats compared within the Brisbane airport boundaries, grasslands surrounding runways, taxiways and aprons possess the greatest richness and abundance of bird species that pose the greatest potential hazard to aircraft. Ibis and the Australian kestrel were identified as the bird species that pose the greatest risk to aircraft at Brisbane airport, and both were found in greatest numbers within the managed grasslands surrounding operational areas at the airport.    An improved reporting process that allows correct identification of all individual bird species involved in bird strikes will not only increase the accuracy of risk assessments, but will also allow implementation of more effective control strategies at Brisbane airport.    Compared with current grassland management practice, a vegetation management option of maintaining grass height at 30-50cm reduced total bird utilisation by 89% while utilisation of grassland by potentially hazardous birds was also reduced by 85%. Maintaining grass height within the 30-50cm range also resulted in a 45% reduction in the number of manipulations required per year (11 to 6), when compared with current management practices, and a 64% reduction in annual maintenance cost per hectare. When extrapolated to the entire maintained grass area at Brisbane airport, this resulted in a saving of over $60 000 annually. Optimisation of potential hazard reduction will rely on future studies that investigate the effect of particular vegetation species that could replace the existing mix of grasses used at Brisbane airport and an understanding of the relative importance of vegetation structure and food supply in determining utilisation by potentially hazardous bird species.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">ATSB</field><field name="subject">Australian Transport Safety Bureau</field><field name="subject">BAC</field><field name="subject">Brisbane Airport Corporation</field><field name="subject">BAM</field><field name="subject">United States Bird Avoidance Model</field><field name="subject">GIS</field><field name="subject">Geographic Information System</field><field name="subject">USGAO</field><field name="subject">United States Government Accountability Office</field><field name="identifier">http://eprints.qut.edu.au/16576/</field><field name="validLink">True</field></doc><doc><field name="title">The design and preliminary evaluation of an intervention to reduce risk-taking behaviour among adolescents : the potential for protective behaviour toward friends</field><field name="creator">Buckley, Lisa D.</field><field name="description">Many adolescents are at risk of injury as a result of lifestyle, with high morbidity and mortality rates primarily affected by engagement in risk-taking behaviour (AIHW, 2004b). The study aimed to reduce injury through the design, implementation and evaluation of an intervention to affect risk-taking behaviour. The intervention was guided by theory,(Theory of Planned Behavior, TPB Ajzen, 1985) and selectively focused on increasing protective behaviour toward friends. To meet the aim, the intervention focused on the following risk-taking behaviours: alcohol use, interpersonal violence, being a passenger of, and own risky use of a motor vehicle or bicycle. The average age of participants of the study was fourteen. The program of research was divided into three stages that, as a whole, met the aim of designing and evaluating an intervention to reduce risk-taking behaviour among adolescents. 
 
 The aim of the first stage was to provide the detail required for the program design (Stage 2). Stage 1 comprised a number of research processes including (i) a comprehensive literature review. The literature review included the rationale for reducing injury and risk-taking behaviour among adolescents, examination of the friendship relationship and assessing key issues and components of previously evaluated behaviour change programs. Stage 1 also included (ii) an assessment and operationalisation of the theoretical design (Theory of Planned Behavior and cognitive behavioural strategies). It was also found, in this Study 1, that the constructs of the TPB could explain friends' protective behaviour. Further, Stage 1 included (iii) Study 2, a qualitative evaluation of injury, risk-taking behaviour and key risk and protective factors for risk-taking behaviour from the perspective of young people conducted through focus groups. The information gathered in Stage 1 was used to develop the design of the program which comprised Stage 2. The next stage (Stage 3) involved an impact evaluation of the program. Firstly, in Study 3, a qualitative study was conducted to assess intervention participants' and teachers' perceptions of the program and adolescents' change in behaviour and attitudes. Intervention participants felt that they reduced their risk-taking behaviour and increased their protective behaviour toward their friends. Overall, adolescents and teachers viewed the program favourably. Secondly, in Study 4, a quantitative evaluation was conducted. Preliminary investigations found significant differences in change and behaviours among individuals from different ethnic backgrounds and, as such, analyses were conducted with the majority, Caucasian group only. The results indicated a reduction in risk-taking behaviours from baseline to follow-up in the intervention group and an increase in the comparison group. There was no support for the prediction that intervention students would increase their protective behaviour relative to the control group. Overall, the findings indicated challenges associated with designing and implementing an effective program to reduce risk-taking behaviour among adolescents.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">theory of planned behavior</field><field name="subject">protective behaviour</field><field name="subject">risk-taking</field><field name="subject">injury prevention</field><field name="subject">program design</field><field name="subject">program evaluation</field><field name="subject">school-based intervention</field><field name="subject">adolescent</field><field name="subject">friend</field><field name="identifier">http://eprints.qut.edu.au/16577/</field><field name="validLink">True</field></doc><doc><field name="title">Understanding impulsivity : molecular genetic and environmental influences</field><field name="creator">White, Melanie Jade</field><field name="description">Features of impulsivity underlie multiple psychological disorders. The body of work examining impulsivity has largely focussed on self-report measurement and has incorporated psychological constructs without reference to the broader biological factors that may influence impulsive behaviour. Two studies were conducted to examine whether environmental stress and genetic status associated with dopaminergic and serotonergic function (DRD2, ANKK1 and 5HT2AR genotypes) were predictive of dimensions of impulsivity and risky behaviour (alcohol use). The two studies used a multi-method approach in a non-clinical community sample of young adults (aged 17-25 years). Dopamine is integral to the two leading theories of impulsive personality, Gray's Reinforcement Sensitivity Theory and Cloninger's Psychobiological model of personality. Dopamine plays a crucial role in reward reinforcement circuits in the brain. The A1 allele of the ANKK1 gene (also referred to as TaqIA of the DRD2 gene region) and the CC genotype of the C957T polymorphism of the DRD2 gene have both been associated with reduced D2 dopamine receptor density in key structures linked to brain reward. In addition, a strong body of evidence implicates their involvement in a number of clinical disorders associated with impulsivity. Serotonin function has also been associated with impulsivity in Cloninger's theory and there is also evidence of associations of two polymorphisms of the 2A serotonin receptor gene (5HT2AR T102C and -1438A/G SNPs) with impulsivity. Acute and chronic forms of stress are also important correlates of impulsive behaviour and the two studies directly examined the relationship between genotype, stress and impulsivity. Study 1 (N=180) utilised a cross-sectional design and examined interactions between these polymorphisms and chronic stress exposure on key impulsivity dimensions of reward sensitivity, Novelty Seeking and rash impulsiveness. Participants completed psychological questionnaires measuring chronic stress, dimensions of impulsivity, mood and substance use and provided mouth swab samples of buccal mucosal cells for DNA analysis. The study confirmed the association between A1 and CC allelic status and chronic stress being associated with harm avoidance and sensitivity to punishment. This suggests a role for both dopamine and background stress in impulsive behaviour. Study 2 (N=73) built upon this questionnaire research in the laboratory by utilising experimental psychological paradigms of impulsive behaviour and experimentally manipulating acute stress. Study 2 employed a mixed experimental design with a sub-sample of those studied in the cross-sectional sample. These behavioural paradigms included pre- and post- stress induction administration of the Card Arranging Reward Responsiveness Objective Test (capturing behavioural approach in the presence of reward cues, presumed to reflect reward sensitivity) and post-induction delay discounting and response inhibition measures. Study 2 confirmed the role of one of the two dopamine-related polymorphisms, with those with A1+ allelic status demonstrating lower reward responsiveness prior to rest or stress induction, which was overcome in the second administration of this task, independent of environment. A1+ allelic individuals also demonstrated significantly poorer response inhibition independent of stress, further confirming the association between A1+ allelic status and impulsivity. Those with CC allelic status showed an increase in reward responsiveness only in the stress induction condition. Together, results from the two studies inform the development of a multidimensional model of impulsivity that captures gene-environment influences on discrete aspects of impulsive personality and behaviour. Further refinement of this model may lead to the development of more effective customised prevention and treatment interventions for clinically disordered impulsivity. The implications of dopaminergic systems and stress in understanding disorders such as ADHD and substance dependence are discussed.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">impulsivity</field><field name="subject">reward</field><field name="subject">punishment</field><field name="subject">reinforcement sensitivity theory</field><field name="subject">psychobiological model</field><field name="subject">personality</field><field name="subject">reward deficiency theory</field><field name="subject">molecular genetics</field><field name="subject">dopamine</field><field name="subject">serotonin</field><field name="subject">receptor gene</field><field name="subject">A1 allele</field><field name="subject">TaqIA</field><field name="subject">C957T</field><field name="subject">T102C</field><field name="subject">-1438A/G</field><field name="subject">chronic stress</field><field name="subject">acute stress</field><field name="subject">psychosocial stressor</field><field name="identifier">http://eprints.qut.edu.au/16578/</field><field name="validLink">True</field></doc><doc><field name="title">Technical and further education diploma graduates : personal capital investments and returns</field><field name="creator">Van Der Linde, Christopher Jae</field><field name="description">This research has examined the personal capital investments and returns of a group of TAFE Diploma of Community Work graduates through the use of qualitative research methodology. Recognising that the concept of personal capital is distinct from human capital in that it considers the intrinsic reasons, impetus and values that individuals ascribe to their motivation to undertake and complete a course of study. Personal capital is not quantifiable within the present human capital outcomes paradigm, however the personal capital paradigm allows for a deeper exploration of a range of further tangible and valid outcomes not addressed in the human capital approach. There is a gap in the current research literature regarding evaluation of TAFE outcomes and it stems from a predominant human capital focus. The existing paradigm of human capital, which values the acquisition of knowledge and skills for their economic value, has been of primary interest and significance, particularly in terms of government policy in relation to vocational education and training  By using an interpretivist approach comprising in-depth interviews, the researcher was able to explore the intrinsic drives, motivations and aspirations and impetus that brought the TAFE graduates to initially undertake their studies in the diploma program. This approach also allowed for an examination as to whether the graduates perceived that they had obtained a return on this personal capital investment in the study program. Through the conceptual framework, the research established a set of predetermined personal capital investments and returns, although the research was not constrained by these pre-determined themes. The use of grounded theory data analysis procedures in the study allowed for the evolution and analysis of emergent categories or themes relating to personal capital investments and returns. Consequently, the qualitative analysis of the in-depth interviews has revealed a broader range of themes relating to personal capital investments and returns than otherwise might have been discovered if the research had been limited to the pre-determined themes arising from the conceptual framework. It is the author's contention that this qualitative study of TAFE diploma graduate's personal capital investments and returns gives insights about the notion of personal capital and its importance to decision-making as to why individuals undertake the Diploma of Community Work. This study also reveals what they personally and professionally expect from study in such a program. Neither of which the current quantitative data about TAFE graduates, namely the Student Outcomes Surveys; by design and intent  are as yet capable of acknowledging or exploring.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">federal government</field><field name="subject">human capital</field><field name="subject">investments</field><field name="subject">personal capital</field><field name="subject">tafe</field><field name="subject">returns</field><field name="subject">vocational education and training</field><field name="identifier">http://eprints.qut.edu.au/16579/</field><field name="validLink">True</field></doc><doc><field name="title">Indirect interactions between alien and native Senecio species as mediated by insects</field><field name="creator">White, Evelyn M.</field><field name="description">The studies described in this thesis investigate the role of indirect effects in invasion biology. The Introduction provides a brief overview of indirect effects and an outline of the thesis structure. The role of indirect effects in the context of invasion biology is addressed in an in-depth published literature review that comprises the second chapter, providing a theoretical background for the subsequent empirical studies. Chapters Three to Six are comprised of manuscripts that have been published or are under review or in press, which describe studies that investigate the importance of indirect effects in invasion biology using a model system consisting of the alien Asteraceae Senecio madagascariensis, a closelyrelated native, Senecio pinnatifolius, and the insect species with which they interact. Senecio madagascariensis and S. pinnatifolius occur in a similar geographic range in eastern Australia and these studies were conducted in mixed and pure populations of the two species. The herbivore and floral visitor assemblages of the two Senecio species at seven field sites in South-east Queensland were compared using sweep-net sampling, manual searching and floral visitor observation techniques. The floral visitor assemblages were similar between the two species, comprised largely of species of Syrphidae and the European honeybee, Apis mellifera. Herbivore assemblages, however, were highly variable both between species and between sites, with greater herbivore abundance and diversity recorded on the native S. pinnatifolius than its alien congener. The most commonly recorded herbivores were sap-sucking species such as Myridae. The magpie moth, Nyctemera amica was the most common folivore on both Senecio species and laboratory studies demonstrated a clear preference by ovipositing females and feeding larvae of this species for the native Senecio species, over the alien. Field surveys supported these findings, recording greater leaf damage on the native species than the invader. Herbivory levels were lower, rather than higher, in mixed populations than in pure populations, thus there was no evidence that the presence of one species enhanced herbivory in the other.    Field pollination trials were conducted to determine whether competition for pollinators or facilitation of pollination occurred in mixed Senecio populations. The presence of the native S. pinnatifolius affected pollinator visitation rates to the alien Senecio; bee visits to S. madagascariensis were significantly reduced by the presence of S. pinnatifolius, whilst syrphid visits increased. However, altered visitation rates were not reflected in seed set. The presence of the alien species had no impact on pollinator visits to the native. Surprisingly, S. pinnatifolius seed set was higher in mixed populations than in pure populations. This might be due to abiotic factors, lower rates of herbivory at these sites or transfer of pollen between species resulting in the production of hybrid seed (if S. madagascariensis has greater male fitness). Hybridisation in the field was investigated using AFLP techniques. No mature hybrid plants were recorded in mixed populations, but hybrid seeds were produced by both species. Senecio pinnatifolius maternal parents produced higher numbers of hybrid seed than expected based on the relative frequencies of the two species, whilst hybridisation in S. madagascariensis was lower than expected. This may indicate greater male fitness of the invader.    A range of complex indirect interactions can occur between invasive and native species, with these interactions having the potential to influence the success or failure of the invader and its impacts on co-occurring natives. The Discussion addresses the findings of the studies described here in the context of invasion biology theory.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">exotic</field><field name="subject">herbivory</field><field name="subject">higher order interactions</field><field name="subject">hybridisation</field><field name="subject">indirect effects</field><field name="subject">insectplant</field><field name="identifier">http://eprints.qut.edu.au/16580/</field><field name="validLink">True</field></doc><doc><field name="title">Acts of Dissension : how political theatre has been presented in the past and what strategies the playwright can employ to make issues of radical or alternative politics more accessible to a mainstream theatre audience</field><field name="creator">Reid, Robert</field><field name="description">The key focus of this research project is the marginalisation of radical and alternative politics in modern democratic societies, how they have been presented in a mainstream theatrical context and what strategies a political playwright can employ to present the issues of those politics while overcoming such marginalisation.  Referencing cultural theorists including Noam Chomsky, Naomi Klein and Howard Zinn, this study argues that contemporary cultures operate within the boundaries of an internalised conservative value set propagated through systems of coercion utilised by the media, governments and corporations.  With a specific interest in contemporary theatre, this study proposes that this internalisation functions as an efficient and nearly invisible censor, rendering more complex the task of the political playwright in communicating with a wider and more inclusive audience and that by examining the methods used in the manufacture of consent and then returning to the strategies utilized by political playwrights in the past and at present, we can better identify how to bypass that internal censor and do something more than " preach to the converted."  This project comprises two interrelated components; one is an original full length play script, Pornography: The True Confessions of Mandy Lightspeed; the other is an exegesis which compliments and augments the play.  The play script represents %60 and the exegesis the remaining %40 of the examinable output of this project, although both are considered integral (and integrate) parts of the whole.  Central to both these texts is the question; " How has political theatre been presented in the past and what strategies can the playwright employ to make issues of radical or alternative politics more accessible to a mainstream theatre audience?"</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">political theatre</field><field name="subject">mainstream audiences</field><field name="subject">globalisation</field><field name="subject">manufacture of consent</field><field name="subject">coercion</field><field name="subject">practice-led research</field><field name="subject">playwriting</field><field name="identifier">http://eprints.qut.edu.au/16581/</field><field name="validLink">True</field></doc><doc><field name="title">The collaborative impact : writing a play with the collaboration of actors</field><field name="creator">Lyall-Watson, Katherine</field><field name="description">How can a playwright share authorial control with a group of actors when creating a new play script? How does the individual playwright address matters of genre, form, style and structure to create a unifying theme, while remaining true to the dramatic intention and aesthetics of the group? What impact will the collaborators have on a playwright's work? Will they help or hinder the writing process? This exegesis closely follows the creation of a new play, The Woods, in a process where the playwright intended to facilitate a collaborative process with the actors rather than act as sole author. Issues arising in this mode of working include the real meaning of sole authorship, aesthetic integrity and creative power balance. The analysis of these issues will have relevance for theatre practitioners working in collaborative contexts.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">collaboration</field><field name="subject">collaborative theatre</field><field name="subject">group devised theatre</field><field name="subject">devising</field><field name="subject">playwrights</field><field name="subject">creativity</field><field name="subject">play building</field><field name="subject">play script</field><field name="subject">authorial control</field><field name="subject">theatre</field><field name="identifier">http://eprints.qut.edu.au/16582/</field><field name="validLink">True</field></doc><doc><field name="title">Activating simultaneity in performance : exploring Robert Lepage's working principles in the making of Gaijin</field><field name="creator">Knapton, Benjamin</field><field name="description">In this research I have explored the performance making process of world renowned director Robert Lepage. This exploration informed my own process, creating an original performance called GAIJIN, where my roles included producer / director / designer and co-writer. The practice-led research strategy employed in this research has allowed me to navigate the sometimes slippery slope of connecting various performance discourses with the pragmatics of the performance making process. The reason for this research is my strong interest in the director&#8217;s role and my affinity with the practice of Robert Lepage.  My observation of the performance making process of Robert Lepage prompted the creation of a conceptual framework informed by Hans-Thies Lehmann&#8217;s work Postdramatic Theatre. These theoretical concerns were then further investigated in the creation of my own show. This research process has uncovered a performance making process that foregrounds the working principles of simultaneity and synaesthesia, which together offer a changed conception of the performance text in live performance.  Simultaneity is a space of chaotic interaction where many resources are used to build a perpetually evolving performance text. Synaesthesia is the type of navigation required &#8211; an engagement consisting of interrelated sense-impressions that uniquely connect the performance makers with the abundance of content and stimulus; they search for poetic connections and harmonious movement between the resources. This engagement relies on intuitive playmaking where the artists must exhibit restraint and reserve to privilege the interaction of resources and observe the emerging performance. This process has the potential to create a performance that is built by referential layers of theatrical signifiers and impressions.
 
 
 
 This research offers an insight into the practices of Robert Lepage as well as a lens through which to view other unique devising processes. It also offers a performance making language that is worthy of consideration by all performance makers, from directors to performers. The significance of this process is its inherent qualities of innovation produced by all manner of art forms and resources interacting in a unique performance making space.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">collaboration</field><field name="subject">contemporary performance</field><field name="subject">devised theatre</field><field name="subject">interaction</field><field name="subject">intuition</field><field name="subject">performance making</field><field name="subject">performance text</field><field name="subject">postdramatic theatre</field><field name="subject">process</field><field name="subject">Robert Lepage</field><field name="subject">simultaneity</field><field name="subject">synaesthesia</field><field name="identifier">http://eprints.qut.edu.au/16583/</field><field name="validLink">True</field></doc><doc><field name="title">Development of improved diagnostics for acute and persistent Chlamydia trachomatis infections</field><field name="creator">Armitage, Trudi</field><field name="description">The asymptomatic nature of chlamydial infection renders the differential diagnosis of acute and chronic infection difficult.  An untreated Chlamydia trachomatis infection can become chronic, result in disease sequelae such as salpingitis and pelvic inflammatory disease (PID), and ultimately culminate in tubal occlusion and infertility.  Diagnostic tests for C. trachomatis such as nucleic acid amplification testing (PCR), antigen detection and serological methods have variable performance capabilities with respect to sensitivity, specificity and stage of infection.  The use of PCR as a diagnostic tool is somewhat limited, as specimen collection is routinely sampled from the lower genital tract; hence, infections in the fallopian tube where inflammatory damage is most significant, escape detection.  Furthermore, PCR can only detect selected Chlamydia DNA sequences from readily accessible sites of the genital tract, and therefore cannot differentiate between acute and chronic infection.  Other serological assays aim to discriminate the various stages of C. trachomatis infection through identification of key antigens.  The efficacy of these assays however is impeded due to cross-reactivity between chlamydial species and the subsequent antibody response against the target antigen is not restricted to patients with a specific stage of infection.    To identify antibody responses capable of differentiating various states of chlamydial infection, samples were collected from both men and women given the variability of immune responses between the two genders.  Samples were assigned to a patient group according to infection status and then probed against protein extracts of HEp-2 cells infected with C. trachomatis serovar L2 and HEp-2 cells pre-treated with IFN-&#947; and infected with C. trachomatis serovar L2. (persistence cell culture)  Serological analysis revealed the presence of five antigens (denoted bands A, B, C, D and M) which were shown to be differential between patient groups.  Identification of bands B and C by N-terminal sequencing provided two possible candidates for each antigen, ie. CT727 and CT396 (band B) and CT157 and CT423 (band C).  In contrast, band M which was unique to males was a PmpB (probable outer membrane protein B) fragment.  The four target antigens (CT157, CT423, CT727 and CT396) were expressed as recombinant proteins using autoinduction media and were subsequently probed by both male and female sera to evaluate their diagnostic potential.  Results showed that two chlamydial antigenic targets (CT157 and CT727) have the potential to discriminate between acute and chronic C. trachomatis infection.  However, since only a small number of samples (n = 3) were used for this aspect of the study, the findings should simply be viewed as preliminary.  In females, sensitivity and specificity values were derived using various combinations of the four target antigens into a panel format for the purpose of detecting chronic C. trachomatis infections.  The preferred format was B + C with a sensitivity and specificity of 80% and 84% respectively.  Using the IFN-&#947;-mediated persistence model, only two of the five antigenic targets were shown to be differentially expressed.  PmpB in males and CT157 (the most likely band C candidate) in females were shown to be up-regulated to varying degrees in samples across the patient groups.  We also demonstrated that no other chlamydial antigens are up-regulated during a persistent C. trachomatis infection.  In conclusion, although combinations of bands A, B, C, D and M differentiate between male and female patient groups under normal chlamydial growth conditions, during IFN-&#947;-induced persistence, only bands C (CT157) and M (CT413 - PmpB) are up-regulated thus suggesting a potential role in chronic C. trachomatis infection.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Chlamydia trachomatis</field><field name="subject">pelvic inflammatory disease</field><field name="subject">chronic infection</field><field name="subject">persistence</field><field name="subject">diagnostic test</field><field name="subject">autoinduction</field><field name="subject">differential banding</field><field name="subject">sensitivity</field><field name="subject">specificity</field><field name="identifier">http://eprints.qut.edu.au/16584/</field><field name="validLink">True</field></doc><doc><field name="title">The role of human suppressor with morphogenic effect on genitalia (hSMG-1) in the cellular response to DNA damage</field><field name="creator">Brown, James Andrew</field><field name="description">hSMG-1 (human suppressor with morphogenic effect on genitalia) is the most recent addition to the family of phosphatidyl-inositol-3 kinase related kinases (PIKK). This family includes proteins such as Ataxia Telangiectasia Mutated (ATM), DNA Dependent Protein Kinase (DNA-PK), ATM and Rad3 related kinase (ATR) which are involved in stress induced signal transduction, cell cycle checkpoint control and DNA damage repair. hSMG-1 was first described in Caenorhabditis elegans where it was shown to be essential for Nonsense Mediated mRNA Decay (NMD). More recently hSMG-1 has been implicated in NMD and in the DNA damage response in mammalian cells. Three hSMG-1 isoforms have been described in the literature to date. Isoform 1 is 3 657 amino acids long with isoforms 2 (3 521 amino acids) and 3 (3 031 amino acids) N-terminal truncations of isoform 1. To explore the role of hSMG-1 in the DNA damage response three separate antibodies were generated. Each antibody was raised against a different region of hSMG-1, which allowed detection of specific hSMG-1 isoforms. These hSMG-1 antibodies were found to be suitable for immunoprecipitations, immunoblotting and immunofluorescence. The specificity of the antibodies was further confirmed using mass spectrometric analysis which identified the immunoprecipitated band as hSMG-1. Using these antibodies hSMG-1 was found to be located primarily in the cytoplasm, a novel location for a PIKK protein predicted to be involved in the DNA damage response. In addition, it was found that hSMG-1 isoform 2 was the only isoform present in the cytoplasm and is the major cellular isoform. All three isoforms were detected in the nucleus, with isoforms 1 and 3 only present in this cellular compartment, consistent with a proposed role in the DNA damage response. The generation of hSMG-1 specific antibodies allowed the characterisation of endogenous hSMG-1 kinase activity, which was found to be Mn2+ dependent and was stimulated after DNA damage (ionising radiation, ultraviolet radiation and hydrogen peroxide). Endogenous hSMG-1 was also demonstrated to bind to N-terminal hSMG-1 GST fusion proteins, suggesting that hSMG-1 can from multimers. In addition, hSMG-1 was found to associate with p53, a key component of the DNA damage response pathway, which is also targeted by other members of the PIKK family in response to DNA damage. In response to DNA damage hSMG-1 was observed by immunofluorescence to localise to discrete cytoplasmic granules. These sites were subsequently identified as stress granules (SG). During NMD hSMG-1 targets Upf1, a key step leading to the degradation of aberrant mRNA. Upf1 is recruited to the aberrant mRNA by Upf2 and both proteins were detected in SG. DNA damage induced SG were also demonstrated to be sites of phosphorylated hSMG-1 target motifs [phospho S(/T)Q], suggesting that hSMG-1 has kinase activity within SG. The presence of this phosphorylated site in SG parallels the presence of hSMG-1 at all times observed during SG formation and disassociation. Interestingly, not all treatments with genotoxic agents resulted in hSMG-1 inclusion in SG, indicating that hSMG-1 is not a core component of SG. Indeed, hSMG-1 was excluded from SG induced with the mitochondrial poisons clotrimazole (CZ) and sodium arsenite (NaAs), agents commonly used to induce SG. In addition to hSMG-1, Upf1, Upf2 and phospho S(/T)Q motifs were also excluded from CZ and NaAs induced SG. Reducing the cellular levels of hSMG-1 using small interfering RNA (siRNA) abrogated the formation of SG in response to DNA damage, indicating a crucial role for hSMG-1 in the formation of these SG. Surprisingly, a role for ATM in SG formation after DNA damage was suggested. Abrogation of ATM activity with small molecule inhibitors resulted in decreased SG formation after DNA damage. This novel role of ATM was not required for the induction of SG after treatment with CZ or NaAs. This was confirmed by observing SG induction with the same agents in ATM deficient (A-T) cells. Given that hSMG-1 is excluded from CZ or NaAs induced stress granules this indicates that not only is ATM signalling required for SG formation after DNA damage but this ATM-dependent pathway for SG formation involves the recruitment of hSMG-1, as well as the previously described proteins. This suggests that there are at least two distinct signaling pathways responsible for SG formation, one pathway which is both hSMG-1 and ATM dependent and the other which is ATM and hSMG-1 independent. Here I describe a novel and essential role for hSMG-1 and ATM in stress granule formation after exposure to agents that damage DNA and produce physiological stress.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">DNA damage</field><field name="subject">cancer</field><field name="subject">hSMG-1</field><field name="subject">human suppressor</field><field name="identifier">http://eprints.qut.edu.au/16585/</field><field name="validLink">True</field></doc><doc><field name="title">A study of the integration of health promotion principles and practice in palliative care organisations</field><field name="creator">Rosenberg, John Patrick</field><field name="description">The modern hospice movement emerged in the 1960s as a grassroots social movement that attempted to restore an holistic and contextualised approach to the care of people at the end of life. This approach embraced the lived experience of the dying person at the centre of care across physical, emotional, social and spiritual domains of life. To achieve this, the care of dying people was largely removed from mainstream health care systems to promote more holistic and socially contextualised dying. In recent decades, the evolution of palliative care demonstrates the gradual return of palliative care services to the mainstream. It has been asserted that, in this process, palliative care services have progressively abandoned the social context of dying people, increasing instead an emphasis on "physical care [while] simultaneously de-emphasizing psychological, social and spiritual care" (Kellehear, 1999a, p.76). Kellehear and others have proposed that the repositioning of palliative care within mainstream health care systems has increased a focus upon illness and disease at the expense of health and wellbeing. Subsequently, conventional palliative care services have been criticised for not adequately locating end of life care within the social contexts in which death and dying take place.    In an attempt to address this problem, Australian sociologist Allan Kellehear proposed an approach to end of life care that brought together the core concerns of palliative care with the principles and practices of health promotion (Kellehear, 1999b). Whilst their congruence is not immediately apparent, these two fields have been increasingly examined for their potential benefits in the provision of end of life care. In the current policy climate in Australia, there is an imperative to consider how end of life support services might be improved through adopting a health promoting palliative care approach.    The aim of this study has been to investigate the integration of health promotion principles and practice by a selected palliative care service by examining the qualitative impact of this change on the organisation. Specifically, it endeavoured to identify the factors that advanced or impeded this integration by examining how the structures and processes of, and outcomes for, the organisation reflected a health promoting approach. To meet these aims, this study undertook an in-depth examination of the implementation of a health promoting palliative care model by a community based palliative care organisation. Based in a constructionist-interpretivist paradigm, a mixed-method (QUAL+quant), instrumental case study research design was utilised to capture multiple perspectives of the implementation process. Data collection comprised examination of 127 organisational documents, 32 in-depth interviews with staff, volunteers and consumers, 5 focus groups with staff and volunteers, and 25 carer questionnaires. Qualitative data were subject to thematic analysis, with supplementary quantitative data analysed to generate descriptive statistics.    The findings demonstrated a large number of complex and interrelated enabling and impeding factors to the implementation in the case study site. These factors have been grouped into four key themes which have been examined in light of the aims of this study and the issues identified in a comprehensive review of the literature. This study found that:    &#9702; Conceptual congruence between health promotion and palliative care was a fundamental starting point in the implementation of a health promoting palliative care model.    &#9702; Where conceptual congruence was clear, activities associated with the model that were regarded as beyond conventional approaches to palliative care core business were viewed favourably by stakeholders and were less likely to encounter resistance within the organisation.    &#9702; When systematic approaches to organisational change, such as quality improvement systems, were rigorously applied, the impact of the transition upon stakeholders was qualitatively less.    &#9702; Where this transition had been effectively made, consumers, staff, volunteers and members of the wider community were seen to benefit.    This study adds to the current discourse regarding the intersection between end of life support and health promotion, and provides insight into how palliative care organisations might undertake the transition from conventional models to a health promoting palliative care approach.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">palliative care</field><field name="subject">hospice</field><field name="subject">death and dying</field><field name="subject">grief and loss</field><field name="subject">consumers</field><field name="subject">carers</field><field name="subject">social models</field><field name="subject">public health</field><field name="subject">Ottawa charter for health promotion</field><field name="subject">health promotion</field><field name="subject">public policy</field><field name="subject">supportive environments</field><field name="subject">community action</field><field name="subject">personal skills</field><field name="subject">health services</field><field name="subject">case study research</field><field name="subject">mixed methods</field><field name="subject">documentation review</field><field name="subject">in-depth interviews</field><field name="subject">focus groups</field><field name="subject">self-administered questionnaires</field><field name="subject">matrices</field><field name="identifier">http://eprints.qut.edu.au/16586/</field><field name="validLink">True</field></doc><doc><field name="title">Improving human computer interaction in intelligent tutoring systems</field><field name="creator">Wheeldon, Alan</field><field name="description">ITSs (Intelligent Tutoring Systems) provide a way of addressing some of the issues that the more traditional CAI (Computer Aided Instruction) systems do not address - the individual learning needs and individual learning abilities and levels of users - so that the user is in control of their learning experience. An ITS needs to be able to provide an explanation, for a real world situation, that successfully meets the needs of the user. To ensure relevant explanation content requires the ITS be based on sound planning principles and tutoring knowledge as well as knowledge of the domain and the user. To ensure a coherent explanation structure requires that the tutoring knowledge be applied with full recognition of the knowledge of the domain and the user. For a model of the user's knowledge to be effective, the system should be able to use it to enhance the flexibility and responsiveness of explanations generated. A user model should guide the generation of explanations so they are pitched at the correct level of the user's existing knowledge; models should be able to actively support the needs of the user so that the user's efforts in seeking out information are minimised. The aim of this research is to generate effective, flexible and responsive explanations, in educational software systems, through developing better explanation facilities than exist in currently available ITS software. In achieving this aim, I am advancing research into dialogue planning and user modelling. The explanation facilities described meet the requirements of an explanation that is tailored to the user's needs, a sound theory from which particular explanations are constructed, and a user model that can accurately represent the behaviour and beliefs of the user. My research contributions include explicitly and formally representing discourse planning / reasoning, from both the user's view and the tutor's view so that they can be clearly understood and represented in the ITS. More recent planners have adopted approaches that can be characterised as using adaptations of the classical planning approach, with informally specified planning algorithms and planning languages. Without clear, explicit and full descriptions of actions and the planning algorithm we can not be certain of the plans that such planners produce. I adopt a theoretically rigorous approach based on classical planning theory - the actions available to the planner, the planning language and algorithm should be explicitly represented to ensure that plans are complete and consistent. Classical regression planning uses dynamic planning thus enabling the system to be flexible in a variety of situations and providing the responsiveness required for an ITS. I take a theoretically rigorous approach in constructing a well specified model of discourse, building upon existing research in the area. I present a tutoring module that is able to find a way to motivate the user to take a recommended action, by relating the action to the user's goals, and that is able to reason about the text structure to generate an effective explanation - putting together several clauses of text whilst maintaining coherency. As part of developing such constructs for motivating, enabling and recommending, as well as constructs for structuring text, I use a pedagogic model based on the principled approach of (i) advising the user to take an action (ii) motivating the user to want to take the action and (iii) ensuring the user knows how to do the action. I take a clear and realistic approach to user modelling, making explicit models of the user's behaviour and beliefs. I adopt a theoretically rigorous approach, formally distinguishing between the user's reasoning and their actions, so they can be focused on separately. Formally making this distinction, more easily enables models of the user's reasoning to be tailored to the individual user. To enable the tutor to consider the full impact on the user, of the information to be delivered to the user, I use different plan spaces. I explicitly identify the different perspectives of the user and the tutor so that they can be focused on separately to generate an explanation that is tailored to the user. In my approach, reasoning about the user's skills, rules and knowledge is independent from reasoning about those of the tutor.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">intelligent tutoring systems</field><field name="subject">explanatory dialogue</field><field name="subject">dialogue planning</field><field name="subject">classical planning</field><field name="subject">user</field><field name="subject">model</field><field name="subject">motivation</field><field name="subject">computational linguistics</field><field name="subject">rhetorical structure theory.</field><field name="identifier">http://eprints.qut.edu.au/16587/</field><field name="validLink">True</field></doc><doc><field name="title">Waiting for Certainty:  young people, mobile phones and uncertain science</field><field name="creator">Christensen, Clare Karen</field><field name="description">This dissertation is an empirical study of the scientific literacy of 28 young adults (aged 18-26 years) in the context of their decision making about the health risks of mobile phones.  The issue of possible health effects is one of a number of socioscientific issues now confronting adults in the 'knowledge/risk' society where scientific knowledge plays an increasingly significant role in people's lives. The focus of interest is the young people's responses to the uncertain science of 'science in the making' (Latour, 1987) and their positioning of this scientific knowledge in their risk assessments.  The study is based on an interactive model of the public understanding of science and applies a critical realist and moderate social constructionist methodology. Data construction included focus groups and semi-structured individual interviews.  The stimulus for discussion in the focus groups was a recent television news report presenting contradictory scientific research findings about whether mobile phones pose significant health risks. In the individual interviews understanding of the nature of science and risk judgments were explored.    Data analysis involved a coding of the discourse in terms of themes and issues and interpretation of these in terms of the theoretical framework of the thesis.  A major finding was that these young people interpreted the uncertainty of the scientific knowledge mainly in social terms and with limited understanding of the role of theory in interpreting data. They talked spontaneously of risk but did not draw on scientific knowledge or risk estimates in their judgment about mobile phone safety.    Findings have important implications for science education and suggest a broadened conception of scientific literacy which includes critical dimensions and risk literacy.  It is argued that this functional scientific literacy is essential for effective citizenship in contemporary society.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">science education</field><field name="subject">school science</field><field name="subject">sociocultural</field><field name="subject">socioscientific issues</field><field name="subject">contested science</field><field name="subject">uncertain science</field><field name="subject">nature of science</field><field name="subject">public understanding of science</field><field name="subject">scientific literacy</field><field name="subject">citizenship</field><field name="subject">risk</field><field name="subject">risk literacy</field><field name="subject">critical literacy</field><field name="subject">decision-making</field><field name="subject">young adults</field><field name="subject">youth</field><field name="subject">mobile phones</field><field name="subject">cellular phones</field><field name="subject">critical realism</field><field name="identifier">http://eprints.qut.edu.au/16588/</field><field name="validLink">True</field></doc><doc><field name="title">Structural behaviour of an innovative cold-formed steel building system</field><field name="creator">Darcy, Greg</field><field name="description">Cold-formed steel structures have been in service for many years and are used as shelters for both domestic and industrial purposes.  To produce an economical product, manufacturers have typically based their designs on the simple portal frame concept.  As there is almost a direct relationship between overall cost and the weight of steel in a portal frame structure, it is of great importance to provide a structure with the minimum amount of steel whilst providing structural adequacy.  Portal frame sheds have been refined continuously for many years, with only minimal amounts of savings in steel.  Therefore, to provide even greater savings in steel, an innovative building system is required.  Modern Garages Australia (MGA) is one of the leading cold-formed steel shed manufacturers in Queensland.  MGA has recently developed such an innovative building system that has significant economic savings when compared with portal frame structures.    The MGA building system has two key differences to that of the conventional portal frame system.  These differences are that the MGA system has no conventional frames or framing system, and it has no purlins or girts.  This results in the MGA system being completely fabricated from thin cladding, which significantly reduces the quantity of steel.  However, the key problem with this building system is that the load paths and structural behaviour are unknown, and therefore the structure cannot be analysed using conventional methods.  Therefore, the objectives of this research were to first investigate the structural behaviour of this new building system and its adequacy for an ultimate design wind speed of 41 m/s using full scale testing.  The next objectives were to use finite element analysis to optimise the original MGA building system so that it is adequate for an ultimate design wind speed of 41 m/s, and to develop a new improved cold-formed steel building system that has greater structural efficiency than the original MGA building system.    This thesis presents the details of the innovative MGA building system, full scale test setup, testing program, finite element analysis of the MGA building system and the results.  Details and results from the optimisation of the MGA building system, and the development of a new improved cold-formed steel building system are also presented.  The full scale experimental investigation considered the required loadings of cross wind, longitudinal wind and live load test cases and simulated them on the test structure accurately using an innovative load simulation system.  The wind loads were calculated for a 41 m/s ultimate design wind speed.  Full scale test program included both non-destructive and destructive tests.    The finite element analyses contained in this thesis have considered cross wind, longitudinal wind and live load cases, as well as the destructive load case of the MGA building system.  A number of different model types were created and their results were compared with the experimental results.  In general, two main model types were created.  The first type consisted of a 'strip' of the MGA building system (Strip model) and the second modelled the full structure (Full model).  Both of these model types were further divided into models which contained no contact surfaces and those which contained contact surfaces to simulate the interfaces between the various components such as the brackets and cladding. The experimental test results showed that the MGA test structure is not suitable for an ultimate design wind speed of 41 m/s.  This conclusion is a result of a number of observed failures that occurred during the extensive testing program.  These failures included local buckling, crushing failures, and distortional buckling of the cladding panels.  Extremely large deflections were also observed.  It was calculated that for the MGA building system to be adequate for the design wind speed of 41 m/s, a cladding thickness of 0.8 mm was required.  This also agreed well with the finite element analysis results which concluded that a cladding thickness of 0.8 mm was required.    In order to avoid the increased use of steel in the building system, a new improved cold-formed steel building system was developed and its details are provided in this thesis.  A finite element model of this new improved cold-formed steel building system was created and the results showed that the new building system was able to achieve a load step equivalent to an ultimate design wind speed of 50.4 m/s and was approximately 250% stiffer than the original MGA building system, without any increase in the overall weight of the building system.  It is recommended that this new improved cold-formed steel building system be further developed with the aid of finite element modelling and be tested using a similar full scale testing program that was used for the original MGA building system.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">cold-formed steel</field><field name="subject">innovative</field><field name="subject">steel building system</field><field name="subject">full-scale testing</field><field name="subject">innovative frameless structure</field><field name="subject">light weight building system</field><field name="subject">load simulation</field><field name="subject">non-linear analysis</field><field name="subject">and finite element analysis</field><field name="identifier">http://eprints.qut.edu.au/16589/</field><field name="validLink">True</field></doc><doc><field name="title">Using results from the exploration of human autobiographical memory to build software agents</field><field name="creator">Stanton, Julie</field><field name="description">As a result of globalisation the cultural, political, economical and technological environments people live in today are becoming increasingly integrated and interdependent. It is common knowledge that the problems we face in these environments are almost always interdisciplinary, yet building interdisciplinary frameworks is still a niche in scientific research. 
 
 This thesis addresses the problem of how to incorporate in an experimental interdisciplinary framework, diverse concepts from several independent scientific areas. This work is specifically about implementing results emerging from naturalistic studies, such as autobiographical memory, in the context of information and communication technologies within an interdisciplinary framework.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">autobiographical memory</field><field name="subject">software agents</field><field name="identifier">http://eprints.qut.edu.au/16590/</field><field name="validLink">False</field></doc><doc><field name="title">The internal dynamics of terrorist cells:  a social network analysis of terrorist cells in an Australian context</field><field name="creator">Koschade, Stuart Andrew</field><field name="description">The rise of the 21st Century Islamic extremist movement, which was mobilised by the al-Qaeda attacks of and responses to September 11, 2001, heralds a new period in the history of terrorism. The increased frequency and intensity of this type of terrorism affects every nation in the world, not least Australia. Rising to meet the challenges posed by terrorism is the field of terrorism studies, the field which aims at understanding, explaining, and countering terrorism. Despite the importance of the field, it has been beleaguered with criticisms since its inception as a response to the rise of international terrorism. These criticisms specifically aim at the field's lack of objectivity, abstraction, levels of research, and levels of analysis. These criticisms were the impetus behind the adoption of the methodology of this thesis, which offers the distinct ability to understand, explain, and forecast the way in which terrorists interact within covert cells. Through social network analysis, this thesis examines four terrorist cells that have operated in or against Australia. These cells are from the groups Hrvatsko Revolucionarno Bratstvo (Croatian Revolutionary Brotherhood), Aum Shinrikyo (Supreme Truth), Lashkar-e-Taiba (Army of the Pure), and Jemaah Islamiyah (Islamic Community) and operated between 1963 and 2003. Essentially, this methodology attempts to discover, map, and analyse the interaction within the cells during the covert stage of their respective operations. Following this, the results are analysed through the traditional social network analysis frameworks to discover the internal dynamics of the cell and identify the critical nodes (leaders) within the cells. Destabilisation techniques are subsequently employed, targeting these critical nodes to establish the most effective disruption techniques from a counter-terrorism point of view.    The major findings of this thesis are: (1) that cells with a focus on efficiency rather than covertness were more successful in completing their objectives (contrary to popular belief); and (2) betweenness centrality (control over the flow of communication) is a critical factor in identifying leaders within terrorist cells. The analysis also offered significant insight into how a Jemaah Islamiyah cell might operate effectively in Australia, as well as the importance of local contacts to terrorist operations and the significance of international counter-terrorism cooperation and coordination.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">terrorism</field><field name="subject">terrorist cells</field><field name="subject">terrorism studies</field><field name="subject">social network analysis</field><field name="subject">Croatian Revolutionary Brotherhood</field><field name="subject">Ustashi</field><field name="subject">Ustasha</field><field name="subject">Aum Shinrikyo</field><field name="subject">Lashkar-e-Taiba</field><field name="subject">Jemaah Islamiyah</field><field name="subject">history of terrorism</field><field name="subject">Australia</field><field name="subject">destabilisation techniques</field><field name="subject">betweenness</field><field name="subject">critical node</field><field name="subject">counter-terrorism</field><field name="subject">Willie Brigitte</field><field name="subject">Faheem Khalid Lodhi</field><field name="subject">Shoko Asahara</field><field name="subject">Imam Samudra</field><field name="subject">Muklas</field><field name="subject">Bali bombing</field><field name="subject">Islamic extremism</field><field name="identifier">http://eprints.qut.edu.au/16591/</field><field name="validLink">True</field></doc><doc><field name="title">Foundations of process-aware information systems</field><field name="creator">Russell, Nicholas Charles</field><field name="description">Over the past decade, the ubiquity of business processes and their need for ongoing management in the same manner as other corporate assets has been recognized through the establishment of a dedicated research area: Business Process Management (or BPM). There are a wide range of potential software technologies on which a BPM o&#174;ering can be founded. Although there is signi&#175;cant variation between these alternatives, they all share one common factor { their execution occurs on the basis of a business process model { and consequently, this &#175;eld of technologies can be termed Process-Aware Information Systems (or PAIS). This thesis develops a conceptual foundation for PAIS based on the results of a detailed examination of contemporary o&#174;erings including work&#176;ow and case han- dling systems, business process modelling languages and web service composition languages. This foundation is based on 126 patterns that identify recurrent core constructs in the control-&#176;ow, data and resource perspectives of PAIS. These patterns have been used to evaluate some of the leading systems and business process modelling languages. It also proposes a generic graphical language for de&#175;ning exception handling strategies that span these perspectives. On the basis of these insights, a comprehensive reference language { newYAWL { is developed for business process modelling and enactment. This language is formally de&#175;ned and an abstract syntax and operational semantics are provided for it. An assessment of its capabilities is provided through a comprehensive patterns-based analysis which allows direct comparison of its functionality with other PAIS. newYAWL serves as a reference language and many of the ideas embodied within it are also applicable to existing languages and systems. The ultimate goal of both the patterns and newYAWL is to improve the support and applicability of PAIS.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">process-aware information systems</field><field name="subject">PAIS</field><field name="subject">business process management</field><field name="subject">workflow management</field><field name="subject">business process modelling</field><field name="subject">workflow patterns</field><field name="subject">coloured Petri nets</field><field name="subject">yet another workflow language (YAWL)</field><field name="subject">newYAWL</field><field name="identifier">http://eprints.qut.edu.au/16592/</field><field name="validLink">True</field></doc><doc><field name="title">In vitro mineralisation of well-defined polymers and surfaces</field><field name="creator">Suzuki, Shuko</field><field name="description">Currently, many polymeric biomaterials do not possess the most desirable surface properties for direct bone bonding due to the lack of suitable surface functionalities. The incorporation of negatively charged groups has been shown to enhance calcium phosphate formation in vitro and bone bonding ability in vivo. However, there are some conflicting literature reports that highlight the complicated nature of the mineralisation process as well as the sometimes apparent contradictory effect of the negatively charged groups. Surface modification using well-defined polymers offer a more precise control of the chain structures. The aims of this study were to synthesise well-defined polymers containing phosphate and carboxylic acid groups, and perform various surface modification techniques. The influence of the polymer structure on mineralisation was examined using a series of specially synthesised phosphate-containing polymers. The mineralisation ability of the fabricated surfaces was also tested. Soluble poly(monoacryloxyethyl phosphate) (PMAEP) and poly(2-(methacryloyloxy)ethyl phosphate) (PMOEP)  were synthesised using reversible addition fragmentation chain transfer (RAFT)-mediated polymerisation. The polymerisation conversions were monitored by in situ Raman spectroscopy. Subsequently 31P NMR investigation revealed the presence of large amounts of diene impurities as well as free orthophosphoric acids in both the MAEP and MOEP monomers. Elemental analyses of the polymers showed loss of phosphate groups due to hydrolysis during the polymerisation. Both gel and soluble PMAEP polymers were found to contain large amounts of carboxyl groups indicating hydrolysis at the C-O-C ester linkages. Block copolymers consisting of PMAEP or PMOEP and poly(2-(acetoacetoxy) ethyl methacrylate) PAAEMA were successfully prepared for the purpose of immobilisation of these polymers onto aminated slides. Well-defined fluorinated polymers, (poly(pentafluorostyrene) (PFS), poly(tetrafluoropropyl acrylate) (TFPA) and poly(tetrafluoropropyl methacrylate) (TFPMA)) were synthesised by RAFT-mediated polymerisation. It was found that the Mn values of PFS at higher conversions were significantly lower than those calculated from the theory, although the PDI's were low (&amp;lt1.1).  One possible explanation for this is that it may be a result of the self-initiation of FS which created more chains than the added RAFT agents. Both TFPA and TFPMA showed well-controlled RAFT polymerisations. Chain extension of the fluorinated polymers with tert-butyl acrylate (tBA) followed by hydrolysis of the tBA groups produced the amphiphilic block copolymers containing carboxylic acid groups. Block copolymers consisting of PAAEMA segments were further reacted with glycine and L-phenylalanyl glycine. Three types of surface modifications were carried out: Layer-by-Layer (LbL) assemblies of the soluble phosphate- and carboxylic acid-containing homopolymers, coupling reactions of block copolymers consisting of phosphate and keto groups onto aminated slides, and adsorption of fluorinated homo and block copolymers containing carboxylic acid groups onto PTFE. For LbL assemblies XPS analyses revealed that the thickness of the poly(acrylic acid) (PAA) layer was found to be strongly dependent on the pH at deposition. AFM images showed that the PMAEP LbL had a patchy morphology which was due to the carboxylate groups that were not deprotonated at low pH. Successful coupling of the block copolymers consisting of phosphate and keto groups onto aminated slides was evident in the XPS results. The conformation of attached P(MOEP-b-AAEMA) was investigated by ToF-SIMS. Adsorption of the fluorinated polymers onto the PTFE film was examined using different solvents. PFS showed the best adsorption onto PTFE. The block copolymers consisting of PFS and PtBA or PAA were successfully adsorbed onto PTFE. Contact angle measurements showed that the adsorbed block copolymers reorganised quickly to form a  hydrophilic surface during the investigation.  In vitro mineralisation of various phosphate-containing polymers and the fabricated surfaces were studied using the simulated body fluid (SBF) technique. The SEM/EDX investigation showed that either brushite or monetite, with a tile-like morphology, was formed on both soluble and gel PMAEP polymers after seven days in SBF. The PMOEP gel formed a similar layer as well as a secondary growth of hydroxyapatite (HAP) that exhibited a typical globular morphology. Fourier transform infrared (FTIR) spectroscopy of the PMOEP film prepared from soluble PMOEP showed large amounts of carbonated HAP formation after seven days in SBF. Carbonated HAP is the phase that most closely resembles that found in biological systems. Both the LbL surfaces and the block copolymer-attached aminated slides showed only patchy mineralisation even after 14 days in SBF. This indicates that ionic interactions of the negatively charged phosphates or carboxylates and protonated amines prevented chelation of calcium ions, which is believed to be the first step in mineralisation. The P(FS-b-AA) adsorbed PTFE film also showed only small amounts of mineral formation after 14 days in SBF. These results highlight the many features controlling the mineralisation outcomes.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">mineralisation</field><field name="subject">polymers</field><field name="subject">polymeric biomaterials</field><field name="identifier">http://eprints.qut.edu.au/16593/</field><field name="validLink">True</field></doc><doc><field name="title">Hydrogeochemistry and hydrology of a basalt aquifer system, the Atherton Tablelands, North Queensland</field><field name="creator">Locsey, Katrina L.</field><field name="description">The Atherton Tablelands basalt aquifer is a major source of groundwater supply for irrigation and other agricultural use. The Tertiary to Quaternary age basaltic aquifer can be regarded as a generally unconfined, layered system, comprising numerous basalt flows separated by palaeo-weathering surfaces and minor alluvial gravels of palaeo-drainage channels. Layers of massive basalt and clay-rich weathered zones act as local aquitards, with some local perched aquifers also present. The aquifer is regarded as a system in which several factors interact to produce the overall characteristics of the hydrogeochemistry of the groundwaters. They include the mineralogical composition of both the basalt aquifer and the thick overlying weathered zone, the porosity and permeability of the basalt aquifer, its thickness, bedrock composition, and climate and topography. The hydrogeochemical processes operating in this aquifer system have been investigated though the analysis of 90 groundwater samples collected from October 1998 to October 1999, groundwater chemistry data provided by the Queensland Department of Natural Resources &amp; Mines for more than 800 groundwater samples, rain water samples collected during 1999 by CSIRO, stream chemistry data provided by CSIRO and James Cook University, and mineralogical and whole rock geochemistry data of drill chip samples. The methods used in this research study include the assessment of groundwater major ion chemistry data and field physico-chemical parameters using hydrochemical facies and statistical approaches, investigation of the mineralogical composition of the aquifer, assessment of concentrations and activities of the ions in solution, the degree of saturation with respect to both primary and secondary minerals, and hydrogeochemical modelling to determine the likely controls on the chemical evolution of these groundwaters. The basaltic groundwaters are mostly Mg-Ca-Na, HCO3 type waters, with electrical conductivities generally less than 250 &#956;S/cm and pH values from 6.5 to 8.5. Dissolved silica (H4SiO4) comprises a large proportion of the total dissolved load, with average concentrations of around 140 mg/L. Concentrations of potassium, chloride and sulphate are low, that is, generally less than 3 mg/L, 15 mg/L and 10 mg/L, respectively. Despite the very low salinity of the Atherton Tablelands basalt groundwaters, the relative concentrations of the major ions are comparable to groundwaters from other basaltic regions, and are consistent with expected waterrock interactions. A variety of multivariate statistical techniques may be used to aid in the analysis of hydrochemical data, including for example, principal component analysis, factor analysis and cluster analysis. Principal component factor analyses undertaken using the hydrochemical data for the Atherton groundwaters has enabled the differentiation of groundwaters from various lithological formations, the underlying geochemical processes controlling groundwater composition in the basalt aquifer to be inferred, relative groundwater residence and flow directions to be inferred and mapping of the estimated thickness of the basalt aquifer. The limitations of multivariate statistical methods have been examined, with emphasis on the issues pertinent to hydrochemical data, that is, data that are compositional and typically, non-normally distributed. The need to validate, normalize and standardize hydrochemical data prior to the application of multivariate statistical methods is demonstrated. Assessment of the saturation states of the Atherton basalt groundwaters with respect to some of the primary minerals present indicate that the groundwaters are mostly at equilibrium or saturated with respect to K-feldspar, and approach equilibrium with respect to the plagioclase feldspars (albite and anorthite) with increasing pH. These groundwaters are at equilibrium or saturated with respect to the major secondary minerals, kaolinite, smectite (Ca-montmorillonite) and gibbsite. They also tend to be saturated with respect to the oxidation products, goethite and hematite, common accessory minerals in the Atherton Tablelands basalt sequence. Silicate mineral weathering processes are the predominant influence on the composition of these basalt groundwaters. These weathering processes include the weathering of pyroxenes, feldspars and other primary minerals to clays, aluminium and iron oxides, amorphous or crystalline silica, carbonates and zeolites, releasing ions to solution. The contribution of substantial organic carbon dioxide to the groundwater is an important factor in the extent to which silicate mineral weathering occurs in this aquifer system. Evaporative enrichment of recharging waters, oxidation and ion-exchange reactions and the uptake of ions from, and decomposition of, organic matter, are processes that have a minor influence on the composition of the basalt groundwaters. The relationships observed between mineralogical compositions, basalt character and groundwater occurrence in the Atherton Tablelands region improved the understanding how groundwater is stored and transmitted in this basalt aquifer system. Groundwater is mostly stored in vesicular basalt that may be fresh to highly weathered, and movement of this water is facilitated by pathways through both vesicular and fractured basalt. Related work undertaken as part of this research project showed that the groundwater flow patterns defined by the hydrogeochemical interpretations correspond well with the spatial trends in water level fluctuations, and response to recharge events in particular. Groundwater baseflow to streams and discharge to topographic lows in the Atherton Tablelands region is indicated by the relationships between the major cations and anions in the stream waters. Fracture zones are likely to be preferred pathways of groundwater movement. Recharge estimates, based on a chloride mass balance, range from 310 mm/yr in the north-western part of the study area (north of Atherton) to 600 mm/yr in the wetter southern and eastern parts of the study area. These recharge estimates should be treated with caution however, due to the low groundwater chloride concentrations and the high variability in rainfall chloride concentrations. The findings of this research project have improved the understanding of the hydrogeochemical processes controlling the composition of the low salinity basalt groundwaters in the Atherton Tablelands region, and are applicable to other basalt groundwater systems, particularly those in high rainfall environments.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">hydrogeochemistry</field><field name="subject">basalt aquifer</field><field name="subject">mineralogy</field><field name="subject">multivariate statistical analysis</field><field name="identifier">http://eprints.qut.edu.au/16594/</field><field name="validLink">True</field></doc><doc><field name="title">Nutritional management in pre-dialysis chronic kidney disease : an investigation of methods for nutritional assessment and intervention in pre-dialysis chronic kidney disease</field><field name="creator">Campbell, Katrina Louise</field><field name="description">Malnutrition is present in up to 48% of chronic kidney disease patients on the initiation of renal replacement therapy (dialysis)1. At this time, malnutrition is an independent and significant predictor of morbidity and mortality2. As a consequence of progressive deterioration in kidney function, symptoms of decreased appetite and reduced intake are common factors leading to the decline in nutritional status3. However, at present there is little evidence to inform nutrition assessment and intervention for pre-dialysis chronic kidney disease (CKD). The purpose of this study was to provide evidence for the nutritional management of CKD patients prior to dialysis with an aim to optimise nutritional status. To address this, an investigation comprising of two phases examining nutrition assessment and intervention in a sample of pre-dialysis Stage IV and V CKD patients was undertaken. Both phases of the study were conducted through Royal Brisbane and Women&#8217;s Hospital (RBWH) Department of Renal Medicine pre-dialysis clinic. Participants met the following criteria: adult (&amp;gt18 years) Glomerular Filtration Rate (GFR) &amp;lt30ml/min CKD, not previously seen by a dietitian for Stage IV CKD, absence of communication or intellectual impairment inhibiting their ability to undertake the intervention and an absence of malnutrition from a cause other than CKD. Phase I was a cross-sectional investigation into the performance of a range of tools assessing nutrition status, conducted at baseline of Phase II. Phase II was a randomisedcontrolled trial designed to determine if providing individual nutrition counselling with regular telephone follow-up resulted in improved body composition, nutritional status, dietary intake and quality of life, compared with standard care. A range of intermediate, clinical and patient-centred outcome measures were collected at baseline and twelve weeks. Body composition was measured by total body potassium counting (TBK), considered a gold-standard measure of body cell mass (BCM, the body&#8217;s functional metabolising tissue). Nutritional status was measured using Subjective Global Assessment (SGA) and a number of modified versions of SGA, 7-point SGA, Malnutrition Inflammation Score (MIS) and the scored Patient-Generated Subjective Global Assessment (PG-SGA). Dietary intake was measured using 3-day food records. Quality of life was measured by Kidney Disease Quality of Life Short Form version 1.3 (KDQOL-SFTM v1.3 &#169; RAND University), combining the Short Form-36 (SF-36), with a kidney disease-specific module4. Statistical analysis was carried out using SPSS Version 13 (SPSS Inc, Chicago, IL, USA). Phase I analysis was based on descriptive and bi-variate statistics, including chi-square, t-test and ANOVA. For phase II, change variables (Week 12 &#8211; Week 0) were created for the outcome measures (BCM, SGA tools, dietary intake (energy and protein) and the 18 KDQOL-SFTM subscales). The assessment of change in outcome measures by treatment group was undertaken by ANCOVA, adjusting for baseline values. Further multivariate analysis (ANCOVA and MANCOVA models) were created for outcome variables when confounding variables were identified and adjusted for. In Phase I, 56 patients (Male n=34; age mean (&#177;SD) 70.7 (&#177;14.0); GFRMDRD 22.4 (&#177;6.5) mL/min) underwent baseline assessment. In this population the prevalence of malnutrition was 19.6% (n=11, SGA B; no C ratings). Malnutrition was associated with lower body cell mass (mean BCM, 26.3 vs. 33.4 kg p=0.007), body weight (64.8 vs. 76.1 kg p=0.042), BMI (23.7 vs. 27.6 kg/m2 p=0.015) and greater weight loss over previous 6 months (-6.2 vs. -0.1 kg p=0.004). Body cell mass indexed for height (BCM-I kg/m3.5) had a relationship with MIS (r=-0.27 p=0.063) and scored PG-SGA (r=-0.27 p=0.060), but not with 7-point SGA (F(4) 2.24 p=0.080). PG-SGA best discriminated malnutrition based on a BCM-I cut-off of &amp;lt5.25kg/ m3.5 of all the modified SGA tools. The scored PG-SGA including the global SGA rating is recommended for use in pre-dialysis CKD. In Phase II, 50 patients, (Male n=31 (62.0%); age 69.7 (&#177;12.0) years; GFRMDRD 22.1 (&#177;6.9) ml/min) completed the 12 week study period (intervention n=24; standard care n=26). At 12 weeks, there was a clinically significant improvement in all outcome measures in the intervention group. There was a 3.9% (95% CI, -1.0 to 8.7%) mean difference in change for Body Cell Mass between the treatment groups, represented by a significant decrease in the standard care group and maintenance in the intervention group. Nutritional status measured by SGA improved or was maintained (24/24) in the intervention group, however, decreased in 14% (4/26) of the standard care group. Energy intake significantly improved in the intervention group resulting in a mean difference in change of 17.7kJ/kg (8.2 to 27.2 kJ/kg). Quality of life improved significantly in 10 of the 18 sub-scales in the intervention group. Significant effect modification for gender was apparent for many of the outcome variables, with females responding most significantly to the intervention treatment. This study concluded that, overall, structured nutrition intervention limits the deterioration in nutritional status, improves dietary intake and quality of life in patients with CKD prior to the onset of renal replacement therapy. This thesis makes a significant contribution to the evidence base for nutritional management of pre-dialysis Stage IV CKD. The use of SGA for nutrition assessment and including PG-SGA to measure change is recommended for routine nutrition assessment of pre-dialysis CKD. The provision of individual nutrition counselling with regular follow-up, with a focus on promoting intake provides beneficial patient outcomes supporting optimal nutritional status in pre-dialysis CKD patients.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">chronic kidney disease</field><field name="subject">dialysis</field><field name="subject">nutritional assessment</field><field name="identifier">http://eprints.qut.edu.au/16595/</field><field name="validLink">True</field></doc><doc><field name="title">IT enhanced communication protocols for building project management by small and medium enterprises in the Indian construction industry</field><field name="creator">Ahuja, Vanita</field><field name="description">The Research has developed protocols for effective adoption of Information Communication Technologies (ICT) for Building Project Management by Small and Medium Enterprises (SMEs) in the Indian construction industry. Project Managers are required to facilitate the integration of work of all the agencies and project team organizations are geographically separated beyond national boundaries or in context of large countries like India, within the national boundaries. In doing so, there is a need to make better use of information and knowledge generated in all stages of development. The key to project information management is the information flow associated with inter-organizational communication and the effectiveness of the project manager to communicate with and feedback to the rest of the project team throughout the project life cycle. Better communication can be achieved by using computer tools for effective data processing and information management, through Information Communication Technologies (ICT). As the majority of the construction organizations are Small and Medium Enterprises (SMEs), the communication management research is required to address management and communication processes adopted by SMEs. These issues can be addressed by global research, but also require clear understanding of the management and communication processes followed by SMEs of each distinct regional area or country. The research was conducted through a sequential mixed methods approach focusing on collecting and analyzing both quantitative and qualitative data in the study in a sequential manner. To develop a balance check mechanism, the research was divided into four phases: Interpretive analysis of perceived benefits of use of ICT for building project management, conducted by Interpretive Structural Modeling analysis; Questionnaire survey data collection and empirical analysis of data including Structural Equation Modeling analysis (quantitative method); Semi-structured interview survey data collection and analysis including Data Envelopment Analysis (quantitative and qualitative method) and case studies analysis conducted by SAP-LAP analysis (qualitative method) leading to synthesis of the results of the four phases. The purpose of this four-phase, sequential mixed methods study was to start with the pragmatic assumptions; obtain statistical, quantitative results from a broad sample of organizations to analyze or study research variables at industry and organization levels and then follow up with a few organizations and projects to study the research variables at the level of the organization and people. Synthesis of the knowledge enhancement from the literature survey, data analysis results and their interpretation led to the proposed 'IT Enhanced Communication Protocols for Building Project Management'. The protocols are proposed as a 'Strategic Model for Enhancing ICT Diffusion in Building Projects'. The model is based on Everett Rogers's 'Diffusions of innovations theory' and is formulated at three levels of study i.e industry, organization and people. It is discussed as a generic framework of five stages of Roger's 'Diffusions of innovations theory' i.e Knowledge, Persuasion, Decision, Implementation and Confirmation.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">building project management</field><field name="subject">ICT</field><field name="subject">Indian construction industry</field><field name="subject">SMEs</field><field name="identifier">http://eprints.qut.edu.au/16596/</field><field name="validLink">True</field></doc><doc><field name="title">Process and outcome of narrative therapy for major depressive disorder in adults : narrative reflexivity, working alliance and improved symptom and inter-personal outcomes</field><field name="creator">Vromans, Lynette Patricia</field><field name="description">The inter-subjective and dialogical nature of narrative therapy, as commonly practiced, remains unarticulated. Further, there currently exists no rigorous empirical research investigating the process or outcome of narrative therapy.  
 
 The research aim, to investigate the process and outcome of narrative therapy, comprised theoretical and empirical objectives. The first objective was to articulate a theoretical synthesis of narrative theory, research and practice. The process of narrative reflexivity was identified as a theoretical construct linking narrative theory with narrative research and practice. The second objective was to substantiate this synthesis empirically by examining narrative therapy processes, specifically narrative reflexivity and the therapeutic alliance, and their relation to therapy outcomes. The third objective was to support the proposed synthesis of theory, research and practice and provide quantitative evidence for the utility of narrative therapy, by evaluating depressive symptom and inter-personal relatedness outcomes through analyses of statistical significance, clinical significance and benchmarking. 
 
 Founded in theories of self, language and narrative (James, 1890; Bruner, 1986; Gergen, 1991; Hollway, 2006; Vygotsky, 1934/ 1987), narrative therapy was conceptualized as involving dialogical and intra-personal processes. Narrative therapists generally apply a story metaphor and commonly focus on the inter-personal field (White, 2007). This thesis recognised the storied and inter-personal nature of narrative therapy, but proposed this does not represent narrative therapy in its entirety. The notion of story connotes monological processes, inconsistent with the conversations of narrative practice, and neglect of intra-personal dimensions is inconsistent with narrative notions of inter-subjectivity.     
 
 This thesis proposed an integration of dialogical narrative theory (Cooper, 2003; Hermans &amp; Kempen, 1993; Lysaker &amp; Lysaker, 2006) and narrative research (Angus, Levitt, &amp; Hardtke, 1999) provides a model for understanding narrative therapy (White, 2007) as involving the inter-subjective and dialogical process of narrative reflexivity. During the process of narrative reflexivity, a person engages in dialogue with his or her own self and others as extensions of self, interpreting experience from diverse perspectives in the context of personal aspects, such as beliefs, values and intentions that give meaning to experience, to achieve a rich narrative and a sense of well-being.
 
 To support this theoretical synthesis, a process-outcome trial evaluated eight-sessions of narrative therapy for 47 adults with major depressive disorder. Dependent process variables were narrative reflexivity (assessed at Sessions 1 and 8) and therapeutic alliance (assessed at Sessions 1, 3 and 8). Primary dependent outcome variables were depressive symptoms and inter-personal relatedness. Primary analyses assessed therapy outcome at pre-therapy, post-therapy and three-month follow-up and utilized a benchmarking strategy to the evaluate pre-therapy to post-therapy and post-therapy to follow-up gains, effect size and pre-therapy to post-therapy clinical significance. 
 
 Results indicated that when a sub-sample of clients were categorised into five least-improved and five most-improved groups (according to depressive symptom change), there was a differential change in the percentage of reflexive sequences in the discourse of clients at the end of therapy depending on outcome. Improvement in the quality of the working alliance was associated with improvements in depressive symptoms and inter-personal relatedness, with working alliance improvement from Session 1 to 8 sharing 19% of the variance in depressive symptom improvement and 17% of the variance in inter-personal relatedness improvement from pre-therapy to post-therapy. 
 
 The clinical trial provided empirical support for the utility of narrative therapy in improving depressive symptoms and inter-personal relatedness from pre-therapy to post-therapy: the magnitude of change indicating large effect sizes (d = 1.10 to 1.36) for depressive symptoms and medium effect sizes (d = .52 to .62) for inter-personal relatedness. Therapy was effective in reducing depressive symptoms in clients with moderate and severe pre-therapy depressive symptom severity. Improvements in depressive symptoms, but not inter-personal relatedness, were maintained three-months following therapy. The reduction in depressive symptoms and the proportion of clients who achieved clinically significant improvement (53%) in depressive symptoms at post-therapy were comparable to improvements from standard psychotherapies, reported in benchmark research. 
 
 This research has implications for assisting our understanding of narrative approaches, refining strategies that will facilitate recovery from psychological disorder and providing clinicians with a broader evidence base for narrative practice. Despite limitations of a repeated-measures research design, use of a standardised intervention protocol, coupled with outcome evaluation of clinical significance enhanced internal validity. Future research could examine narrative therapy in a larger sample, with different disorders, and with an alternative therapy or control group. Coding a greater number of therapy transcripts for evaluating associations of narrative reflexivity with working alliance and outcomes could enhance understanding of narrative reflexivity. Thesis strengths included a strong theoretical foundation underpinning the research design and arguments, examination of therapy process in the context of outcome, and a parsimonious evaluation of narrative therapy outcomes.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">benchmarking</field><field name="subject">clinical significance</field><field name="subject">depressive symptoms</field><field name="subject">dialogical theory</field><field name="subject">inter-personal relatedness</field><field name="subject">inter-subjectivity</field><field name="subject">narrative processes coding system</field><field name="subject">narrative reflexivity</field><field name="subject">narrative therapy</field><field name="subject">outcome</field><field name="subject">process</field><field name="subject">self</field><field name="subject">working alliance</field><field name="identifier">http://eprints.qut.edu.au/16597/</field><field name="validLink">True</field></doc><doc><field name="title">Towards feeder-free and serum-free growth of cells</field><field name="creator">Richards, Sean Dennis</field><field name="description">The in-vitro culture of human embryonic stem and keratinocyte cells has great potential to revolutionise the therapeutics industry. Indeed it is hoped that these cells will provide a superior alternative to current tissue and organ transplantation. However, both of these cell types require animal and/or donor products for their successful maintenance in-vitro. This requirement results in a significant risk of cross contamination from the animal or donor products to either the primary keratinocyte or hES cells. These potentially transplantable cells therefore need to be cultured in an environment free from animal or donor products to remove the risk of contamination to the patient. The ideal growth conditions must comprise of two attributes; firstly they must be free from animal or donor products, and secondly the culture system must be fully defined. Recently, it was discovered that an extra-cellular matrix protein, vitronectin, could be used in conjunction with growth factors and growth factor-binding proteins (VN:GF combination), to promote enhanced cell migration and growth through the co-activation of integrin and growth factor receptors.  Given that growth factors and serum are clearly important in supporting the in-vitro cultivation of mammalian cells, and that vitronectin is an abundant protein in serum, I hypothesised that these VN:GF combinations could be translated into a serum-free medium that would support the serial propagation and self renewal of primary keratinocytes and hES cells. As reported in this thesis I have developed a defined, serum-free media for the culture of these cells that incorporates the VN:GF combinations. While the two media differ slightly in their compositions, both support the serial, undifferentiated expansion of their respective cells types. Together, this represents a significant advance that will ultimately facilitate the therapeutic use of these cells. However, the in-vitro expansion of these cells in these new media still required the presence of a feeder cell layer. In view of this I aimed to explore the in-vitro micro-environment of primary keratinocytes using a novel proteomic approach in an attempt to find candidate factors that could be used in conjunction with the VN:GF media to replace both serum and the feeder cells.  The proteomic approach adopted examined the secretion of proteins into the defined, minimal protein content VN:GF media when the feeder cells were cultured alone, as well as in co-culture with primary keratinocytes. This strategy allowed assessment of proteins/factors that are secreted in response to both autocrine and paracrine cellular interactions and revealed a number of candidate factors that warrant further investigation. Ultimately this proteomic information and the associated new insights into the keratinocyte in-vitro culture microenvironment may lead to the development of a culture system for these cells that is not reliant on either a feeder cell layer or serum for their successful propagation. Moreover, it is likely that this will also be relevant to the feeder cell-free propagation of hES cells. This has obvious advantages for the culture of primary keratinocytes and hES cells in that it will allow a safe defined culture system for the undifferentiated propagation of these cells. This will facilitate the generation of cells and tissues free from xenogeneic and allogeneic contaminants, thus ensuring any therapeutics developed from these cell types are approved for therapeutic applications and importantly, will minimise risks to patients.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">embryonic stem cells</field><field name="subject">keratinocyte cells</field><field name="subject">hES cells</field><field name="subject">extra-cellular matrix</field><field name="identifier">http://eprints.qut.edu.au/16598/</field><field name="validLink">True</field></doc><doc><field name="title">Sexual and reproductive health problems among Aboriginal and Torres Strait Islander males</field><field name="creator">Adams, Michael John</field><field name="description">Compared to males in almost any social group in all affluent nations, Australia's Aboriginal and Torres Strait Islander men suffer from substantially more serious illnesses and early death. To date, research done by or in collaboration with Indigenous communities has revealed the extent of the problems that arise from diabetes, heart disease, hypertension, cancers, respiratory diseases, psychological disorders, accidental injuries, violence and other causes. Reproductive health, however, rarely has been studied among Indigenous men. To date, research in this field has been limited mainly to studies of sexually transmitted infections. No data has been published on Aboriginal men's symptoms of prostate disease or erectile dysfunction, nor has the clinical screening and treatment of these disorders among these men been assessed. In-depth search of the worldwide web demonstrated that little information on these issues was available from other Indigenous populations. It does appear that Indigenous men in Australia, New Zealand and North America are less likely than European-ancestry men to die from prostate cancer, or for living cases to be recorded on cancer registries. This may arise because Indigenous men genuinely have a lower risk, or because they are not captured by official statistics, or because they do not live long enough to develop severe prostate disease. We also know very little about other reproductive health problems such as sexual dysfunction and specifically erectile difficulties. One reason for our scant knowledge is that research mainly relies on self-report of sensitive information. The aim of the research study was to improve the understanding of sexual and reproductive health problems experienced by Indigenous men. This is best gathered by Aboriginal males who are inside the culture of middleaged and older Indigenous men, but until now this has not been attempted. In this study we adopted the World Health Organization (WHO) definitions for Reproductive and Sexual Health (WHO, 2001). Thus, we consider reproductive system disorders (prostate disease, erectile dysfunction) and related health care-seeking, and also men's perceptions about a "satisfying and safe sexual life". The methodology was framed within an Aboriginal and Torres Strait Islander research protocol that advocates respect for cultural, social and community customs. A mixed method design combined qualitative inquiry (4 focus groups and 18 in-depth interviews) and quantitative survey (n=301) involving men living in remote, rural and urban communities (Tiwi Islands, Darwin and north and south-east Queensland). Survey data were compared to recently published self-reports from 5990 randomly selected men aged over 40 years in Australia (Holden et al., 2005, The Lancet, 366, 218-224. The qualitative interviews revealed that most men were silent about reproductive health. They were unwilling to reveal their inner feelings to wives or partners, and they were unwilling to discuss such issues with doctors and other health care workers. Men's reaction to sexual difficulties included shame, denial, substance abuse and occasionally violence. On a positive note many men said they want to learn about it, so they understand how to cope with such problems. The Indigenous men reported symptoms of erectile dysfunction at least as much as non-Indigenous men in other Australian studies. Bivariate analysis showed that erectile dysfunction was correlated with many health and lifestyle variable. However multivariate analysis revealed that only three factors significantly predicted ED: presence of chronic disease, presence of pain when working, and living in a remote geographic location The quantitative survey data indicate that Indigenous men have more symptoms of prostate disease than non-Indigenous men. The syndrome appears to be poorly managed in clinical practice (e.g. rates of PSA testing and digital-rectal examination are only one-third the rate reported by non-Aboriginal men, despite equivalent likelihood of GP visits). The research study adds to the literature by providing better insight and depth into the issues impacting on Aboriginal and Torres Strait Islander males experiencing reproductive and sexual health difficulties. It also provides a platform to undertake comprehensive research with Aboriginal and Torres Strait Islander men to explore a wider spectrum of questions in this important but neglected area. Implications for education of primary healthcare workers and community-based awareness campaigns for Indigenous males are discussed. Most of all, this study revealed "layers" of silence around sexual and reproductive health of Indigenous men. This includes silence in the scientific establishments in health services, and in the community. It is hoped that this study puts the voices of the men forward to help to break down this silence.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Aboriginal</field><field name="subject">Torres Strait Islander</field><field name="subject">sexual dysfunction</field><field name="subject">erectile dysfunction</field><field name="subject">cardiovascular diseases</field><field name="subject">prostate</field><field name="subject">ejaculation</field><field name="subject">sexual activity</field><field name="subject">urination disorders</field><field name="subject">prostatic hyperplasia</field><field name="subject">urinary tract</field><field name="subject">health status indicators</field><field name="subject">remote Aboriginal community</field><field name="subject">HIV/AIDS</field><field name="subject">pathophysiologic</field><field name="subject">reproductive health</field><field name="subject">STD</field><field name="subject">Sildenafil</field><field name="subject">socioeconomic factors</field><field name="subject">risk factors</field><field name="subject">primary health care</field><field name="subject">substance misuse</field><field name="subject">chronic disease</field><field name="subject">urinary incontinence</field><field name="subject">hypertension</field><field name="subject">smoking</field><field name="subject">alcohol consumption</field><field name="subject">prevalence</field><field name="subject">correlates</field><field name="identifier">http://eprints.qut.edu.au/16599/</field><field name="validLink">True</field></doc><doc><field name="title">Facilitating dynamic flexibility and exception handling for workflows</field><field name="creator">Adams, Michael James</field><field name="description">Workflow Management Systems (WfMSs) are used to support the modelling, analysis, and enactment of business processes. The key benefits WfMSs seek to bring to an organisation include improved efficiency, better process control and improved customer service, which are realised by modelling rigidly structured business processes that in turn derive well-defined workflow process instances. However, the proprietary process definition frameworks imposed by WfMSs make it difficult to support (i) dynamic evolution and adaptation (i.e. modifying process definitions during execution) following unexpected or developmental change in the business processes being modelled; and (ii) exceptions, or deviations from the prescribed process model at runtime, even though it has been shown that such deviations are a common occurrence for almost all processes. These limitations imply that a large subset of business processes do not easily translate to the 'system-centric' modelling frameworks imposed. This research re-examines the fundamental theoretical principles that underpin workflow technologies to derive an approach that moves forward from the productionline paradigm and thereby offers workflow management support for a wider range of work environments. It develops a sound theoretical foundation based on Activity Theory to deliver an implementation of an approach for dynamic and extensible flexibility, evolution and exception handling in workflows, based not on proprietary frameworks, but on accepted ideas of how people actually perform their work activities. The approach produces a framework called worklets to provide an extensible repertoire of self-contained selection and exception-handling processes, coupled with an extensible ripple-down rule set. Using a Service-Oriented Architecture (SOA), a selection service provides workflow flexibility and adaptation by allowing the substitution of a task at runtime with a sub-process, dynamically selected from its repertoire depending on the context of the particular work instance. Additionally, an exceptionhandling service uses the same repertoire and rule set framework to provide targeted and multi-functional exception-handling processes, which may be dynamically invoked at the task, case or specification level, depending on the context of the work instance and the type of exception that has occurred. Seven different types of exception can be handled by the service. Both expected and unexpected exceptions are catered for in real time. The work is formalised through a series of Coloured Petri Nets and validated using two exemplary studies: one involving a structured business environment and the other a more creative setting. It has been deployed as a discrete service for the well-known, open-source workflow environment YAWL, and, having a service orientation, its applicability is in no way limited to that environment, but may be regarded as a case study in service-oriented computing whereby dynamic flexibility and exception handling for workflows, orthogonal to the underlying workflow language, is provided. Also, being open-source, it is freely available for use and extension.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">workflow exception handling</field><field name="subject">workflow flexibility</field><field name="subject">adaptive workflow</field><field name="subject">service oriented architecture</field><field name="subject">activity theory</field><field name="subject">ripple-down rules</field><field name="subject">worklet</field><field name="subject">exlet</field><field name="subject">YAWL</field><field name="identifier">http://eprints.qut.edu.au/16600/</field><field name="validLink">True</field></doc><doc><field name="title">Development of novel combinatorial methods for genotyping the common foodborne pathogen Campylobacter jejuni</field><field name="creator">Price, Erin Peta</field><field name="description">Campylobacter jejuni is the commonest cause of bacterial foodborne gastroenteritis in industrialised countries. Despite its significance, it remains unclear how C. jejuni is disseminated in the environment, whether particular strains are more pathogenic than others, and by what routes this bacterium is transmitted to humans. One major factor hampering this knowledge is the lack of a standardised method for fingerprinting C. jejuni. Therefore, the overall aim of this project was to develop systematic and novel genotyping methods for C. jejuni.    Chapter Three describes the use of single nucleotide polymorphisms (SNPs) derived from the multilocus sequence typing (MLST) database of C. jejuni and the closely related Campylobacter coli for genotyping these pathogens. The MLST database contains DNA sequence data for over 4000 strains, making it the largest comparative database available for these organisms. Using the in-house software package "Minimum SNPs", seven SNPs were identified from the C. jejuni/C. coli MLST database that gave a Simpson's Index of Diversity (D), or resolving power, of 0.98. An allele-specific real-time PCR method was developed and tested on 154 Australian C. jejuni and C. coli isolates. The major advantage of the seven SNPs over MLST is that they are cheaper, faster and simpler to interrogate than the sequence-based MLST method. When the SNP profiles were combined with sequencing of the rapidly evolving flaA short variable region (flaA SVR) locus, the genotype distributions were comparable to those obtained by MLST-flaA SVR. Recent technological advances have facilitated the characterisation of entire bacterial genomes using comparative genome hybridisation (CGH) microarrays. Chapter Four of this thesis explores the large volume of CGH data generated for C. jejuni and eight binary genes (genes present in some strains but absent in others) were identified that provided complete discrimination of 20 epidemiologically unrelated strains of C. jejuni. Real-time PCR assays were developed for the eight binary genes and tested on the Australian isolates. The results from this study showed that the SNP-binary assay provided a sufficient replacement for the more laborious MLST-flaA SVR sequencing method. The clustered regularly interspaced short palindromic repeat (CRISPR) region is comprised of tandem repeats, with one half of the repeat region highly conserved and the other half highly diverse in sequence. Recent advances in real-time PCR enabled the interrogation of these repeat regions in C. jejuni using high-resolution melt differentiation of PCR products. It was found that the CRISPR loci discriminated epidemiologically distinct isolates that were indistinguishable by the other typing methods (Chapter Five). Importantly, the combinatorial SNP-binary-CRISPR assay provided resolution comparable to the current 'gold standard' genotyping methodology, pulsed-field gel electrophoresis.    Chapter Six describes a novel third module of "Minimum SNPs", 'Not-N', to identify genetic targets diagnostic for strain populations of interest from the remaining population. The applicability of Not-N was tested using bacterial and viral sequence databases. Due to the weakly clonal population structure of C. jejuni and C. coli, Not-N was inefficient at identifying small numbers of SNPs for the major MLST clonal complexes. In contrast, Not-N completely discriminated the 13 major subtypes of hepatitis C virus using 15 SNPs, and identified binary gene targets superior to those previously found for phylogenetic clades of C. jejuni, Yersinia enterocolitica and Clostridium difficile, demonstrating the utility of this additional module of "Minimum SNPs".  Taken together, the presented work demonstrates the potentially far-reaching applications of novel and systematic genotyping assays to characterise bacterial pathogens with high accuracy and discriminatory power. This project has exploited known genetic diversity of C. jejuni to develop highly targeted assays that are akin to the resolution of the current 'gold standard' typing methods. By targeting differentially evolving genetic markers, an epidemiologically relevant, high-resolution fingerprint of the isolate in question can be determined at a fraction of the time, effort and cost of current genotyping procedures. The outcomes from this study will pave the way for improved diagnostics for many clinically significant pathogens as the concept of hierarchal combinatorial genotyping gains momentum amongst infectious disease specialists and public health-related agencies.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Campylobacter jejuni</field><field name="subject">Campylobacter coli</field><field name="subject">genotyping</field><field name="subject">single-nucleotide polymorphism</field><field name="subject">SNP</field><field name="subject">binary gene</field><field name="subject">CRISPR</field><field name="subject">HRM</field><field name="subject">high-resolution melt</field><field name="subject">Minimum SNPs</field><field name="subject">Not-N</field><field name="subject">bacteria</field><field name="subject">real-time PCR</field><field name="subject">comparative genome hybridisation</field><field name="subject">CGH</field><field name="subject">microarray</field><field name="subject">software</field><field name="subject">hepatitis C virus</field><field name="subject">HCV</field><field name="identifier">http://eprints.qut.edu.au/16601/</field><field name="validLink">True</field></doc><doc><field name="title">User empowerment : an enabler of enterprise systems success</field><field name="creator">Sehgal, Rashi</field><field name="description">This research project has established a new measurement model for User Empowerment as an enabler to Enterprise Systems 1 success. This study was inspired by the reported relationship between Empowerment and improved work outcomes. From this, it was hypothesised that empowering the users of Enterprise Systems during the implementation process would improve the reports of post implementation system success. A new related concept of system oriented User Empowerment was conceived. The outcomes of empowering users (increased worker effectiveness; (increased work satisfaction) conceptually resonates very closely to the outcomes of individual performance, quality of system outputs, goodness of system functionality and, on a broader level, effective use of the system to yield successful business outcomes. These latter outcomes represent the measures of Enterprise Systems success. Thus Empowerment as an independent variable, and Enterprise Systems success as a dependent variable, provided a launching platform for the study. The research model was built upon the existing research into Empowerment as articulated by Spreitzer (Spreitzer, 1996) and Thomas and Velthouse (Thomas &amp; Velthouse, 1990) and its derived systems related construct of User Empowerment, first explored by Doll, Deng and Metts (Doll, Deng, &amp; Metts, 2003). It used a current and validated measure of Enterprise Systems Success as developed by Gable, Sedera and Chan (Gable, Sedera, &amp; Chan, 2003); this measure is a refinement of the Information Systems Success Model of DeLone and McLean (DeLone &amp; McLean, 2002). 2 In order to test the relationships of Empowerment to (Enterprise) System success, the following research sub-problems were explored:    *	What types of Empowerment are relevant in the Enterprise System context?  *	Is User Empowerment different from Psychological Empowerment and if so, how?  *	What is the relationship between Psychological Empowerment and User Empowerment?  *	How can User Empowerment be measured?  *	What is the effect of Psychological Empowerment on Enterprise Systems success?  *	What is the effect of User Empowerment on Enterprise Systems success?    This research project was a PhD study funded by the Australian Research Council through an industry linkage program. The industry partner in this project was SAP - the most successful vendor of Enterprise Systems. Although limited in analysis the study spanned across two industry sectors, with two Enterprise Systems (Oracle and SAP). This research was a multimethod study and involved both qualitative and quantitative phases. The multimethod included content analysis, survey, and case study. This research was led by an explorative research strategy and paid considerable attention to analysing each research method in relation to other research methods, and also in relation to the demands of the research problem. A comprehensive literature review established extant definitions and constructs for Psychological Empowerment, User Empowerment and, Enterprise Systems success. The literature review employed a formal qualitative research method, using open coding supported through the use of Nvivo, a Qualitative software package, in order to identify and derive key themes in the referent disciplines. The responses from the email survey of Information Systems researchers, and Enterprise Systems consultants were triangulated with the findings from the categorised literature review on Empowerment. This sub-study utilised WordStat software and the findings were presented at the QualIT conference (Sehgal &amp; Stewart, 2006). Drawing from the existing perspectives on Empowerment a contextbased perspective on Empowerment was proposed by the researcher. From this work, a new working definition of (User) Empowerment was derived. This construct proposed that User Empowerment involved Computer Self-efficacy, Perceived Usefulness, Intrinsic Motivation, User Autonomy, and Problem-solving and Decision support. Psychological Empowerment involves Meaning, Self-determination, Competence, and Impact. The research project then empirically tested the relationship of both Psychological Empowerment and User Empowerment to Enterprise Systems success using a quantitative enquiry. The new User Empowerment construct was statistically tested for validity and reliability. This quantitative study found no statistical evidence for a relationship between Psychological Empowerment and Enterprise Systems success. The study findings suggest significant statistical evidence for a relationship between User Empowerment and Enterprise Systems success. Statistical analysis showed that the construct for User Empowerment was different from the construct of Enterprise Systems success. These relationships held regardless of the level of the user: senior management, operational, end users or technical. This phase of the study was presented at the Americas Conference of Information Systems (Sehgal &amp; Stewart, 2004). This exploratory survey was followed by another industry based case study, which confirmed the results for a different industry sector and different Enterprise System. This latter study was used in an independent confirmatory factor analysis of the Enterprise Systems success measurement which was presented at the Americas Conference on Information Systems (Sehgal &amp; Stewart, 2004) and International Conference on Information Systems (Sedera, Gable, &amp; Chan, 2004) by fellow researchers. This research has demonstrated that User Empowerment, rather than Psychological Empowerment was significantly related to Enterprise Systems Success. The study findings identified potentially significant benefits to the Enterprise System implementing organisations as well as the Enterprise System vendor from empowering Enterprise System users. Of the reported benefits one of the relevant one was improved and positive reports about the implemented Enterprise System. Further, the study highlights the importance of context when measuring a construct such as Empowerment. There are clear practical implications for the research outcomes. These include a recommendation that training programs should ensure that users have a high degree of computer self-efficacy when using the enterprise system. The validated User Empowerment instrument will be utilised as a diagnostic tool for organisational readiness prior to an ES implementation. This would assist in benchmarking the level of empowerment and predicted Enterprise Systems success. Future research will explore the effects of an Enterprise System on the components of User Empowerment as it is conjectured that there is a reciprocal relationship between the system and user attributes of Computer Self-efficacy, Problem-solving Decision Support, and understanding of business logic.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">user empowerment</field><field name="subject">enterprise systems success</field><field name="subject">enterprise systems</field><field name="subject">empowerment</field><field name="subject">user autonomy</field><field name="subject">system-oriented user empowerment</field><field name="subject">enabler of enterprise systems success</field><field name="identifier">http://eprints.qut.edu.au/16602/</field><field name="validLink">True</field></doc><doc><field name="title">'Playing football fiction' : leveraging the strengths of autodiegesis in a football narrative</field><field name="creator">McGowan, Lee Hugh</field><field name="description">This thesis consists of a novel, Some Tartan Hyde, and an exegesis, Playing Football Fiction: Leveraging the strengths of autodiegesis in a football narrative and will address my research question; How do I leverage the strengths of an autodiegetic narrator to represent 'playing football fiction' in an engaging way? Some Tartan Hyde is the story of immigrant Mish Gordon, an amateur footballer, who joins a local team to help him become more comfortable in his new surroundings. He is having trouble settling into life in a new country and getting his head around cultural barriers. The protagonist's dealings with these issues and his character development are symbolised and paralleled in the football games that periodically take place within the narrative. Some Tartan Hyde is written in a present tense autodiegetic perspective. Approximately 25% of the page space is given over to 'playing football fiction'. The exegesis explores the portrayal of the football game events from a player's realtime on the pitch perspective. It examines the use of present tense autodiegesis within the broader football fiction genre, and the strengths and weaknesses associated with using the perspective as a means of narration. It will then examine Some Tartan Hyde and consider the level of success and previously unrealised benefits achieved in using this perspective in a football fiction narrative. Together, the elements of this practice-led research will present an overview of the historical and contemporary developments and understanding of the autodiegetic perspective, address the dominant perspectives within the genre, offer an interpretation of the conventions as they have been presented in football fiction, and examine the context of a new approach in a novel-length work of creative writing research.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">autodiegesis</field><field name="subject">football narrative</field><field name="identifier">http://eprints.qut.edu.au/16603/</field><field name="validLink">True</field></doc><doc><field name="title">Joanna Murray-Smith and Daniel Keene : class oppositions</field><field name="creator">Carroll, Kieran</field><field name="description">Joanna Murray-Smith and Daniel Keene are both successful mid-career Melbourne playwrights. Taking them as a starting point and re-tracing an Australian theatrical lineage, this project explores new Melbourne narratives in which two branches of the Australian theatrical idiom converge in a single creative work, my play Friday Night, In Town. An analysis of the writing of Friday Night, In Town, authored by myself and presented for examination herein, demonstrates its narratives are structured with deliberate reference to Murray-Smith and Keene revealing a new form of contemporary urban playwriting. The play's originality, it will be shown, and its contribution to new knowledge, lie in its engagement with these playwrights and their Australian predecessors. These elements combine with a redeployment of the medieval pageant-play, which is thus reinvigorated as a mode of contemporary playwriting practice. The play text presented herein (Friday Night, In Town) represents 75 per cent of the weighting for this M.A. (by Research) with the exegetical component weighted at 25 per cent.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Australian theatre</field><field name="subject">urban plays</field><field name="subject">urban drama</field><field name="subject">Melbourne playwrights</field><field name="subject">pageant-play</field><field name="subject">Daniel Keene</field><field name="subject">Joanna Murray-Smith</field><field name="identifier">http://eprints.qut.edu.au/16604/</field><field name="validLink">True</field></doc><doc><field name="title">Writing Wales : Welsh historians and the search for Welsh identity, 1970-1997</field><field name="creator">Henderson, Lindsay Jane</field><field name="description">This thesis is a study of the way in which Wales and Welshness have been depicted in Welsh general histories published in the period between 1970 and 1997.  National identity has been and remains a topical and controversial issue in Wales, due to the complex and multiple nature of the identities that could be classified as 'national' identities.  Correspondingly, the issue of identity, particularly national and regional identities, has been the subject of considerable study within Wales.  These studies have provided considerable insight into the nature of Welsh identity but there remain significant gaps in the overall research picture.  This study focuses on one: the way in which Welsh historiography has portrayed Wales and Welshness. 	The very nature of Welsh history means that such a study must also involve consideration of the impact of England and the relationship between Wales and England on the historiographical depictions of Wales and Welshness.  England, as the dominant country in Britain and Wales' neighbour, has played a major role in shaping both the Welsh historical experience and Welsh identity, facts to which Welsh historians must respond, particularly when writing general histories of their country.  This thesis, then, also examines the depiction of the Welsh-English relationship within Welsh national historiography and the way this, in turn, impacted on the way in which the historians portrayed Wales and Welshness. 	These concepts are very significant for both Welsh historiography and the wider study of Welsh identity.  Historical studies, in providing the information for the construction of historically based national identities, are heavily involved in the larger issue of Welsh identity.  This study aims to contribute to the research on Welsh identity through the analysis of this specific area of Welsh historiography.  In doing so, this thesis offers a new way of approaching the complicated and very real issues of understanding Wales, Welshness and the relationship between Wales and England.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Wales</field><field name="subject">identity</field><field name="subject">Britain</field><field name="subject">Welsh-English relationship</field><field name="subject">historiography</field><field name="identifier">http://eprints.qut.edu.au/16605/</field><field name="validLink">True</field></doc><doc><field name="title">Secure electronic tendering</field><field name="creator">Du, Rong</field><field name="description">Tendering is a method for entering into a sales contract. Numerous electronic  tendering systems have been established with the intent of improving the efficiency  of the tendering process. Although providing adequate security services  is a desired feature in an e-tendering system, current e-tendering systems are  usually designed with little consideration of security and legal compliance.  This research focuses on designing secure protocols for e-tendering systems.  It involves developing methodologies for establishing security requirements, constructing  security protocols and using formal methods in protocol security verification.  The implication is that it may prove suitable for developing secure  protocols in other electronic business domains.  In depth investigations are conducted into a range of issues in relation to establishing  generic security requirements for e-tendering systems. The outcomes are  presented in a form of basic and advanced security requirements for e-tendering  process. This analysis shows that advanced security services are required to secure  e-tender negotiation integrity and the submission process.  Two generic issues discovered in the course of this research, functional difference  and functional limitations, are fundamental in constructing secure protocols  for tender negotiation and submission processes. Functional difference identification  derives advanced security requirements. Functional limitation assessment  defines how the logic of generic security mechanisms should be constructed. These  principles form a proactive analysis applied prior to the construction of security  protocols.  Security protocols have been successfully constructed using generic cryptographic  security mechanisms. These protocols are secure e-tender negotiation  integrity protocol suite, and secure e-tender submission protocols. Their security  has been verified progressively during the design. Verification results show that  protocols are secure against common threat scenarios. The primary contribution of this stage are the procedures developed for the complex e-business protocol  analysis using formal methods. The research shows that proactive analysis has  made this formal security verification possible and practical for complex protocols.  These primary outcomes have raised awareness of security issues in e-tendering.  The security solutions proposed in the protocol format are the first in e-tendering  with verifiable security against common threat scenarios, and which are also practical  for implementation. The procedures developed for securing the e-tendering  process are generic and can be applied to other business domains. The study  has made improvements in: establishing adequate security for a business process;  applying proactive analysis prior to secure protocol construction; and verifying  security of complex e-business protocols using tool aided formal methods.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">e-tendering</field><field name="subject">e-procurement</field><field name="subject">e-auction</field><field name="subject">e-commerce</field><field name="subject">e-business</field><field name="subject">business process</field><field name="subject">e-tender negotiation</field><field name="subject">e-tender submission</field><field name="subject">security</field><field name="subject">security requirements</field><field name="subject">secure protocol</field><field name="subject">security functions</field><field name="subject">integrity</field><field name="subject">confidentiality</field><field name="subject">threat</field><field name="subject">threat scenario</field><field name="subject">cryptology</field><field name="subject">cryptography</field><field name="subject">generic securitymechanism</field><field name="subject">cryptographic hash function</field><field name="subject">digital signature</field><field name="subject">commitment scheme</field><field name="subject">identity based encryption</field><field name="subject">formal method</field><field name="subject">shvt</field><field name="subject">model checking</field><field name="subject">threat modeling</field><field name="subject">verification elements</field><field name="subject">verification process</field><field name="identifier">http://eprints.qut.edu.au/16606/</field><field name="validLink">True</field></doc><doc><field name="title">Cipher cities : creating tools to support and sustain community co-production in the area of mobile game design</field><field name="creator">Huang, Duzhi Sherwin</field><field name="description">My foray into location based gaming started because as a web designer, I felt that I wanted to expand my practice from one that consisted of straightforward interface design, to one that encompassed a wider variety of skills by improving on my knowledge and expertise in the burgeoning field of interaction design. This allowed me at the same time, to incorporate other aspects of design that include the usercentred design of tools for collaboration, content creation and community creation. I take a particular interest in the opportunities afforded by the convergence of web and game based technologies, especially when mobile interaction is afforded by such convergences. This exegesis describes the theoretical underpinnings that have informed the creation of a series of graphical interfaces that serve to bridge the gap between system capabilities as envisaged by the developers and a user's experience facilitated by an interface. The actual research into creation of the interface was preceded by an exploration of the field of location based gaming from which the initial area of interest was derived. Due to the fact that location based gaming is still an emerging field, it required the creation of a custom taxonomy for the works to be systematically separated into their various elements for analysis. The taxonomy to be created involved the combination of three smaller individual taxonomies in a way that has not been attempted previously and in a way that would give a balanced account of what makes up a location based game. The area of interested identified was how location based games might be made more readily available for a wider audience. Cipher Cities, which was a system in development at the time, was one that was already designed for such an application, but now required an interface that would appropriately represent what it aimed to achieve. I joined the team as their interface designer and it became clear that due to the location centric nature of the game, the only feasible way to go about democratising the participation in such games was to make it easy for people to build their own. The issue that arose was how an interface could encourage the creation of as well as participation in location based games. This required reference from current Web 2.0 applications that use members as creators of content as well as research into the theories behind community building, content creation and distribution in support of such an interface.  These theories were put into practice and implemented before being evaluated and verified through a series of user testing sessions that served to refine the system in terms of user interface design and system functions. The result of the research is the first interface ever created that works to support a system for the creation of location based games by the public. More importantly, it is a robust, interface that is attractive as well as usable.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">web-based interface</field><field name="subject">mobile phone</field><field name="subject">location-based game</field><field name="subject">online community</field><field name="subject">mobile game design</field><field name="identifier">http://eprints.qut.edu.au/16607/</field><field name="validLink">True</field></doc><doc><field name="title">Identifying sources of stress and level of job satisfaction amongst registered nurses within the first three years of work as a registered nurse in Brunei Darussalam</field><field name="creator">Damit, Abd Rahim</field><field name="description">Method This study used a descriptive correlational study design to examine new nurses within the first three years of work as a registered nurses' perception of stress and level of job satisfaction in today's complex clinical nursing working environment. Data was collected through distribution of self administered questionnaires, which comprised 59 items of Expanded Nursing Stress Scale (French, Lenton, Walters and Eyles, 1995) and the two part measurement tool of Index of Work Satisfaction Survey (Stamps, 2001). This questionnaire was distributed to 120 new registered nurses working in Raja Isteri Pengiran Anak Saleha Hospital (R.I.P.A.S.), the main referral hospital in Brunei Darussalam. The sample consisted of both male and female registered nurses (RN) who had less than three years working experience in nursing.      Results  Responses to the Expanded Nursing Stress Scale (ENSS) identified that the new registered nurses rated their Uncertainty Concerning Treatment as highly stressful events that frequently occurred in the workplace. The study findings also revealed that the level of stress and the common stressors in new registered nurses within the first three years of work as a registered nurses were similar irrespective of whether they were working in the speciality units or in general wards. Results for Index Work Satisfaction Survey (IWSS) Part A and B also suggested that there was no significant difference on the levels of job satisfaction in both groups of new registered nurses, with the majority of nurse choosing Professional Status as the most important component.  Conclusion  Results of this study are likely to have important implications for nursing education, administration, management, organisation, practice, knowledge, and research. The study findings have the potential to make a significant contribution to determining coping strategies that might help in reducing the amount of stress experienced by the new registered nurses in day to day challenging and demanding nursing roles. The study also has the potential to have wider benefits to nursing practice not just at Brunei Darussalam.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">stress</field><field name="subject">job satisfaction</field><field name="subject">nursing</field><field name="subject">Brunei Darussalam</field><field name="identifier">http://eprints.qut.edu.au/16608/</field><field name="validLink">True</field></doc><doc><field name="title">Real time financial information analysis</field><field name="creator">Robertson, Calum Stewart</field><field name="description">The efficient market hypothesis states that an efficient market incorporates all available information to provide an accurate valuation of an asset. Presently investors and researchers attempt to forecast future returns (profit/loss if the asset is held for a certain period) and volatility (variance of the returns) of the asset based on past trading behaviour, and commonly ignore non-numerical information. It is almost impossible to forecast future returns for frequently traded assets such as stocks, bonds, and currencies, so many institutional investors prefer to forecast future volatility. Volatility is frequently used by traders and fund managers to measure the risk of continuing to own the asset. Most volatility forecasting models completely disregard the arrival of news and therefore theoretically violate the efficient market hypothesis. The aim of this research is to investigate how the inclusion of details of the arrival of asset specific news (news which is relevant to the asset) can improve the volatility forecasts of a model. The problem is that the efficient market hypothesis indicates that only new information will cause the market to react, and therefore it is necessary to determine whether the news contains any new information. Most news does not include any new information and therefore assuming all news will trigger abnormal market behaviour is unlikely to improve the performance of a model. Furthermore news which causes a shock, i.e., news which contains highly unexpected new information, will cause a greater change in volatility than news which contains expected information. Therefore to produce a model that factors in the arrival of news into volatility forecasts, it is beneficial to examine the content to predict the reaction to the news. This research combines the field of econometrics with machine learning and intelligent data analysis. All hypotheses tested within this thesis are tested on a large collection of stocks traded in the US, UK and Australia. To my knowledge, this is the largest dataset used for the types of experiments conducted in this thesis. In this thesis evidence is provided to suggest that asset specific news is correlated with abnormal returns, volatility, and volatility forecast errors. There is also evidence to suggest that abnormal volumes and trading activity correlate to asset specific news. This confirms the findings of previous studies though in most cases only a small dataset was used and often only one or two time series (i.e., return, volatility, volume etc.) were used. Furthermore many studies did not investigate the intraday effect of news (i.e., the reaction on the day the news was released). The studies which investigated the intraday effect tended to focus on macroeconomic news, which is scheduled and eagerly anticipated by investors. Therefore the behaviour is easier to detect that for asset specific news. It is demonstrated that the content of news can be used to forecast abnormal returns and forecast periods when the given volatility forecasting model exhibits abnormally large errors (the difference between the realised volatility and the volatility which the given model forecast) with a high degree of accuracy. This was achieved by analysing the content of past news which correlated with abnormal market behaviour. For this research a new method for ranking terms is introduced and demonstrated to be very effective. Previous studies have revealed that the content of news can be used to forecast abnormal returns but, to my knowledge, no study has investigated the volatility forecast error. Furthermore, most previous studies have used a small dataset, and to forecast at relatively low frequencies (most are daily, though one is hourly). To the best of my knowledge no previous study has use such a large dataset to predict the high frequency (as little as 5 minutes) market reaction to news. Nor has any previous study achieved classification accuracies as high as those achieved in this thesis.  Finally, a news aware volatility forecasting model is produced and the evidence demonstrates that the performance is better than an alternative model which does not account for news under certain circumstances. Furthermore it is demonstrated that using the content of news to choose documents which are more likely to cause the market to react yields better forecasts. Very few researchers have included the arrival of news in a volatility forecasting model, and all of these have used small datasets. Furthermore, to my knowledge, none of these researchers have used the content of the news to choose news which is more likely to cause the market to react.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">financial information</field><field name="subject">analysis</field><field name="identifier">http://eprints.qut.edu.au/16609/</field><field name="validLink">True</field></doc><doc><field name="title">Terrestrial habitat requirements of a suite of anuran species inhabiting a semi-arid region of South East Queensland</field><field name="creator">Chambers, Joanne</field><field name="description">Hypothesised causes of the observed world-wide decline of amphibian populations are varied and in some cases contentious. Insufficient information relating to the autecology of many amphibian species can cause erroneous speculations regarding critical habitat requirements and hence management programs designed to enhance population viability are often unsuccessful. Most amphibians display a bi-phasic life history that involves occupation of an aquatic breeding habitat and terrestrial habitats that are used for foraging, and shelter from predation and environmental stress. However, the focus of most amphibian research is centred on the breeding habitat, with limited research being conducted into the terrestrial habitat requirements of most amphibian species. Barakula State Forest is a large continuous area of open woodland situated in the semi-arid region of Queensland. The forest supports 21 species of endemic anurans, many of which use ephemeral waterbodies for breeding. This area is, therefore, an ideal location to test the relative importance of terrestrial habitat on the distribution of a suite of frogs that display different morphological and physiological characteristics. On the landscape scale, the attributes of the terrestrial environment at three survey areas within Barakula were similar. However, at the patch scale, ground truthing showed there were considerable variations in vegetation and ground cover attributes within and between each survey site. Measured properties of the soil also tended to vary within and between sites. Soil texture ranged from sandy to heavy clay, soil pH ranged from 3.9 to 6.4 and soil moisture varied considerably. Agar models, used for testing evaporative moisture loss at different microhabitats, retained significantly higher levels of moisture when positioned in the buried microhabitat during summer, but in winter, models that were placed under leaf litter retained higher levels of moisture. Variations in levels of moisture loss at the five different microhabitats were evident within and between the survey sites. Despite a prolonged drought, 1844 native frogs representing 17 species were pitfall trapped. Members from the family Myobatrachidae comprised 94% of these captures, and burrowing species accounted for 75% of total captures. Species were not randomly distributed within or between the survey sites. Vegetation attributes and soil properties played a significant role in influencing the catch rates and traplines that supported similar vegetation and soil attributes also tended to catch similar species. Capture rates of six of the seven burrowing species were significantly influenced by soil properties. When given a choice of four different microhabitats created in enclosures, individuals from five species showed varying responses to habitat choice during night time activity. During daylight all species tended to avoid bare areas and burrowing species tended to burrow under some form of cover. Pseudophryne bibronii metamorphs showed a significant avoidance to soils with high pH. The number of Limnodynastes ornatus metamorphs was significantly and positively correlated with moisture levels surrounding a breeding area. Limnodynastes ornatus metamorphs tended to avoid areas that did not support some form of cover. Embryos from the terrestrial egg laying P. bibronii translocated to sites with varying levels of soil pH, suffered increased mortality where the soil pH was &amp;gt4.8. In the laboratory, embryonic survival was not significantly different between the four pH treatments. There was a significant influence of fungal infection on survival rates and ranked fungal infection was significantly different between the four pH treatments.  The terrestrial environment at the three survey sites has provided sufficient protection from environmental elements to allow a large diversity of anurans to persist for long periods without access to permanent water. Management must consider the importance of the non-breeding habitat when defining buffer zones, restoration programs and conservation strategies to ensure that the complete set of ecological requirements for frog species are provided.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">amphibian</field><field name="subject">anuran</field><field name="subject">terrestrial habitat</field><field name="subject">habitat choice</field><field name="subject">burrowing frog</field><field name="subject">evaporative water loss</field><field name="subject">ground cover</field><field name="subject">soil pH</field><field name="subject">Barakula State Forest</field><field name="subject">frog conservation</field><field name="identifier">http://eprints.qut.edu.au/16610/</field><field name="validLink">True</field></doc><doc><field name="title">Op writing : text ornamenting vision</field><field name="creator">Speight, Amanda Gaye</field><field name="description">The decorative and the textual have a complex and uneasy entanglement within the history and practice of modernist art.  Sometimes celebrated as critical modernist strategies, sometimes denigrated or repressed as the opposite of Art, the decorative and the textual were understood as "foreign" forms that variously endangered, or, in turn, invigorated the power of art. My creative practice, which includes installation, painting, photography, text and an exhibition catalogue, exploits and explores this decorative and textual instability within modernist art practice.  In my work, (visual) codes conventionally associated with the fields of writing and pattern, are re-examined and problematised by placing them within the context of visual art.   When writing and pattern become the subject of painting there is an intriguing oscillation, complication and dialogue between the spaces and codes of reading and seeing, writing and pattern, the decorative and the abstract.    The thesis also explores the decorative and textual instability within modernism by analysing some key contradictory moments in aesthetic thought and arts practice.  In the writings of Clement Greenberg, a "decorative" painting is deemed the highest achievement of modernist abstract painting but to arrive at this goal, the decorative must be used against itself.  In Frank Stella's early abstract paintings, decorative patterns structure the work, and yet the artist and his commentators only see the work as a kind of pure, abstract painting.  In Lawrence Weiner's statement-sculptures, the terse, laconic text, that nominates materials and processes, is thought to be a "direct" form of art information that would remain unchanged even in reproduction.  But as Weiner's work is reproduced in journals and magazines, this "direct" form of art is complicated through a variety of reproductive forms - documentary photographs, transcription errors and differences in the visual format and typography of the text.     In these key moments of contradiction, concepts such as the decorative and the textual, that have often been regarded as peripheral to visual art, will be shown to have central significance in analysing its specific qualities.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">arts practice</field><field name="subject">art history-theory</field><field name="subject">contemporary visual arts</field><field name="subject">Clement Greenberg</field><field name="subject">ornament and modern art</field><field name="subject">Frank Stella</field><field name="subject">text and modern art</field><field name="subject">Lawrence Weiner</field><field name="identifier">http://eprints.qut.edu.au/16611/</field><field name="validLink">True</field></doc><doc><field name="title">Open access to next generation broadband</field><field name="creator">Kelso, Douglas Ross</field><field name="description">Wireline telecommunications infrastructure in the customer access network or CAN is undergoing a veritable technological and commercial revolution.  The paired-copper CAN is being modernised with optical fibre deployed ever closer to customers, culminating soon with fibre-to-the-home networks or some variant thereof.  Although bandwidth ceases to be a scarce commodity, the underlying natural monopoly will most likely be strengthened.    National competition policy desires open access to multiple service providers yet commercial pressure calls for closure.  This has been the recent experience with the hybrid fibre coaxial networks delivering pay television and Internet access.    This research asks the question: What are the factors that prevent open access to the broadband services of next generation wireline infrastructure?  How can these obstacles be overcome?  A particular focus is given to non-price considerations which come to the fore due to the unique strategic and technological characteristics of optical fibre in the access network.    The methodological approach involves data gathering via three case studies - that of the Telstra/Foxtel pay television network, the TransACT broadband network and fibre-to-the-home networks in general.  Although the ultimate focus is on the research question above, these cases are discussed in a holistic way with consideration of a number of contextual factors.  The research also examines the relationship between the concepts of 'open access' and 'network neutrality', visiting the concept of 'common carriage' in doing so.    Several findings are reached that illuminate the field of telecommunications access regulation as applied to infrastructure capable of delivering truly next generation broadband services.  Since 1993, our politicians have only paid lip service to the importance of competition and have deferred to the demands of the dominant builder of telecommunications infrastructure.  From the viewpoints of end-users and access seekers, the access regime is found to be incapable of dealing with the technical and commercial bottlenecks arising from optical fibre in the CAN.    It is concluded that communication between users should be recognised as the prime purpose of telecommunications and that the regulatory regime should not reward discriminatory practices detracting from the development of a networked information economy.  It is also concluded that dominant players should never be rewarded with access holidays which could otherwise entrench market dominance through the creation of new bottlenecks.  Access regulation is ill-equipped to cope with optical fibre in the CAN until it also recognizes the strategic potential of such infrastructure.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">ACCC</field><field name="subject">access</field><field name="subject">broadband</field><field name="subject">communications policy</field><field name="subject">fibre to the home</field><field name="subject">fibre to the node</field><field name="subject">Foxtel</field><field name="subject">next generation broadband</field><field name="subject">next generation networks</field><field name="subject">network neutrality</field><field name="subject">open access</field><field name="subject">optical fibre</field><field name="subject">telecommunications</field><field name="subject">telecommunications policy</field><field name="subject">Telstra</field><field name="subject">TransACT</field><field name="identifier">http://eprints.qut.edu.au/16612/</field><field name="validLink">True</field></doc><doc><field name="title">Model driven coordination framework for concurrency programming</field><field name="creator">Zimmerman, John Dean</field><field name="description">Ensembles of distributed, autonomous and heterogenous entities that are situated in an environment, interacting over both space and time, and striving to uphold some global system coherence, mission, and goal characterize a new class of systems coined Open Computational Systems (OCS). OCS are materializing as a result of various enabling Internet technologies and examples include: ubiquitous computing, proactive computing, autonomic computing, network-centric computing, and network-centric warfare.    OCS require a fundamental shift in the way we think about software development. In order to address these issues we advocate a holistic approach where models and tools come together to provide a platform for the building, understanding and monitoring of software based on the notion of these type of systems.    In this research project, this was investigated by adopting the generative communication paradigm, a framework for entity communication and collaboration that will allow us to construct systems with characteristics of an OCS. Model-Driven Engineering (MDE) technologies (Domain Specific Modelling Languages and Transformation Engines) were used to provision a modelling environment for the construction, visualization and transformation of systems based on the notion of OCS. An initial mechanism was then established, and a prototype built for system understanding, verification and validation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">concurrency programming</field><field name="subject">model driven coordination framework</field><field name="identifier">http://eprints.qut.edu.au/16613/</field><field name="validLink">True</field></doc><doc><field name="title">The plasma adenosine triphosphate response to dynamic handgrip exercise</field><field name="creator">Wood, Rachel Elise</field><field name="description">Despite over a century of inquiry, the mechanisms that achieve the close matching of oxygen supply to demand during exercise remain elusive. It has been proposed that in addition to its role as the primary oxygen carrier, the red blood cell (RBC) functions as a roving oxygen sensor, linking the oxygen demand at the muscle with oxygen delivery via the circulation (Ellsworth et al. 1995). It is hypothesised that the RBC would release adenosine triphosphate (ATP) in proportion to the number of unoccupied binding sites on the haemoglobin molecule as it traverses regions of high oxygen demand such as the microcirculation of active skeletal muscle. ATP would then stimulate the release of vasodilatory substances from the endothelium which would diffuse to neighbouring vascular smooth muscle resulting in vasodilation and an increase in blood flow in accordance with the oxygen demand set by the muscle. The first step in establishing a role for this mechanism during exercise in humans is to determine whether ATP increases in the venous blood draining an active muscle bed. Based on the handful of published studies, there is an increase in ATP concentration in the femoral vein during knee extensor exercise. However the response has not been studied in other vascular beds in humans. As such, the main aim of this thesis was to measure the ATP response to dynamic handgrip exercise. Secondary aims were to determine whether the response was modified by hypoxia, and to provide information about the timing of the changes in ATP concentration during a bout of handgrip exercise. These questions were addressed in Studies 3 and 4. Because blood flow is central to this hypothesis, a substantial portion of this thesis was also associated with the measurement of forearm blood flow (FBF) using venous occlusion strain gauge plethysmography (VOSGP), and this was conducted in Studies 1 and 2. VOSGP is based on the assumption that with venous outflow prevented, any increase in limb volume is proportional to the rate of arterial inflow. The rate of arterial inflow is determined as the slope of the change in limb volume over time. The slope must be calculated over the initial linear portion of this relationship, when arterial inflow is unaffected by the inevitable rise in venous pressure associated with venous occlusion. VOSGP was initially used to measure blood flow at rest and in response to pharmacological interventions which produced only modest increases in arterial inflow (Joyner et al. 2001). However, measurement of the high rates of arterial inflow that occur with exercise may challenge the limits of this technique. Tschakovsky et al. (1995) reported a marked reduction in arterial inflow over the first four cardiac cycles during venous occlusion following static handgrip exercise that elevated blood flow to 22-24 mL/min/100mL. Only during the first cardiac cycle was arterial inflow unaffected by cuff inflation. As such, the window for measuring high rates of arterial inflow may be very brief. Therefore Study 1 aimed to determine whether blood flow could be measured using VOSGP across the range of arterial inflows that occur with dynamic handgrip exercise. Participants (n = 7) completed four, five-minute bouts of dynamic handgrip exercise at 15, 30, 45, and 60% of maximum voluntary contraction (MVC). FBF was measured using VOSGP at rest, and following five minutes of dynamic handgrip exercise. The slope of the change in limb volume was measured over the first one, two, three, and four consecutive cardiac cycles following the onset of occlusion. FBF was 2.5 &#177; 0.5 at rest, and 16.5 &#177; 4.9, 24.9 &#177; 9.4, 44.1 &#177; 22.0, and 57.8 &#177; 14.9 mL/min/100mL following five minutes of exercise at 15, 30, 45, and 60% MVC, respectively. At rest, arterial inflow decreased across the four cardiac cycles (P = 0.017 for the main effect), however post-hoc pairwise comparisons revealed no significant differences between any of the cardiac cycles. In contrast, the inclusion of two, three, or four cardiac cycles at 30 and 60% MVC, and three or four cardiac cycles at 15 and 45% MVC resulted in reductions in calculated arterial inflow compared with using the first cardiac cycle alone (P &gt; 0.05). The inclusion of just two cardiac cycles resulted in a 9-26% reduction in calculated arterial inflow depending on the workload. This reduction was even more pronounced when three (19-40%) or four (26-50%) cardiac cycles were included. In conclusion, resting FBF can be calculated over at least four cardiac cycles during venous occlusion at rest. However, exercising FBF should be calculated from the first cardiac cycle only following dynamic handgrip exercise across the range of intensities used in this study. This extends the findings of Tschakovsky et al. (1995) who demonstrated this effect following handgrip exercise at a single intensity. Study 2 was designed to establish the FBF response to dynamic handgrip exercise, whether the workloads produced different blood flow responses, and to establish the within- and between-day reproducibility of FBF measured using VOSGP. In Part A (within-day reproducibility), participants (n = 7) completed three trials of dynamic handgrip exercise at four intensities (15, 30, 45, and 60% MVC), with each exercise trial separated by 10 minutes of rest. In Part B (between-day reproducibility) participants (n = 7) completed three trials of dynamic handgrip exercise at 15, 30, and 45% MVC on three separate days within a two week period. FBF was measured at rest, and each minute of exercise during brief (5-7 second) pauses in contractions. FBF response. FBF increased from rest at all workloads (P &gt; 0.05), and then plateaued between Minutes 1 to 5 at the 15 and 30% MVC workloads and between Minutes 2 and 5 at the 45% workload (P &gt; 0.05 for each minute compared to Minute 5). Too few participants completed the 60% workload to permit any statistical analysis. FBF reached values of 13.0 &#177; 2.0, 26.8 &#177; 8.4, 44.8 &#177; 14.9, and 52.9 &#177; 5.1 mL/min/100mL in the final minute of exercise at the 15, 30, 45, and 60% MVC workloads. FBF was different between the 15, 30, and 45% workloads by Minute 3 (P &gt; 0.05). Reproducibility. The within-day test-retest reliability of exercising FBF was poor to moderate (ICC = 0.375-0.624) with individual coefficients of variation (CVs) ranging from 6-25%, 9-23%, and 9-31% for the 15, 30, and 45% MVC workloads, respectively. The between-day test-retest reliability for resting FBF was moderate (ICC = 0.644, P &gt; 0.05; individual CVs between 1 and 31%). Between-day test-retest reliability for exercising FBF was poor to moderate (ICC = 0.381-0.614), with individual CVs ranging from 14-24%, 8-23%, and 6-18% for the 15, 30, and 45% workloads, respectively. It was concluded from this study that VOSGP provides adequately reproducible measurements to detect changes in FBF of the magnitude seen between workloads in this study. However, the variability in the measurement precludes its use when smaller differences are of interest. Based on the previous findings reporting an increase in ATP concentration during dynamic knee extensor exercise in the leg (Gonzalez-Alonso et al. 2002; Yegutkin et al. 2007), Study 3 was designed to determine whether ATP concentration increased in the venous effluent during dynamic handgrip exercise in the forearm. Since the deoxygenation of haemoglobin is a primary stimulus for ATP release from red blood cells, a further aim was to determine whether this response was augmented by systemic hypoxia. Participants (n = 6) completed four, five-minute bouts of dynamic handgrip exercise at 30, 45, 65, and 85% MVC under normoxia (inspired oxygen fraction = 0.21) and hypoxia (inspired oxygen fraction = 0.12). Blood samples for the determination of ATP concentration were drawn at rest and 180 seconds after the onset of exercise at each workload from a catheter inserted into a forearm vein. Venous plasma ATP concentration at rest was 0.28 &#177; 0.11 &#956;M/L and remained unchanged during exercise at workloads up to 85% MVC (P &gt; 0.05). Systemic hypoxia, sufficient to reduce arterial oxygen saturation to 83 &#177; 2%, also failed to alter the plasma ATP concentration (P = 0.148). The lack of a change in ATP concentration was unexpected but there are several possible explanations. It is possible, although unlikely, that ATP was not released in the forearm microcirculation. The previous demonstration that ATP increased in response to static handgrip exercise (Forrester and Lind 1969) would suggest that this was probably not the case. When considered in the context of the findings from Study 4, the most plausible explanation is that a less than optimal blood sampling site may have hindered the measurement of a change in ATP. The blood flow response at the onset of dynamic exercise in the forearm is at least biphasic; Phase 1 describes the immediate, large increase in blood flow within 2 seconds of the onset of exercise and is believed to be governed by mechanical factors whereas Phase 2 has a latency of ~20 seconds and describes a further, slower increase until blood flow reaches steady state (Saunders et al. 2005b). The temporal characteristics of Phase 2, along with the fact that blood flow during this phase is closely related to the metabolic rate of the muscle, suggest regulation by metabolic factors. Currently there is scant evidence detailing the time course of vasodilator release, although it is important to demonstrate that the release of a vasodilatory substance precedes the blood flow response it is proposed to influence (Delp 1999). ATP is released from red blood cells in proportion to the offloading of oxygen and a reduction in the oxygen content of venous blood draining a muscle bed occurs within 10 seconds of the onset of exercise. Thus the release of ATP should follow soon thereafter. As such, Study 4 was designed to determine whether ATP increased in the venous effluent of the forearm following 30 and 180 seconds of dynamic handgrip exercise at 45% MVC; and whether this increase corresponded with a decrease in venous oxygen content. Participants (n = 10) completed two bouts of dynamic handgrip exercise at 45% MVC; the first was one minute in duration, and the second was four minutes in duration. Venous blood samples for the determination of ATP and venous oxygen content were drawn at rest and during exercise from a catheter inserted in a retrograde manner into the median cubital vein. Arterialised samples for the estimation of arterial blood gases and ATP concentration were obtained from the non-exercising hand. ATP concentration in arterialised blood from the non-exercising arm was 0.79 &#177; 0.30 &#956;M/L at rest and remained unchanged at both time points during exercise (P &gt; 0.05). ATP concentration in the venous blood of the exercising arm increased from 0.60 &#177; 0.17 &#956;M/L at rest to 1.04 &#177; 0.33 &#956;M/L 30 seconds after the onset of exercise (P &gt; 0.05), and remained at this higher level after 180 seconds (0.92 &#177; 0.26 &#956;M/L, P &gt; 0.05 versus rest). This corresponded with a decrease in venous oxygen content from 103 &#177; 23 mL/L at rest to 68 &#177; 16 mL/L 30 seconds after the onset of exercise (P &gt; 0.05) and 76 &#177; 15 mL/L (P &gt; 0.05 versus rest) 180 seconds into exercise. Furthermore, at 180 seconds of exercise, ATP concentration was moderately and inversely related to venous oxygen content (r = -0.651, p &gt; 0.05). In conclusion, this study provides the first evidence that ATP concentration is increased in the blood draining the exercising forearm muscles in response to dynamic handgrip exercise. The finding that ATP concentration was increased just 30 seconds after the onset of exercise is also novel, and particularly interesting in the context of the recently reported dynamic response characteristics of the forearm blood flow response. In conclusion, the work contained within this thesis provides several important findings. The first study has provided evidence that measuring high rates of arterial inflow using VOSGP is possible, but that the window for making these measurements is small, probably as brief as a single cardiac cycle. The second study demonstrated that while the reproducibility of forearm blood flow measurements using VOSGP is poor, it is adequate to detect the large changes that occurred between workloads. However, VOSGP cannot be used to detect more modest differences. Common to both Study 3 and 4 was the measurement of ATP at rest, and 180 seconds after the onset of dynamic handgrip exercise at 45% MVC. The primary difference was the position of the catheter which was inserted in an antegrade manner in Study 3, and in a retrograde manner in Study 4. Since ATP was unchanged in Study 3 but increased under similar conditions in Study 4, it is likely that ATP was also released during exercise in Study 3, but that a less than optimal blood sampling site precluded its measurement. This illustrates the necessity to sample blood from as close as possible to the probable site of ATP release, the muscle microcirculation. The most important and novel findings from this body of work come from Study 4. This is the first study to demonstrate an increase in ATP concentration in the forearm in response to dynamic handgrip exercise. However, the most novel finding was that ATP concentration was elevated just 30 seconds after the onset of exercise. Such an early increase has not previously been reported during dynamic exercise in any vascular bed. This is an important finding since establishing the time course for the release of vasodilatory substances is critical to our understanding of the mechanisms that regulate blood flow during exercise.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">forearm blood flow</field><field name="subject">dynamic handgrip exercise</field><field name="subject">adenosine triphosphate</field><field name="subject">venous oxygen content</field><field name="subject">venous occlusion strain gauge plethysmography</field><field name="identifier">http://eprints.qut.edu.au/16614/</field><field name="validLink">True</field></doc><doc><field name="title">Evaluation of the nutritional requirements of redclaw crayfish, Cherax quadricarinatus</field><field name="creator">Pavasovic, Ana</field><field name="description">Aquaculture represents a sustainable alternative to natural fisheries for provision of high quality, animal protein. Crustaceans make a significant contribution to global aquaculture production, of which decapods are the most economically important group. Among freshwater crayfish, the genus Cherax includes several species that have emerged as important culture species. A suite of favourable biological attributes, including fast growth and an omnivorous feeding habit, have contributed to establishment of successful culture of Cherax quadricarinatus (redclaw) in many countries. Aspects of redclaw production, however, remain relatively undeveloped, in particular feed formulation. To better understand the digestive processes and nutritional requirements of redclaw, this study examined the relationship between diet composition and digestive enzyme activity, growth performance and diet digestibility coefficients. The extent to which redclaw can efficiently utilise complex polysaccharides, such as cellulose, has been speculated on by authors who reported endogenous cellulase activity in this species. I evaluated the use of insoluble &#945;-cellulose by redclaw, demonstrated that high dietary levels (30%) can significantly reduce the specific activity of selected digestive enzymes (amylase and cellulase), while also lowering apparent digestibility coefficients. Inclusion of &#945;-cellulose above 12% also significantly reduced survival rate, specific growth rate and feeding efficiency in this organism which corresponds with low tolerance for insoluble fibre by other decapods. Even though redclaw possess endogenous cellulases, they appear to have only a limited capacity to utilise insoluble fibre in their diets.  Further, I assessed the impact of different nutrient profiles on digestive enzyme activity, growth and tail muscle composition in redclaw. Purified diets containing varying levels of dietary protein significantly affected activity of digestive enzymes (protease, amylase and cellulase) and the composition of the tail muscle tissue.  Redclaw have a relatively low protein requirement, which was reflected here, as little significant difference was observed in growth rates and the feed conversion ratio was only significantly affected by the lowest protein diet.  Manipulation of the non-protein energy component in purified diets (protein to lipid ratio) had no effect on growth performance indices in redclaw. Digestive enzyme activity (protease) was however, strongly influenced by both the amount of protein and lipid in the diet and a significant correlation was observed between protease activity and growth performance indices. The findings here, provide preliminary data for consideration of digestive enzymes such as proteases as potential growth indicators for freshwater crayfish. These enzymes are already recognised as reliable biological indicators for comparison of digestive efficiency and potential growth rate in fish. The relationship between diet composition and digestive enzyme expression observed here, stress the need for further empirical evaluation of specific ingredients in artificial diets for redclaw. A range of single cell, plant and animal-based, agricultural products were assessed for their potential use in diets formulated for redclaw. Analysis of dietary supplements revealed that apparent digestibility of crude protein was generally higher for diets containing plant-based ingredients. A similar outcome was observed for digestibility coefficients of test ingredients. Ingredient type also had a significant effect on digestive enzyme activity. Importantly, a significant correlation was observed for enzyme activity and apparent digestibility coefficients. It appears that redclaw have the capacity to utilise nutrients from a broad range of dietary ingredients successfully including animal, single cell and in particular, plant matter in their diet. Taken together, the results presented here demonstrate that digestive enzyme activities in redclaw are significantly influenced by diet composition. I show clearly that the ability of redclaw to utilise various nutrients (measured as digestibility coefficients) is highly correlated with digestive enzyme activity. Finally, protease activity demonstrated a potential for use as an indicator of redclaw growth performance. The data presented here will contribute to development of better and cheaper feed formulations for use in redclaw aquaculture and have broader applications to freshwater crustacean culture. In particular, the potential for use of plant-based ingredients in aqua-feeds for redclaw will contribute to a more economically and environmentally sustainable redclaw culture.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">aquaculture</field><field name="subject">Cherax quadricarinatus</field><field name="subject">redclaw</field><field name="subject">freshwater crayfish</field><field name="subject">crustaceans</field><field name="subject">crustacean nutrition</field><field name="subject">digestive enzymes</field><field name="subject">protease</field><field name="subject">amylase</field><field name="subject">cellulase</field><field name="subject">lipase</field><field name="subject">cellulose</field><field name="subject">dietary fibre</field><field name="subject">protein</field><field name="subject">protein/lipid ratio</field><field name="subject">lipid</field><field name="subject">carbohydrates</field><field name="subject">digestibility</field><field name="identifier">http://eprints.qut.edu.au/16615/</field><field name="validLink">True</field></doc><doc><field name="title">Aerobic fitness, physical function and falls among older people : a prospective study</field><field name="creator">Bell, Rebecca A.</field><field name="description">Falls in people aged over 65 years account for the largest proportion of all injury-related deaths and hospitalisations within Australia. Falls contributed to 1,000 deaths and 50,000 hospitalisations in older people during 1998 (Commonwealth Department of  Health and Aged Care 2001). It has been predicted that by 2016, 16% of the Australian population will be aged over 65 years (Australian Bureau of Statistics 1999) placing considerable pressure on the health care system. Furthermore, prospective studies have shown that 30-50% of people aged 65 years and over, will experience a fall (Tinetti et al. 1988b; Campbell et al. 1989; Lord et al. 1994b; Hill 1999; Brauer et al. 2000; Stalenhoef et al. 2002) and this figure increases exponentially with age (Lord et al. 1994b).    Many physiological falls risk factors have been established including reduced leg strength, poor balance, impaired vision, slowed reaction time and proprioception deficits. However, little research has been conducted to determine whether performance on aerobic fitness tasks is also a physiological falls risk factor. Aerobic fitness has previously been related to an individual's ability to perform activities of daily living, which in turn has been linked to falls. It was therefore proposed that aerobic fitness might also be a risk factor for falls among community dwelling older people.    This research aimed to provide clinical evidence to inform public health practice. This thesis comprised of four objectives: the first to find suitable measures of aerobic fitness for older people; the second investigated relationships between existing clinical tests and future falls; the third explored relationships between aerobic fitness tests and future falls; the final objective was to examine the independent relationships between falls and clinical and physiological characteristics. The participants were recruited through a random sample from the local electoral roll, with an average age of 73 &#177;6 years.  Of the 87 participants who completed the prospective component of the study, 37% were male and 63% were female. Sixty-three participants (65%) reported no previous falls, 19 (20%) reported a single fall, and 16 (15%) reported two or more falls in the previous 12 months. The first objective required participants recruited from the community to take part in submaximal and maximal fitness tests in order to find suitable measures of aerobic fitness.  A further objective was to determine whether older people were able to fulfil the 'standard' criteria for completion of a maximum oxygen consumption test.  The measures used in this research included: maximum oxygen consumption, peak oxygen consumption, ventilatory threshold, oxygen uptake kinetics, oxygen deficit, efficiencies, oxygen consumption at zero, 30 and 50 watts, predicted  max and Six-Minute Walk Test distance.  Only weak relationships were observed between submaximal aerobic measures and peak oxygen consumption.  Furthermore, only 54% of participants were able to fulfil the criteria to complete a test of maximum oxygen consumption, indicating it was not a suitable measure for use among a sample of community dwelling older people. Therefore submaximal aerobic variables were used in the following chapters.    The second objective investigated the relationship between clinical measures and falls among older people and was carried out to enable comparisons between the population in this study and those described in the literature.  This research found that the Timed Up and Go (TUG) test was the most sensitive of all clinical tests (including the Berg Balance Scale, Function Reach, Performance Oriented Mobility Assessment and Physiological Profile Assessment) for the assessment of future falls. The TUG requires participants to stand up, walk 3m, turn, walk back, and sit down. Time taken to complete the test is the recorded value. For this study, a cut-off value of 7-seconds was established, above which individuals were at increased risk of falls. Previous research suggested cut-off times of over 10s were appropriate for older people. However, this is the first study to assess falls prospectively and definitively find that the TUG can discriminate between future fallers and non-fallers.    This research also investigated the differences in falls risk factors for functionally different subsamples, as defined by their ability to undertake and complete the cycle test. The participants who could complete the test had significantly better balance ability and strength than those unable to undertake or complete the cycle test. However, this inability to undertake or complete the cycle test was not itself a predictor of future falls. These two groups also differed in the relationships between clinical test results and falls risk. Participants in the no-cycle group had very similar results to that of the entire cohort. Even after adjustment for age, the TUG, foot and hand reaction times and knee flexion strength were all performed better by non-fallers than fallers.  However, none of these differed between fallers and non-fallers for participants in the cycle group. This group had better balance ability and strength than the no-cycle group. These results indicated that the cycle group differed from the no-cycle group and the entire sample, further indicating that factors other than the physiological variables measured in this research influence falls risk in strong participants with good balance ability.    Similar results were reported when aerobic tests and falls were investigated in the third objective. In the whole sample, the fallers walked significantly less distance than non-fallers for the 6-MWT. Similar results were found for participants in the no-cycle group but not the cycle group. All participants were able to complete the Six-Minute Walk Test (6-MWT) although only 74% were able to undertake and complete the cycle test.    The fourth objective was to consider all measures from the previous chapters as potential predictors of falls. The variables most predictive of future falls were the TUG and having experienced one or more falls in the previous 12 months. As a result they could be used as screening tools for the identification of high-risk fallers who require referral for further assessment. This could be completed by a General Practitioner or Practice Nurse, which would ensure that screening is being undertaken in the wider population. If the patient is at high risk they should be referred for falls risk factor assessment to determine an optimal tailored intervention to reduce future falls. Low risk patients should be referred for preventive evidence-based activities. These steps can potentially improve quality of life for individuals, and if effective in preventing future falls, will result in reduced costs to the individual and the Australian public.    The results of this work demonstrate that the best screening tests are simple tasks like the TUG and asking an individual if they have experienced a fall in the last 12 months. This research also found that strong, mobile older people who could undertake and complete a submaximal cycle ergometer test, still experienced falls in the following 12 months, although the causes of this are currently unknown. This research showed that physiological falls risk factors are less relevant as these highly functional older people do not have physiological deficits. However, this research found that the 6-MWT showed promise as a predictor of falls in a group who could not complete a submaximal cycle ergometer test, who had lower strength, balance and functional fitness scores than a group who could complete this cycle test. The results showed that physiological falls risk factors are still very important for older people with lower physical abilities, and this is where aerobic fitness may still be related to falls. While the association between aerobic fitness and falls remains unclear, these are novel and provocative findings highlighting the need for future falls risk investigations to consider aerobic fitness as a contributing factor.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">falls risk assessment</field><field name="subject">screening</field><field name="subject">predictors</field><field name="subject">maximum oxygen uptake</field><field name="subject">submaximal fitness measures</field><field name="subject">six-minute walk test</field><field name="subject">clinical tests</field><field name="identifier">http://eprints.qut.edu.au/16616/</field><field name="validLink">True</field></doc><doc><field name="title">Physical activity among breast cancer survivors</field><field name="creator">Harrison, Sheree</field><field name="description">In Australia, women with breast cancer comprise one of the largest groups of cancer survivors. As a consequence of this, and improved survival rates, the interest in programs to enhance the recovery of cancer survivors is growing. Exercise during and after treatment has been identified as a potential strategy to assist women throughout their treatment and positively influence the recovery and health-related quality of life (HRQoL) of breast cancer survivors. Through the use of an existing data source, this study investigated physical activity rates, explored the factors associated with low levels of physical activity participation, and assessed the relationship between levels of activity and HRQoL among women diagnosed with breast cancer. The population-based sample, obtained in 2002 was comprised of 287 women newly diagnosed with breast cancer, residing in South-East Queensland. Women were followed-up (via subjective questionnaire and objective physical testing) every three months over a 12-month period, from six months post-diagnosis. Physical activity was assessed using the Behavioural Risk Factor Surveillance System (BRFSS) while HRQoL was assessed using the Functional Assessment of Cancer Therapy for breast cancer (FACTB+4). Based on National Physical Activity Guidelines, women were categorised as being sufficiently active, insufficiently active or sedentary at each of the five testing phases (specifically at 6-, 9-, 12-, 15- and 18-months post-diagnosis). Rates of participation in physical activity were relatively stable over the testing period. At 18 months post-diagnosis, 44%, 43% and 13% of women, respectively, were categorised as being sufficiently active, insufficiently active or sedentary. The sedentary or insufficiently active women were more likely to be older, obese or overweight, lack private health insurance, and have received both chemotherapy and radiotherapy, compared with sufficiently active women. Sedentary women consistently reported a lower HRQoL compared to active women (sufficiently or insufficiently active) over the 12-month testing period. This was especially apparent amongst the group of younger women (aged less than 50 years at diagnosis) (p=0.02). This work is among the first to explore physical activity rates specifically among Australian breast cancer survivors, and highlights the potential importance of participating in physical activity to optimise HRQoL during recovery from breast cancer. Specific attention to promote physical activity to the identified group of sedentary and insufficiently active survivors is of particular importance.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">breast cancer</field><field name="subject">physical activity</field><field name="subject">exercise</field><field name="subject">recovery</field><field name="subject">health-related quality of life</field><field name="subject">longitudinal data</field><field name="subject">public health</field><field name="identifier">http://eprints.qut.edu.au/16617/</field><field name="validLink">True</field></doc><doc><field name="title">Improving numeracy: co-constructing a whole-school numeracy plan in a secondary school</field><field name="creator">McDonald, Susan Ellen</field><field name="description">Numeracy is a cross-curricular priority, an intersystemic priority and, of late, a federal government priority.  Yet as a priority "numeracy" is inadequately defined and the term is used to describe a wide-range of notions. Many educators are unsure of what constitutes numeracy, unaware of how it differs from mathematics, and uncertain as to how its demands may be met in their planning and teaching. Secondary schools have few models upon which to develop a whole-school numeracy plan. This study describes the journey of a secondary school staff as they developed a shared understanding of numeracy, identified the numeracy demands throughout the curriculum and planned for a whole-school approach to address these demands.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">numeracy</field><field name="subject">secondary school</field><field name="subject">whole-school plan</field><field name="subject">mathematics</field><field name="subject">audit</field><field name="subject">and social constructionist</field><field name="identifier">http://eprints.qut.edu.au/16618/</field><field name="validLink">True</field></doc><doc><field name="title">An experimental study of the mixing performance of boat propellers</field><field name="creator">Loberto, Anthony</field><field name="description">Two-stroke outboard boat engines using total loss lubrication deposit a significant proportion of their lubricant and fuel directly into the water environment. Extensive atmospheric emission testing of outboard motors has taken place, however, emissions to the water are largely unaddressed in the literature and could be critical because the exhaust of most outboard engines is released below the water and mixed by the action of the propeller. The purpose of this work is to document the velocity and scalar field characteristics of a submerged swirling jet emanating from a propeller. The aim is to provide guidance on fundamental characteristics of such a jet, far enough downstream that it is relevant to the eventual modelling of this mixing problem (i.e. the mixing of engine emissions with water). Measurements of the velocity field (axial, tangential, and radial) and scalar field (concentration) were performed in a turbulent jet generated by a model boat propeller (0.02 m diameter) operating in a weak co-flow of 0.04 ms-1. The measurements were carried out up to 50 propeller diameters downstream of the source which was placed in a glass-walled flume, 0.4 m wide with a free surface depth of 0.15 m. The jet and scalar plume development were compared to that of a classical free round jet. Further, results with respect to velocity distribution, turbulence decay and integral flow properties plus scalar distribution, dilution and integral plume properties were all calculated and compared to existing literature. The velocity field results are the first published results to show the development of the flow fifty propeller diameters downstream. Up to ten propeller diameters downstream the results corroborate the earlier work of Petersson [1, 2]. Beyond ten propeller diameters downstream, the walls of the flume affected the flow. The concentration field results show that under these experimental conditions the propeller induced mixing exhibited a complete mixing length some 300 times shorter than for the wall-shear induced diffusion alone. Furthermore, a first principles relation was derived that illustrates the link between engine emission rate and propeller kinematics in generating the propeller-jet source concentration of pollutants. Using experimental results an estimate for benzene concentration fifty propeller diameters downstream of a 74 kW vessel was calculated to be around one third of the regulatory threshold for that chemical.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">boat propellers</field><field name="subject">mixing performance</field><field name="identifier">http://eprints.qut.edu.au/16619/</field><field name="validLink">True</field></doc><doc><field name="title">The child protection systems' response to domestic violence</field><field name="creator">Des Lauriers, Julie</field><field name="description">The co-occurrence of domestic violence (DV) and child maltreatment is high. Response to both problems has historically been via two different systems. However, child protection workers are increasingly asked to respond to this co-occurrence since research has identified that exposure to DV can negatively impact on children and that child maltreatment often co-occurs with DV. This study looks at child protection systems response to families affected by DV by using two research methods. First, a systematic review was conducted using research papers focusing on child protection workers response to families experiencing DV. Second, a critical discourse analysis of current Australian child protection policies was conducted. Findings from the systematic review show that child protection workers' response to abused mothers went from treating them as 'mad' in the 1980s, to labelling them 'failure to protect' in the 1990s and early 2000. These findings showed continued focus on abused mothers rather than on perpetrators of DV. Some contradictions were found around child removal data. However, important links were found between re-notification of children and subsequent removal. Findings from the Australian policy analysis revealed that most policies referred to DV as a child protection issue and used a feminist definition of DV. However, not all states had detailed guidelines on how to intervene safely and effectively with families affected by DV. Discussions and recommendations focus around the pressing need for more DV expertise within child protection systems. It also discusses the issue of responsibility placed on abused mothers while perpetrators of DV remain invisible. Finally, it discusses the response to children exposed to DV compared to the response to children exposed to DV who are also victim of direct child maltreatment. The key recommendations of this study are to have DV expertise within the child protection systems, to empower abused mothers rather than blaming them, which implies putting the responsibility back on the perpetrator of DV and to have resources and systems in place before responding to child exposure to DV as child maltreatment per se.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">spouse abuse</field><field name="subject">domestic violence</field><field name="subject">family violence</field><field name="subject">battered wife/wives</field><field name="subject">abused women</field><field name="subject">abused mothers</field><field name="subject">intimate partner violence</field><field name="subject">domestic abuse</field><field name="subject">violence against women</field><field name="subject">child abuse</field><field name="subject">child protection</field><field name="subject">youth protection</field><field name="subject">child neglect</field><field name="subject">children services</field><field name="subject">child welfare</field><field name="subject">child mistreatment</field><field name="subject">child maltreatment</field><field name="identifier">http://eprints.qut.edu.au/16620/</field><field name="validLink">True</field></doc><doc><field name="title">Marian McPartland, jazz pianist : an overview of a musical career</field><field name="creator">Hansson, Clare</field><field name="description">This, the first study at doctoral level of any white female jazz instrumentalist, provides an overview to the long, active and enduring musical career of British-born, New York-based jazz pianist, Marian McPartland (born 1918). For over six decades, besides being a pianist and a composer, she has been prominent in the professional roles of educator, writer, record producer and recording artist, radio broadcaster and advocate. The scope and impact of this multi-layered career are conveyed through the medium of a Website profiling significant aspects of her professional life through textual, aural and visual presentation. Although not claiming to be exhaustive, this Website brings together a comprehensive collection of data covering all aspects of Marian McPartland's career. Data have been gathered and collated from material in the public domain, and all such sources are acknowledged and referenced. The Website is navigable through three links at the bottom of the Home Page - 1) Historical Perspective; 2) Selected Analyses; and 3) Marian McPartland In Context. Part One of the Website provides access to Marian McPartland's various professional roles in jazz, as well as public profiles, and is consolidated by listings of support material. Part Two of the Website contains formal analyses of four of her compositions, each preceded by a short introduction. The analyses are based on scores transcribed from her recorded improvisations. A discussion of her stylistic approach follows the analyses. Part Three of the Website contextualizes Marian McPartland as a woman in jazz during its major historical and stylistic movements. An Introduction and a Conclusion provide the academic framework for this study. The Introduction outlines the rationale for the study, the dimensions of the study, the methodologies used, and the research process. The Conclusion provides critical commentary on Marian McPartland's musical career, and deductions are made about her significance in and contribution to jazz, based on the evidence presented in the Website. A CD of the entire Website completes the presentation of this thesis, included under Supplementary Material in the back pocket of the thesis. This overview of Marian McPartland's entire career makes an original contribution to knowledge on this jazz artist, and, in a broader sense, provides an important resource for future research in the area of jazz music and musicians.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Marian McPartland (1918 - )</field><field name="subject">Marian Page (early stage name)</field><field name="subject">Margaret Marian Turner (maiden name)</field><field name="subject">American jazz history (1946 - 2005)</field><field name="subject">biography</field><field name="subject">discography</field><field name="subject">Halcyon Records &#150; jazz recording company</field><field name="subject">Halcyon Music &#150; music publishing company</field><field name="subject">jazz advocacy</field><field name="subject">jazz analysis</field><field name="subject">jazz broadcasting</field><field name="subject">jazz composition</field><field name="subject">jazz education</field><field name="subject">jazz entrepreneurship</field><field name="subject">jazz journalism</field><field name="subject">jazz performance</field><field name="subject">jazz piano</field><field name="subject">jazz recording</field><field name="subject">piano jazz radio program</field><field name="subject">web-based resource</field><field name="subject">women in jazz</field><field name="identifier">http://eprints.qut.edu.au/16621/</field><field name="validLink">True</field></doc><doc><field name="title">Development of statistical methods for the surveillance and monitoring of adverse events which adjust for differing patient and surgical risks</field><field name="creator">Webster, Ronald A.</field><field name="description">The research in this thesis has been undertaken to develop statistical tools for monitoring adverse events in hospitals that adjust for varying patient risk. The studies involved a detailed literature review of risk adjustment scores for patient mortality following cardiac surgery, comparison of institutional performance, the performance of risk adjusted CUSUM schemes for varying risk profiles of the populations being monitored, the effects of uncertainty in the estimates of expected probabilities of mortality on performance of risk adjusted CUSUM schemes, and the instability of the estimated average run lengths of risk adjusted CUSUM schemes found using the Markov chain approach. The literature review of cardiac surgical risk found that the number of risk factors in a risk model and its discriminating ability were independent, the risk factors could be classified into their "dimensions of risk", and a risk score could not be generalized to populations remote from its developmental database if accurate predictions of patients' probabilities of mortality were required. The conclusions were that an institution could use an "off the shelf" risk score, provided it was recalibrated, or it could construct a customized risk score with risk factors that provide at least one measure for each dimension of risk. The use of report cards to publish adverse outcomes as a tool for quality improvement has been criticized in the medical literature. An analysis of the report cards for cardiac surgery in New York State showed that the institutions' outcome rates appeared overdispersed compared to the model used to construct confidence intervals, and the uncertainty associated with the estimation of institutions' out come rates could be mitigated with trend analysis. A second analysis of the mortality of patients admitted to coronary care units demonstrated the use of notched box plots, fixed and random effect models, and risk adjusted CUSUM schemes as tools to identify outlying hospitals. An important finding from the literature review was that the primary reason for publication of outcomes is to ensure that health care institutions are accountable for the services they provide. A detailed review of the risk adjusted CUSUM scheme was undertaken and the use of average run lengths (ARLs) to assess the scheme, as the risk profile of the population being monitored changes, was justified. The ARLs for in-control and out-of-control processes were found to increase markedly as the average outcome rate of the patient population decreased towards zero. A modification of the risk adjusted CUSUM scheme, where the step size for in-control to out-of-control outcome probabilities were constrained to no less than 0.05, was proposed. The ARLs of this "minimum effect" CUSUM scheme were found to be stable. The previous assessment of the risk adjusted CUSUM scheme assumed that the predicted probability of a patient's mortality is known. A study of its performance, where the estimates of the expected probability of patient mortality were uncertain, showed that uncertainty at the patient level did not affect the performance of the CUSUM schemes, provided that the risk score was well calibrated. Uncertainty in the calibration of the risk model appeared to cause considerable variation in the ARL performance measures. The ARLs of the risk adjusted CUSUM schemes were approximated using simulation because the approximation method using the Markov chain property of CUSUMs, as proposed by Steiner et al. (2000), gave unstable results. The cause of the instability was the method of computing the Markov chain transition probabilities, where probability is concentrated at the midpoint of its Markov state. If probability was assumed to be uniformly distributed over each Markov state, the ARLs were stabilized, provided that the scores for the patients' risk of adverse outcomes were discrete and finite.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">adverse outcomes</field><field name="subject">ARL</field><field name="subject">control chart</field><field name="subject">Markov chain property</field><field name="subject">medical monitoring</field><field name="subject">minimum effect CUSUM</field><field name="subject">meta-factors</field><field name="subject">patient level uncertainty</field><field name="subject">parameter estimation uncertainty</field><field name="subject">risk adjustment</field><field name="subject">risk adjusted CUSUM</field><field name="subject">report cards</field><field name="subject">risk score</field><field name="subject">risk model performance</field><field name="identifier">http://eprints.qut.edu.au/16622/</field><field name="validLink">True</field></doc><doc><field name="title">A long-term evaluation of the impact of rehabilitation in home (RIO) program on health outcomes in older adults</field><field name="creator">Chan, Raymond</field><field name="description">Background:  Older adults experience health deconditioning during hospitalization. There are many facets of care impacting on older adults' health characteristics and their self confidence in managing their health. The aim of this follow-up study is to examine the long term effect of comprehensive discharge planning and nursing in-home follow-up for older adults (over 65 year old) incorporating physiotherapy exercise strategies on health characteristics. No published studies were located that had examined the impact of a comprehensive discharge program on the functional status and psychosocial among older frail adults at 12 months post-discharge.  Design and methodology:  Rehabilitation in Older People (RIO program) is a randomised controlled trial which evaluates the intervention of a comprehensive discharge program, exercise program incorporating nursing follow up. Participants of the RIO study were randomly allocated into usual care control group and an intervention group. The intervention group received a comprehensive training from an advanced practice gerontic nurse (APGN) and exercise strategies by physiotherapists. The APGN visited the participants in their home 48 hours post discharge, followed by telephone follow-up at 4, 8, 12 and 24 weeks. This study followed-up this cohort at 12 month via telephone interviews to evaluate their functional ability, quality of life, psychosocial characteristics and the levels of self-efficacy. The General Self-efficacy Scale (GSE) was used to measure their self-efficacy.  Results:  There is no difference between the demographic and health characteristics between the control and intervention group. There are significant difference in their functional ability, psychosocial health, measured by the tools mentioned above at 4 weeks (p &lt; 0.05), 12 weeks (p &lt; 0.05), and 24 weeks (p &lt; 0.05), but not at 52 weeks. The possible reason could be due to lack of telephone follow up. Moreover, the levels of self-efficacy in this sample have been found to correlate with the functional ability and psychosocial at 12 months after discharge from an acute hospital.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">older adults</field><field name="subject">exercise</field><field name="subject">self-efficacy</field><field name="subject">comprehensive discharge program</field><field name="subject">telephone</field><field name="subject">nurse in-home follow-up</field><field name="identifier">http://eprints.qut.edu.au/16623/</field><field name="validLink">True</field></doc><doc><field name="title">Conservation genetics of a Gondwana relict rainforest tree, Nothofagus moorei (F. Muell.) Krasser</field><field name="creator">Schultz, Lee</field><field name="description">Nothofagus moorei is a long-lived, Gondwana relict cool temperate rainforest tree. Nothofagus-dominated rainforests were widespread across much of eastern Australia during the mid-Tertiary but today, N. moorei occurs only as a series of disjunct, isolated populations in south-east Queensland and northern New South Wales.  Clonal regeneration via coppicing is reported to be a common feature of most N. moorei populations, while successful sexual regeneration is believed to be rare, occurring largely only in niches with high light levels and limited competition. While clonal propagation enables population persistence and individual longevity, it cannot generate novel genotypes.  Isolated populations, potentially high levels of clonality, low-potential for successful sexual regeneration, long-lived individuals and predicted global warming effects make N. moorei vulnerable to local, if not total, population extinction.  The current study aimed to assess the relative conservation status of extant N. moorei populations in order to develop appropriate conservation management strategies for long-term population persistence. Levels of genetic diversity and population structure were examined across the remaining natural distribution of N. moorei using nuclear amplified fragment length polymorphism (AFLP), microsatellite and chloroplast DNA markers.   In total 607 individuals were sampled from 20 populations and 5 geographical regions: Lamington/Border Ranges, Ballow, Dorrigo/New England, Werrikimbe and Barrington. Genetic results were then analysed to assess conservation status of each population and geographical region.  Microsatellite and AFLP data identified comparatively high levels of genetic diversity in all remnant populations sampled.  The prevalence of coppicing in the northern Lamington/Border Ranges populations appears to have had little impact on relative levels of genetic diversity, heterozygosity or population structure.  Population differentiation was limited, with the majority of genetic variation retained within populations, no regional structuring and high levels of admixture.  Analysis of cpDNA variation showed that the three Dorrigo/New England populations were divergent from all other populations, suggesting an ancient divergence in N. moorei prior to Pleistocene glaciations. While levels of genetic diversity were essentially the same across all populations, Bayesian analysis of genetic structure did identify four populations with differing gene pool proportions which would be important to include in conservation efforts in addition to individuals from other populations.  Similarly, individuals from four significantly differentiated groups identified using traditional F-statistics suggests individuals from each of these four groups should be included in future conservation plans.   In order to maintain ancient chloroplast lineages, populations from the Dorrigo/New England region should also be assigned special conservation value.  Populations of N. moorei appear to have retained significant levels of genetic diversity and show little population divergence in spite of marked reductions in the natural distribution since the Early Miocene. Sampling of these ancient trees however, suggests current levels of diversity in N. moorei actually reflect past diversity and differentiation, and that there have been insufficient generations since the historical contraction in distribution for genetic diversity to be adversely affected and regional differentiation to evolve. Long-term persistence of N. moorei is still threatened by future accelerated climate change and the limited preferred habitat that remains where N. moorei can expand its range.  While the ability to regenerate clonally may enable long-term persistence of N. moorei, populations are still likely to continue to decline as climatic conditions will increasingly favour sub-tropical and warm temperate species across much of N. moorei's northern distribution.  Southern populations of N. moorei, in contrast, could expand their ranges into eucalypt woodlands as predicted climate becomes warmer and wetter. However, this will ultimately be determined by the frequency of fires, with increased fire frequencies favouring the expansion of eucalypts and contraction and possible local population extinction of N. moorei dominated cool temperate rainforests.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Nothofagus moorei</field><field name="subject">antarctic beech</field><field name="subject">relictual</field><field name="subject">cool temperate rainforest</field><field name="subject">conservation genetics</field><field name="subject">AFLPs</field><field name="subject">microsatellites</field><field name="subject">chloroplast DNA</field><field name="subject">historical genetic diversity and structure</field><field name="subject">clonality</field><field name="identifier">http://eprints.qut.edu.au/16624/</field><field name="validLink">True</field></doc><doc><field name="title">Understanding the resource-based view : implications of methodological choice and a new creative context</field><field name="creator">Robinson, Susan Maureen</field><field name="description">Over the past two decades, the resource-based view of the firm (RBV) has emerged as one of the more influential paradigms from the field of strategic management. However, the theory has been subjected to a number of criticisms, particularly related to the use of methodologies in past research. Many RBV studies have tended to use averaged findings across broad industry samples. Approaches reliant on "averaging" methods will only uncover what is the case for the average, "representative" firm, and will not identify those unique, firm-specific assets that can result in sustained profitability.   In order to examine the implications of methodological choice and the RBV, the subjective approach of Q methodology was used in a sample of music industry firms to identify a key resource set for the context of interest, identify strategic groups within the sample based on resource emphasis, and explore the ways in which managers use their resources to generate firm profits. A comparative approach examined resource outcomes by performance group, over multiple levels of analysis. The findings revealed (i) a number of relevant and new, context-specific resources from the music industry, (ii) the identification of three distinct clusters of firms that emerged from the sample based on resource preferences, firm characteristics, and managerial perceptions (iii) key resource findings that varied by level of analysis and by firm performance, and (iv) distinct processes through which the resources become valuable at the level of the firm--even when the same resources are considered.  The outcomes of this thesis illustrate how methodological choice can affect findings when using the RBV to uncover important sources of advantage. Furthermore, the outcomes in this thesis point to the weaknesses of many past RBV studies that investigate the impact of resources and capabilities on firm performance, and remind scholars that a defining feature of the RBV is that its intention was to identify sources of advantage at the level of the firm. Moreover, the findings show that past RBV research using aggregated data across multi-industry samples can be misleading in its prescription to managers.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">methodological choice</field><field name="subject">new creative content</field><field name="subject">resource-based view</field><field name="identifier">http://eprints.qut.edu.au/16625/</field><field name="validLink">True</field></doc><doc><field name="title">Optimisation of container process at multimodal container terminals</field><field name="creator">Wong, Andy King-sing</field><field name="description">Multimodal container terminals are an important part of the logistics systems in international trade. Any improvement in the terminal efficiency is likely to reduce the costs of transporting goods, and to strengthen the trading position of the nation. During the import process, containers flow from ships to the storage yard for temporary storage and then are later moved to the hinterland by rail, or by road. The export process is the reverse of the import process. From the marshalling area, it is possible for a yard machine to carry an inbound container to the storage area and back with an inbound container in one round trip. This thesis investigates the inbound and outbound container process of multimodal container terminals in a multi-ship and multi-berth environment. The aim is to develop mathematical models and analytical tools for yard operation and planning. This study concerns the yardlayout,   storage locations, operation strategies as well as the sequencing and scheduling of container process. Several models are developed for the scheduling of container process, taking account of planned and unplanned disruptions, and the intermediate buffer at the marshalling area. The problem is NP-hard and real-life problems often involve large number of containers. In addition, many schedules may not be feasible due to deadlock or violation of precedence-constraints. Good results were achieved on benchmark problems using the proposed innovative. In dealing with unplanned disruptions, reactive scheduling approach was found to give the results similar to as if the disruptions were planned in advance. Numerical investigations are also presented on various factors affecting the efficiency of seaport container terminals including the number of yard machines, and the number of quay crane. As with the various yard-layouts studied, it was found that containers are best stored in rows perpendicular to the quay-line with about 10 to 14 bays in each row. For a shorter ship service time, ideally the containers should be stored as close as possible to the ship. The best storage locations, however, are scarce resources and are not always available. Another model is developed for the best storage location as well as the best schedule for the container process. From an initial best schedule with predefined storage locations, the problem is solved by iterating through the refinement of storage scheme and re-scheduling.   At a seaport terminal, ships are planned to arrive and leave within a scheduled time window. Nevertheless, a ship may arrive late due to poor weather conditions or disruptions at the previous port. Such delay may also affect its departure to the subsequent port. To minimise the impact of ship delays, port operators must consider alternate arrangements including re-assignment of berths, re-sequencing of ships and rescheduling of the container process. A ship delay model is developed and the problem is solved by combining branching and Tabu Search.   The models developed in this thesis establish the relationship between significant factors and the options for increasing throughput by discovering the bottlenecks. The models are applicable as decision tools for operation planning, yard layout, and cost and benefit analysis for investment in infrastructures.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">container process</field><field name="subject">scheduling</field><field name="subject">storage allocation</field><field name="subject">ship delays</field><field name="subject">meta-heuristics</field><field name="identifier">http://eprints.qut.edu.au/16626/</field><field name="validLink">True</field></doc><doc><field name="title">Spatial analysis of long-term exposure to air pollution and cardiorespiratory mortality in Brisbane, Australia</field><field name="creator">Wang, Xiao-Yu</field><field name="description">Air pollution is ranked by the World Health Organisation as one of the top ten contributors to the global burden of disease and injury. Epidemiological studies have shown that exposure to air pollution is associated with cardiorespiratory diseases. However, most of the previous studies have looked at this issue using air pollution data from a single monitoring site or average values from a few monitoring sites in a city. There is increasing concern that the relationships between air pollution and mortality may vary with geographical area, particularly for a big city. This thesis consisted of three interlinked studies that aimed to examine the spatial variation in the relationship between long-term exposure to air pollution and cardiorespiratory mortality in Brisbane, Australia. The first study evaluated the long-term air pollution trends in Brisbane, Australia. Air pollution data used in this study were provided by the Queensland Environmental Protection Agency (QEPA). The data comprised the daily average concentrations of particulate matter less then 10 &#181;m in aerodynamic diameter (PM10), nitrogen dioxide (NO2), ozone (O3) and sulphur dioxide (SO2) between 1 January 1980 and 31 December 2004 in two monitoring sites (i.e. Eagle farm and Rocklea), and in other available monitoring sites between 1 January 1996 and 31 December 2004. Computerised data files of daily mortality between 1 January 1996 and 31 December 2004 in Brisbane city were provided by the Office of Economic and Statistical Research of the Queensland Treasury. Population data and the Socio-Economic Indexes for Areas (SEIFA) data in 2001 were obtained from the Australian Bureau of Statistics (ABS) for each statistical local area (SLA) of the Brisbane city.    The long-term air pollution (the daily maximum 1-hour average or daily 24-hour average concentrations of NO2, O3 and PM10) trends were evaluated using a polynomial regression model in two monitoring sites (Eagle Farm and Rocklea) in Brisbane, Australia, between 1980 and 2003. The study found that there were significant up-and-down features for air pollution concentrations in both monitoring sites in Brisbane. Rocklea recorded a substantially higher number of days with concentrations above the relevant daily maximum 1-hour or 24-hour standards than that in Eagle Farm. Additionally, there was a significant spatial variation in air pollution concentrations between these areas. Therefore, the results indicated a need to examine the spatial variation in the relationship between long-term exposure to air pollution and cardiorespiratory mortality in Brisbane.    The second study examined the spatial variation of SO2 concentrations and cardiorespiratory mortality in Brisbane between 1999 and 2001. Air pollutant concentrations were estimated using geographical information systems (GIS) techniques at a SLA level. Spatial distribution analysis and a multivariable logistic regression model were employed to investigate the impact of gaseous air pollution on cardiorespiratory mortality after adjusting for potential confounding effects of age, sex, calendar year and SEIFA.  The results of this study indicate that for every 1 ppb increase in annual average SO2 concentration, there was an estimated increase of 4.4 % (95 % confidence interval (CI): 1.4 - 7.6 %) and 4.8 % (95 % CI: 2.0 - 7.7 %) in cardiovascular and cardiorespiratory mortality, respectively. We estimated that the excess number of cardiorespiratory deaths attributable to SO2 was 312 (3.4% of total cardiorespiratory deaths) in Brisbane during the study period. Our results suggest that long-term exposure to SO2, even at low levels, is a significant hazard to population health.    The final study examined the association of long-term exposure to gaseous air pollution (including NO2, O3 and SO2) with cardiorespiratory mortality in Brisbane, Australia, 1996 - 2004. The pollutant concentrations were estimated using GIS techniques at a SLA level. Logistic regression was used to investigate the impact of NO2, O3 and SO2 on cardiorespiratory mortality after adjusting for potential confounding effects of age, sex, calendar year and SEIFA. The study found that there was an estimated 3.1% (95% CI: 0.4 - 5.8%) and 0.5% (95% CI: -0.03 - 1.3 %) increase in cardiorespiratory mortality for 1 ppb increment in annual average concentration of SO2 and O3, respectively. However there was no significant relationship between NO2 and cardiorespiratory mortality observed in the multiple gaseous pollutants model. The results also indicated that long-term exposure to gaseous air pollutants in Brisbane, even at the levels lower than most cities in the world (especially SO2), were associated with cardiorespiratory mortality. Therefore, spatial patterns of gaseous air pollutants and their impact on health outcomes need to be assessed for an evaluation of long-term effects of air pollution on population health in metropolitan areas.    This study examined the relationship between air pollution and health outcomes. GIS and relevant mapping technologies were used to display the spatial patterns of air pollution and cardiorespiratory mortality at a SLA level. The results of this study show that long-term exposure to gaseous air pollution was associated with cardiorespiratory mortality in Brisbane and this association appeared to vary with geographic area. These findings may have important public health implications in the control and prevention of air pollution-related health effects, since now many countries and governments have paid more attention to control wide spread air pollution and to protect our environment and human health.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">air pollution</field><field name="subject">cardiorespiratory</field><field name="subject">cardiovascular</field><field name="subject">geographic information system</field><field name="subject">interpolation</field><field name="subject">logistic regression model</field><field name="subject">mortality</field><field name="subject">nitrogen dioxide; ozone; particulate matter; respiratory disease</field><field name="subject">spatial distribution</field><field name="subject">socio-ecological factors</field><field name="subject">sulphur dioxide</field><field name="identifier">http://eprints.qut.edu.au/16627/</field><field name="validLink">True</field></doc><doc><field name="title">The seasons of a police officer's life : an analysis of the influence of career stage on the job satisfaction and work commitment of Queensland police officers</field><field name="creator">Bragg, Daniel Joseph</field><field name="description">Recent decades have witnessed a wealth of research into the concept of career stages and the relationship between these stages and the needs, attitudes and behaviours of individuals in the workforce. This high level of research interest has been fuelled by the belief that the human factor is the most critical factor in the success of organisations today and if organisations are to remain competitive in a rapidly changing environment they need to better understand the development needs, work-related attitudes and career concerns of their employees. Whilst a diverse range of career stage models have been put forward over the past fifty years, the models proposed by Super, Crites, Hummel, Moser, Overstreet and Warnath (1957) (psychological fit) and Levinson, Darrow, Klein, Levinson and McKee (1978) (age) have received considerable research attention and are generally considered to be the most useful in explaining the needs, attitudes and behaviours of individuals over the course of their career.
 
 Research into career stages has been conducted using a wide range of occupational groups. Only a limited number of researchers, however, have sought to test the utility of career stage concepts using a police sample. Despite their popularity and strong theoretical and empirical grounding, there is no known research that has tested the utility of Super et al. (1957) and Levinson et al.&#8217;s (1978) models of career stage using a police sample. The purpose of this study therefore was to contribute to the literature on career stage theory by testing the utility of these models of career stage in explaining the job satisfaction and work commitment of Queensland police officers. The study also explored the influence of other background variables that may also impact on job satisfaction and work commitment.
 
 The sample consisted of 246 police officers from the Metropolitan South Region of the Queensland Police Service. A cross sectional design was used to gather the data for the study. The Adult Career Concerns Inventory (ACCI) was used to group respondents into a career stage according to Super et al.&#8217;s conceptualisation of career stage. Respondents were also grouped into age-based career stages according to Levinson et al.&#8217;s conceptualisation of career stage.
 
 The study used established survey instruments to collect data on five facets of job satisfaction, these being satisfaction with pay, promotion, supervision, co-workers and work and five facets of work commitment, these being organisational commitment, job involvement, Protestant work ethic, career commitment and union commitment. Data was also collected on the background variables of organisational and occupational tenure, rank, gender, education level and type, type of duty performed, marital status, completion of the Queensland Police Service&#8217;s Management Development Program and membership of an Equal Employment Opportunity target group. A series of MANOVAs were used to explore the relationship between the career stage and other background variables and the various facets of job satisfaction and work commitment. Multiple regression analyses were used to determine if the results were being confounded by relationships with other independent variables.
 
 The current study failed to find any evidence to support the utility of Levinson et al.&#8217;s model in explaining job satisfaction and work commitment for Queensland Police officers. Whilst some significant differences in job satisfaction and work commitment between Levinson et al.&#8217;s age groupings were identified, none of the findings were consistent with the assumptions of their model. In fact, there was some evidence of differences in job-related attitudes across age groupings that directly contradict the assumptions of the Levinson et al. model. The current study also found no support for the utility of Super et al.&#8217;s model in explaining the job satisfaction of police officers. Some limited support, however, was found for the utility of Super et al.&#8217;s model in predicting work commitment, most notably with respect to organisational commitment, job involvement and career commitment. Differences in mean organisational commitment, job involvement and career commitment scores generally supported the propositions of Super et al., however, only the results for the exploration and disengagement stages reached statistical significance.
 
 Statistically significant relationships were found for the background variables of organisational tenure, rank, gender and type of duty. Statistically significant relationships were found for several facets of job satisfaction and work commitment. Work-related attitudes were generally found to peak in the first two years of a police officer&#8217;s tenure and then decline as tenure increased. The reason for this decline is complex and not completely clear, but may be at least partially explained by: the structural characteristics of police services; the distinct lack of support and confidence in officers; the influence of the police sub-culture; and the existence of a phenomenon known as police &#8216;bullshit&#8217;.
 
 Commissioned officers were found to be significantly more satisfied with promotions and constables were found to have significantly higher levels of organisational commitment than senior constables and sergeants and significantly higher levels of career commitment than sergeants. Other statistically significant relationships found in the current study include female officers reporting significantly higher levels of satisfaction with promotions than male officers and general duties officers reporting significantly higher levels of satisfaction with promotions than officers performing specialist duties and significantly higher levels of loyalty to the union than plain-clothes officers.
 
 The study concluded by highlighting the pioneering nature of the current study. It was suggested that considerably more research is necessary in order to clarify and refine the conceptualisation and measurement of police career stages and the relationship between these stages and work-related attitudes. It was recommended that future research should verify and extend the results of the current study, particularly with respect to the influence of tenure as a career stage variable and the nature and role of disengagement in any conceptualisation of career stage for police.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">Queensland police officers</field><field name="subject">career structure</field><field name="subject">job satisfaction</field><field name="identifier">http://eprints.qut.edu.au/16628/</field><field name="validLink">True</field></doc><doc><field name="title">The design and synthesis of potential dual action cardioprotective agents acting at adenosine receptors</field><field name="creator">Gregg, Alison Dianne</field><field name="description">Adenosine and adenosine analogues are recognised as cardioprotective agents due to the responses that they induce through the activation of myocardial adenosine receptors.  Antioxidants such as nitroxide radicals have also been found to possess cardioprotective properties in biological systems, namely through their ability to scavenge the oxygen-based free radicals that are potentially damaging to tissues and cells. It was envisaged that the linking of an antioxidant moiety to adenosine would produce an adenosine analogue that activates adenosine receptors and also scavenges oxygen-derived free radicals in the body. Consequently, one aim of this project was to synthesise a series of adenosine analogues that possessed a nitroxide or a phenolic antioxidant at the N6 position of the adenosine skeleton.
 
 
 
 Allosteric ligands have several advantages over orthosteric ligands as potential therapeutic agents, and research into the allosteric enhancement of adenosine receptors is a burgeoning field. It was envisaged that the linking of an antioxidant moiety to an allosteric enhancer would produce a compound that enhances the response of endogenous activation of adenosine receptors and also scavenges oxygen-based free radicals in the body. Consequently, a second aim of this project was to synthesise a series of allosteric enhancers of the A1 adenosine receptor that possessed antioxidant capability endowed by a nitroxide or a phenolic antioxidant functionality.
 
 
 
 This project has resulted in the synthesis and characterisation of 19 novel N6 substituted adenosine analogues, and additionally 12 novel derivatised thiophenes. Each of the target compounds was tested for its ability to bind to each of the adenosine receptor subtypes and some analogues were found to be potent and selective adenosine receptor agonists.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">Adenosine</field><field name="subject">adenosine receptor</field><field name="subject">allosteric enhancer</field><field name="subject">antioxidant</field><field name="subject">BHT</field><field name="subject">chemistry</field><field name="subject">nitroxide</field><field name="subject">radical</field><field name="subject">synthesis</field><field name="subject">thiophene</field><field name="identifier">http://eprints.qut.edu.au/16629/</field><field name="validLink">False</field></doc><doc><field name="title">It made you feel what?  Using structure to convey theme : playscript and exegesis</field><field name="creator">Grossetti, Adam Gordon</field><field name="description">The exegesis and accompanying playscript 3606202 is concerned with how the structural framework of a play might be manipulated to help deliver a writer's response to global events. The exegesis looks at examples of writers who have responded to global events over the last several decades and examines as a case study the structure of Caryl Churchill's play Far Away. The writer then applies a similar structural blueprint to the writing of his play 3606202 and reflects on the outcomes such a structure achieved. As part of this reflection, the exegesis explores how the writer's desire to respond to global events led him to consider the impacts of structure on the sub-textual articulation of themes within a playscript. The exegesis concludes by detailing the findings of an experiment conducted at the reading of his play and its professional presentation within the Wharf2Loud season at the Sydney Theatre Company.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">playwriting</field><field name="subject">structure</field><field name="subject">theme</field><field name="subject">Caryl Churchill</field><field name="subject">political theatre</field><field name="identifier">http://eprints.qut.edu.au/16630/</field><field name="validLink">True</field></doc><doc><field name="title">Living lens: exploring interdependencies between performing bodies, visual and sonic media in immersive installation</field><field name="creator">Verdaasdonk, Maria Adriana</field><field name="description">Living Lens is a practice-led study that explores interdependencies between performing bodies, visual images and sonic elements through two main areas of investigation: the propensity for the visual mode to be dominant in an interdisciplinary performance environment; and, a compositional structure to integrate performing bodies, visual and sonic elements. To address these concerns, the study necessitated a collaborative team comprising performers, visual artists, sound designers and computer programmers. The poetic title, Living Lens, became an important interpretative device and organising principle in this study, which is weighted 70% for the creative work and 30% for the written component. Working from an experiential and emergent methodology, the research employed two iterative cycles of development. Drawing on a previous work, Patchwork in Motion (2005), the extraction of one fragment entitled Living Lens (2005-6) was selected for further development, specifically to balance the relationship between performers and visual media with a deeper focus on the sonic component. The initial creative development (June-July 2005) addressed the area of interdependencies through the concepts of "poetic felt space" and "living painting", whilst the final stage of the study (June-July 2006) adopted the concept of "worlds within worlds" to facilitate greater contrast and connectivity in the piece. The final performance made partial progress towards shifting visual dominance and the development of an integrative structure, the digital media serving to enhance tangible connections between aural, visual and kinesthetic senses. As an immersive performance installation, the study thus adapts and extends painterly and sculptural sensibilities into a contemporary and interactive arts setting. Presenting a case for the personalised position of the practitioner voice, the study also offers practical and conceptual insights and solutions, to be adopted, adapted or applied tangentially, by other practitioners and researchers working in the domains of body movement practices, visual and sonic arts and human communication technologies.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">performer-media interdependencies</field><field name="subject">immersive installation</field><field name="subject">poetic felt space</field><field name="subject">living painting</field><field name="subject">multi-sensory</field><field name="subject">butoh</field><field name="subject">dance/movement</field><field name="subject">body-as-texturiser</field><field name="subject">embodied visualisation</field><field name="subject">visual imagery</field><field name="subject">digital collage</field><field name="subject">sound palette</field><field name="subject">adaptable clusters</field><field name="subject">interactivity</field><field name="identifier">http://eprints.qut.edu.au/16631/</field><field name="validLink">True</field></doc><doc><field name="title">It's all a plot : an examination of the usefulness of the popularly accepted structural paradigm in the practice of writing of a feature film script</field><field name="creator">Morris, Anthony Kevin</field><field name="description">This study took the widely-accepted, &#8216;industry standard&#8217; Structural Paradigm of feature film plotting, and &#8216;road tested&#8217; it, assessing its value as a tool in the process of actually writing a feature film script.  The methodology employed was to write a feature film script (titled THE ARM THAT DOES THE HARM) and look to apply the Paradigm to the writing process.  Journals recording the process were kept and peer assessment undertaken.  The data from these sources was then analysed and conclusions drawn.
 
 
 
 The reason for and value of this study are that, while this Paradigm is widely espoused by screenwriting gurus, taught as part of film courses and applied as a tool of script assessment and review, there is very little documented evidence of its actual value to the practice of writing a script.  My findings revealed that, though a useful reference point throughout, the Paradigm is most valuable during the early stages of story structuring and again, most particularly, when editing later drafts.  
 
 
 
 An important outcome of this study was that it identified the Paradigm as a valuable tool, not a rule that must be adhered to, a series of points a narrative must be seen to &#8216;hit&#8217; in order for it to be considered to have been told correctly.  Further, this study demonstrated in practice how this tool can be applied.  This study suggests that trying to force an evolving story into the confines of the Paradigm can inhibit the story from developing &#8216;organically&#8217; from its characters.  Rather, the Paradigm should be applied as a tool for helping shape stories that first and foremost should be character-driven.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">scriptwriting</field><field name="subject">film structure</field><field name="subject">story structure</field><field name="subject">film plotting</field><field name="identifier">http://eprints.qut.edu.au/16632/</field><field name="validLink">True</field></doc><doc><field name="title">Modelling hydrodynamic processes within Pumicestone Passage, Northern Moreton Bay, Queensland</field><field name="creator">Larsen, Genevieve Ruth</field><field name="description">Estuaries can be considered as vital natural resources and are unique ecosystems at the interface between terrestrial and marine environments. The increase of population density centred on these coastal features and associated anthropogenic activities such as trade, industry, agriculture and recreation can adversely affect these sensitive environments.  The Pumicestone Passage, located in northern Moreton Bay, Australia, is one such estuarine environment where there are concerns about degradation of water quality resulting from rapid land use change. These changes are both immediate to the Passage and within its wider catchment. Of notable concern are the outbreaks of Lyngbya (a toxic blue-green algae) in the Passage itself and near its interface with Deception Bay to the south. Other factors of concern are increased suspended and dissolved loads, and maintenance of ecosystem integrity.  In this study, numerical modelling, graphical methods and water surface elevation and current velocity parameter calculations are used to describe hydrological processes in the Pumicestone Passage. A hydrodynamic model is developed using the modelling software SMS and RMA2 as a foundation for future hydrodynamic and water quality modelling. In addition, observed data are used to interpret general hydrodynamic behaviour in the passage, and determine various parameters for use in model development and calibration. Tidal prediction is also discussed and used for model calibration.  To support the modelling and for preliminary interpretation of hydrodynamic processes within the Passage, measurements were made in the field of (a) water surface elevation variation at 17 sites; (b) tidal current velocities in four of the tributary creeks and at the northern boundary; (c) volumetric flow rates at two cross-sections within the Passage; and (d) cross-sectional bathymetry at sites where tidal current velocities were measured in the creeks.  In general, examination of the observational data reveals a number of important processes in the Pumicestone Passage. Almost all sites within Pumicestone Passage and its tributaries are flood dominant indicating that tidal storage and bottom friction effects are significant. Mesotidal ranges occur at sites close to the southern boundary of the passage, however, bottom friction greatly reduces the tidal response at the remaining sites which results in microtidal ranges. The influence of both the southern and northern tides can be seen in the deformation of tidal waveforms in the central passage. Extensive intertidal areas at and inside the northern inlet to the Passage markedly reduce tidal ranges in the northern estuary and its tributary creeks.  Issues involved in hydrodynamic model development and performance are discussed. Overall, model results for the southern estuary have satisfactory correlation with observed data whereas model results for the northern estuary are less satisfactory. In addition, water surface elevation variation model results are generally more accurate than tidal current velocity model results. Reasons for the differences between model and observed values are considered and possible solutions given. Factors discussed relate to boundary condition locations, resolution of bathymetric and geographical data, mesh development methods and parameter assignment.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">estuary</field><field name="subject">hydrodynamic modelling</field><field name="subject">harmonic analysis</field><field name="subject">tidal prediction</field><field name="subject">RMA2</field><field name="subject">Pumicestone Passage</field><field name="subject">tides</field><field name="subject">tidal currents</field><field name="identifier">http://eprints.qut.edu.au/16634/</field><field name="validLink">True</field></doc><doc><field name="title">Screening and identification of dehydration in older people admitted to a geriatric and rehabilitation unit</field><field name="creator">Vivanti, Angela Patricia</field><field name="description">The diagnosis of dehydration in the older person admitted to hospital has been associated with increased morbidity and mortality. In spite of the high US hospital mortality and morbidity rates associated with dehydration (although presumably not the only contributing factor), no standardised or validated approach to assess or easily screen for dehydration in the hospital setting is reported in the international literature. Therefore, a series of studies was undertaken to assess the extent of this, and to identify other gaps in the current literature. The first study estimated the dehydration prevalence amongst older people upon admission to geriatric and rehabilitation unit in the Australian setting to estimate the morbidity burden in the Australian context. The second study assessed the application of dilution and bio-electrical impedance (BIA) techniques as alternative means to assess dehydration in the clinical setting. The third study undertook to validate against total body water the parameters required to confirm dehydration and to identify those that contribute little to discrimination. The final study integrated the information from the first two studies to identify a clinically practical, sensitive and specific screen suitable for the identification of those at risk of dehydration in a geriatric and rehabilitation unit. Older people aged 60 years or over admitted to the Geriatric and Rehabilitation Unit (GARU) of a tertiary teaching hospital in Brisbane. Australia, were eligible for participation in the study. Individuals were excluded if: involuntarily admitted, informed consent was not obtained, younger than 60 years or fitted with a pacemaker (due to contraindication with the use of BIA). Of 82 GARU participants approached, 43 fulfilled the inclusion criteria and consented, 21 declined and 18 were ineligible. Thirty-five (35) of the 43 were able to be involved in the assessment of prevalence. The studies in this thesis provide original insights into dehydration including prevalence, body water contents, useful clinical assessment and screening parameters. Results showed that dehydration prevalence amongst older people is substantially underreported in the Australian geriatric and rehabilitation unit setting (17.1%) when compared to the reported through coding from the medical record (5.3%). The presence of dehydration has frequently been measured in healthy populations by assessing total body water loss through short-term weight change. Gold standard dilution and bio-electrical impedance techniques were used to assess body water as the assessment of dehydration by weight change has practical and ethical limitations in the clinical setting for either research or assessment applications. Gold standard dilution studies and the bio-electrical impedance technique were not confirmed to be either practical or valid alternates to assess dehydration in the clinical setting. Weight and body mass index (BMI) confounded the association between body water and dehydration. Good agreement (78-87%) of global clinical dehydration assessment (clinical assessment) was confirmed between the study's medical officer and the consultants of the Geriatric and Rehabilitation Unit (GARU) and thus become the alternate dependant variable. Although the optimal combination of parameters for clinical dehydration assessment was unable to be elucidated, clinically significant changes upon mild dehydration were more apparent with physical as opposed to biochemical parameters. BMI confounded the association between dehydration and some physical measurements, such as the drop in systolic blood pressure on standing and skin turgor. Of all the clinical assessment and screening variables explored, tongue dryness was validated and represents a practical, sensitive (64%) and specific (62%) dehydration screen suitable for use with all older people in a geriatric and rehabilitation unit setting. Dehydration was established to be more prevalent amongst older Australians admitted to hospital than previously acknowledged or identified by hospitals. The finding identifies dehydration as a significant clinical issue considering the ageing Australian population, limited health resources and the association of dehydration with increased morbidity and mortality. The validation of the simple dehydration screen will contribute to the identification and treatment of dehydration. Although the highest sensitivity and specificity is always desired for screening, it is not always achieved. Moderate sensitivity results in more people being identified at risk by the screen than confirmed to be dehydrated through clinical assessment. Moderate specificity results in the screen's failure to identify those who would be clinically assessed with dehydration. Moderate sensitivity and specificity necessitates the assessment of more people than those with the condition and results in other people with the condition of interest not being identified. Each situation is reduced with increasing levels of sensitivity and specificity. A valid and simple dehydration screen provides future opportunities to confirm improved clinical (prevent adverse events, improve or stabilise disease), cost (reduce intensity of care, hospital stay) and client (death, disability) outcomes as a result of improved identification and timely and appropriate treatment. New insights are provided into individual clinical assessment measures as well as valid and reliable screening. A number of recommendations and future dehydration studies are discussed. The key recommendation for future studies is to discern between intracellular and intravascular volume depletion to enable investigation of an homogenous sample. Further studies are needed to also establish optimal dehydration prevention methods (e.g. awareness and positioning of fluids, beverage carts) and provide evidence that hydration support enhances primary (e.g. morbidity and mortality) and secondary (e.g. cognitive or functional measures, quality of life) health outcomes. Through responsive systems in health delivery, dehydration amongst older hospitalised people can be identified, better managed if present, and avoided with suitable treatment.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">dehydration</field><field name="subject">hypovolaemia</field><field name="subject">hypovolemia</field><field name="subject">old</field><field name="subject">older</field><field name="subject">elderly</field><field name="subject">age</field><field name="subject">aged</field><field name="subject">screen</field><field name="subject">screening</field><field name="subject">tool</field><field name="subject">screening tool</field><field name="subject">clinical</field><field name="subject">assessment</field><field name="subject">dehydration assessment</field><field name="identifier">http://eprints.qut.edu.au/16635/</field><field name="validLink">True</field></doc><doc><field name="title">An intrusion detection system for supervisory control and data acquisition systems</field><field name="creator">Hansen, Sinclair D.</field><field name="description">Despite increased awareness of threats against Critical Infrastructure (CI), securing of Supervisory Control and Data Acquisition (SCADA) systems remains incomplete. The majority of research focuses on preventative measures such as improving communication protocols and implementing security policies. New attempts are being made to use commercial Intrusion Detection System (IDS) software to protect SCADA systems. These have limited effectiveness because the ability to detect specific threats requires the context of the SCADA system. SCADA context is defined as any information that can be used to characterise the current status and function of the SCADA system. In this thesis the standard IDS model will be used with the varying SCADA data sources to provide SCADA context to a signature and anomaly detection engine. A novel addition to enhance the IDS model will be to use the SCADA data sources to simulate the remote SCADA site. The data resulting from the simulation is used by the IDS to make behavioural comparison between the real and simulated SCADA site. To evaluate the enhanced IDS model the specific context of a water and wastewater system is used to develop a prototype. Using this context it was found that the inflow between sites has similar diurnal characteristic to network traffic. This introduced the idea of using inflow data to detect abnormal behaviour for a remote wastewater site. Several experiments are proposed to validate the prototype using data from a real SCADA site. Initial results show good promise for detecting abnormal behaviour and specific threats against water and wastewater SCADA systems.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Information security</field><field name="subject">supervisory control and data acquisition (SCADA)</field><field name="subject">intrusion detection system (IDS)</field><field name="subject">remote telemetry device (RTU)</field><field name="subject">anomaly detection</field><field name="subject">signature detection</field><field name="identifier">http://eprints.qut.edu.au/16636/</field><field name="validLink">True</field></doc><doc><field name="title">The role of the registered nurse in Taiwanese nursing homes : a grounded theory study</field><field name="creator">Lin, Chun-Chih</field><field name="description">The global trend towards an ageing population presents challenges for  health-care professionals, including registered nurses (RNs). In Taiwan,  health care policies relating to the aged and to gerontological nursing are still  in the early stages of development. Integral to this development is the  evolving definition of the clinical role of RNs who make a major contribution  to aged care. Using data from in-depth interviews of 29 RNs working across  eight nursing homes, this grounded theory study examines the factors that  shape the care work of RNs in long-term aged care in Taiwan.  The objectives of this study were to:  * examine the work-experience perceptions of RNs employed in nursing  homes in Taiwan  * explore the factors that influence the delivery of nursing care to the  aged by RNs  * explain the events that constitute nursing practices in aged care  provision that have an effect on the roles of RNs, and  * develop a theoretical proposition that can guide future nursing practice  in aged care.  Grounded theory and symbolic interactionism are the complementary  methodologies selected to underpin this study. The perspective of grounded  theory allows for a critical investigation of the social processes that are  integral in shaping the perspectives of RNs who work in Taiwanese nursing homes. The application of the theory of symbolic interactionism facilitates an  exploration of the roles of RNs in this context and of the different meanings  for individuals in the various situations they confront. Organizational factors  and interactions that shape the role of RNs in the working environment of  aged care are highlighted in the interaction between the data and the theory.  The core category that emerged from the study was searching for an identity.  This core process reflects ambivalence in the perceptions of RNs in  describing and explaining the nursing role in Taiwanese nursing homes. Five  categories that bring some greater understanding of this ambivalence are:  coming to know, doing anything and everything, negotiating the work role,  dealing with the system, and learning by being there.  The specific intention of this study was to extend our understanding of  nursing work and the delivery of care to older people in nursing homes in  Taiwan. The findings of this study will contribute to the development of an  educational framework that may be applied to improve nursing practices in  nursing homes. These findings also have the potential to make a positive  contribution to aged health care policy-making in Taiwan.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">aged care</field><field name="subject">nursing home</field><field name="subject">registered nurse</field><field name="subject">work role</field><field name="subject">Taiwan</field><field name="subject">grounded theory</field><field name="subject">symbolic interactionism</field><field name="identifier">http://eprints.qut.edu.au/16637/</field><field name="validLink">True</field></doc><doc><field name="title">Neo-liberalism and health care</field><field name="creator">Ruthjersen, Anne Linda</field><field name="description">Neo-liberal political-economic ideology, theory and practice have had an immense influence on public and private life across the world, including the delivery of health care, and neo-liberalism has become the dominant economic paradigm. Market practices, business management theories and practices, and private enterprise have become increasingly significant in health care, as the welfare state and public health services have been challenged by factors such as rising costs, economic efficiency, globalisation and increasing competitive demands. The question of how, and to what extent, neo-liberalism has influenced contemporary health care is, however, deserving of more critical attention.    This thesis examines the neo-liberal approach to, and effect on, contemporary health care, in the context of Western developed countries, and offers a conceptual analysis of the theoretical and ideological framework of neo-liberalism, especially regarding its ethical and moral underpinnings. Additionally, this thesis is concerned with the moral nature of health care.  The objectives of this thesis are to articulate and analyse the neo-liberal interpretive framework, moral values and language; and to articulate and analyse the neo-liberal approach to, and effect on, contemporary health care. Thus, it is the intention that this thesis will provide a framework for reflection on the context of contemporary health care in Western developed countries and the influence of neo-liberalism. To achieve these objectives, the research strategy of this thesis is that of philosophical inquiry, additionally drawing on political philosophy; and the research is, therefore, basic, theoretical research.    This thesis finds that neo-liberalism, and the neo-liberal approach to health care, is a highly complex theory and ideology, constituted of several intricate concepts and moral underpinnings. It is found that the neo-liberal approach affects the nature and purpose of health care, for example by making health care part of the free, competitive market, by commodifying health care, and by replacing the notions of the common good, social justice and public health care with an emphasis on the rational, self-interested consumer, individual responsibility and self-sufficiency. Another essential aspect of the neo-liberal approach is that it emphasises the ability to pay (user-pays system), rather than health care need, as the dominant determinant in health care. Furthermore, this thesis finds that the neo-liberal ideology excludes the ontological complexity and reality of the human condition, and in health care this has consequences in relation to, for example, interdependency, interrelationships, vulnerability and need.    In essence, this thesis finds that there are several pragmatic and moral problems with applying a neo-liberal approach to health care, and that the complexities, irregularities, and unpredictability of health care make a neo-liberal approach difficult to realise in health care. The neo-liberal approach undermines the moral purposes of health care, and it is concluded that the neo-liberal approach offers no well-founded moral alternative to the universalistic, solidarity based approach common in most Western developed countries (except in the United States).    This thesis seeks to add to the knowledge and literature concerning neo-liberalism, especially as regards its moral underpinnings and normative framework, and, furthermore, concerning the neo-liberal approach to, and effect on, contemporary health care in Western developed countries. Additionally, this thesis seeks to contribute to the knowledge of philosophical inquiry by documenting the method of 'doing' philosophical inquiry. Based on the research in this thesis, it is clear that there is a need for more empirical research into the pragmatic consequences of applying neo-liberal policies and practices to health care, and the analysis in this thesis could favorably serve as a basis for empirical inquiry.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">neo-liberalism</field><field name="subject">free market</field><field name="subject">health care</field><field name="subject">philosophical inquiry</field><field name="identifier">http://eprints.qut.edu.au/16638/</field><field name="validLink">True</field></doc><doc><field name="title">IGF:VN complexes and their role in breast cell migration</field><field name="creator">Hollier, Brett G.</field><field name="description">Members of the insulin-like growth factor (IGF) family are mitogenic growth factors which have been shown to play critical roles in both normal growth and development, and tumour biology. The IGF system is complex and the biological effects of the IGFs are determined by diverse interactions between many molecules, including interactions with the extracellular matrix (ECM). Recent observations have demonstrated that IGFs can associate with the ECM protein vitronectin (VN) and this interaction can modulate IGF-stimulated biological functions. It has been demonstrated previously that IGF-II can bind directly to VN, while IGF-I associates with VN indirectly via the involvement of IGF-binding proteins (IGFBPs) -2, -3, -4 and -5. As the IGF system plays important roles in both normal breast development and in the transformation and progression of breast cancer, this study aimed to describe the effects of substrate-bound IGF-I:IGFBP:VN complexes on breast cell functions and to dissect the mechanisms underlying these responses. The studies reported in this thesis demonstrate that substrate-bound IGF-I:IGFBP:VN complexes, containing IGFBP-3 and IGFBP-5, are  potent stimulators of proliferation and migration in the "normal", non-tumourigenic MCF-10A breast epithelial and MCF-7 breast carcinoma cell lines. Interestingly, substrate-bound IGF-I:IGFBP:VN complexes were less effective in increasing the migration of the metastatic MDA-MB-231 breast cancer cell line. This, however, is due to these cells expressing the &#945;v&#946;3 integrin which can support a highly migratory phenotype independent of IGF-I-stimulation. Taken together this suggests a particularly important role for these complexes in stimulating a highly migratory phenotype in pre-invasive or poorly metastatic breast cells.  Studies using IGF-I analogues were also undertaken to establish if there was a requirement for ternary complex formation and the type-1-IGF receptor (IGF-1R) in the enhanced migration responses observed. These studies determined IGF-I:IGFBP:VN-stimulated migration to be dependent upon both heterotrimeric IGF-I:IGFBP:VN complex formation and activation of the IGF-1R. Furthermore, the enhanced cellular migration was abolished upon incubation of MCF-7 and MCF-10A cells with function blocking antibodies directed at VN-binding integrins and the IGF-IR. In addition, analysis of the signal transduction pathways underlying the enhanced cell migration revealed that the complexes stimulate a transient activation of the ERK/MAPK signaling pathway, while simultaneously producing a sustained activation of the PI3-K/AKT pathway. Optimal intracellular signaling required activation of both the IGF-1R and VN-binding integrins, as antibody mediated inhibition of either receptor led to substantial decreases in both ERK/MAPK and PI3-K/AKT pathway activation. Furthermore, experiments using pharmacological inhibitors of these pathways determined a pivotal role for PI3-K/AKT activation in substrate-bound IGF-I:IGFBP:VN-stimulated cell migration. In order to confirm an important role for the PI3-K/AKT pathway in these responses, wild-type and activated-AKT was transiently overexpressed in MCF-10A cells. Overexpression of both wild-type and activated-AKT further enhanced cellular migration in response to substrate-bound IGF-I:IGFBP:VN complexes. However, these responses still required co-activation of the IGF-1R and VN-binding integrins. In an attempt to obtain a global view of the possible molecular mechanisms underpinning IGF-I:IGFBP:VN-stimulated cell migration, oligonucleotide microarrays were used to screen for candidate genes important for the observed migratory responses. The microarray studies identified 165 genes which were differentially expressed in cells migrating in response to substrate-bound IGF-I:IGFBP:VN complexes. Gene ontology and functional analysis revealed many of these genes to be significantly associated with biological functions relevant to cancer transformation and progression, including cell growth and proliferation, cell death and cellular movement. In regard to cell migration, a number of the genes identified have previously reported roles in cellular movement, migration and metastasis, which may provide future targets to augment IGF-I:IGFBP:VN-stimulated cell migration. Taken together, the studies reported throughout this thesis have provided the first mechanistic insights into the action of IGF-I:IGFBP:VN complexes and add further evidence to support the involvement of VN-binding integrins and their co-operativity with the IGF-IR in the promotion of tumour cell migration. Importantly, identifying the molecular mechanisms by which IGF:VN complexes enhance breast cell function will lead to not only a better understanding of this critical interaction, but also aid in developing diagnostic tests and therapeutics directed at treating breast cancer.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">IGF</field><field name="subject">mitogenic growth factors</field><field name="subject">tumour</field><field name="subject">cancer</field><field name="subject">breast cancer</field><field name="subject">VN-binding integrins</field><field name="subject">IGF-IR</field><field name="subject">cancer cell migration</field><field name="identifier">http://eprints.qut.edu.au/16639/</field><field name="validLink">True</field></doc><doc><field name="title">Shop local : building a 'local' tribe through consumption experiences in servicescapes</field><field name="creator">Hall, Michelle Louise</field><field name="description">The notion of community remains an important concern, for individuals, in urban planning practice, and more recently in consumer research. This thesis research explores community at the junction of these areas, through a grounded study of the consumption practices of a place based consumer tribe that exists within an inner city suburb undergoing urban renewal. The process of urban renewal is positioned as a means to revitalise under-utilised inner city areas, and broaden opportunities for city residents and visitors to experience an inner city lifestyle. It can also be seen as a standardising project that commodifies diversity and devalues existing communities and is associated with gentrification. Both perspectives can obscure the possibility that consumption practices can be used to build community like connections. This thesis applies a framework of literature from marketing and consumer research to an urban renewal context, to explore this area of ambiguity. The result of this exploration is a grounded theory of assuming a 'local' identity through consumption experiences in servicescapes. This thesis argues that consumers seek out individual servicescapes for the value experiences that they offer, which can be identity defining. In particular the interaction generated through these experiences can work to build tribal connections to, and within, that servicescape. These consumption experiences can also be used to make assumptions regarding the identity of others; both of the businesses themselves, and the individuals encountered within them. The tribal connections these experiences may generate can have individual benefits in that they can build into existing social networks, but through repetition and shared experiences, may also link an individual to a broader place based community. This thesis also proposes that servicescapes can work to encourage this process, by encouraging identity defining consumption experiences. Like individuals, businesses can come to be assumed to be tribe members and this 'localness' can become a symbolic operant resource that is valued by the tribe. As key sites in which members of the 'local' tribe reinforce their commitment to the tribe, locally owned businesses may benefit by being more likely to be chosen over their 'non-local' competitors. However, as an element of their tribal membership these businesses have a moral responsibility to reinforce the collective ethic of the tribe and assist in integrating new tribe members. In this way they can become ambassadors for the identity of the community, communicating the shared values of the tribe to members and non-members alike. Such a place based tribe is primarily based on public interaction, thus the servicescapes and public spaces that link them can come to work as a theatre in which the tribe is manifested and its rituals performed. As the experience of a sense of shared value is repeated across a range of geographically united servicescapes, this shared experience can be displaced from any one servicescape and generalised into a localness experience that is grounded within the geographic community. It is here that the physical and ideological aspects of the community combine, and the experienced value of a shared identity that originated in a servicescape based consumption experience can come to symbolise the values of the greater community itself. These research findings have implications for inner city urban renewal developments, suggesting that the increased availability of consumption activities that are associated with urban renewal may also be considered as an increased opportunity to build place based consumer tribes. This thesis proposes ways of encouraging this process.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Brisbane</field><field name="subject">community</field><field name="subject">consumer experiences</field><field name="subject">consumer research</field><field name="subject">consumer tribes</field><field name="subject">consumer value</field><field name="subject">consumption</field><field name="subject">gentrification</field><field name="subject">identity</field><field name="subject">servicescapes</field><field name="subject">urban renewal</field><field name="subject">West End</field><field name="identifier">http://eprints.qut.edu.au/16640/</field><field name="validLink">True</field></doc><doc><field name="title">Section 24 of the criminal code : navigating veracity and verisimilitude in verbatim theatre</field><field name="creator">Faulkner, Natalie</field><field name="description">This research project comprises a stage play Section 24 of the Criminal Code, and accompanying exegesis, which focuses upon the experience of a woman accessing the Criminal Justice system after she is raped. The play is in the verbatim model and draws upon court transcript, which is deconstructed to reveal the workings of Defence counsel 'storylines' and meta-narratives of gender, sexual availability and power. The exegesis investigates attitudes toward rape and rape victims perpetuated by Australian popular culture, and the way that myths about false rape complaints and 'deserving victims' continue to influence the reporting and conviction rates for rape. The thesis argues that recent reforms have yet to make an impact on the conviction rate or experience of women accessing the Justice system, because of entrenched misogyny within the system itself. Several factors contribute to widespread ignorance of the reality of our own Criminal Justice system, and the thesis proposes that a work of verbatim theatre may redress the paucity of understanding that enables the dysfunction of the current system. The paper explores the different approaches taken by Verbatim theatre practitioners and the appropriateness of the Verbatim theatre model for communicating this particular (lived) experience. Questions of ownership over one's story, and representation in that story indicate the emancipatory potential of a work. Where practitioners do not have a personal connection to their subject matter or material and access material that is already in the public domain, they may feel a greater freedom to manipulate story and character for dramatic effect, or to suit an activist agenda for change. It is shown that a playwright with a personal connection to her material and subject must address issues of ownership, ethical representation, veracity and verisimilitude when creating a piece of verbatim theatre. Preferencing the truth of the Complainant Woman's experience over the orthodoxies of the well-made play may contribute to a negative response to the work from male audiences. However, the thesis concludes that the subject of rape and its prosecution invokes a gendered response in itself, and ultimately questions the desirability of presenting a play that delivers a palatable story rather than an unpleasant truth.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Verbatim theatre</field><field name="subject">transcript theatre</field><field name="subject">Australian Justice system</field><field name="subject">rape and sexual assault</field><field name="subject">deserving victim</field><field name="subject">false rape</field><field name="subject">autobiography</field><field name="subject">testimonio</field><field name="subject">life history</field><field name="subject">feminist theatre</field><field name="subject">playwrighting</field><field name="subject">practice as research.</field><field name="identifier">http://eprints.qut.edu.au/16641/</field><field name="validLink">True</field></doc><doc><field name="title">NLPX : a natural language query interface for facilitating user-oriented XML-IR</field><field name="creator">Woodley, Alan Paul</field><field name="description">Most information retrieval (IR) systems respond to users' representation of their information needs (queries) with a ranked list of relevant results, usually text documents. XML documents di er from traditional text documents by explicitly separating structure and content. XML-IR systems aim to exploit this separation by searching and retrieving relevant components of documents (called elements) rather than entire documents   thereby, better ful lling users' information needs. Despite the potential bene t of XML-IR systems, most research in this area has not been centered on the needs of users. In particular, current XML-IR query formation interfaces, namely keywords-only and formal language, are not able to optimally address the needs of users. Keywords-only interfaces are too unsophisticated to fully capture the users' complex information needs that contain both content and structural requirements. In contrast, while formal languages are able to capture users' content and structural requirements they are too di cult to use, even for experts, and are too closely tied to the physical structure of the collection. This thesis presents a solution to these problems by presenting NLPX, a natural language interface for XML-IR systems. NLPX allows users to enter XML-IR queries in natural language and translates them into a formal language (NEXI) to be processed by existing XML retrieval systems. When evaluated by system testing, NLPX outperformed alternative translation approaches. When tested in a user-based experiment, NLPX performed comparably to a query-by-template interface, the baseline user-oriented interface for formulating structured queries. It is hoped that the outcomes of this thesis will help to refocus the  eld of XML-IR around the user. This will lead to the development of more useful XML-IR systems, which will hopefully result in the more widespread use of XML-IR systems.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">information retrieval systems</field><field name="subject">information needs</field><field name="subject">XML-IR systems</field><field name="subject">NEXI</field><field name="subject">NLPX</field><field name="identifier">http://eprints.qut.edu.au/16642/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis and characterisation of substituted smithsonite and calcite</field><field name="creator">Hales, Matthew Cameron</field><field name="description">Carbonate minerals play a very important role in nature, they represent some of the most diverse and common mineral species on the Planet. They are directly involved in the carbon dioxide (CO2) cycle acting as relatively stable long term chemical storage reservoirs, moderating both global warming trends and oceanaquatic chemistry through carbonate buffering systems. A range of synthetic metal carbonates have been synthesised for analysis under multiple experimental conditions, in order to study the variation in physical and chemical properties such as phase specificity, metal substitution, hydration/hydroxy carbonate formation under varying partial pressures of CO2 and thermal stability. Synthetic samples were characterised by a variety of instrumental analysis techniques in order to investigate chemical purity and phase specificity. Some of the techniques included, vibrational spectroscopy (IR/Raman), thermal analysis (TGA-MS) (thermal Raman), X-Ray diffraction (XRD) and electron microscopy (SEM-EDX). From the instrumental characterisation techniques, it was found that single phase smithsonite, hydrozincite, calcite and nesquehonite could successfully be synthesised under the conditions used. Minor impurities of other minerals and / or phases were found to form under specific chemical or physical conditions such as in the case of hydrozincite / simonkolleite if zinc chloride was used during hydrothermal synthesis.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Raman</field><field name="subject">Infrared</field><field name="subject">IR</field><field name="subject">spectroscopy</field><field name="subject">characterisation</field><field name="subject">synthesis</field><field name="subject">synthetic</field><field name="subject">natural</field><field name="subject">scanning electron microscopy</field><field name="subject">SEM</field><field name="subject">thermo-gravimetric analysis</field><field name="subject">mass spectroscopy</field><field name="subject">TGA-MS</field><field name="subject">X-Ray diffraction</field><field name="subject">XRD</field><field name="subject">carbonate</field><field name="subject">hydrogen carbonate</field><field name="subject">hydroxy</field><field name="subject">hydrate</field><field name="subject">minerals</field><field name="subject">crystal</field><field name="subject">point group</field><field name="subject">factor group</field><field name="subject">phase</field><field name="subject">symmetry</field><field name="subject">elements</field><field name="subject">calcite</field><field name="subject">magnesite</field><field name="subject">aragonite</field><field name="subject">vaterite</field><field name="subject">aurichalcite</field><field name="subject">azurite</field><field name="subject">malachite</field><field name="subject">hydrozincite</field><field name="subject">zincite</field><field name="subject">nesquehonite</field><field name="subject">strontianite</field><field name="subject">witherite</field><field name="subject">oxide zone</field><field name="subject">partial pressure</field><field name="subject">carbon dioxide</field><field name="subject">CO2</field><field name="subject">geological</field><field name="subject">settling</field><field name="subject">coral</field><field name="subject">geo-sequestration</field><field name="subject">green house gas</field><field name="identifier">http://eprints.qut.edu.au/16643/</field><field name="validLink">True</field></doc><doc><field name="title">Parallel training algorithms for analogue hardware neural nets</field><field name="creator">Zhang, Liang</field><field name="description">Feedforward neural networks are massively parallel computing structures that have the capability of universal function approximation. The most prevalent realisation of neural nets is in the form of an algorithm implemented in a computer program. Neural networks as computer programs lose the inher- ent parallism. Parallism can only be recovered by executing the program on an expensive parallel digital computer. Achievement of the inherent massive parallelism at a lower cost requires direct hardware realisation of the neural net. Such hardware has been developed jointly by QUT and the Heinz Nixdorf Institute (Germany) called the Local Cluster Neural Network (LCNN) chip. But this neural net chip lacks the capability of in-circuit learning or on-chip training. The weights for the analogue LCNN network have to be computed o&#174; chip on a digital computer. Based on the previous work, this research focuses on the Local Cluster Neu- ral Network and its analogue chip. The characteristic of the LCNN chip was measured exhaustively and its behaviours were compared to the theoretical functionality of the LCNN. To overcome the manufacturing &#176;uctuations and deviations presented in analogue circuits, we used chip-in-the-loop strategy for training of the LCNN chip. A new training algorithm: Probabilistic Random Weight Change for the chip-in-the-loop training for function approximation. In order to implement the LCNN analogue chip with on-chip training, two training algorithms are studied in on-line training mode in simulations: the Probabilistic Random Weight Change (PRWC) algorithm and the modified Gradient Descent (GD) algorithm. The circuits design for the PRWC on-chip training and the GD on-chip training are outlined. These two methods are compared for their training performance and the complexity of their circuits. This research provides the foundation for the next version of LCNN analogue hardware implementation.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">neural networks</field><field name="subject">parallism</field><field name="subject">parallel computing</field><field name="subject">LCNN</field><field name="identifier">http://eprints.qut.edu.au/16644/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation of the use of CALL by college english teachers : perspectives in a Chinese normal university</field><field name="creator">Xiong, Xing</field><field name="description">Technology innovations have occurred in schools all over the world to accommodate Computer Assisted Language Learning (CALL). In 2004, a national reform was initiated by the Ministry of Education in China which aimed to improve the teaching of College English curriculum by adopting modern technologies. Since then, Chinese College English teachers have been adapting to CALL. This research project presents a case study of one Chinese university, Huazhong Normal University (HZNU). It investigates how CALL is currently used by the College English teachers and the problems teachers are having in using CALL. This study focuses on teachers&#8217; use of, and perspectives on, CALL. Data were collected by two means: a questionnaire involving 31 respondents, and five in-depth interviews concerning several aspects of the College English teachers&#8217; use of CALL in HZNU. Results showed that even with a broad introduction of modern technologies in College English teaching, most of the teachers in HZNU were using computers in a limited way. Most of them lacked a clear understanding of what CALL is and what CALL can do. As well, the results indicated that the professional development in CALL for College English teachers has been insufficient both in terms of techniques and pedagogies in technology. The study indicates further obstacles to College English teachers&#8217; use of CALL, such as insufficient technical support, heavy workloads and the difficulties adapting to the new teaching mode. The researcher recommends that these identified problems warrant immediate attention and she presents a model to guide the improvement of the use of CALL by College English teachers.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">CALL (Computer Assisted Language Learning)</field><field name="subject">China</field><field name="subject">college english teacher</field><field name="subject">innovation</field><field name="subject">investigation</field><field name="subject">perspective</field><field name="subject">normal university</field><field name="subject">technology</field><field name="identifier">http://eprints.qut.edu.au/16645/</field><field name="validLink">True</field></doc><doc><field name="title">Healing writes : restoring the authorial self through creative practice : and Birthright, a speculative fiction novel</field><field name="creator">Parv, Valerie</field><field name="description">Writing the speculative fiction novel, Birthright, and this accompanying exegesis, led me to challenge the validity of the disclaimer usually found in the front matter of most novels that the story is purely imaginary, bears no relationship to reality, with the characters not being inspired by anyone known or unknown to the author. For the first time in my career, I began to consider how writers including myself might frequently revisit themes and ideas which resonate with our lived experiences. I call this restorying, an unconscious process whereby aspects of one's life history are rewritten through one's creative work to achieve a more satisfactory result. Through personal contact, studying authors' accounts of their creative practices, and surveying current literature on narrative therapy, a case is made that, far from being generated purely from imagination, writers' creative choices are driven by an unconscious need to restory ourselves.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">alienation</field><field name="subject">author</field><field name="subject">authorial self</field><field name="subject">authorship</field><field name="subject">birthright</field><field name="subject">catharsis</field><field name="subject">creativity</field><field name="subject">creative writing</field><field name="subject">hindsight</field><field name="subject">idea</field><field name="subject">lived experience</field><field name="subject">narrative therapy</field><field name="subject">psychology</field><field name="subject">romance writing</field><field name="subject">storytelling</field><field name="subject">writing</field><field name="subject">David Alexander</field><field name="subject">Sherman Alexie</field><field name="subject">Aristotle</field><field name="subject">Foucault</field><field name="subject">Freud</field><field name="subject">Harlequin Mills &amp; Boon</field><field name="subject">Stephen King</field><field name="subject">Anne Lamott</field><field name="subject">Charles Mauron</field><field name="subject">Valerie Parv</field><field name="subject">Plato</field><field name="subject">Gene Roddenberry</field><field name="subject">Silhouette Books</field><field name="subject">Star Trek</field><field name="subject">Virginia Woolf</field><field name="identifier">http://eprints.qut.edu.au/16646/</field><field name="validLink">True</field></doc><doc><field name="title">Groundwater chemistry and hydrological processes within a Quaternary coastal plain: Pimpama, Southeast Queensland</field><field name="creator">Harbison, John Edwin</field><field name="description">The Pimpama estuarine plain in subtropical southeast Queensland is comprised of Quaternary sediments infilling older bedrock. These multilayered unconsolidated sediments have various depositional origins, and are highly heterogeneous. The plain is low-lying and the surface drainage is controlled by flood mitigation measures including tidal gates and channelised streams. The control of surface drainage potentially affects the shallow water table. This modification of hydrology has implications for future viability of agriculture and also the environmental health of waterways. Increased landscape modification and water management is likely in the coming years. The combination of sediment heterogeneity, low hydraulic gradients, and artificial drainage modification result in the plain being hydrogeologically complex. In order to understand hydrologic processes in this setting, a multi-disciplinary research programme was conducted which included a drilling program, overland electromagnetic induction and other geophysical surveys (downhole gamma log, electromagnetic induction and magnetic susceptibility) to initially establish the geologic framework. These surveys were followed by hydrogeochemical testing which includes for major and minor ions and also stable isotopes, and mineralogical analysis of drillhole material. Underlying basement rock occurs at up to 60 m depth. Unconsolidated gravel and sand deposits occur within incised paleo-valleys and are overlain by predominantly low-permeability fluvial sandy clays and estuarine and lagoonal muds. Fine-grained delta sands occur in the top 15 m of the sub-surface. Within the unconsolidated sediments, hydrodynamic trends clearly discriminated between upper unconfined and lower semi-confined aquifer systems. A comparison of surface water and shallow groundwater levels indicate limited interaction of groundwater and surface water. Hydrogeochemical analysis effectively distinguished between groundwater bodies, and also distinguished saline groundwater from seawater. Trends in major ion chemistry in the semi-confined system (particularly Na/Cl and Ca/Cl ratios) showed ion exchange accompanying saline intrusion. However, due to factors such as mineral dissolution, major ion chemistry does not clearly identify solute flux trends in the shallow aquifer system. Water stable isotope analysis (&#948;18O and &#948;2H) indicated the provenance of fresh and saline groundwater and also the relative importance of the principal hydrologic processes, i.e. evaporation and water uptake by plants. Groundwater exhibited a wide range in salinity, from very fresh to hypersaline. The formation of hypersaline groundwater was attributed largely to uptake of water by mangrove forests. Since mangrove forests were more extensive at the time of the Holocene maximum sea level (approximately 6,000 years ago) than at present, some of this groundwater may represent relict salinity from this earlier time. The relationship of relict salinity to low permeability sediments, particularly at intermediate depths, and their depositional history was examined. Vertical salinity gradients and hydrogeochemistry within these sediments varied according to position within the plain, suggesting deposition under various hydrological and sea level regimes. A preliminary investigation using analysis of stable sulfate isotopes (&#948;34S and &#948;18OSO4) was made. This study shows substantial potential for the application of this technique for quantification of solute flux and sulfur chemical transformations within settings such as this coastal plain. To establish shallow groundwater flow processes, a MODFLOW-based numerical model was used to inversely estimate aquifer parameters under various recharge scenarios. The model was designed to examine the relative importance of evapotranspiration and discharge to surface waters. However, largely due to the complexity of the drainage network and non-uniform surface water flows, the quantification of surface water- groundwater interaction by consideration of hydrodynamics is problematic. Therefore, the chemistry of groundwater and surface water was compared. While the estimated contribution of rainfall to groundwater level fluctuations was significant (46%), high evapotranspiration rates reduced net recharge and it was concluded that baseflow to drains and creeks during dry periods was insignificant, and groundwater velocities in the shallow aquifer are low. The study illustrates the value of both hydrodynamic and hydrogeochemical analyses in estuarine settings where relict salinity and groundwater-aquifer interactions impact significantly on water quality. Saline groundwater is chemically distinct from theoretical mixtures of seawater and freshwater. The study also demonstrates the value of particular chemical parameters, e.g. Na/Cl and SO4/Cl ratios and stable water isotopes, for identifying hydrologic processes in this setting.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Pimpama River</field><field name="subject">southern Moreton Bay</field><field name="subject">estuarine plain</field><field name="subject">coastal</field><field name="subject">hydrogeology</field><field name="subject">estuarine stratigraphy</field><field name="subject">sedimentary evolution</field><field name="subject">Holocene</field><field name="subject">mangroves</field><field name="subject">crop removal</field><field name="subject">hypersalinity</field><field name="subject">electromagnetic induction</field><field name="subject">sediment mineralogy</field><field name="subject">geophysical methods</field><field name="subject">groundwater monitoring</field><field name="subject">groundwater/ surface water relations</field><field name="subject">hydrogeochemistry</field><field name="subject">inverse groundwater modelling</field><field name="subject">isotopes</field><field name="subject">numerical modelling</field><field name="subject">paleohydrology</field><field name="subject">salt-water/fresh-water relations</field><field name="subject">unconsolidated sediments</field><field name="identifier">http://eprints.qut.edu.au/16647/</field><field name="validLink">True</field></doc><doc><field name="title">Knowledge construction of 3D geometry in virtual reality microworlds</field><field name="creator">Yeh, Andy Ju-Chih</field><field name="description">The recent development of virtual reality (VR) technology carries powerful potential that can be utilised to facilitate the learning of 3D geometry. Therefore, a new approach for teaching and learning of 3D geometry that utilises a virtual reality learning environment (VRLE) is proposed in this research study. This research study aimed to: (a) design and evaluate a VRLE to facilitate the learning of 3D geometry concepts and processes by upper primary school students, and (b) generate theoretical and design principles that will have application both within and beyond the immediate research study. The research methodology employed was design experiments or design-based research. Informed by this methodology, the research design consisted of iterative cycles of developing/revising a conceptual framework, designing/prototyping a VRLE, enacting/evaluating the VRLE, and reflecting/redesigning the research. An initial conceptual framework was generated through extensive literature review to inform the design and evaluation of a VRLE. Based on the conceptual framework, a prototype VRLE named VRMath was then designed and implemented. The enactment and evaluation of VRMath consisted of two iterations. Iteration 1 (six hours/sessions with two students of Year 5 and 6) was conducted using the prototype VRMath (Yeh &amp; Nason, 2004). Based on the findings from Iteration 1, nine learning activities were developed and research protocols (e.g., observation and interview) were revised for Iteration 2. Iteration 2 involved six primary school students (Year 4-5) for eight weeks (two hours/sessions per week). Findings from Iteration 2 confirmed and identified some usability issues of VRMath system and many new ways of thinking and doing 3D geometry when students interacted with VRMath. These have implications on the design of VRMath and the teaching and learning of 3D geometry within the VRMath environment. Justifications about the conceptual framework and students' learning within VRMath were made after the two iterations of enactment and evaluation. The learning activities and VRMath were also revised and redesigned for the preparation of future iterations. After a full cycle of the design-experiments, this research study concluded with a proto-theory (semiotic framework) for the design of and learning  within VRLEs, and visions for using VRLEs in mathematic and technology education.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">3D geometry</field><field name="subject">virtual reality (VR)</field><field name="subject">microworlds</field><field name="subject">virtual reality learning</field><field name="subject">environment (VRLE)</field><field name="subject">constructivism</field><field name="subject">constructionism</field><field name="subject">semiotics</field><field name="subject">design</field><field name="subject">experiments</field><field name="subject">design-based research</field><field name="subject">logo</field><field name="subject">virtual reality modelling language</field><field name="subject">(VRML)</field><field name="identifier">http://eprints.qut.edu.au/16648/</field><field name="validLink">True</field></doc><doc><field name="title">An even better start? : parent conceptions of the preparatory year in a non-government school in Queensland</field><field name="creator">O'Gorman, Lyndal May</field><field name="description">The introduction of a universal, full-time Preparatory Year in all Queensland schools from 2007 is a significant reform in early childhood education and care (ECEC) in that state. Rapidly increasing enrolment of children in full-time Preparatory Year programs in non-government schools has been a feature of the Queensland context over the past decade. These trends, along with efforts towards consistency of services and universal school starting ages across Australian states and territories have prompted this important reform to early education in Queensland. Constructions of the role of parents as consumers of early childhood services and/or partners in their children's early education suggest that consideration of parent views of this reform is both timely and strategic. This thesis reports the findings of a research project investigating parent conceptions of a Preparatory Year in a non-government school in outer urban Queensland. The research used a phenomenographic approach to elicit and describe the qualitatively different ways in which a group of 26 parents viewed the Preparatory Year. Analysis revealed that the range of parent conceptions of the Preparatory Year demonstrated varying emphasis on parent needs, child needs and preparation for future success in school and beyond. The study led to the construction of five categories of description outlining five different ways of understanding the Preparatory Year. The Preparatory Year was viewed in relation to (1) the current needs of the parents, (2) the current needs of the child, (3) preparation for Year One, (4) providing an advantage in primary school, and (5) preparation for future success beyond school. These five categories were linked and differentiated from each other by two central themes, or dimensions of variation: (1) a beneficiary dimension in which either the parent or the child were seen to benefit from the program, and (2) a temporal dimension in which the program was viewed in relation to meeting current needs or preparing for the future. The results of the study suggest that variation exists in the ways that parents may conceptualise the phenomenon of the Preparatory Year in Queensland. Analysis of the data further suggests that tensions exist around whether the Preparatory Year ought to emphasise preparation for the future and/or meet current needs of children; and whether those programs should meet the needs of the parent and/or the needs of the child. This thesis opens up the possibility of future tensions, with the potential for parent preferences for a formal interpretation of the Preparatory Year curriculum being at odds with the new play-based Early Years Curriculum Guidelines. Results of the study suggest that more attention be given to engaging parents and eliciting their views of the early childhood programs experienced by their children. Moreover, it provides an approach for ways in which parent views might be generated, analysed and incorporated into future policy developments and reforms.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">early childhood education and care (ECEC)</field><field name="subject">preparatory year</field><field name="subject">parents</field><field name="subject">views</field><field name="subject">Queensland</field><field name="subject">Australia</field><field name="subject">phenomenography</field><field name="subject">conceptions</field><field name="identifier">http://eprints.qut.edu.au/16649/</field><field name="validLink">True</field></doc><doc><field name="title">Novel growth factor complexes for bone tissue engineering</field><field name="creator">Parker, Anthony James</field><field name="description">Various members of the insulin-like growth factor (IGF) family of growth factors are highly expressed in bone tissue and are vitally important for the normal development and function of bone. Recent studies have shown that IGF-I can associate with the extra-cellular matrix proteins vitronectin (VN) and fibronectin (FN) via IGF binding protein-5 (IGFBP-5). Furthermore, when these complexes are pre-bound to a tissue culture surface they can stimulate enhanced responses in epithelial cell types in vitro. More recently, transforming growth factor-beta 1 (TGF-&#946;1), epidermal growth factor (EGF) and basic fibroblast growth factor (bFGF) have also been shown to interact with VN and to elicit functional responses in various cell types. Taken together, these findings indicate that exploitation of the adhesive properties of these ECM proteins might allow immobilisation of various growth factors at the culture surface. This may provide a novel means of coating engineered biomaterial constructs with agents which can elicit specific functional effects in therapeutically important cells, such as those used in cell-based therapeutics for the replacement and / or regeneration of damaged bone tissue. Since both VN and FN are also important matrix components of bone, this study sought to investigate the hypothesis that select pre-bound combinations of these matrix proteins and growth factors could also stimulate functional responses in bone cells and the therapeutically important so called mesenchymal stem cells. Thus it is reported here that pre-bound combinations of VN, IGFBP-5 and IGF-I or FN IGFBP-5 and IGF-I significantly stimulate cell migration in the osteoblast-like SaOS-2 cells. While, VN, IGFBP-5 and IGF-I stimulated cell proliferation over 72 hr, FN, IGFBP-5 and IGF-I did not. Moreover, I found that VN, IGFBP-5 and IGF-I could facilitate alkaline phosphatase (ALP) expression in SaOS-2 cells. VN, FN and EGF on the other hand could sustain SaOS-2 cells for up to 12 days in culture, but could not sustain ALP expression; hence it is possible that these cells may have entered a state of quiescence in response to this treatment. Extending these studies to cells derived from clinical samples, pre-bound combinations of VN / IGFBP-5 / IGF-I were not able to support initiation of human mesenchymal stem cell (hMSC) cultures. Nevertheless, VN alone in serum free media stimulated substantial metabolic activity and protein synthesis in hMSCs once the cultures were established. Moreover, the addition of IGFBP-3 or -5 together with IGF-I can enhance the response to levels equivalent to that observed with 10% FCS. I also report that the responses to VN and TGF-&#946;1 are synergistic and stimulate greater hMSC metabolic activity than 10% FCS. Interestingly, hMSCs cultured in IGF-I or TGF-&#946;1 and low concentrations of VN aggregated, an effect that was not observed when higher concentrations of VN were used. I hypothesise that this aggregation effect was due to endogenous protease activity, and therefore examined MMP-2 and 9 activity in hMSC conditioned media. Both pro-MMP-2 and pro-MMP-9 were constitutively expressed by hMSCs but there was no evidence of the active forms in the conditioned media, indicating that neither IGF-I nor TGF-&#946;1 affect MMP-2 or -9 expression or activation in serum-free media. However, hMSC conditioned media could degrade IGFBP-5, suggesting that there is proteolytic activity within the conditioned media which may impact on the function of ECM / growth factor components in serum-free media settings. Thus, while ECM and growth factors may stimulate desirable responses in therapeutically important cells in serum-free culture, the role that endogenously expressed proteases have on the efficacy of such media supplements needs to be examined closely. Taken together, the studies reported in this thesis provide proof of principle data indicating that select combinations of ECM proteins and growth factors could be utilised in bone tissue engineering applications. This may be achieved for example, as a biomaterial coating, or could form the basis of a viable alternative media supplement for the serum-free culture of hMSCs.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">insulin-like growth factor</field><field name="subject">bone</field><field name="subject">extra-cellular matrix</field><field name="subject">bone tissue engineering</field><field name="identifier">http://eprints.qut.edu.au/16650/</field><field name="validLink">True</field></doc><doc><field name="title">Trust within teams : the relative importance of ability, benevolence and integrity</field><field name="creator">Beatton, Douglas A.</field><field name="description">Trust between team members is important: Research has shown that teams with higher levels of trust have a propensity to be higher performers. This study built on contemporary trust theory by examining initial interpersonal trust development between a new team member and a newly formed work-team using experimental rather than correlation-based survey methods. Undergraduate students from a metropolitan Australian university participated in a vignette experiment examining the effect of teams with varying levels of Ability, Benevolence and Integrity on trust development. It was hypothesised that these antecedents of trust do not have similar effect on our Intention to Trust as is currently depicted in Mayer, Davis and Schoorman's (1995) integrative model of organisational trust. Their model is developed by hypothesising that the type and magnitude of the information we receive about a trustee moderates the relationship between our Intention to Trust and its antecedents. Initial examination of the traditional scales identified overlaps that needed clarification. This was completed by informing existing scales and the vignette manipulations with the context specific information that emerged from the thematic analysis of structured interviews. Subsequent analyses of the questionnaire data used ANOVA and Structural Equation Modelling techniques. In testing the hypotheses, Ability was found to be most salient in the development of Intention to Trust. This research contributes methodologically by developing a vignette-based experimental method that improves the reliability of existing trust scales. The study contributes theoretically by further explaining the salience of the trust antecedents and practically by identifying that the judgment and decision-making of new workteam members can be distorted by halo bias wherein they ignore the Benevolence traits of team members of a group that exhibits high levels of Ability.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">ability</field><field name="subject">ANOVA</field><field name="subject">benevolence</field><field name="subject">integrity</field><field name="subject">intention to trust</field><field name="subject">groups</field><field name="subject">halo bias</field><field name="subject">teams</field><field name="subject">trust</field><field name="subject">vignette</field><field name="subject">structural equation modelling</field><field name="identifier">http://eprints.qut.edu.au/16651/</field><field name="validLink">True</field></doc><doc><field name="title">Modeling expressive character motion for narrative and ambient intelligence based on emotion and personality</field><field name="creator">Su, Wen Poh</field><field name="description">Animated agent technology has been rapidly developed to provide ubiquitously psychological and functional benefits for fulfilling communicative goals. However, the character motions of most character-centered models based on pre-stored movement, finite state machine and scripted conditional logic are generally restrictive. The major drawback lies in the lack of maturity of integrating the elements between personality, emotion and behaviour. To bridge the gap between cognitive and behavioural elements, we examine the connections between human personality, emotion, movement and cartoon modeling for the agent design. Human personality and emotional behaviour are the essences in the recognition of a believable synthetic character. Personality and emotion come from the storylines and result in characters&#8217; motions. Cartoon animations successfully engage the audience and create emotional connections with the spectators. However, even a sophisticated animator often faces some difficulties while performing a very laborious task to simulate an emotion- and personality-rich character. This thesis focuses on exploring effective techniques to extract personality and emotion features for a high-level control of character movements. A hierarchical fuzzy rule-based system was constructed, in which personality and emotion were mapped into the body&#8217;s movement zones of a character. This facilitates agent designers to control the personality and emotion of a dynamic synthetic character. The system was then applied to a Narrative Intelligent system and extended to an Ambient Intelligent environment. An innovative storyboard-structured storytelling method was devised by using story scripts and action descriptions in a form similar to the content description of storyboards to predict specific personality and emotion. As software or device agents evolve into the Ambient Intelligence, new concepts for effective agent presentations and delegating control are necessary to minimise the human&#8217;s tasks and interventions in the complex and dynamic environment. A novel customizable personalised agent framework was developed by utilising the spirit of cartoon animation to match each user&#8217;s profile in the form of a cartoon reciprocal agent. As a result, users could explicitly modify personality and emotion values to change the psychology traits of the agent, which would affect their appearance and behaviour through body posture expression. An evaluation of the system was conducted to verify the effectiveness and the applicability in both Narrative and Ambient intelligent agent frameworks. The significance of this research is that applying higher cognitive factors to animated characters can lead to a better animation design tool and reduce strenuous animation production efforts in agent designs. It will also enable animated characters to embody more adaptive, flexible and stylised performance.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">animated agent modeling</field><field name="subject">narrative intelligence</field><field name="subject">ambient intelligence</field><field name="subject">fuzzy logic</field><field name="subject">human behaviour modeling</field><field name="subject">personality</field><field name="subject">emotion</field><field name="subject">animation</field><field name="subject">cartoon</field><field name="subject">character appearance</field><field name="identifier">http://eprints.qut.edu.au/16652/</field><field name="validLink">True</field></doc><doc><field name="title">A decompositional investigation of 3D face recognition</field><field name="creator">Cook, James Allen</field><field name="description">Automated Face Recognition is the process of determining a subject's identity from digital imagery of their face without user intervention. The term in fact encompasses two distinct tasks; Face Verficiation is the process of verifying a subject's claimed identity while Face Identification involves selecting the most likely identity from a database of subjects. This dissertation focuses on the task of Face Verification, which has a myriad of applications in security ranging from border control to personal banking. Recently the use of 3D facial imagery has found favour in the research community due to its inherent robustness to the pose and illumination variations which plague the 2D modality. The field of 3D face recognition is, however, yet to fully mature and there remain many unanswered research questions particular to the modality. The relative expense and specialty of 3D acquisition devices also means that the availability of databases of 3D face imagery lags significantly behind that of standard 2D face images. Human recognition of faces is rooted in an inherently 2D visual system and much is known regarding the use of 2D image information in the recognition of individuals. The corresponding knowledge of how discriminative information is distributed in the 3D modality is much less well defined. This dissertations addresses these issues through the use of decompositional techniques. Decomposition alleviates the problems associated with dimensionality explosion and the Small Sample Size (SSS) problem and spatial decomposition is a technique which has been widely used in face recognition. The application of decomposition in the frequency domain, however, has not received the same attention in the literature. The use of decomposition techniques allows a map ping of the regions (both spatial and frequency) which contain the discriminative information that enables recognition. In this dissertation these techniques are covered in significant detail, both in terms of practical issues in the respective domains and in terms of the underlying distributions which they expose. Significant discussion is given to the manner in which the inherent information of the human face is manifested in the 2D and 3D domains and how these two modalities inter-relate. This investigation is extended to cover also the manner in which the decomposition techniques presented can be recombined into a single decision. Two new methods for learning the weighting functions for both the sum and product rules are presented and extensive testing against established methods is presented. Knowledge acquired from these examinations is then used to create a combined technique termed Log-Gabor Templates. The proposed technique utilises both the spatial and frequency domains to extract superior performance to either in isolation. Experimentation demonstrates that the spatial and frequency domain decompositions are complimentary and can combined to give improved performance and robustness.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">face recognition</field><field name="subject">face verification</field><field name="subject">three-dimensional</field><field name="subject">two-dimensional</field><field name="subject">decomposition</field><field name="subject">log-gabor filters</field><field name="subject">log-gabor templates</field><field name="subject">gabor filters</field><field name="subject">wavelets</field><field name="subject">discrete cosine transform</field><field name="subject">pattern recognition</field><field name="subject">classifier fusion</field><field name="subject">subspace projection</field><field name="subject">small sample size problem</field><field name="identifier">http://eprints.qut.edu.au/16653/</field><field name="validLink">True</field></doc><doc><field name="title">Marriageability and Indigenous representation in the white mainstream media in Australia</field><field name="creator">King, Andrew Stephen</field><field name="description">By means of a historical analysis of representations, this thesis argues that an increasing sexualisation of Indigenous personalities in popular culture contributes to the reconciliation of non-Indigenous and Indigenous Australia. It considers how sexualised images and narratives of Indigenous people, as they are produced across a range of film, television, advertising, sport and pornographic texts, are connected to a broader politics of liberty and justice in the present postmodern and postcolonial context. By addressing this objective the thesis will identify and evaluate the significance of 'banal' or everyday representations of Aboriginal sexuality, which may range from advertising images of kissing, television soap episodes of weddings, sultry film romances through to more evocatively oiled-up representations of the pinup- calendar variety. This project seeks to explore how such images offer possibilities for creating informal narratives of reconciliation, and engendering understandings of Aboriginality in the media beyond predominant academic concerns for exceptional or fatalistic versions.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Aboriginality</field><field name="subject">Indigenous</field><field name="subject">marriageability</field><field name="subject">reconciliation</field><field name="subject">popular culture</field><field name="subject">sexuality</field><field name="subject">relationships</field><field name="subject">interracial</field><field name="subject">public sphere</field><field name="subject">mediasphere</field><field name="subject">celebrity</field><field name="identifier">http://eprints.qut.edu.au/16654/</field><field name="validLink">True</field></doc><doc><field name="title">Towards a design methodology to support social networks of residents in inner-city apartment buildings</field><field name="creator">Foth, Marcus</field><field name="description">This PhD study is at the intersection of people, place and technology and pioneers innovative development approaches towards interactive social networking systems informed by community, social and urban studies and employs human-centred and participatory design methods.
 The project delivers a greater understanding of the potential for internet-based systems to support and facilitate social networks of urban residents and the role of those networks to foster neighbourhood identity and social capital. Departing from conventional notions that regard communities as collectives, this study builds upon more contemporary interpretations of community inherent in Castells&#8217; and Wellman&#8217;s theories of the network society and networked individualism. The thesis challenges the view that a mere re-appropriation of applications used to support dispersed virtual communities of interest is adequate to meet the place and proximity-based design requirements that community networks in urban neighbourhoods pose.
 The overarching principal research aim of the study is to propose new ways of conceptualising the roles of social networks of urban residents to better inform the design of new technology facilitating urban neighbourhood developments.
 Addressing this aim requires a new understanding of the roles of social networks of urban residents. The study sets out to critique the implicit theories underlying technology design in this area and to propose a more appropriate theory based on recent developments in the field and empirical findings from the study. The key research questions are:
 1.	What theoretical model can better represent social interaction of residents in inner-city apartment buildings?
 2.	How can relevant research methods be adapted to take the network qualities of social interactions into account?
 3.	What are the implications of a new understanding of social networks for the design of technology that supports the growth of neighbourhoods?
 4.	What are the implications of a new understanding of social networks for an urban architecture that supports the growth of neighbourhoods?
 Within a framework of action research, the study follows a case study approach of three different inner-city residential apartment complexes in Brisbane. Research methods are mostly qualitative and ethnographic and include surveys, focus groups, participant observation and interviews, as well as participatory design.
 The study delivers innovative outcomes on three levels:
 1.	Theoretical innovation with an analytical translation of Wellman&#8217;s notion of networked individualism and a conceptualisation of the communicative ecology model into the context of system design that supports social networks of residents in inner-city apartment buildings;
 2.	Methodological innovation with the presentation of Network Action Research, an addition to the action research family which pays particular attention to the network quality of social formations in communities;
 3.	Empirical innovation with research findings which indicate that the key factors influencing the successful design and uptake of interactive systems to support social networks in urban neighbourhoods. They include the swarming social behaviour of urban dwellers, the dynamics of their existing communicative ecology, and the serendipitous, voluntary and place-based quality of interaction between residents on the basis of choice, like-mindedness, mutual interest and support needs. Findings are presented in three parts to audiences interested in people, technology and place.
 Drawing on social, urban and computer sciences, this research project delivers insights which will assist efforts to facilitate urban neighbourhood community building with new media and network ICTs. Understanding the issues and challenges as well as opportunities and strengths in forming a local meshwork of social networks will help Australians negotiate the complex web of daily choices, access a greater social safety net, and participate in the socio-cultural and socio-economic life of their city. This in turn will contribute to greater social inclusion, urban sustainability and healthier local economies.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">action research</field><field name="subject">apartment buildings</field><field name="subject">communicative ecology</field><field name="subject">community informatics</field><field name="subject">community</field><field name="subject">networks</field><field name="subject">design methodology</field><field name="subject">information and communication technology</field><field name="subject">networked individualism</field><field name="subject">new media</field><field name="subject">participatory design</field><field name="subject">residential architecture</field><field name="subject">social networks</field><field name="subject">sociocultural animation</field><field name="subject">urban neighbourhoods</field><field name="subject">urban sociology</field><field name="identifier">http://eprints.qut.edu.au/16655/</field><field name="validLink">True</field></doc><doc><field name="title">Understanding process modelling grammar continuance : a study of the consequences of representational capabilities</field><field name="creator">Recker, Jan Christof</field><field name="description">The graphical modelling of processes is of growing popularity and high relevance to organisations that seek to document, analyse and improve their business operations. This research investigates the phenomenon of continued user acceptance of the grammars that are used to build process models. It develops and tests a theory that can be used to explain and predict why users would opt to continue working with certain grammars in their process modelling efforts. This study builds on established theories, including the Technology Acceptance Model, Expectation-Confirmation Theory, Task-Technology Fit Theory and Representation Theory. These theories suggest that end users typically strive for tools that are useful and easy to use, which confirm their expectations through firsthand utility, and which match task requirements and individual abilities. Representation theory suggests that modelling grammars should be complete and clear in their capabilities to represent real-world domains. The research model has been designed by combining conceptual studies of acceptance and continuance theories with a representational analysis of the BPMN grammar, which is a recently ratified industry standard for process modelling and thereby of high practical relevance to process modelling practice. It further incorporates findings from nineteen semi-structured interviews with process modellers in Australia. The research model has been tested and validated by means of a web-based survey with 590 process modellers world-wide. This thesis contributes to the body of knowledge in a number of ways: First, it presents an empirically validated model of the factors determining a user's intention to continue using a process modelling grammar. Second, it measures the impact that grammar characteristics as well as user and task characteristics have on user evaluations of a process modelling grammar. Third, it presents empirical evidence on the consequences that perceived representational deficiencies entail on user perceptions of a process modelling grammar.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">business process modelling</field><field name="subject">post-adoption behaviour</field><field name="subject">technology acceptance</field><field name="subject">expectation-confirmation theory</field><field name="subject">task-technology-fit</field><field name="subject">representation theory</field><field name="identifier">http://eprints.qut.edu.au/16656/</field><field name="validLink">True</field></doc><doc><field name="title">A case for the inclusion of educational gerontology in adult education programs in Australian universities</field><field name="creator">Engelbrecht, Carol A.</field><field name="description">At the intersection of adult education and social gerontology, and propelled by the ageing phenomenon, educational gerontology has a critical place in the study of older adult education. To contend with older learners' needs, professional adult educators require an enhanced preparation, and concomitance to a reinvigoration of current adult learning programs to include the constructs of educational gerontology and the geragogical imperative. Through survey and interviews, this research investigated evidence of, and the capacity for, Australian Adult Education programs and Ageing Research centres to meet this requirement. Results of this case study indicate a paucity of evidence of educational gerontology in adult education programs, coupled with significant potential for capacity development in this field through collaboration with Ageing Research initiatives. The findings suggest an expansion of current curriculum in adult education programs to include aspects of educational gerontology, professional development of Adult Education academics in the specialized area of educational gerontology, and broader adult education engagement with external stakeholders and the ageing research community as a contribution to social betterment.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">adult education</field><field name="subject">educational gerontology</field><field name="subject">ageing</field><field name="subject">social gerontology</field><field name="subject">older adults</field><field name="subject">geragogy</field><field name="subject">older workers</field><field name="subject">age management</field><field name="subject">gerontology</field><field name="identifier">http://eprints.qut.edu.au/16657/</field><field name="validLink">True</field></doc><doc><field name="title">Young children's accounts of quality in early childhood classrooms in Singapore</field><field name="creator">Harcourt, Deborah Sue</field><field name="description">Early childhood research and policy are focusing increasingly on issues of 'quality' in early childhood education. Much of the focus, however, has been on adult-generated notions of quality, with little attention being devoted to children's own views of their experience in early childhood settings. Conducted in the context of early childhood education in Singapore, this research breaks new ground by contributing children's own insights into their experience in two early childhood classrooms in Singapore. Informed by the sociology of childhood conceptualisation of child competence (James &amp; James, 2004), the research methodology drew on the mosaic approach to researching with children used by Clark and Moss (2001), whereby children's photography, mapping and conversations were used by them to consider their early childhood settings.    The findings of this study were generated, beginning with the understanding that young children have the competence to articulate their ideas using a range of symbolic literacies. They formed views and constructed theories about their preschool experiences, in particular about the teachers, the curriculum, the physical environment and friends, and gave a clear indication of what constitutes good quality in those domains. When offered a platform to discuss the issue of quality in early childhood settings, the children articulated ideas about their own best interests.    This study calls for those engaged with children, to act upon the contributions offered by this group of children to our understanding of quality.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">quality</field><field name="subject">socio-cultural theory</field><field name="subject">children&#146;s accounts</field><field name="subject">new sociology of childhood</field><field name="subject">United Nations Convention on the Rights Of the Child (UNCROC)</field><field name="subject">early childhood education</field><field name="subject">Singapore</field><field name="identifier">http://eprints.qut.edu.au/16658/</field><field name="validLink">True</field></doc><doc><field name="title">Functional vision performance in Indian school-going children with visual impairment</field><field name="creator">Gothwal, Vijaya Kumari</field><field name="description">Functional vision refers to the use of vision to perform day-day tasks and is assessed by the ability to perform these tasks. Assessment of functional vision is an integral component of the management of children with visual impairment. The results of the assessment help in designing appropriate educational and rehabilitation intervention strategies. The L V Prasad-Functional Vision Questionnaire (LVP-FVQ) is a reliable and valid tool for assessing self-reported functional vision performance (FVP) in children. Self-reports are obviously the child's perception of his or her ability to perform certain tasks but they may not reflect actual performance. Various studies of FVP in adults have used actual performance measures of everyday tasks, but very few studies, even in adults with visual impairment, have compared self-reports and performance measures and none have included identical tasks on the 2 methods of assessment. To date, no study has assessed FVP using performance measures of daily tasks in the paediatric population. Therefore, the aims of the current study were: (1) To develop performance measures of FVP and compare them with self-reports of FVP from the LVP-FVQ in a prospective cohort of Indian school-going children with visual impairment. (2) To investigate the effect of a psychological attribute, self-concept, on self-reports, performance measures and the relationships between the 2 measures. (3) To investigate the relationship between clinical measures of vision and FVP. Performance measures of FVP for children with visual impairment were developed for 17 day to day tasks for comparison with self-reports of the same tasks for the LVP-FVQ. The LVP-FVQ was verbally administered by the researcher to 178 Indian school-going children aged between 8 and 17 years with visual impairment. Similarly, the performance of each of the tasks by these children was measured by the researcher. The performance measures for most of these tasks were recorded on continuous scales and later categorized to match the ordinal ratings from the LVP-FVQ. The self-report and performance measure ratings for the 17 tasks were then converted into the same metric using a Rasch model allowing an accurate picture of whether and how these two measures of FVP compared with each other. Rasch analysis was used to estimate the person ability and item difficulty for FVP from the 2 methods of assessment. Self-reports showed stronger correlations with performance measures of FVP than were hypothesized. Similar to some studies in adults, binocular high-contrast visual acuity was found to be the single most significant predictor of a child's functional vision performance. Contrary to expectations, self-concept did not have a significant effect on the relationship between the 2 measures. A few reasons for the stronger than expected relationship between the 2 methods of assessment of FVP in children with visual impairment are suggested. Firstly, the use of identical tasks for self-reports and performance measures of FVP is likely to improve the relationship. Secondly, the LVP-FVQ was developed using focus groups of children with visual impairment, their parents, low vision specialists and rehabilitation professionals leading to good content validity. Since children were included in the development of the LVP-FVQ, the tasks were representative of a child's typical daily life. Thus, the performance measures were also suited to the day-day tasks of school-going children but were not tapping any social and psychological issues relating to visual impairment. Thirdly, the use of Rasch analysis which addresses many of the issues of unequal measurement and defines a hierarchy of items for self-reports and performance measures could have led to higher correlations in the present study. Finally, the high reliability and validity of self-reports and performance measures of FVP in the present study may have contributed to the higher than expected correlations. None of the demographic variables or self-concept affected the relationship between self-reports and performance measures of FVP, but self-concept had a weak significant association with self-reports. This result is unique to this study and warrants further investigation. Binocular high-contrast visual acuity alone, the most common visual function measured in ophthalmic clinics, explained between one-third and two-thirds of the variance in functional vision performance. This confirms the expected trend that with worse visual impairment, FVP is lower. The addition of the variable, self-concept, resulted in a very small increase in the variability explained for self-reported FVP. Similarly, the addition of other clinical measures of vision such as binocular low contrast visual acuity and colour vision resulted in a small increase in the variability explained for performance measures of FVP. The correlation between binocular high-contrast visual acuity and performance measures of FVP was statistically significantly higher than that between binocular high-contrast visual acuity and self-reports of FVP. There are a few possible reasons for this higher correlation. Firstly, performance measures are considered to be a more "objective" form of assessment, while self-reports are a child's perception of his or her ability and therefore lack a context, which may result in either over-estimation or under-estimation of actual ability. Furthermore, performance measures include dimensions such as the time taken to perform a task or other criteria specific to a task, while self-reports do not use such qualifiers.  Secondly, the higher correlation may be the result of the visual complexity of some of the tasks. While self-concepts of children with visual impairment played a small but significant role in the self-reported FVP, studies in adults with visual impairment have suggested that other psychological factors such as mood, anxiety, motivation etc. are associated with an individual's perception of visual performance. Future studies are required to explore the possible role of these and other factors in FVP in Indian school-going children with visual impairment.  This thesis makes a significant contribution to the field of paediatric low vision rehabilitation by providing performance measures of FVP and relating them to self-reports in children with visual impairment and their relationship with common measures of visual function. With self-reports, the child is reporting his or her perception of ability to complete a task, where performance measures examine the child's ability to complete a task by observing his or her performance. Thus, although the two methods are comparable, it is because of the different yields from each of these measures that they are not considered interchangeable. A combination of the 2 measures where practical would perhaps provide a richer depiction of the FVP of children with visual impairment. As developing countries such as India have limited resources allocated for eye care services where less than seven percent of the gross national product is spent on health care, self-reports can be utilized together with clinical measures of vision (mainly visual acuity) to assess the FVP in children with visual impairment in a community setting. However, both methods of assessment of FVP together with clinical measures of vision are essential if a comprehensive assessment of FVP is to be carried out in children with visual impairment. Information from these assessments can help clinicians better understand the functioning of children with visual impairment and incorporate them in the management of low vision in school-going children with visual impairment in India.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">low vision</field><field name="subject">children</field><field name="subject">visual impairment</field><field name="subject">visual acuity</field><field name="subject">functional vision performance</field><field name="subject">self-reports</field><field name="subject">performance measures</field><field name="subject">clinical measures of vision</field><field name="subject">Rasch analysis</field><field name="subject">self-concept</field><field name="identifier">http://eprints.qut.edu.au/16659/</field><field name="validLink">True</field></doc><doc><field name="title">Factors influencing the effectiveness of advertising countermeasures in road safety</field><field name="creator">Lewis, Ioni M.</field><field name="description">The current program of research contributes to the World Health Organisation's (WHO, 2004) recent call to pool global resources in the attempt to uncover the most effective countermeasures and polices for the prevention of road trauma. Specifically, this program of research investigates the persuasive outcomes of different emotional health messages in an important applied context, road safety. In this context the use of negative, fear-based approaches has predominated with limited use of more positive-based approaches such as humorous- or pride-based emotional appeals. The overarching aim of the current research program was to examine the effectiveness (i.e., persuasiveness) of positive and negative emotional appeals and, specifically, the issue- or message-relevant affect that such appeals evoke. An additional aim was to ascertain the relative influence and effectiveness of positive and negative emotional appeals for specific target audiences. Particular attention was given to the effectiveness of such messages for males, a high risk road user group of particular concern. The research program also aimed to examine the relative roles and interplay of emotion and cognition in determining message effectiveness. The research focused upon the cognitive constructs of response efficacy (i.e., the extent to which a message incorporates coping strategies and information as well as the extent that individuals' perceive a message as incorporating such coping strategies and information) and involvement (i.e., the extent to which individuals perceive an issue or message as personally relevant and/or as being at risk of experiencing).-----   
 
 The research program may be conceptualised as three stages, with each stage comprised of an empirical study and one or more manuscripts. The first stage of the research explored the roles and effectiveness of negative and positive emotional appeals. With a substantial body of literature available on the use of fear as a persuasive strategy, Paper One reviewed the theoretical and empirical evidence relating to the function and effectiveness of such appeals. This paper highlighted the mixed findings that have been reported and the controversy surrounding the nature of the fear-persuasion relationship. This paper also highlighted the importance of cognitive components of a message and, in particular, the need to incorporate high levels of response efficacy and to be cognisant of the issue of threat and message relevance.-----
 
 Paper Two was based on qualitative research derived from focus groups of licensed drivers (N = 16). The study investigated the roles and effectiveness of positive and negative emotional appeals in road safety advertisements addressing speeding and drink driving. The results suggested that positive and negative emotional appeals may serve different functions. Positive emotional appeals were regarded as a potentially efficacious means of promoting the message of prevention and to model safe behaviour and the rewards received whereas negative emotional appeals were regarded an important way to remind drivers of the dangers of driving.----- 
 
	The second stage of the research program endeavoured to extend upon the findings reported in the first stage by providing an empirical comparison of positive, humorous appeals and negative, fear-based appeals on a range of outcome measures and over time. In Paper Three, the type of emotional appeal (positive/humorous, negative/fear), level of response efficacy (low, high), level of involvement (low, high), and gender were manipulated in a 2 x 2 x 2 x 2 mixed group design. Licensed drivers (N = 201) completed either a paper-and-pencil or internet-based version of a questionnaire. Prior to the anti-drink driving television advertisements being shown, pre-exposure were assessed. Attitudes and intentions were then assessed immediately after exposure and attitudes, intentions, and behaviour, 2 to 4 weeks later. The results provided evidence of the greater persuasiveness of negative appeals immediately after exposure and greater improvement of positive appeals over time. Also, the results highlighted the importance of high levels of response efficacy, irrespective of emotional appeal type. Paper Three also supported and extended upon earlier findings by examining third-person perceptions in relation to positive, humorous emotional appeals. The results revealed that males reported significantly greater overall influence both to themselves personally, as well as other drivers in general, than females for the humorous appeals. Further, consistent with the multiple roles of affect posited by Elaboration Likelihood Model, explanations were provided for the differential effectiveness of positive and negative affect.----- 
 
	An additional aim of the second stage of the research program was to clarify an important methodological issue; the sampling adequacy of traditional university student samples versus internet-based samples for health message persuasion research. Fear appeal empirical literature has been criticised for its over-reliance upon student samples. Paper Four examined the extent that the internet may function as an efficacious means of accessing drivers for road safety advertising research. The sample characteristics and results obtained from student and internet samples of drivers were compared empirically. The results provided support for the greater diversity and representativeness of the internet sample and suggested that the two sampling approaches produce equivalent results. This paper served to inform the validity of prior research and informed the choice of sampling methodologies for the subsequent research stage reported in Paper Five.-----	
 
 The third stage of the research built upon the preceding stages and, most notably, broadened the scope of emotional appeals examined by comparing a range of negative and positive emotional appeals addressing the issue of speeding. Drawing upon the Rossiter-Percy (1987, 1997) motivational model, Paper Five examined two different negative and two positive emotional appeals designed as audio messages. Specifically, the type of emotional appeal (Problem Avoidance/Fear based; Problem Removal/ Agitation or annoyance-based; Social Approval/ Pride-based; and Intellectual Mastery/ Humour-based), level of response efficacy (low, high), level of involvement (low, high), and gender were manipulated in a 2 x 2 x 2 x 2 fully between groups design. A range of persuasion outcome measures, including attitudes and intentions, were assessed immediately after exposure and 1 month later. Further, the study assessed adaptive (message acceptance) as well as maladaptive (message rejection) intentions. The results provided evidence of the effectiveness of humorous-based appeals for males and highlighted that appeals of the same valence (positive or negative) need not have the same persuasive effects. The results also supported the importance of response efficacy for all appeal types and highlighted that a message's overall effectiveness requires consideration of both message acceptance and rejection rates.-----
 
 Overall, the current research program, based upon a sound, multi-disciplinary theoretical framework, provided evidence for the need to broaden the scope of emotional appeals in the road safety advertising context and which may also be relevant within a wider health persuasion context. The results of the three studies have important theoretical and practical implications for future campaign development which are discussed.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">road safety advertising</field><field name="subject">threat appeals</field><field name="subject">emotional appeals</field><field name="subject">message-relevant affect</field><field name="subject">positive emotion</field><field name="subject">response efficacy</field><field name="subject">persuasion</field><field name="subject">driver safety</field><field name="subject">gender</field><field name="identifier">http://eprints.qut.edu.au/16660/</field><field name="validLink">True</field></doc><doc><field name="title">How to evaluate the effectiveness of an environmental legal system</field><field name="creator">McGrath, Christopher James</field><field name="description">The principal research question addressed in this thesis is how the effectiveness of an environmental legal system can best be evaluated. A legal system is effective if it is achieving or likely to achieve its objectives. For an environmental legal system this means achieving sustainable development. The hypothesis tested in relation to this research question is that the pressure-state-response ("PSR") method of State of the Environment ("SoE") Reporting provides the best available framework for evaluating the effectiveness of an environmental legal system. A subsidiary research question addressed in this thesis is whether the environmental legal system protecting the Great Barrier Reef ("GBR") in north-eastern Australia is likely to achieve sustainable development of it. The hypothesis tested in relation to this research question is that the environmental legal system protecting the GBR is likely to achieve sustainable development of the GBR. The principal method used to address these research questions and test the hypotheses is a case study of the effectiveness of the laws protecting the GBR. Particular emphasis is given in the case study to climate change both because it is now recognised as the major threat to the GBR and is a topic of significant international and national interest. This thesis is intended to contribute, in particular, to the current public and policy debate on responding effectively to climate change by using the GBR as a yardstick against which to measure "dangerous climate change" and, conversely, acceptable climate change. There are five major findings of the research. First, most of the legal writing regarding environmental legal systems is descriptive, explanatory and interpretative rather than evaluative. Second, most legal writers who attempt to evaluate the effectiveness of part or the whole of an environmental legal system implicitly use the PSR method and refer to pressures, conditions, and responses but do not acknowledge this conceptual framework. Third, the best available conceptual and analytical framework for evaluating the effectiveness of an environmental legal system is the PSR method. It is the simplest, most systematic, comprehensive and meaningful framework with the greatest predictive power for evaluating the effectiveness of the total social and legal response to human-induced environmental degradation currently available. Fourth, current practice in SoE reporting, at least in relation to the GBR, is largely descriptive and rarely evaluates the effectiveness of the response. The fifth major finding of this research is that, while there are many effective parts of the response to pressures on the GBR, the current environmental legal system is not likely to be effective in preventing climate change from causing very serious damage to the GBR. Based on what we know at this point in time, particularly the technology that is currently available and current greenhouse gas emissions, the impacts of climate change appear likely to swamp the many good aspects of the legal system protecting the GBR. Atmospheric concentrations of carbon dioxide in 2005 were approximately 379 parts per million ("ppm") and rising by 2 ppm per year. Including the effect of other greenhouse gases such as methane, the total concentration of atmospheric greenhouse gases was around 455 ppm carbon dioxide equivalents ("CO2-eq") in 2005, although the cooling effect of aerosols and landuse changes reduced the net effect to around 375 ppm CO2-eq. Limiting the total increase in mean global temperature to approximately 1&#176;C requires stabilization of atmospheric greenhouse gases and aerosols around 350 ppm CO2-eq. Increasing the net effect of greenhouse gases and aerosols to 450-550 ppm CO2-eq is expected to result in a 2-3&#176;C rise in mean surface temperatures. There are currently no international or national legal constraints to hold greenhouse gas concentrations beneath these levels and they appear likely to be exceeded. These increases in mean global temperatures are expected to severely degrade the GBR by 2030-2040. Even the targets being set by the new Australian Government of reducing Australia's greenhouse gas emissions by 60% by 2050 appear insufficient to protect the GBR. If a 60% reduction in emissions can be achieved globally by 2050 a rise in mean global temperature of around 2.4&#176;C is expected. This indicates the environmental legal system protecting the GBR is not likely to be effective in relation to climate change and, therefore, is failing to reach its objective of sustainable development. Three major recommendations arise from the research. First, legal writers attempting to evaluate the effectiveness of the whole or part of an environmental legal system should use and acknowledge the PSR method. Second, SoE reports should include a stand-alone chapter evaluating the effectiveness of the response. Third, the environmental legal system protecting the GBR should take strong and comprehensive measures to reduce greenhouse gas emissions if the objective of sustainable development is to be achieved. Such measures should include setting policy targets for stabilizing atmospheric greenhouse gas and aerosol concentrations around 350 ppm CO2-eq to limit increases in mean global temperature to 1&#176;C. Policy targets of stabilizing atmospheric greenhouse gases and aerosols at 450-550 ppm CO2-eq to limit increases in mean global temperatures to 2-3&#176;C are likely to be too high to avoid severe impacts of coral bleaching to the GBR.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">environmental law</field><field name="subject">environmental legal system</field><field name="subject">natural resources law</field><field name="subject">law and legislation</field><field name="subject">effectiveness</field><field name="subject">evaluation theory</field><field name="subject">policy analysis</field><field name="subject">environmental policy</field><field name="subject">climate change</field><field name="subject">ecologically sustainable development</field><field name="subject">state of the environment reporting</field><field name="subject">Great Barrier Reef</field><field name="subject">Queensland</field><field name="subject">Australia</field><field name="identifier">http://eprints.qut.edu.au/16661/</field><field name="validLink">True</field></doc><doc><field name="title">Response of concrete pavements under moving vehicular loads and environmental effects</field><field name="creator">Darestani, Mostafa Yousefi</field><field name="description">The need for modern transportation systems together with the high demand for sustainable pavements under applied loads have led to a great deal of research on concrete pavements worldwide. Development of finite element techniques enabled researchers to analyse the concrete pavement under a combination of axle group loadings and environmental effects. Consequently, mechanistic approaches for designing of concrete pavements were developed based on results of finite element analyses. However, unpredictable failure modes of concrete pavements associated with expensive maintenance and rehabilitation costs have led to the use of empiricalmechanistic approach in concrete pavement design. Despite progressive knowledge of concrete pavement behaviour under applied loads, concrete pavements still suffer from deterioration due to crack initiation and propagation, indicating the need for further research. Cracks can be related to fatigue of the concrete and/or erosion of materials in sub-layers. Although longitudinal, midedge and corner cracks are the most common damage modes in concrete pavements, Austroads method for concrete pavement design was developed based on traditional mid-edge bottom-up transverse cracking introduced by Packard and Tayabji (1985). Research presented in this thesis aims to address the most common fatigue related distresses in concrete pavements. It uses comprehensive finite element models and analyses to determine the structural behaviour of concrete pavements under vehicular loads and environmental effects. Results of this research are supported by laboratory tests and an experimental field test. Results of this research indicate that the induced tensile stresses within the concrete pavement are significantly affected by vehicle speed, differential temperature gradient and loss of moisture content. Subsequently, the interaction between the above mentioned factors and concrete damage modes are discussed. Typical dynamic amplifications of different axle groups are presented. A new fatigue test setup is also developed to take into consideration effects of pavement curvature on fatigue life of the concrete. Ultimately, results of the research presented in this thesis are employed to develop a new guide for designing concrete pavements with zero maintenance of fatigue damage.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">dynamic analysis</field><field name="subject">dynamic amplification</field><field name="subject">finite element analysis</field><field name="subject">finite element model</field><field name="subject">static analysis</field><field name="subject">axle group loads</field><field name="subject">critical axle group configuration</field><field name="subject">critical position of axle groups</field><field name="subject">tyre pavement interaction</field><field name="subject">stress distribution</field><field name="subject">fatigue failure</field><field name="subject">concrete pavement distresses</field><field name="subject">corner cracking</field><field name="subject">longitudinal cracking</field><field name="subject">transverse cracking</field><field name="subject">top-down cracking</field><field name="subject">bottom-up cracking</field><field name="subject">boundary conditions</field><field name="subject">debonding layer</field><field name="subject">temperature effects</field><field name="subject">loss of moisture contents</field><field name="subject">shrinkage effects</field><field name="subject">curling induced stress</field><field name="subject">warping stress</field><field name="subject">pavement curvature</field><field name="subject">field test</field><field name="subject">laboratory text</field><field name="subject">experimental study</field><field name="subject">truck load</field><field name="subject">JPCP</field><field name="subject">JRCP</field><field name="subject">CRCP</field><field name="subject">SAST</field><field name="subject">SADT</field><field name="subject">TAST</field><field name="subject">TADT</field><field name="subject">TRDT</field><field name="subject">QADT</field><field name="identifier">http://eprints.qut.edu.au/16662/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation of the Australian layered elastic tool for flexible aircraft pavement thickness design</field><field name="creator">White, Gregory William</field><field name="description">APSDS is a layered elastic tool for aircraft pavement thickness determination developed and distributed by Mincad Systems and based on the sister software Circly. As aircraft pavement thickness determination remains an empirical science, mechanistic-empirical design tools such as APSDS require calibration to full scale pavement performance, via the S77-1 curve. APSDS provides the unique advantage over other tools that it models all the aircraft in all their wandering positions, negating the need for designers to use pass to cover ratios and acknowledging that different aircraft have their wheels located at difference distances from the aircraft centerline.    APSDS requires a range of input parameters to be entered, including subgrade modulus, aircraft types, masses and passes and a pavement structure. A pavement thickness is then returned which has 50% design reliability. Greater levels of reliability are obtained by conservative selection of input values. Whilst most input parameters have a linear influence on pavement thickness, subgrade modulus changes have a greater influence at lower values and less influence at higher values. When selecting input values, designers should concentrate their efforts on subgrade modulus and aircraft mass as these have the greatest influence on the required pavement thickness. Presumptive or standard values are generally acceptable for the less influential parameters.    S77-1 pavement thicknesses are of a standard composition with only the subbase thickness varying. Non-standard pavement structures are determined using the principle of material equivalence and the FAA provides range of material equivalence factors, of which the mid-range values are most commonly used. APSDS allows direct modelling of non-standard pavement structures. By comparing different APSDS pavements of equal structural capacity, implied material equivalences can be calculated. These APSDS implied material equivalences lie at the lower end of the ranges published by FAA.  In order to obtain consistence between APSDS and the FAA guidance, the following material equivalence values are recommended:    * Asphalt for Crushed Rock. 1.3.  * Crushed Rock for Uncrushed Gravel. 1.2.  * Asphalt for Uncrushed Gravel. 1.6.    Proof rolling regimes remain an important part of the design and construction of flexible aircraft pavements. Historically, designers relied on Bousinesq's equation and the assumption of point loads on semi-finite homogenous materials to determine proof rolling regimes using stress as the indicator of damage. The ability of APSDS to generate stress, strain and deflection at any depth and any location across the pavement allows these historical assumptions to be tested. As the design of a proof rolling regime is one of comparing damage indicators modelled under aircraft loads to those under heavy roller loads, the historical simplifications are generally valid for practical design scenarios. Where project specific data is required, APSDS can readily calculate stresses induced by proof rollers and aircraft at any location and depth for comparison.    APSDS is a leading tool for flexible aircraft pavement thickness determination due to its flexibility, transparency and being free from bias. However, the following possible areas for improvement are considered worthy of future research and development:    * Improvements to the user interface.  * Ability to model aircraft masses as frequency distributions.  * Ability to copy stress with depth data to Excel(tm) spreadsheets.  * Ability to perform parametric runs.  * Inclusion of a reliability based design module.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">aircraft pavement structural design system</field><field name="subject">layered elastic thickness design</field><field name="subject">flexible aircraft pavement</field><field name="subject">sensitivity analysis</field><field name="subject">proof rolling</field><field name="subject">material equivalence</field><field name="identifier">http://eprints.qut.edu.au/16663/</field><field name="validLink">True</field></doc><doc><field name="title">Young people, public space and citizenship</field><field name="creator">Dee, Michael John</field><field name="description">The use of public space by young people raises issues in Australia and elsewhere in the world. Contests occur between the disparate players seeking a stake in the use and definition of public space. State and local government, young people, the security industry, shop owners, community groups and property developers are some of the major players. In a context of monitoring and control procedures, young people's use of public space is often viewed as a threat to social order (Loader 1996, Crane and Dee 2001, White 1998).    This study considers critical intersections between young people and the control of public space. It employs an analysis of relevant youth, citizenship and public space theories. Particular attention focuses on the concepts of political, civil and social citizenship formulated by the British sociologist T.H. Marshall, whose key text Citizenship and Social Class (1950), is still relevant (see Yeatman 1994, France 1997, Mann 1995, Manning and Ryan 2004). Grounded Theory methodology as discussed by Glaser and Strauss (1967) is utilised in the surveying of high school students in Brisbane and Logan to discover their perceptions of a range of public space and citizenship issues. The overall aim of this study is to consider if a connection exists between young people, public space and citizenship and if the use of public space by young people may be understood from a broad rights perspective and the concept of social citizenship, as discussed by Marshall (1950).  The self completion survey employed in this study asked 1122 high school students a number of questions about their local community, safety at school, the meaning to them of the word citizenship and their thoughts about CCTV. The key findings were: *	Some communities are less concerned about young people, than others;    *	Most schools are safe, but a number are not. Teachers contribute to student's feelings of safety at school;    *	The word citizenship carries important meanings for most young people around belonging, community and taking part in community life; *	CCTV surveillance does not necessarily make young people feel safe in using public space;    *	Most young people feel negatively stereotyped by their community;    *	Most local areas do not have enough youth facilities    The survey data is discussed further throughout the study along with citizenship and public space issues.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">children</field><field name="subject">young people</field><field name="subject">public space</field><field name="subject">rights</field><field name="subject">contested</field><field name="subject">social</field><field name="subject">civil</field><field name="subject">political citizenships</field><field name="subject">futurity</field><field name="subject">surveillance</field><field name="subject">participation</field><field name="subject">CCTV</field><field name="subject">grounded theory</field><field name="identifier">http://eprints.qut.edu.au/16664/</field><field name="validLink">True</field></doc><doc><field name="title">Information literacy and learning</field><field name="creator">Lupton, Mandy</field><field name="description">This thesis explores the relationship between information literacy and learning. In formal education, students are frequently required to independently find and use information to learn about a topic, and information literacy is often claimed to be a generic skill and graduate attribute. However, to date; the experienced relationship between information literacy and learning has not been investigated.    In order to investigate this experience, I have based this research on interviews with 19 students enrolled in third year music composition courses, and 18 students enrolled in a third year tax law course at an Australian university. My primary research question was 'What is the experienced relationship between information literacy and learning?' The secondary research question was "What are the generic and situated aspects of information literacy?'    In this study, I have used phenomenography to describe the qualitatively different ways that students in two distinct disciplines experience the relationship between information literacy and learning. I have suggested curriculum implications of this description based on a relational approach to learning and teaching. The outcomes of the study include two related sets of categories which map the experience of students in music composition and tax law, and the theoretical GeST windows model for information literacy which is based upon literacy models and theories.    The key findings of this study include:  *	A description of the nature of the experienced relationship between information literacy and learning in music composition and tax law as 1) Applying, 2) Discovering and 3) Expressing (music) or Understanding (tax law);  *	the theoretical GeST windows model and alignment of the model with the empirical study; *	the presentation of curriculum implications in music and tax law, and *	an exploration of the nature of information as-it-is-experienced.    The findings may be used by teachers, students, librarians, academic skills advisors,  academic developers and policy makers in higher education.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">information literacy</field><field name="subject">learning</field><field name="subject">phenomenography</field><field name="subject">music composition</field><field name="subject">tax law</field><field name="subject">GeST windows</field><field name="subject">generic skills</field><field name="subject">graduate attributes</field><field name="identifier">http://eprints.qut.edu.au/16665/</field><field name="validLink">True</field></doc><doc><field name="title">The significance of genetic and ecological diversity in a wide-ranging insect pest, Paropsis atomaria Olivier (Coleoptera: Chrysomelidae)</field><field name="creator">Schutze, Mark Kurt</field><field name="description">Paropsis atomaria (Coleoptera; Chrysomelidae) is a eucalypt feeding leaf beetle endemic to southern and east coast Australia, and it is an emergent pest of the eucalypt hardwood industry. Paropsis atomaria was suspected to be a cryptic species complex based on apparent differences in life history characteristics between populations, its wide geographical distribution, and extensive host range within Eucalyptus. In this study genetic and ecological characters of P. atomaria were examined to determine the likelihood of a cryptic complex, and to identify the nature and causes of ecological variation within the taxon.  Mitochondrial sequence variation of the gene COI was compared between populations from the east coast of Australia (South Australia to central Queensland) to assess genetic divergence between individuals from different localities and host plant of origin. Individuals from four collection localities used for the molecular analysis were then compared in a morphometric study to determine if observed genetic divergence was reflected by morphology, and common-garden trials using individuals from Lowmead (central Qld) and Canberra (ACT) were conducted to determine if morphological (body size) variation had a genetic component. Host plant utilisation (larval survival, development time, and pupal weight) by individuals from Lowmead and Canberra were then compared to determine whether differential host plant use had occurred between populations of P. atomaria; individuals from each population were reared on an allopatric and sympatric host eucalypt species (E. cloeziana and E. pilularis). Finally, developmental data from each population was compared and incorporated into a phenology modelling program (Dymex(tm)) using temperature as the principle factor explaining and predicting population phenology under field conditions. Molecular results demonstrated relatively low genetic divergence between populations of P. atomaria which is concomitant with the single species hypothesis, however, there is reduced gene flow between northern and southern populations, but no host plant related genetic structuring. Morphometric data revealed insufficient evidence to separate populations into different taxa; however a correlation between latitude and size of adults was discovered, with larger beetles found at lower latitudes (i.e., adhering to a converse Bergmann cline). Common garden experiments revealed body size to be driven by both genetic and environmental components. Host plant utilisation trials showed one host plant, E. cloeziana, to be superior for both northern and southern P. atomaria populations (increased larval survival and reduced larval development time). Eucalyptus pilularis had a negative effect on pupal weight for Lowmead (northern) individuals (to which it is allopatric), but not so for Canberra (southern) individuals. DYMEX(tm) modelling showed voltinism to be a highly plastic trait driven largely by temperature. Results from across all trials suggest that P. atomaria represents a single species with populations locally adapted to season length, with no evidence of differential host plant utilisation between populations. Further, voltinism is a seasonally plastic trait driven by temperature, but with secondary influential factors such as host plant quality. These data, taken combined, reveal phenotypic variability within P. atomaria as the product of multiple abiotic and biotic factors and representing a complex interplay between local adaptation, phenotypic plasticity, and seasonal plasticity. Implications for pest management include an understanding of population structure, nature of local adaptation and host use characteristics, and predictive models for development of seasonal control regimens.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">cryptic species</field><field name="subject">local adaptation</field><field name="subject">phenotypic plasticity</field><field name="subject">seasonal plasticity</field><field name="subject">host specialisation</field><field name="subject">population genetics</field><field name="subject">Eucalyptus</field><field name="subject">forestry</field><field name="subject">predictive modelling</field><field name="subject">body size</field><field name="subject">Bergmann&#146;s Rule</field><field name="identifier">http://eprints.qut.edu.au/16666/</field><field name="validLink">True</field></doc><doc><field name="title">Investigation of laser frequency stabilisation using modulation transfer spectroscopy</field><field name="creator">Hopper, David J.</field><field name="description">Optical frequency standards are necessary tools for accurate measurement of time and length. In practice these standards are stabilised laser systems locked to a known frequency reference. These references are typically the resonant frequencies of the atoms of an absorption medium that have been theoretically calculated to a high degree of accuracy. This thesis describes a combination of experimental and theoretical research performed on modulation transfer spectroscopy (MTS)--a technique used to frequency stabilise a laser in order to produce an accurate frequency reference--with emphasis placed on developing techniques and procedures to overcome the limitations found in existing MTS stabilised laser systems. The focus of the thesis is to generate a highly accurate frequency reference by researching the system parameters that will increase the signal to noise ratio and improve the accuracy of the reference through refinement of the signal structure.    The early theoretical interpretation of MTS was effectively a low absorption approximation that occurs at low pressures. This approximation ignores the depletion of beam energy through absorption and is a distinct limitation of the theoretical model in its ability to accurately predict the influence of a range of system parameters on signal strength and structure. To overcome this limitation a 3-D (or volumetric) analysis was developed and is presented here for the first time. This volumetric model is a measure of two depleted beams interacting collinearly in an absorbing medium of iodine and is described to accurately predict the signal maximum as a function of pressure for all wavelengths. This model was found to be more accurate in predicting the influence of system parameters on the signal strength and structure, including that of pump beam intensity, pressure, saturation parameter, cell length and modulation parameters.    The volumetric model is a novel approach to MTS theory but is more complex computationally than the traditional low pressure model and therefore more difficult to implement in many situations. To overcome this problem a hybrid model was developed as a combination of the low pressure and volumetric models.    The comparison between the rigorous volume model and the hybrid model indicate that there is a deviation in the signal strength at high pressures. However, the agreement was very good in the pressure regimes that are commonly used to realise actual frequency references. Comparison of the hybrid model to experimental data was performed over a range of different wavelengths (532 nm, 543.5 nm, 612 nm and 633 nm) and found to be in close agreement. This gives confidence in the model to accurately predict signal strength and structure in any situation.    Three mechanisms have been identified that limit the accuracy of frequency references due to the creation of residual amplitude modulation (RAM) where it shifts the frequency of the reference. The influence of RAM is included in the hybrid model as a ratio of the amplitude modulated and frequency modulated components of the saturating beam. These RAM production mechanisms result from the modulation of the saturating beam, the overlap of the beams in the medium, and the differential absorption of the sidebands in the medium. While the first mechanism has been previously reported the latter two are discussed here in detail for the first time. RAM generated by the modulators used (acousto-optic or electro-optic modulators) was typically of the order of 10% to 12%, depending on the excursion of the created sidebands. RAM generated by an asymmetric beam overlap with the modulators used was found to be as large as 30%. A combination of these two independent mechanisms can be used to provide a "RAM-free" state of the system by using one to cancel the effects of the other. The third RAM generation process--medium induced RAM--is difficult to remove but through a careful combination of absorption related parameters--namely, pump intensity, cell length, pressure and detector phase--the effects of RAM can be removed, leading to a distortion free MTS signal.    Further investigation into the predictions provided by the hybrid model shows that there is a complex relationship between cell length and the optimum pressure required for maximum signal strength, such that longer cell lengths will not necessarily improve the signal strength. This is contrary to conventional thinking and is important in the MTS design process to reduce unnecessary costs and improve the signal to noise ratio and frequency accuracy. Optimisation of frequency stabilised laser systems using MTS are generally performed using trial and error. Comparison of these optimum parameter values to those predicted by the hybrid model show that for popular wavelengths such as 532 nm they are similar. In addition, the hybrid model is able to predict the frequency shifts that arise within the system parameters used and has shown that existing systems being used at 532 nm, 633 nm and 778 nm could improve their signal to noise ratio and accuracy through a variation in the parameters. A methodology based on the hybrid model is presented that can be used to calculate the optimum parameters for maximum signal strength and a "RAM-free" state for any wavelength. This systematic approach can therefore be used to guide the design of actual frequency stabilised laser systems prior to and during the design process.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">modulation transfer spectroscopy</field><field name="subject">MTS</field><field name="subject">saturated absorption spectroscopy</field><field name="subject">SAS</field><field name="subject">spectroscopy</field><field name="subject">absorption</field><field name="subject">residual amplitude modulation</field><field name="subject">RAM</field><field name="subject">saturation</field><field name="subject">frequency standard</field><field name="subject">length standard</field><field name="subject">frequency stabilised laser</field><field name="subject">frequency locking</field><field name="subject">frequency reference</field><field name="subject">metrology</field><field name="subject">M&#232;tre des Archives</field><field name="subject">metre</field><field name="identifier">http://eprints.qut.edu.au/16667/</field><field name="validLink">True</field></doc><doc><field name="title">Vampires in the sunburnt country : adapting vampire Gothic to the Australian landscape</field><field name="creator">Nahrung, Jason</field><field name="description">I first became enamoured with vampire Gothic after reading Bram Stoker's Dracula in high school, but gradually became dissatisfied with the Australian adaptations of the sub-genre. In looking for examples of Australian vampire Gothic, a survey of more than 50 short stories, 23 novels and five movies made by Australians reveals fewer than half were set in an identifiably Australian setting. Even fewer make use of three key, landscape-related tropes of vampire Gothic - darkness, earth and ruins. Why are so few Australian vampire stories set in Australia? In what ways can the metaphorical elements of vampire Gothic be applied to the Sunburnt Country? This paper seeks to answer these questions by examining examples of Australian vampire narratives, including film. Particular attention is given to Mudrooroo's Master of the Ghost Dreaming series which, more than any other Australian novel, succeeds in manipulating and subverting the tropes of vampire Gothic. The process of adaptation of vampire Gothic to the Australian environment, both natural and man-made, is also a core concern of my own novel, Vampires' Bane, which uses earth, darkness and a modern permutation of ruins to explore its metaphorical intentions. Through examining previous works and through my own creative process, Vampires' Bane, I argue that Australia's growing urbanisation can be juxtaposed against the vampire-hostile natural environment to enhance the tropes of vampire Gothic, and make Australia a suitable home for narratives that explore the ongoing evolution of Count Dracula and his many-faceted descendants.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">vampire</field><field name="subject">Gothic</field><field name="subject">fiction</field><field name="subject">Bram Stoker</field><field name="subject">Dracula</field><field name="subject">Mudrooroo</field><field name="subject">Master of the Ghost Dreaming</field><field name="subject">Australian fiction</field><field name="subject">horror</field><field name="subject">Dani Cavallaro</field><field name="subject">Ken Gelder</field><field name="subject">Gina Wisker</field><field name="subject">David Stevens</field><field name="subject">Edmund Burke</field><field name="subject">darkness</field><field name="subject">earth</field><field name="subject">blood</field><field name="subject">ruins</field><field name="subject">Milissa Deitz</field><field name="subject">Tracy Ryan</field><field name="subject">Jackie French</field><field name="subject">Keri Arthur</field><field name="subject">Outback Vampires</field><field name="subject">Thirst</field><field name="subject">Bloodlust</field><field name="identifier">http://eprints.qut.edu.au/16668/</field><field name="validLink">True</field></doc><doc><field name="title">Laponite-supported titania photocatalysts</field><field name="creator">Daniel, Lisa Maree</field><field name="description">This thesis describes the synthesis and characterisation of titania photocatalysts for incorporation into a polyethylene film.  Monodisperse, anatase-phase titania nanoparticles are prepared and the synthesis conditions necessary for attraction to a laponite clay support are determined.  Methods of preventing agglomeration of the laponite system such as the use of a polyethylene oxide surfactant or chemical modification of the laponite plate edges with a dimethyloctyl methoxysilane are also explored. Finally, photocatalytic studies on the laponite-supported titania nanoparticles are performed, and the compatibility and photoactivity of these materials in the polyethylene film are examined.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Titania</field><field name="subject">titanium dioxide</field><field name="subject">anatase</field><field name="subject">photoactivity</field><field name="subject">photocatalyst</field><field name="subject">clay</field><field name="subject">colloid</field><field name="subject">hydrothermal treatment</field><field name="subject">laponite</field><field name="subject">surfactant</field><field name="subject">silane</field><field name="subject">silylation</field><field name="subject">edge-modification</field><field name="subject">X-ray diffraction</field><field name="subject">polymer degradation</field><field name="subject">transmission electron microscopy</field><field name="subject">infrared emission spectroscopy</field><field name="subject">attenuated total reflectance infrared spectroscopy</field><field name="subject">BET N2 sorption</field><field name="subject">thermogravimetric analysis</field><field name="subject">29Si Nuclear magnetic Resonance Spectroscopy</field><field name="identifier">http://eprints.qut.edu.au/16669/</field><field name="validLink">True</field></doc><doc><field name="title">In vitro examination of vitronectin, insulin-like growth factor, insulin-like growth factor binding protein complexes as treatments to accelerate the healing of diabetic ulcers</field><field name="creator">Noble, Anthony M.</field><field name="description">It has previously been shown that VN can form complexes with IGF-II or IGF-I in combination with its binding proteins IGFBP-3 or -5.  This study aimed to determine the efficacy of using these complexes as a treatment designed to accelerate wound healing, particularly in diabetic ulcers.  The primary functions of skin cells in wound healing are attachment, proliferation and migration, thus these functions were assessed in response to these complexes in skin cells derived from patients with diabetic ulcers and from non-diabetic patients. These studies examined responses to the complexes in both skin keratinocyte and fibroblast cells. Furthermore, in order to investigate the mechanisms that underlie the responses observed, I also examined the ability of skin cells to retain these functional responses when the complexes incorporated an IGF-I analogue that does not activate the IGF receptor or when the cells had been pre-incubated with an anti-&#945;v-integrin function blocking antibody.  In addition, the ability of the cells to survive and grow when treated with the complexes under conditions mimicking the diabetic wound was assessed using growth assays in which the media contained elevated concentrations of glucose and calcium. I found that cells derived from skin from normal patients showed enhanced proliferation in response to these complexes, whereas only the presence of IGF-I and IGFBP seemed to be important in stimulating the proliferation of cells derived from diabetic patients. I also found that enhanced migration was observed in fibroblasts from diabetic ulcers in response to the complexes but these responses only required the presence of VN in normal cells. Both normal and diabetic keratinocytes showed enhanced migration in response to the complexes and the responses involved the interaction of both IGF-I and VN with their respective cell surface receptors. However the enhanced migration observed in diabetic ulcer derived keratinocytes was approximately half the level seen in normal keratinocytes.  Furthermore, I showed that cells derived from skin from normal patients exhibited greater proliferation when treated with complexes in the presence of high concentrations of glucose and calcium ion compared to cells that were not treated with the complexes. Likewise, cells derived from skin surrounding diabetic ulcers were able to grow in media containing high levels of glucose and calcium when treated with VN:IGFBP:IGF-I complexes. In particular diabetic skin derived fibroblasts grown in high calcium media demonstrated enhanced proliferation when treated with the complexes, whereas diabetic keratinocyte cells seemed less affected by these conditions than their normal counterparts were.    The findings in this thesis show that VN:IGFBP:IGF-I complexes can elicit enhanced growth and migration in cells derived from skin from both normal and diabetic patients. Further, these responses are maintained in conditions found in the diabetic wound microenvironment, namely in the presence of high glucose and high calcium. Together these findings demonstrate the potential of the VN:IGFBP:IGF complexes as wound healing agents to treat wounds, especially diabetic ulcers. Such delayed healing wounds represent a significant burden to health care systems and are one of the primary conditions that leads to the amputation of limbs. Current treatments do not address the co-ordination of ECM and growth factor action on cells that is here demonstrated to stimulate multiple wound healing related functional effects in skin cells. The data presented here represents important new information that may guide the design of new integrated therapeutics that may enhance the healing of recalcitrant diabetic ulcers.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">vitronectin</field><field name="subject">insulin-like growth factor</field><field name="subject">diabetic ulcers</field><field name="subject">healing</field><field name="identifier">http://eprints.qut.edu.au/16670/</field><field name="validLink">True</field></doc><doc><field name="title">Population phenology of the tropical fruit fly, Bactrocera tryoni (Froggatt) (Diptera: Tephritidae), in Queensland, Australia</field><field name="creator">Muthuthantri, Weerawickramage Sakuntala Nayanatara</field><field name="description">Bactrocera tryoni, the Queensland fruit fly, is established along the entire Australian east coast.  It is a major pest of horticulture and arguably the worst horticultural insect pest in Australia.  Adult flies lay eggs into fruit and resultant larvae feed on the  flesh of the fruit.  The population biology of B. tryoni has been well studied in temperate regions, where it has been established that climatic factors, particularly temperature and rainfall, limit population growth.  In contrast, in subtropical and tropical regions, the population dynamics of the fly have been little studied.  This thesis investigates the fly's phenology and abundance changes across subtropical and tropical Queensland and asks what factors govern the population cycles of B. tryoni in this state.  Winter breeding and abundance of the fly, a component of the seasonal cycle which in south-east Queensland is fundamentally different from that observed in temperate Australia, is also investigated. A historical, extensive multi-year and multi-site trapping data set with from across Queensland was analysed to look at the effects of temperature, rainfall and relative humidity on B. tryoni trap catch.  Trap data was further compared with the predicted phenology data generated by a DYMEX&#174; based B. tryoni population phenology model.  The phenology model used was based on a previously published model, but was also modified to more explicitly look at the effects of host plant availability and the presence or absence of non-reproductive over-wintering flies.  Over-wintering field cage studies and a winter-spring field trapping study, both carried out in Brisbane, supplied additional data on B. tryoni's population abundance and capacity to breed during winter in the subtropics. Results show significant variation of monthly fly abundance for nine sites across Queensland.  Abundance changed across sites in non-predictable ways.  Annual population phenology within a site was, for some sites, highly consistent from year to year, but inconsistent for other sites.  All sites in the subtropics showed some form of population depression during the cooler months, but breeding was continuous, albeit reduced at nearly all sites. Some tropical sites, where the climate is regarded as highly favourable for B. tryoni, still showed dramatic peaks and troughs in annual population abundance.  There were relatively few significant correlations observed between weather factors and fly populations for any site.  Output from the DYMEX population model suggested that fruit availability is a major driver of population dynamics in the tropical north of the state, while weather is more important in the subtropical south.  The population dynamics of B. tryoni at sites along the central Queensland coast, where it is assumed that a mix of both weather and host fruit availability drive local populations, were poorly captured by the population model. Field cage results showed that B. tryoni successfully bred during winter in Brisbane, with pupal emergence starting in mid-winter (1st week of August), peaking in early spring (2nd week of September).  Trap catch at orchards in Brisbane increased with increasing temperature and fruit availability, but diminished with decreasing temperature and fruit availability.    The results suggest that B. tryoni has an optimal climate for population growth in the tropics, but fruit availability for offspring production limits population growth. In the subtropics however, both climate and fruit availability determine the population size. Winter temperatures are marginal for B. tryoni population growth in the subtropics.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Bactrocera tryoni</field><field name="subject">breeding</field><field name="subject">Dymex</field><field name="subject">insect</field><field name="subject">integrated pest management</field><field name="subject">population phenology</field><field name="subject">climate</field><field name="subject">larval host</field><field name="subject">over-wintering</field><field name="identifier">http://eprints.qut.edu.au/16671/</field><field name="validLink">True</field></doc><doc><field name="title">Investigating and developing a model for iris changes under varied lighting conditions</field><field name="creator">Phang, Shiau Shing</field><field name="description">Biometric identification systems have several distinct advantages over other authentication technologies, such as passwords, in reliably recognising individuals. Iris based recognition is one such biometric recognition system. Unlike other biometrics such as fingerprints or face images, the distinct aspect of the iris comes from its randomly distributed features. The patterns of these randomly distributed features on the iris have been proved to be fixed in a person's lifetime, and are stable over time for healthy eyes except for the distortions caused by the constriction and dilation of the pupil.    The distortion of the iris pattern caused by pupillary activity, which is mainly due changes in ambient lighting conditions, can be significant. One important question that arises from this is: How closely do two different iris images of the same person, taken at different times using different cameras, in different environments, and under different lighting conditions, agree with each other? It is also problematic for iris recognition systems to correctly identify a person when his/her pupil size is very different from the person's iris images, used at the time of constructing the system's data-base. To date, researchers in the field of iris recognition have made attempts to address this problem, with varying degrees of success. However, there is still a need to conduct in-depth investigations into this matter in order to arrive at more reliable solutions.    It is therefore necessary to study the behaviour of iris surface deformation caused by the change of lighting conditions. In this thesis, a study of the physiological behaviour of pupil size variation under different normal indoor lighting conditions (100 lux ~ 1,200 lux) and brightness levels is presented. The thesis also presents the results of applying Elastic Graph Matching (EGM) tracking techniques to study the mechanisms of iris surface deformation.    A study of the pupil size variation under different normal indoor lighting conditions was conducted. The study showed that the behaviour of the pupil size can be significantly different from one person to another under the same lighting conditions. There was no evidence from this study to show that the exact pupil sizes of an individual can be determined at a given illumination level. However, the range of pupil sizes can be estimated for a range of specific lighting conditions. The range of average pupil sizes under normal indoor lighting found was between 3 mm and 4 mm.    One of the advantages of using EGM for iris surface deformation tracking is that it incorporates the benefit of the use of Gabor wavelets to encode the iris features for tracking. The tracking results showed that the radial stretch of the iris surface is nonlinear. However, the amount of extension of iris surface at any point on the iris during the stretch is approximately linear. The analyses of the tracking results also showed that the behaviour of iris surface deformation is different from one person to another. This implies that a generalised iris surface deformation model cannot be established for personal identification. However, a deformation model can be established for every individual based on their analysis result, which can be useful for personal verification using the iris.    Therefore, analysis of the tracking results of each individual was used to model iris surface deformations for that individual. The model was able to estimate the movement of a point on the iris surface at a particular pupil size. This makes it possible to estimate and construct the 2D deformed iris image of a desired pupil size from a given iris image of another different pupil size. The estimated deformed iris images were compared with their actual images for similarity, using an intensitybased (zero mean normalised cross-correlation). The result shows that 86% of the comparisons have over 65% similarity between the estimated and actual iris image. Preliminary tests of the estimated deformed iris images using an open-source iris recognition algorithm have showed an improved personal verification performance. The studies presented in this thesis were conducted using a very small sample of iris images and therefore should not be generalised, before further investigations are conducted.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">iris surface deformation</field><field name="subject">iris movement</field><field name="subject">mechanisms of iris movement</field><field name="subject">change of pupil size</field><field name="subject">elastic graph matching</field><field name="subject">Gabor wavelets</field><field name="subject">image warping</field><field name="subject">biometrics based recognition</field><field name="subject">iris recognition</field><field name="identifier">http://eprints.qut.edu.au/16672/</field><field name="validLink">True</field></doc><doc><field name="title">The rate-limiting mechanism for the heterogeneous burning of iron in normal gravity and reduced gravity</field><field name="creator">Ward, Nicholas Rhys</field><field name="description">This thesis presents a research project in the field of oxygen system fire safety relating to the heterogeneous burning of iron in normal gravity and reduced gravity. Fires involving metallic components in oxygen systems often occur, with devastating and costly results, motivating continued research to improve the safety of these devices through a better understanding of the burning phenomena. Metallic materials typically burn in the liquid phase, referred to as heterogeneous burning. A review of the literature indicates that there is a need to improve the overall understanding of heterogeneous burning and better understand the factors that influence metal flammability in normal gravity and reduced gravity. Melting rates for metals burning in reduced gravity have been shown to be higher than those observed under similar conditions in normal gravity, indicating that there is a need for further insight into heterogeneous burning, especially in regard to the rate-limiting mechanism. The objective of the current research is to determine the cause of the higher melting rates observed for metals burning in reduced gravity to (a) identify the rate-limiting mechanism during heterogeneous burning and thus contribute to an improved fundamental understanding of the system, and (b) contribute to improved oxygen system fire safety for both ground-based and space-based applications. In support of the work, a 2-s duration ground-based drop tower reduced-gravity facility was commissioned and a reduced-gravity metals combustion test system was designed, constructed, commissioned and utilised. These experimental systems were used to conduct tests involving burning 3.2-mm diameter cylindrical iron rods in high-pressure oxygen in normal gravity and reduced gravity. Experimental results demonstrate that at the onset of reduced gravity, the burning liquid droplet rapidly attains a spherical shape and engulfs the solid rod, and that this is associated with a rapid increase in the observed melting rate. This link between the geometry of the solid/liquid interface and melting rate during heterogeneous burning is of particular interest in the current research. Heat transfer analysis was performed and shows that a proportional relationship exists between the surface area of the solid/liquid interface and the observed melting rate. This is confirmed through detailed microanalysis of quenched samples that shows excellent agreement between the proportional change in interfacial surface area and the observed melting rate. Thus, it is concluded that the increased melting rates observed for metals burning in reduced gravity are due to altered interfacial geometry, which increases the contact area for heat transfer between the liquid and solid phases. This leads to the conclusion that heat transfer across the solid/liquid interface is the rate-limiting mechanism for melting and burning, limited by the interfacial surface area. This is a fundamental result that applies in normal gravity and reduced gravity and clarifies that oxygen availability, as postulated in the literature, is not rate limiting. It is also established that, except for geometric changes at the solid/liquid interface, the heterogeneous burning phenomenon is the same at each gravity level. A conceptual framework for understanding and discussing the many factors that influence heterogeneous burning is proposed, which is relevant to the study of burning metals and to oxygen system fire safety in both normal-gravity and reduced-gravity applications.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">metal combustion</field><field name="subject">microgravity</field><field name="subject">reduced gravity</field><field name="subject">normal gravity</field><field name="subject">oxygen</field><field name="subject">fire safety</field><field name="subject">metal flammability</field><field name="subject">burning iron</field><field name="subject">heterogeneous burning</field><field name="subject">cylindrical rod</field><field name="subject">heat transfer model</field><field name="subject">rate-limiting mechanism</field><field name="subject">rate-limiting step</field><field name="subject">solid/liquid interface</field><field name="subject">melting interface</field><field name="subject">regression rate of the melting interface</field><field name="subject">melting rate</field><field name="subject">surface tension</field><field name="subject">microanalysis</field><field name="subject">test methods</field><field name="subject">drop tower</field><field name="identifier">http://eprints.qut.edu.au/16673/</field><field name="validLink">True</field></doc><doc><field name="title">Flexural behaviour and design of the new LiteSteel beams</field><field name="creator">Kurniawan, Cyrilus Winatama</field><field name="description">The flexural capacity of the new hollow flange steel section known as LiteSteel beam (LSB) is limited by lateral distortional buckling for intermediate spans, which is characterised by simultaneous lateral deflection, twist and web distortion. Recent research based on finite element analysis and testing has developed design rules for the member capacity of LiteSteel beams subject to this unique lateral distortional buckling. These design rules are limited to a uniform bending moment distribution. However, uniform bending moment conditions rarely exist in practice despite being considered as the worst case due to uniform yielding across the span. Loading position or load height is also known to have significant effects on the lateral buckling strength of beams. Therefore it is important to include the effects of these loading conditions in the assessment of LSB member capacities.    Many steel design codes have adopted equivalent uniform moment distribution and load height factors for this purpose. But they were derived mostly based on data for conventional hot-rolled, doubly symmetric I-beams subject to lateral torsional buckling. In contrast LSBs are made of high strength steel and have a unique crosssection with specific residual stresses and geometrical imperfections along with a unique lateral distortional buckling mode. The moment distribution and load height effects for LSBs, and the suitability of the current steel design code methods to accommodate these effects for LSBs are not yet known. The research study presented in this thesis was therefore undertaken to investigate the effects of nonuniform moment distribution and load height on the lateral buckling strength of simply supported and cantilever LSBs.    Finite element analyses of LSBs subject to lateral buckling formed the main component of this study. As the first step the original finite element model used to develop the current LSB design rules for uniform moment was improved to eliminate some of the modelling inaccuracies. The modified finite element model was validated using the elastic buckling analysis results from well established finite strip analysis programs. It was used to review the current LSB design curve for uniform moment distribution, based on which appropriate recommendations were made.    The modified finite element model was further modified to simulate various loading and support configurations and used to investigate the effects of many commonly used moment distributions and load height for both simply supported and cantilever LSBs. The results were compared with the predictions based on the current steel code design rules. Based on these comparisons, appropriate recommendations were made on the suitability of the current steel code design methods. New design recommendations were made for LSBs subjected to non-uniform moment distributions and varying load positions. A number of LSB experiments was also undertaken to confirm the results of finite element analysis study.    In summary the research reported in this thesis has developed an improved finite element model that can be used to investigate the buckling behaviour of LSBs for the purpose of developing design rules. It has increased the understanding and knowledge of simply supported and cantilever LSBs subject to non-uniform moment distributions and load height effects. Finally it has proposed suitable design rules for LSBs in the form of equations and factors within the current steel code design provisions. All of these advances have thus further enhanced the economical and safe design of LSBs.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">lateral distortional buckling</field><field name="subject">lateral torsional buckling</field><field name="subject">LiteSteel beam</field><field name="subject">moment distribution effect</field><field name="subject">moment gradient</field><field name="subject">load height effect</field><field name="subject">finite element analysis</field><field name="subject">elastic buckling analysis</field><field name="subject">non-linear static analysis</field><field name="subject">flexural behaviour</field><field name="subject">structural stability</field><field name="identifier">http://eprints.qut.edu.au/16674/</field><field name="validLink">True</field></doc><doc><field name="title">Knowledge discovery using pattern taxonomy model in text mining</field><field name="creator">Wu, Sheng-Tang</field><field name="description">In the last decade, many data mining techniques have been proposed for fulfilling various knowledge discovery tasks in order to achieve the goal of retrieving useful information for users. Various types of patterns can then be generated using these techniques, such as sequential patterns, frequent itemsets, and closed and maximum patterns. However, how to effectively exploit the discovered patterns is still an open research issue, especially in the domain of text mining. Most of the text mining methods adopt the keyword-based approach to construct text representations which consist of single words or single terms, whereas other methods have tried to use phrases instead of keywords, based on the hypothesis that the information carried by a phrase is considered more than that by a single term. Nevertheless, these phrase-based methods did not yield significant improvements due to the fact that the patterns with high frequency (normally the shorter patterns) usually have a high value on exhaustivity but a low value on specificity, and thus the specific patterns encounter the low frequency problem. This thesis presents the research on the concept of developing an effective Pattern Taxonomy Model (PTM) to overcome the aforementioned problem by deploying discovered patterns into a hypothesis space. PTM is a pattern-based method which adopts the technique of sequential pattern mining and uses closed patterns as features in the representative. A PTM-based information filtering system is implemented and evaluated by a series of experiments on the latest version of the Reuters dataset, RCV1. The pattern evolution schemes are also proposed in this thesis with the attempt of utilising information from negative training examples to update the discovered knowledge. The results show that the PTM outperforms not only all up-to-date data mining-based methods, but also the traditional Rocchio and the state-of-the-art BM25 and Support Vector Machines (SVM) approaches.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">pattern taxonomy model</field><field name="subject">information retrieval</field><field name="subject">text mining</field><field name="subject">data mining</field><field name="subject">association rules</field><field name="subject">sequential pattern mining</field><field name="subject">closed sequential patterns</field><field name="subject">pattern deploying</field><field name="subject">pattern evolving</field><field name="identifier">http://eprints.qut.edu.au/16675/</field><field name="validLink">True</field></doc><doc><field name="title">Lipreading across multiple views</field><field name="creator">Lucey, Patrick Joseph</field><field name="description">Visual information from a speaker's mouth region is known to improve automatic speech recognition (ASR) robustness, especially in the presence of acoustic noise. Currently, the vast majority of audio-visual ASR (AVASR) studies assume frontal images of the speaker's face, which is a rather restrictive human-computer interaction (HCI) scenario. The lack of research into AVASR across multiple views has been dictated by the lack of large corpora that contains varying pose/viewpoint speech data. Recently, research has concentrated on recognising human be- haviours within &amp;quotmeeting " or &amp;quotlecture " type scenarios via &amp;quotsmart-rooms ". This has resulted in the collection of audio-visual speech data which allows for the recognition of visual speech from both frontal and non-frontal views to occur. Using this data, the main focus of this thesis was to investigate and develop various methods within the confines of a lipreading system which can recognise visual speech across multiple views. This reseach constitutes the first published work within the field which looks at this particular aspect of AVASR.    The task of recognising visual speech from non-frontal views (i.e. profile) is in principle very similar to that of frontal views, requiring the lipreading system to initially locate and track the mouth region and subsequently extract visual features. However, this task is far more complicated than the frontal case, because the facial features required to locate and track the mouth lie in a much more limited spatial plane. Nevertheless, accurate mouth region tracking can be achieved by employing techniques similar to frontal facial feature localisation. Once the mouth region has been extracted, the same visual feature extraction process can take place to the frontal view. A novel contribution of this thesis, is to quantify the degradation in lipreading performance between the frontal and profile views. In addition to this, novel patch-based analysis of the various views is conducted, and as a result a novel multi-stream patch-based representation is formulated. Having a lipreading system which can recognise visual speech from both frontal and profile views is a novel contribution to the field of AVASR. How- ever, given both the frontal and profile viewpoints, this begs the question, is there any benefit of having the additional viewpoint? Another major contribution of this thesis, is an exploration of a novel multi-view lipreading system. This system shows that there does exist complimentary information in the additional viewpoint (possibly that of lip protrusion), with superior performance achieved in the multi-view system compared to the frontal-only system.    Even though having a multi-view lipreading system which can recognise visual speech from both front and profile views is very beneficial, it can hardly considered to be realistic, as each particular viewpoint is dedicated to a single pose (i.e. front or profile). In an effort to make the lipreading system more realistic, a unified system based on a single camera was developed which enables a lipreading system to recognise visual speech from both frontal and profile poses. This is called pose-invariant lipreading. Pose-invariant lipreading can be performed on either stationary or continuous tasks. Methods which effectively normalise the various poses into a single pose were investigated for the stationary scenario and in another contribution of this thesis, an algorithm based on regularised linear regression was employed to project all the visual speech features into a uniform pose. This particular method is shown to be beneficial when the lipreading system was biased towards the dominant pose (i.e. frontal). The final contribution of this thesis is the formulation of a continuous pose-invariant lipreading system which contains a pose-estimator at the start of the visual front-end. This system highlights the complexity of developing such a system, as introducing more flexibility within the lipreading system invariability means the introduction of more error.    All the works contained in this thesis present novel and innovative contributions to the field of AVASR, and hopefully this will aid in the future deployment of an AVASR system in realistic scenarios.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">audio-visual automatic speech recognition</field><field name="subject">lipreading</field><field name="subject">frontal pose</field><field name="subject">profile pose</field><field name="subject">multi-view</field><field name="subject">visual front-end</field><field name="subject">visual feature extraction</field><field name="subject">pose-invariance</field><field name="subject">multi-stream fusion</field><field name="identifier">http://eprints.qut.edu.au/16676/</field><field name="validLink">True</field></doc><doc><field name="title">Identification and comparative analysis of novel factors from the venom gland of the coastal taipan (Oxyuranus scutellatus) and related species</field><field name="creator">St Pierre, Liam Daniel</field><field name="description">Snake venoms are a complex mixture of polypeptide and other molecules that adversely affect multiple homeostatic systems within their prey in a highly specific and targeted manner. Amongst the most potently toxic venoms in the world are those of the Australian venomous snakes, which belong almost exclusively to the elapid family. Their venoms posses a number of unique properties by which they target the mammalian cardiovascular and neuromuscular systems and are the focus for the identification of novel pharmacologically interesting compounds which may be of diagnostic or therapeutic benefit. Although much is known about the biochemical properties of Australia snake venoms as a whole, little research attention has focused upon individual components at the molecular level. This thesis describes the cloning, characterisation and comparative analysis of a number of unique toxins from the venom gland of the coastal taipan (Oxyuranus scutellatus) and a total of seven other related Australian snakes. These include the factor X- and factor V-like components of a prothrombin activator that causes a highly coagulable state in mammals. Comparative analysis of the sequences identified in this study, along with recombinant expression of an active form of the factor X-like component, provides important information on the structural, functional and evolutionary relationships of these molecules. Numerous other toxins were similarly identified and characterised including a pseudechetoxin-like protein, multiple phospholipase A2 enzymes and neurotoxin isoforms as well as vasoactive venom natriuretic peptides. Identified transcripts included not only toxin sequences but also other cellular peptides implicated in toxin processing, including a calglandulin-like protein. This thesis is the first description of the majority of these molecules at either the cDNA or protein level, and provides a means to study the activity of individual components from snake venoms and probe their function within the systems they specifically target. This study represents the most detailed and comprehensive description to date of the cloning and characterisation of different genes associated with envenomation from Australian snakes.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">coastal taipan (Oxyuranus scutellatus)</field><field name="subject">Australian elapid snake</field><field name="subject">venom</field><field name="subject">gene cloning</field><field name="subject">recombinant protein expression</field><field name="subject">toxin</field><field name="subject">prothrombin activator</field><field name="subject">phospholipase a2</field><field name="subject">pseudechetoxin</field><field name="subject">neurotoxin</field><field name="subject">natriuretic peptide</field><field name="subject">calglandulin</field><field name="subject">l-amino acid oxidase</field><field name="identifier">http://eprints.qut.edu.au/16677/</field><field name="validLink">True</field></doc><doc><field name="title">Adult Survivors of Childhood Sexual Abuse: Forgetting and Remembering</field><field name="creator">Hodder-Fleming, Leigh</field><field name="description">Past research on adult memory for childhood sexual abuse (CSA) has provided support for the phenomenon of forgetting and subsequent recovery of the memories, after a period of time.  This phenomenon, however, remains a source of debate and is still not fully understood by researchers and psychological and legal practitioners.  The research has provided conflicting evidence about the factors which are thought to lead to CSA forgetting for extensive periods of time, in addition to the processes involved in forgetting, triggering and later remembering of the abuse memories by adult survivors.    This study utilised a mixed method to investigate and explore the factors and processes associated with CSA forgetting, triggering and later remembering, in a sample of Australian adult CSA survivors (N = 77).  Participants were asked to complete a test booklet, containing the Traumatic Events Questionnaire (TEQ), Symptom Checklist-90-Revised (SCL-90-R), Dissociative Experiences Scale II (DES II), Impact of Events Scale - Revised (IES-R), a scale designed to measure persistence of memory (Loftus), and a scale designed to measure emotional intensity at the time of the abuse and now (Williams).  Participants were then asked to participate in a semi-structured interview.  Seventy-one participants completed the interview process. Five separate analyses were conducted on the data.    Methodological issues, such as the use of retrospective data and corroboration of the abuse were outlined.  All participants were asked to provide details about any corroboration they had received that the abuse had occurred.  The participants were streamed into one of three categories of forgetting (Always Remembered, n = 28; Partial Forgetting, n = 16; and Extensive Forgetting, n = 33).  The first analysis (Stage One Analysis One) examined the factors thought to be associated with CSA forgetting, such as abuse parameters (TEQ), current psychological functioning (SCL-90-R), persistence of memory (Loftus), emotional intensity at the time of the abuse and now (Williams), the trauma response experienced at the time of the abuse (IES-R), and current dissociation (DES II), to determine the significant differences between the three groups.  A significant difference was found regarding the age at which the abuse commenced, with the Extensive Forgetting group reporting an earlier age at which the abuse commenced.  Significant differences were found on the variable that related to being abused by an aunt or uncle, and on the current experience of hostility (SCL-90-R sub-scale), and on the current levels of anger (Williams Emotional Intensity) experienced by the participants.  Significant differences between the groups were also found on two of the Persistence of Memory items, namely clarity of memory and participants' memory of the tastes related to the abuse.  Finally, a significant difference was found on the participants' current dissociation levels, with the Extensive Forgetting group reporting higher levels of current dissociation than the other two groups.   Statistical profiles for each of the three groups were constructed, based on the mean scores of the SCL-90-R, IES-R and DES II, for use in the Stage Two, Analysis Two, profile comparison.    Stage Two, Analysis One, provided a qualitative analysis relating to the experience of always remembering the abuse.  The aim of this analysis was to provide a deeper understanding of why some participants (n = 23) did not forget about their abuse, when other participants reported being able to forget for a period of time.  The results indicated that participants' responses formed clusters, such as older age at abuse onset, failed dissociative mechanisms, constant reminders, and others.    Stage Two, Analysis Two, presented and compared each participant's profile against the statistical profiles constructed in Stage One.  The participant's profiles included a summary of their TEQ responses and interview responses, in addition to their Stage One test booklet scores.  The comparison was made, firstly, on a specific basis against the mean scores obtained by each category of forgetting, and secondly, on a broader basis, against the score range for each measure of the statistical profile.  This was done to determine if there was a "typical" member of each category of forgetting and to investigate the within-group differences.  The specific profile comparison demonstrated that there was no "typical" member of any of the three groups, with participants varying widely in their scores and patterns of scores.  However, when the profile comparison was broadened to include score ranges, 61% of participants, who always remembered the abuse, 44% of participants who partially forgot the abuse, and 47% of participants who extensively forgot their abuse, matched the profile of a "typical" member of their relevant category of forgetting.    Stage Two, Analysis Three, provided an in-depth qualitative exploration on the process involved in CSA forgetting, triggering and later remembering, for a selection of participants who reported partially forgetting the abuse (n = 6), and extensively forgetting the abuse (n = 10).  Participants' interview responses were transcribed verbatim and analysed, using Interview Analysis.  This analysis explored the differences between participants, from the two categories of forgetting, on their experiences of CSA forgetting, triggering and later remembering, in addition to exploring how these participants were able to forget about the abuse; what events triggered their abuse memories; and how the initial memories returned.  Issues of memory recovery, while in therapy or under hypnosis, were also explored. Stage Two, Analysis Four, presented the case study of a participant, who had been identified as an "outlier", due to her high score on the DES II, claims of being able to remember abuse incidents that occurred prior to the age of two years, diagnosis of DID, and the substantiated conviction and sentencing of her abuser, based on her recovered memories of the abuse and corroboration from her sister and mother.  Her case was examined against some of the criticisms often made by false memory supporters.    This thesis found that some CSA survivors forgot about their abuse, either partially or extensively.  The thesis also found support for some, but not all, of the factors that previous researchers have identified as being associated with CSA forgetting by adult survivors, specifically the individual's age at the time the abuse commenced and the individual's ability to dissociate from the abuse.  The research then explored, in-depth, the issues of: CSA remembering, CSA survivor profiling, and the "how" of CSA forgetting, triggering and later remembering, by adult survivors.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">childhood sexual abuse; forgetting; remembering; adult survivors; trauma; memory; post-traumatic stress disorder; dissociation</field><field name="identifier">http://eprints.qut.edu.au/16678/</field><field name="validLink">True</field></doc><doc><field name="title">Dynamic contrast-enhanced CT in the investigation of tumour angiogenesis and haemodynamics</field><field name="creator">Griffiths, Matthew R.</field><field name="description">This manuscript presents an investigation and application of the medical radiographic technique of Dynamic Contrast-enhanced Computed Tomography with an emphasis on its application to the measurement of tissue perfusion using the techniques of CT Perfusion. CT Perfusion was used in association with Fluoro- Deoxy Glucose Positron Emission Tomography (FDG PET) to investigate altered blood flow due to the angiogenic effects of tumour in the clinical setting of medical imaging for cancer diagnosis and staging.    CT perfusion, CT enhancement and Doppler ultrasound studies were compared in a series of patient studies performed for the assessment of metastatic liver disease. There was good correlation between all techniques for the arterial phase but not between Doppler measurements of the portal phase and any CT measurement. A new method was developed for quantifying CT perfusion and enhancement values, the Standardised Perfusion Value (SPV) and the Standardised Enhancement Value (SEV). The SPV was shown to correlate with FDG uptake in a series of 16 patient studies of lung nodules, an unexpected and potentially important finding that if confirmed in a larger study may provide an additional diagnostic role for CT in the assessment of lung nodules.    Investigation of a commercially available package for the determination of CT Perfusion, CT Perfusion GE Medical Systems, was undertaken in a small series of brain studies for assessment of acute stroke. This data set showed the technique to positively identify patients with non-hemorrhagic stroke in the presence of a normal conventional CT, to select those cases where thrombolysis is appropriate, and to provide an indication for prognosis.    An investigation of the accuracy and cost-effectiveness of FDG PET in solitary pulmonary nodules using Australian data was carried out. FDG PET was found to be accurate, cost saving and cost effective for the characterisation of indeterminate solitary pulmonary nodules in Australia. This work was expanded to include the impact of quantitative contrast enhancement CT (QECT) on the cost-effectiveness of FDG PET. The addition of QECT is a cost effective approach, however whether QECT is used alone or in combination with FDG PET will depend on local availability of PET, the cost of PET with respect to surgery and the prior probability of malignancy.    A published review of CT perfusion, clinical applications and techniques, is included in the body of the work.    Dynamic contrast-enhanced CT and FDG PET were used to investigate blood flow, expressed as SPV, and metabolic relationships in non-small cell lung cancers (NSCLC) of varying size and stage. A significant correlation between SPV and FDG uptake was only found for tumours smaller than 4.5 cm2. Blood flow-metabolic relationships are not consistent in NSCLC but depend on tumour size and stage. Dynamic contrast-enhanced CT as an adjunct to an FDG study undertaken using integrated PET-CT offers an efficient way to augment the assessment of tumour biology with possible future application as part of clinical care. In summary the work has developed a method for standardizing the results of dynamic contrast-enhanced CT and investigated its potential when applied with FDG PET to improve the diagnosis and staging of cancers.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">dynamic contrast enhanced CT</field><field name="subject">tumour</field><field name="subject">angiogenesis</field><field name="subject">haemodynamics</field><field name="identifier">http://eprints.qut.edu.au/16679/</field><field name="validLink">True</field></doc><doc><field name="title">The impact of financial incentive mechanisms on motivation in Australian government large non-residential building projects</field><field name="creator">Rose, Timothy M.</field><field name="description">The use of financial incentives mechanisms (FIMs) in Australian government large nonresidential building projects is seen as a way to improve project motivation and outcomes and reinforce long-term commitment between participants. Yet very little empirical research has been conducted into how FIMs should be applied in the context of construction projects and what determines their impact on motivation. The primary aim of this research was to identify the motivation drivers impacting on the achievement of FIM goals. This allowed for the formulation of recommendations to improve Australian government building procurement strategies, creating the potential for better project outcomes.    The research involved four major case studies of large construction projects. Analysis of motivation drivers on each project was based on interviews with senior project participants, secondary documentation and site visits. Once the motivation drivers were identified, they were ranked by the weighted number of motivation indicators impacted, to give an indication of their relative importance. The results provide Australian government clients with key areas for policy direction.    The findings indicate that the following motivation drivers (in order of impact) were more important than FIM design in achieving FIM goals:    &#61589;&#61472;equitable contract risk allocation and management  &#61589;&#61472;scope for future project opportunities with the client  &#61589;&#61472;harmonious project relationships  &#61589;&#61472;early contractor involvement in design stages  &#61589;&#61472;value-driven tender selection processes.    A consequence of ignoring these key procurement initiatives can be a less than ideal FIM goal performance, despite the nature of FIM design, including the strength of the reward on offer. FIMs have the potential to be a valuable addition to any project procurement strategy. Yet, the main message of this thesis is: If clients rely solely on financial incentives as the driver of motivation it will likely result in failure.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">financial incentive</field><field name="subject">non-residential building projects</field><field name="identifier">http://eprints.qut.edu.au/16680/</field><field name="validLink">True</field></doc><doc><field name="title">Inverse diffraction propagation applied to the parabolic wave equation model for geolocation applications</field><field name="creator">Spencer, Troy Allan</field><field name="description">Localisation, which is a mechanism for discovering the spatial relationship between objects, is an area that has received considerable research and development in recent times. A common name given to localisation operations based on the absolute reference frame of Earth is Geolocation. One important example of geolocation research is E-911, where wireless carriers in the United States must provide the location of 911 callers. The operation of E-911 can be based on either a network configuration, or the Global Positioning System (GPS). With the importance of localisation being acknowledged, a review concerning the vulnerability of the Global Navigation Satellite System (GNSS) is provided as background and motivation for this research. With the current vulnerability of GNSS, this dissertation presents the results of a research program undertaken with the objective of developing an electromagnetic localisation technique that can determine the relative position of GPS Radio Frequency Interference (RFI) sources. Intended for operation in a hostile environment, blind and passive localisation methodologies must be incorporated into the developed model. In performing localisation research, a background of current techniques is provided in addition to a review of current electromagnetic propagation models. From the review of propagation models, the Parabolic Equation Model (PEM) was chosen for investigation concerning localisation. The selection of PEM is due to model properties that are required for blind/passive localisation. The localisation system developed in this research program is based on the integration of inverse diffraction propagation (IDP) within the parabolic equation model. The title chosen for the localisation method is Inverse Diffraction Parabolic Equation Localisation System (IDPELS). This thesis presents the simulation and field trial results of IDPELS. Under simulation, the terrain or obstacle profiles were not based on any geodetic datum. Any estimate provided by IDPELS under simulation is therefore a "Localisation" solution. In the field trials however, IDPELS operation is referred to as "Geolocation" as geodetic datum's where used to determine the receiver's position. Under simulation analysis, IDPELS operation was considered to provide good promise as it could simultaneously perform localisation on multiple transmission sources. In each investigated simulation scenario, a display of signals amplitude (dB units) is displayed over the entire region. By determining the field convergence regions, a localisation estimate of IDPELS is provided. By defining the convergence regions as areas having the greatest signal amplitude values (i.e. &#8805; 99%), elliptical areas as low as 3.2m&#178; were considered to indicate an excellent localisation capability. With the theoretical validity of IDPELS operation in electromagnetics having been established under simulation, further investigation into the practical feasibility of the IDPELS was performed. The field trials positioned a continuous-wave (CW) transmission source at a known location. By measuring signal phasors along a straight section of road, the geodetic spatial-phase profile was used as the input signal for IDPELS. Road sections used were cross-wise to the transmitter's boresight. Many data sets were recorded, each being made over a sixty second time period. Different regions and ranges where used to continuously measure the spatial-phase profile of the signal with fixed antennas in a moving vehicle. Such a measurement process introduced an analogy with Synthetic Aperture Radar (SAR) processes. In quantitating the accuracy of the IDPELS geolocation estimate in field trials, the linear error of range and cross-range components was analysed. A free-space PEM model was chosen for development of IDPELS and hence, data sets demonstrating properties of a free-space environment were able to be considered suitable for testing of the geolocation method. Data sets demonstrating free-space propagation characteristics were measured at the base of the Mt Lofty ranges in South Australia, where the range and cross-range error are respectively 3.14m, and 0.15m. Such low error values clearly demonstrate the practical feasibility of IDPELS geolocation. With the practical feasibility of IDPELS having been established in this research program, a novel contribution to electromagnetic geolocation methodologies is provided. An important characteristic of any geolocation technique concerns its robustness to operate in a wide variety of possible environments. With continued development of IDPELS, the robustness of this passive/blind geolocation technique can be enhanced. Further assistance with geolocation of multiple transmission sources is also indicated to be available by IDPELS, as shown in the simulation analysis.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">global positioning system</field><field name="subject">global navigation satellite system</field><field name="subject">electromagnetic propagation model</field><field name="subject">inverse diffraction propagation</field><field name="subject">parabolic equation model</field><field name="subject">Huygens principle model</field><field name="subject">blind localisation</field><field name="subject">passive localisation</field><field name="subject">geolocation</field><field name="subject">radio frequency interference</field><field name="identifier">http://eprints.qut.edu.au/16681/</field><field name="validLink">True</field></doc><doc><field name="title">Conceptions of geographic information systems (GIS) held by senior geography students in Queensland</field><field name="creator">West, Bryan A.</field><field name="description">Geographical Information Systems (GIS) represent one of the major contributions to spatial analysis and planning of the new technologies. While teachers and others have viewed its potential contribution to geographical education as considerable, it has not been known with any certainty whether they present a valuable educational tool that aids geographical education. The value of GIS to geographical education is viewed as depending on a geographical education being, in itself, valuable.    Within this context, synergetic focus groups are employed to explore the conceptions of GIS held by 109 secondary school students studying Senior Geography in metropolitan and regional Queensland, Australia. A phenomenographic approach is adopted to identify the six qualitatively different ways, or conceptions, in which the participating students experience GIS as:    1. Maps and a source of maps in geography.  2. Mapping in geography: a way to use and create maps.  3. A professional mapping tool: exceeding the needs of senior  geography.  4. Frustrating geography: irksome and presenting many challenges  to the student-user.  5. Relevant geography: within and beyond the school experience.  6. A better geography: offering a superior curriculum, and broader  geographical education, when contrasted to a senior geography  that omits its use.    The structural and referential elements of each of these conceptions are elucidated within corresponding Categories of Description. The qualitatively different ways in which the conceptions may be experienced are illustrated through an Outcome Space, comprising a metaphoric island landscape. This structural framework reveals that for the Senior Geography students who participated in this investigation, the extent to which GIS may augment the curriculum is influenced by the nature of students' individual understandings of how GIS manages spatial data.    This research project is a response to repeated calls in the literature for teachers of geography themselves to become researchers and for a better understanding of GIS within geography education. It reviews the salient literature with respect to geography and geography education generally, and GIS within geographical education specifically. The investigation has confirmed that qualitatively different conceptions of GIS exist amongst students and that these are not consistently aligned with assumptions about its use and benefits as presented by current literature.    The findings of the study contribute to knowledge of the potential educational outcomes associated with the use of GIS in geography education and decisions related to current and potential geography curricula. It provides guidance for future curriculum development involving GIS and argues for additional research to inform educators and the spatial sciences industry about the actual and perceived role of GIS within geography education.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">conceptions of GIS</field><field name="subject">geographical information systems</field><field name="subject">GIS</field><field name="subject">geography education</field><field name="subject">information and communications technologies</field><field name="subject">maps and mapping</field><field name="subject">phenomenography</field><field name="subject">senior geography</field><field name="subject">students</field><field name="subject">teaching and learning</field><field name="subject">qualitative research methods</field><field name="identifier">http://eprints.qut.edu.au/16682/</field><field name="validLink">True</field></doc><doc><field name="title">The developing clarinet player : new multi-genre, pan-technical repertoire</field><field name="creator">Millard, Bradley David</field><field name="description">Those undertaking the study of a musical instrument may focus on a specific genre of music or diversify through exploration of a range of styles and forms. Students wishing to gain insight into a variety of styles may seek guidance from a number of sources, particularly in their formative years. In the interests of achieving stylistic authenticity and in the absence of teachers with wide-ranging musical experience, the student may seek direction from repertoire and pedagogical resources. This research aims to address a deficiency in existing repertoire and teaching materials for the beginner to intermediate classical clarinet player by contributing to and extending current resources.    The thesis is presented in two parts - folio (60%) and exegesis (40%): The folio involves the creation of a series of original works written in a range of archetypal jazz, popular and classical music styles, aimed at providing a level of instructional support for both student and teacher in the achievement of stylistic integrity. This is realised through the inclusion of annotations and recommended practice strategies for each piece, as well as a general guide to style section. To be of further educational value to the student, compositions in the folio incorporate both traditional and extended techniques.    The exegesis reviews current leading instructional manuals and repertoire, discusses their strengths and weaknesses and identifies areas where resources are deficient. It analyses and presents an overview of compositions in the folio and provides a detailed commentary of the compositional process, using a selected work as an exemplar.    Given the nature of the folio, which is aimed at the young clarinet player and teacher and commences with advice on style followed by a series of compositions, the exegesis precedes the folio in this thesis.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">clarinet</field><field name="subject">pan-technical repertoire</field><field name="subject">clarinet compositions</field><field name="identifier">http://eprints.qut.edu.au/16683/</field><field name="validLink">True</field></doc><doc><field name="title">Environmental performance indicators for the lower Mekong subregion development</field><field name="creator">Amawatana, Chonchinee</field><field name="description">The application of environmental performance indicators (EPIs) has received increasing attention by both governments and international organisations as a tool for assessing complex environmental scenarios in national and local decision making processes. However, at the regional scale there is a gap in the application of EPIs, as this has not been well understood and defined due to a limited theoretical foundation and often insufficient data from all participant countries. The regional scale is important because it can incorporate natural ecosystems which often transcend national boundaries. A case study is developed for the Lower Mekong Subregion (LMS), where four riparian Southeast Asian countries (Lao PDR, Thailand, Cambodia, and Viet Nam) share the Lower Mekong River.    The research proposes a conceptual framework to identify approaches for developing criteria for acceptable and appropriate EPIs which can be used to support and implement decision making processes by relevant organisations at the regional level. This research evaluates the application of environmental performance indicators using methodologies that assess cross-national quantitative and qualitative data and existing decision support systems. In addition, global and national indicators are examined for application and relation to the regional context.    The research finds that the application of EPIs varies according to spatial scale, and is diverse among the four countries. Data availability is also identified as a major problem encountered during the development and selection of EPIs. The study finds that the governance of the existing regional body is ineffective due to differing agendas pursued by each participating country. This is because the current regional body is structured only to facilitate information exchange and cooperation in a limited manner, focusing so far only on water management issues. LMS regional goals need to be set in order to guide the stakeholders in identifying an appropriate set of EPIs. Most importantly, the research is intended to be a catalyst for encouraging the participants to integrate methods and other species of EPIs proposed in this research in their environmental assessment policies.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">adaptive management</field><field name="subject">basin management</field><field name="subject">conceptual framework</field><field name="subject">decision support system (DSS)</field><field name="subject">environmental performance indicators (EPIs)</field><field name="subject">- theme of EPIs</field><field name="subject">- species of EPIs</field><field name="subject">- scale of EPIs</field><field name="subject">evaluative method</field><field name="subject">exploratory method</field><field name="subject">governance</field><field name="subject">institutionalisation</field><field name="subject">integrated environmental performance approaches</field><field name="subject">lower mekong subregion (LMS)</field><field name="subject">pressure-state-response (PSR) model</field><field name="subject">regional study and development</field><field name="subject">spatial scale evaluations</field><field name="identifier">http://eprints.qut.edu.au/16684/</field><field name="validLink">True</field></doc><doc><field name="title">Lateral load response of Cikarang brick wall structures : an experimental study</field><field name="creator">Basoenondo, Essy Arijoeni</field><field name="description">Despite their poor performance, non-standard clay bricks are commonly used in construction of low-rise buildings and rural houses in Indonesia. These clay bricks are produced traditionally in home industries. Indonesia is located in an active seismic region and many masonry buildings were badly damaged or collapsed during recent earthquakes. Such buildings are classified as non-engineered structures as they are built without using any proper design standard. Lateral load response of un-reinforced masonry walls is investigated in this research project, with the aim of better understanding the behaviour of these masonry walls using low quality local bricks. A comprehensive experimental program was undertaken with masonry wall elements of 600 mm x 600 mm x 110 mm constructed from local bricks from Cikarang in West Java - Indonesia. Wall specimens were constructed and tested under a combination of constant vertical compression load and increasing horizontal or lateral in-plane loads, of monotonic, repeated and cyclical nature. The vertical compressive loading was limited to 4% of maximum brick compressive strength. Masonry mortar mix used to construct the specimens was prepared according to Indonesian National Standard. Three different types of masonry wall panels were considered, (i) (normal) brick masonry walls, (ii) surface mortared brick masonry walls and (iii) comforted surface mortared brick masonry walls. The results indicated that the lateral load bearing capacity of masonry wall is usually lower than that of mortared and comforted walls. Despite this, the lateral load capacity under cyclic loads decreased 50 % of the average capacity of the walls under monotonic and repeated lateral loads. Using the results from the experimental program, a simplified model for the equivalent diagonal spring stiffness of local clay brick walls was developed. This stiffness model derived from experimental results in then used to simplify the structural analysis of clay brick wall panels in Indonesia. The design guideline for brick masonry houses and low-rise buildings in six Indonesian seismic zones was developed, as a contribution towards the development of design guidance for constructing brick masonry houses in Indonesia.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">masonry</field><field name="subject">clay brick</field><field name="subject">wall</field><field name="subject">cikarang</field><field name="subject">indonesia</field><field name="subject">lateral load</field><field name="subject">experimental</field><field name="subject">wall stiffness</field><field name="identifier">http://eprints.qut.edu.au/16685/</field><field name="validLink">True</field></doc><doc><field name="title">Sedimentary evolution, hydrogeology and geochemistry of a back-barrier sand island : Toorbul, Southeast Queensland</field><field name="creator">Hodgkinson, Jonathan</field><field name="description">Small back-barrier sand islands are poorly known in terms of hydrogeology and have been overlooked in more extensive studies of coastal groundwater systems that include larger barrier island complexes. This study employs a three-fold sequential approach to aquifer characterisation in a back-barrier sand island. A three-dimensional stratigraphic model forms the foundation framework, being derived from a multidisciplinary approach to sedimentary analysis and the construction of a depositional chronology. A conceptual hydrostratigraphic model is formulated based on the translation of sedimentary facies to hydrofacies, combined with density dependent flow calculations and tidal oscillation measurements. Groundwater hydrochemical data and mineral geochemistry are integrated with the resulting hydrogeological model to examine water-rock interaction and solute transport mechanisms.  The study area is Toorbul Island, a small back-barrier sand mass of ~5 km2 with a maximum surface elevation of ~3.5 m AHD, located in the Pumicestone Passage of Southeast Queensland. The island hosts a dual aquifer system consisting of an unconfined island freshwater lens, underlain by a semi-confined palaeovalley-fill aquifer. Groundwater in the semi-confined aquifer is hyper-saline, carrying high concentrations of dissolved metals, with iron, in particular, ranging from 40 to &lt; 200 mg l-1. This is of significant interest for both human health and environmental management, because iron is an important nutrient source for toxic algal bacteria such as Lyngbya majuscula.  Conceptual modelling demonstrates that iron oxides and hydroxides are the main source of iron in the semi-confined aquifer, with a contribution from ferruginous chlorite dissolution. Aqueous manganese and a proportion of the aqueous iron are derived from the dissolution of manganoan ilmenite. Ferric iron minerals also contribute a significant proportion of dissolved iron in the deeper regions of the unconfined aquifer. Aqueous iron in the shallow unconfined groundwater is limited by iron sulphides, which also regulate acidity and indirectly limit dissolved aluminium concentrations. Groundwater redox state governed by seasonal climatic fluxes is the most significant control on iron-bearing mineral phase stability. Transport of dissolved metals to the surrounding estuary and the adjacent barrier island groundwater system is limited by the rate of ion diffusion across transition zone boundaries.  The overall conclusions derived from this research show that back-barrier islands should be evaluated as discrete hydrogeological entities. The stratigraphic complexity that may be apparent within these island landforms should not be underestimated and the model domain should not necessarily be treated as a homogeneous system. This complexity is exemplified by the relationship between the upper and lower aquifers on Toorbul Island and the associated distribution of groundwater compositional heterogeneity. The complex stratigraphy within the sedimentary pile is derived from the presence of a sub-surface palaeovalley and the sedimentary response to changing sea-level over time. Considering the current widespread distribution of estuarine systems, complex hydrogeology as exhibited by Toobul Island, may be common in many small back-barrier island groundwater systems. The aquifer characteristics and their influence on solute transport and delivery can have significant ramifications for the exploitation of the adjacent coastal plain and barrier island aquifers. The potential influence on the latter is of particular concern due to the pressure imposed on potable groundwater supplies by increasing population densities in coastal areas.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">sedimentary facies; hydrofacies; redox disequilibrium; density dependent flow; baroclinic and barotropic fields; diffusion boundaries</field><field name="identifier">http://eprints.qut.edu.au/16686/</field><field name="validLink">True</field></doc><doc><field name="title">Hollywood's dominance of the movie industry : how did it arise and how has it been maintained?</field><field name="creator">Silver, Jonathan D.</field><field name="description">Hollywood&#8217;s dominance of the movie industry has been the subject of numerous studies. An interdisciplinary literature review in this thesis identified twenty different single or multiple factor explanations that try to account for Major studio dominance at different time periods but cannot comprehensively explain how Hollywood acquired and maintained dominance for nine decades. This thesis reviewed the economics, management and marketing literatures to identify existing theoretical explanations for the acquisition and persistence of market dominance. It then integrated existing theories identified within the business literature into a &#8216;theoretical lens&#8217;. This lens enables an historical analysis of Hollywood&#8217;s longstanding dominance of the movie business to be undertaken from a strategic business perspective. This thesis concludes that the Major studios rise to market leadership and enduring dominance can primarily be explained because they developed and maintained a set of strategic marketing management capabilities that were superior to rival firms and rival film industries. It is argued that a marketing orientation and effective strategic marketing management capabilities also provide a unifying theory for Hollywood&#8217;s enduring dominance because they can account for each of the twenty previously identified explanations for that dominance. The original contribution of this thesis is the development of a strategic marketing management lens and a set of guiding questions that can facilitate a strategic analysis of market dominance in any industry.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">strategic</field><field name="subject">marketing</field><field name="subject">dominance</field><field name="subject">capabilities</field><field name="subject">Hollywood</field><field name="subject">Major studios</field><field name="subject">movie industry</field><field name="identifier">http://eprints.qut.edu.au/16687/</field><field name="validLink">True</field></doc><doc><field name="title">The effects of co-workers' extra-role behaviour on individual task performance and climate perceptions</field><field name="creator">Neale, Matthew C.</field><field name="description">Extra-role helping, defined as assisting co-workers with their work tasks, and extra-role voice, defined as arguing for constructive change, are believed to be functional for work groups. However, the mechanisms by which helping and voice might contribute to group effectiveness have not been described in detail, and relatively little empirical research has addressed the effects that helping and voice actually have within groups, or their relationships with outcomes relevant to group effectiveness. I argue that helping and voice will have their most direct and immediate effects on fellow group members, and that these effects may influence the subsequent performance of the group as a whole. I present a cross-level model of task facilitation, which describes the impact that group level helping may have on the task performance of individual group members. I present a cross-level model of climate building, which describes the impact that group level helping and voice may have on the climate perceptions of individual group members. I test hypotheses drawn from these models in three studies. Study one was conducted with 1086 Australian air traffic controllers in 45 groups. The results provided support for the task facilitation mechanism, and showed that group level helping was positively associated with the task performance and effectiveness of individual air traffic controllers. Study two was conducted in an Australian public sector organisation employing over 4000 individuals in 177 groups. The results of this study provided support for the climate building mechanism. Group level helping was positively associated with individual perceptions of affective climate. The effects of group level voice depended on the level of goal clarity within the group. I argued that group members would perceive a greater need for voice when group goal clarity was low, and that under these circumstances, group members would attribute voice behaviour to a genuine desire to benefit the group. Under conditions of high goal clarity, however, group members would not perceive a need for voice, and so the voice behaviours would be attributed to self-serving motives to gain power, influence or resources. Results supported these arguments, with group voice having a negative effect on climate perceptions when goal clarity was high, and a positive effect on climate perceptions when goal clarity was low. In study three I examined the impact of attributions for voice behaviour directly. I conducted an experiment with 69 second year management students. Students were placed in a simulated organisational context by way of a written vignette. The level of co-worker voice and the motives for voice were manipulated within this vignette to form a two by two factorial design in which the level of voice (no voice vs. some voice) was crossed with co-worker motives (self-serving vs. altruistic). Manipulation checks showed that participants attributed the co-worker's behaviour to self serving motives in the self-serving condition, and to altruistic motives in the altruistic condition. The results showed that voice behaviour had a negative impact on climate perceptions when self-serving attributions were made. When altruistic attributions were made, the presence or absence of voice did not influence climate perceptions. The results of the three studies suggest that extra-role helping and voice form important parts of the technical, social and psychological environment in which group members work. Furthermore, this environment can have important effects on the task performance and climate perceptions of group members. To the extent that group effectiveness depends on high levels of individual task performance and positive climate perceptions, these outcomes will influence subsequent group effectiveness. I close by discussing the contribution of the task facilitation and climate building models, and the practical implications of the results obtained within this thesis.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">organisational behaviour</field><field name="subject">extra-role behaviour</field><field name="subject">helping</field><field name="subject">groups</field><field name="subject">voice</field><field name="subject">climate</field><field name="subject">task performance</field><field name="subject">multilevel</field><field name="identifier">http://eprints.qut.edu.au/16688/</field><field name="validLink">True</field></doc><doc><field name="title">Police corruption and strategies for its prevention in the emirate of Abu Dhabi</field><field name="creator">Al-Muhairi, Humaid Mohamed Saed</field><field name="description">Police Corruption is a complex widespread phenomenon in many developed and developing countries though the intensity varies from country to country. The current study is one of several studies supported by the UAE government will explore the different ways of police corruption and examine the potential ways of external mechanisms to control and minimize police corruption in the state of Abu Dhabi, which is one of the emirates of the United Arab Emirates. The methodology used for this research was by means of collecting data through a survey method distributed in the form of a questionnaire among a large population of police personnel and the public. The collected data was then analysed quantitatively and qualitatively. This research proved that unacceptable police behaviour existed (64.4%), with traffic, investigation and the immigration departments being the highest. Favouritism and nepotism have been identified as the most types of unacceptable behaviour which exists within the Abu Dhabi police force. Police officers (70%) agree to use violence and excessive force against suspects and (54%) believed that the public were worried about repercussions if any complaint was made about corrupt officers. It was established that unacceptable police behaviour exists in Abu Dhabi police force and traffic, investigation and the immigration departments have been identified with the highest levels of unacceptable police behaviour. Police corruption is more often a local police culture involving favouritism and nepotism that protects and even encourages unacceptable police behaviour. Finally, the research suggests the important role of media, public awareness, and training as remedies that should be adopted for instituting long term reforms. A combination of approaches, as well as federal supervision, is needed.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">police</field><field name="subject">UAE</field><field name="subject">corruption</field><field name="subject">favouritism</field><field name="subject">nepotism</field><field name="subject">traffic</field><field name="subject">immigration</field><field name="subject">investigation</field><field name="identifier">http://eprints.qut.edu.au/16689/</field><field name="validLink">True</field></doc><doc><field name="title">Microstructure and early diagenesis of recent reef building scleractinian corals, Heron reef, Great Barrier Reef : implications for paleoclimate analysis</field><field name="creator">Nothdurft, Luke David</field><field name="description">Scleractinian corals increasingly are studied as geochemical archives of modern- and palaeoclimate, but microsampling for geochemical data is complicated by: 1) the microstructural complexity and spatial variability in skeletal growth in different coral genera; and 2) the rapidity and scale of diagenetic alteration that occurs in living coralla. Geochemical sampling techniques now have spatial resolution into the sub-micrometer to tens of micrometers range, and it is hoped that the spatial resolution can be translated to temporal resolution. This study investigated the effects on geochemical analyses imposed by microstructure and diagenesis in different live-collected coral genera representing somewhat different depositional environments. Suites of samples of four reef-building genera (Acropora, Pocillopora, Goniastrea and Porites) were collected from three adjacent environments in intertidal and subtidal positions near the reef edge at Heron Reef, Great Barrier Reef and studied by means of optical and scanning electron microscopy, combined with vibrational and energy dispersive spectroscopy. The first section of this study compares and documents the microstructure of the four coral genera. Each genus was found to have very different three-dimensional arrangements of microstructural elements, and a new general growth model was proposed for Acropora, to take into account differences in the timing of precipitation of trabeculae and thickening deposits. The results highlight the complexity and spatial variability of skeletal growth in different coral genera. Because microstructural patterns vary in different genera, direct observation of microstructural elements and growth lines are necessary to allow geochemical microsamples to be placed into series that represent temporal sequences with known degrees of time averaging. Coral growth rates (i.e., rates of extension) are discussed to determine the range of temporal relationships that exist between closely spaced skeletal microstructural elements. Such data are necessary in order for coral skeletogenesis to be understood and are critical for constraining microsampling strategies aimed at developing true time series geochemical data at very fine spatial and temporal scales.  The second part of the study focused on early diagenetic alteration of the corals, which is an equally important concern for geochemical analysis. Early marine diagenesis was  documented in the same live-collected samples of the four common reef-building coral genera. Samples show extensive early marine diagenesis where parts of the coralla less than three years old contain abundant macro- and microborings (sponges, algae, cyanobacteria and fungi) and significant amounts of aragonite, high-Mg calcite, low-Mg calcite and brucite [Mg(OH)2] cements. Many of the cements are associated with microendoliths and endobionts that inhabit recently abandoned parts of the skeleton. The cements are problematic for palaeoclimate reconstruction because geochemical proxies used for paleoclimate studies are meant to reflect ambient seawater chemistry and conditions, but the occurrence of brucite and low-Mg calcite demonstrates how far fluid chemistry in microenvironments within the corals has evolved from ambient seawater. Some Porites lobata specimens have had as much as 60% of the most recently deposited skeletal aragonite (i.e., the part of the skeleton that projects into the layer of living polyps) bored and replaced by low-Mg calcite cement. The low-Mg calcite cement has significantly different trace element ratios (Sr/Ca(mmol/mol) = 6.3 &#177; 1.4; Mg/Ca(mmol/mol) = 12.0 &#177; 5.1) than the host coral skeletal aragonite (Sr/Ca(mmol/mol) = 9.9 &#177; 1.3; Mg/Ca(mmol/mol) = 4.5 &#177; 2.3), thus providing a serious challenge for Sr/Ca or Mg/Ca based sea surface temperature calculations. This study illustrates that many diagenetic changes that can radically alter important geochemical characteristics of coral skeleton occur very early on the sea floor (i.e., while corals are still alive). Documented cements altered trace element inventories (e.g., Sr and Mg), thus, interfering with the use of those elements in palaeotemperature calculations. Hence, significant diagenetic changes that jeopardise palaeoclimate data do not require long-term diagenesis or meteoric exposure. Some of the diagenetic changes (e.g., calcite filled borings) occur at scales that are very difficult to detect short of visual inspection using SEM. Hence, vetting of coral samples with SEM is required before any sample is subjected to geochemical analysis.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">scleractinian corals</field><field name="subject">Heron reef</field><field name="subject">Great Barrier Reef</field><field name="subject">palaeoclimate analysis</field><field name="identifier">http://eprints.qut.edu.au/16690/</field><field name="validLink">True</field></doc><doc><field name="title">A study of learning in economics</field><field name="creator">Tang, Tommy Yin</field><field name="description">This thesis reports on a research program to study learning in economics utilising non-traditional research methodology. The study aimed to achieve four inter-related objectives. Research in other disciplines (Meyer and Cleary, 1998; Meyer and Eley, 1999; Eley and Meyer, 2004) show that there are important factors influencing learning that are unique to the discourse of a discipline. The first objective of this study was to construct an instrument that captured students' cognitive ability that was specific to learning in economics. The psychometric properties and validity of this construct (called economic thinking ability), and the influence of students' pre-course economic thinking on their learning approaches and academic performance were investigated. Traditional economics education research typically utilises a single end-of-semester score as a measure of learning output. This research program utilised multiple measures of academic performance. By investigating the determinants of academic performance in three assessment types commonly used in introductory economics, namely essay assignment, multiple choice question (MCQ) exam and exam essay, it examined the limitations of the traditional single-score approach. Most traditional input-output learning models in economics education bypass the learning 'black box' (Shanahan et al., 1997), which is the learning approach the student utilises. The third objective of the research program was to construct a learning approach instrument that was sensitive to different assessment contexts so as to investigate the mechanism by which the learning inputs influenced academic performance in economics. This research program also measured students' general learning approaches for assessments utilised before the commencement of their economics unit, and investigated the stability and changes of learning approaches. Based on empirical research evidence and survey findings, it has been observed that many economics students do not possess the ability to apply economic concepts in real world situations. The fourth objective of this research program was to explore the issue of knowledge transfer in economics education. To investigate this issue, students' economic thinking ability was examined at the end of the course using both quantitative and qualitative methodology. The key findings obtained from this research program are:    The discipline-specific construct of economic thinking ability possesses sound psychometric properties and predictive validity. Students' pre-course economic thinking ability was found to measure cognitive ability different from pre-course academic aptitude and have important effects on learning approaches. The determinants of academic performance were shown to be assessment specific. This observation provides an explanation of the inconsistency of findings by the traditional input-output approach that utilises a single measure of learning output in economics education. By examining the mediating role of learning approaches in the learning process, it was found that there were important differences in the mechanism by which different personal learning inputs impacted on academic performance in different assessment contexts. Lastly academic performance and post-course economic thinking ability were found to measure different dimensions of learning outcome. The thesis concluded that economics education as investigated in this research program focused mainly on acquisition and reproduction of knowledge and technical skills in routine academic situations rather than making connections of economic concepts to real world experiences. Implications for teaching and further research in economics education were also discussed in this thesis.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">economics education</field><field name="subject">student learning</field><field name="subject">knowledge transfer</field><field name="subject">learning outcome</field><field name="subject">learning process</field><field name="subject">assessment</field><field name="identifier">http://eprints.qut.edu.au/16691/</field><field name="validLink">True</field></doc><doc><field name="title">Energy expenditure and physical activity patterns in children : applicability of simultaneous methods</field><field name="creator">Amorim, Paulo Roberto dos Santos</field><field name="description">Consistently, reports in the literature have identified that a sedentary lifestyle contributes to the progression of a range of chronic degenerative diseases. The measurement of energy expenditure and physical activity pattern in children is a challenge for all professionals interested in paediatric health and from a broader perspective, the public health fraternity charged with considering longer term health consequences of physical inactivity. The primary objective of this thesis was to identify a suitable indirect and objective measurement technique for the assessment of energy expenditure and physical activity pattern in children. The ideal characteristics of such a technique are that it should be reproducible and have been validated against a criterion reference method. To achieve this goal, a series of methodological studies were undertaken (Chapters II and III). This work was essential to increase accuracy during the individualised laboratory calibration process and further minimise prediction errors when analysing data from 7 days of monitoring under free-living conditions in the second part of the study (Chapters IV and V). In the first study to verify the combined effect of body position, apparatus and distraction on children's resting metabolic rate (RMR), experiments were carried out on 14 children aged 8-12 (mean age = 10.1 years &#177; 1.4). Each participant underwent 2 test sessions, one week apart under three different situations: a) using mouthpiece and nose-clip (MN) or facemask (FM); b) sitting (SEAT) or lying (LY) and c) TV viewing (TV) or no TV viewing. In the first session, following 20 min rest and watching TV, the following protocol was used: LY: 20 min - stabilisation; 10 min using MN and 10 min using FM. Body position was then changed to seated: 20 min stabilisation; 10 min using FM; 10 min using MN. In the second session, FM and MN order was changed and participants did not watch TV. Data were analysed according to the eight combinations among the three studied parameters. Repeated measures ANOVA indicated statistically significant differences for &amp;VO2 (p=0.01) and RMR (p=0.02), with TVMNSEAT showing higher values than TVFMLY. Bland-Altman analysis showed a bias for &amp;VO2, &amp;VCO2, RQ and RMR between TVFMLY and TVMNSEAT of -17.8&#177;14.5 ml.min-1, -8.8&#177;14.5 ml. min-1, 0.03&#177;0.05 and -115.2&#177;101.9 kcal.d-1, respectively. There were no differences in RMR measurements due to body position and apparatus when each variable was isolated. Analyses of distraction in three of four combinations indicated no difference between TV and no TV. In summary, different parameter combinations can result in increased bias and variability and thereby reported differences among children's RMR measurement. The second study dealt with treadmill adaptation and determination of self-selected (SS) walking speed. Assessment of individual and group differences in metabolic energy expenditure using oxygen uptake requires that individuals are comfortable with, and can accommodate to, the equipment being utilised. In this study, a detailed proposal for an adaptation protocol based on the SS was developed. Experiments were carried out on 27 children aged 8-12 (mean age = 10.3&#177;1.2 yr). Results from three treadmill tests following the adaptation protocol showed similar results for step length with no significant differences among tests and lower and no statistically significant variability within- and between-days. Additionally, no statistically significant differences between SS determined over-ground and on a treadmill were verified. These results suggest that SS speed determined over-ground is reproducible on a treadmill and the 10 min familiarisation protocol based on this speed provided sufficient exposure to achieve accommodation to the treadmill. The purpose of the third study was to verify within- and between-day repeatability and variability in children's oxygen uptake ( &amp;VO2), gross economy (GE) [ &amp;VO2 divided by speed] and heart rate (HR) during treadmill walking based on SS. 14 children (mean age = 10.2&#177;1.4 yr) undertook 3 testing sessions over 2 days in which four walking speeds, including SS, were tested. Within- and between-day repeatability was assessed using the Bland and Altman method and coefficients of variability (CV) were determined for each child across exercise bouts and averaged to obtain a mean group CV value for &amp;VO2, GE and HR per speed. Repeated measures ANOVA showed no statistically significant differences in within- or between-day CV for &amp;VO2, GE or HR at any speed. Repeatability within and between-day for &amp;VO2, GE and HR for all speeds was verified. These results suggest that submaximal &amp;V O2 during treadmill walking is stable and reproducible at a range of speeds based on children's SS. In the fourth study, the objective was to establish the effect of walking speed on substrate oxidation during a treadmill protocol based on SS. Experiments were carried out on 12 girls aged 8-12 (mean age = 9.9&#177;1.4 yr). Each participant underwent 2 test sessions, one week apart. Workloads on the treadmill included 2 speeds slower than SS (1.6 [V1] and 0.8 km.h-1 [V2] slower than SS), SS (V3), and a speed 0.8 km.h-1 faster than SS (V4). Indirect calorimetry from respired gas measurements enabled total fat (FO) and carbohydrate (CHO) oxidation rates to be calculated according to the non-protein respiratory quotient (Peronnet and Massicote, 1991) and percentage of CHO and FO calculations using equations from McGilvery and Goldstein (1983). Repeated measures ANOVA followed by a Tukey Post Hoc test (p&lt; 0.05) was used to verify differences in CHO and FO rates among speeds. Paired T-test was used to verify differences in CHO and FO rates between tests per velocity. The reliability between-day was assessed using intraclass correlation coefficient (ICC). Results showed significant differences for CHO among all speeds, as well as significant differences for FO between V1 and V2 against V3 and V4 in both tests. Analyses between trials per velocity showed no significant substrate use differences as well as acceptable reliability. At the self-selected speed (V3) there was an accentuation in FO reduction as well as an increase in CHO oxidation. The purpose of the fifth study was to determine whether there were differences in substrate oxidation between girls (G) and women (W) during a treadmill protocol based on SS. Experiments were carried out on 12 G aged 8-12 (mean age = 9.9&#177;1.4 yr) and 12 W aged 25-38 (mean age = 32.3&#177;3.8 yr). The treadmill protocol included 6 min workloads followed by 5 min rest periods. Workloads included 2 speeds slower than SS (1.6 (V1) and 0.8 km.h-1 (V2) slower than SS), SS (V3), and a speed 0.8 km.h-1 faster than SS (V4). Total fat and carbohydrate (CHO) oxidation rates were calculated from indirect calorimetry according to the non-protein respiratory quotient. Repeated measures ANOVA followed by a Tukey Post Hoc test was used to verify intra-test differences in CHO and fat oxidation rates among speeds. Intergroup differences were analysed using paired T-test. Fat utilisation in W achieved a plateau at a relative velocity 0.8 km.h-1 slower than SS, but for G, fat utilisation increased until SS, and then stabilised upon reaching the higher velocity. CHO oxidation curves rose abruptly above V2 for W, while for G the acute increase occurred after SS (V3). Collectively, these results indicate that as walking intensity increases G are able to meet the energy demands of the work by increasing fat oxidation together with the increased CHO oxidation up to SS. In contrast for W, increasing CHO oxidation is associated with an early decrease in fat utilisation at a velocity slower than the self-selected speed. The sixth study dealt with validation of indirect techniques for the measurement of energy expenditure in free-living conditions against the DLW technique. Experiments were carried out on 19 children aged 8-12 (mean age = 10.3&#177;1.0 yr). To indirectly predict energy expenditure 12 different procedures were used. Only one procedure, combining activity and heart rate (AHbranched), was based on a group equation, the others were based on individualised regression. Three of the individually-based techniques were able to accurately predict energy expenditure in free-living conditions. These tecniques were HRPAnetRMR using HRnet [HR exercise minus sleep HR (SHR)] against PAnet (measured PA exercise minus measured RMR) and upper and lower body equations corrected by RMR; HRPAnet4act using the same procedure but corrected by the mean resting &amp;VO2 for 4 resting activities [(4act) = supine watching TV, sitting watching TV, sitting playing computer games and standing], and HRPALBnet4act using only lower body activities and corrected by 4act. HRPAnetRMR was only slightly more accurate than HRPAnet4act and HRPALBnet4act, but this technique is only adjusted by RMR whereas the other two are heavily dependent on more complex laboratory calibration. Bland and Altman (1986) analyses showed no significant differences between AHbranched predicted and measured TEE using the DLW technique. A SEE of 79 kcal.d-1 and a mean difference of 72 kcal.d-1, with a 95% CI ranging from -238 to 93.9 kcal.d-1 was found. In addition, no significant differences between predicted HRPAnetRMR and measured TEE using DLW were found, showing an SEE of 99 kcal.d-1 and a mean difference of -67 kcal.d-1, and a 95% CI ranging from -276.6 to 141.9 kcal.d-1. AHbranched and HRPAnetRMR were both valid and similarly suitable for the prediction of energy expenditure in children under free-living conditions. Significant associations between DLWAEE and the after-school time window indicated that this time window as an important discretionary period representative of children physical activity. However, the duration of the after-school time windows should be more carefully considered. Accelerometer data showed a better association between the largest after-school time window (3.5 hr) and measured TEE. The final study, completed with 19 children aged 8-12 (10.3&#177;1.0 yr) highlighted, under laboratory conditions across a range of walking and running speeds, the inadequacy of the use of the standard MET in children. This traditional approach overestimates energy expenditure with an increased difference linearly related to speed increments. Minute-by-minute analyses of 7 days of free-living monitoring showed an average overestimation of 64 minutes per day for moderate-to-vigorousphysical- activity (MVPA) using the standard MET compared with the individually measured MET. For all intensities, these differences were statistically significant (p&lt; 0.001). The second part of this study showed a variability of 20% in the average time spent at MVPA when comparing HR I 140 bpm and HR &gt;  50%P &amp;VO2 (P &amp;VO2 = the highest &amp;VO2 observed during an exercise test to exhaustion). Results of the current study compared to observations in the literature showed that HR I 140 bpm consistently estimates lower MVPA time than HR &gt;  50%P &amp;VO2. When these two PA indices were compared with individual and standard MET measured minute-byminute, statistically significant differences were verified among all of them at MPA, but no differences were verified at VPA, except between individual and standard METs. However, whether each one of the PA indices used are under- or overestimating time at MVPA is still debatable due to the lack of a gold standard. Finally, each index used in this study classified different numbers of participants as achieving the PA target of 60 min.d-1. The wide variability between indices when attempting to classify children who are achieving the recommended target is cause for great concern because habitually these indices are utilised as screening tools in paediatric and public health settings and used to guide behavioural interventions.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">children</field><field name="subject">energy metabolism</field><field name="subject">indirect calorimetry</field><field name="subject">resting metabolic rate</field><field name="subject">selfselected speed</field><field name="subject">measurement</field><field name="subject">treadmill walking</field><field name="subject">adaptation</field><field name="subject">protocol</field><field name="subject">oxygen cost of exercise</field><field name="subject">exercise prescription</field><field name="subject">substrate oxidation</field><field name="subject">respiratory quotient</field><field name="subject">reproducibility</field><field name="subject">variability</field><field name="subject">accelerometry</field><field name="subject">heart rate monitoring</field><field name="subject">activity energy expenditure</field><field name="subject">total energy expenditure</field><field name="subject">physical activity pattern</field><field name="subject">metabolic equivalent</field><field name="identifier">http://eprints.qut.edu.au/16692/</field><field name="validLink">True</field></doc><doc><field name="title">Governing through risk : exploring the maltreated child as a potential delinquent</field><field name="creator">Rayment, Cassandra A.</field><field name="description">This thesis examines risk as it applies to children and youth. Specifically, this thesis examines the way that risk enables the governance of child and youth populations. The central argument of this thesis will be that risk creates the maltreated child as a potential delinquent. There is a vast body of literature which has examined a perceived relationship between child maltreatment and juvenile offending. On this basis, a high level of risk has been ascribed to the maltreated child in terms of their potential to engage in criminal and antisocial behaviour. This argument is positioned as a claim of truth, with the truth being that maltreated children are more likely to engage in juvenile delinquency than nonmaltreated children. It is this concept and this truth claim which forms the catalyst for the investigation in this thesis. The underlying assumptions of this thesis are derived from a governmental framework, based on the work of Foucault (1991). This states that the mentality of government comprises of three main factors, political rationalities, governmental programmes and technologies of government (Rose and Miller, 1992). This thesis argues that positivism can be understood as a political rationality, that legislation can be viewed as a governmental programme and that statistics can be conceptualised as a technology of government. Overall, the results of these three analyses combine to demonstrate the powerful ways in which risk is used to position the maltreated child as a potential delinquent. Consequently, it is established that risk is crucial to the ways in which children and youth find themselves targets of governance.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">child abuse</field><field name="subject">maltreatment</field><field name="subject">juvenile offenders</field><field name="subject">delinquency</field><field name="identifier">http://eprints.qut.edu.au/16693/</field><field name="validLink">True</field></doc><doc><field name="title">Afro No-Clash : composing syncretic African/Western music : eleven compositions and the frameworks for their systematic analysis</field><field name="creator">Chapman, James Norman</field><field name="description">This PhD consists of an artistic work (an album of music) and an exegesis. The album contains eleven works for a variety of ensembles, including an eight-piece pop fusion group, a string quartet, an eleven-piece a cappella ensemble, a five-piece contemporary classical ensemble and a six-piece percussion ensemble. Each of these works embraces a blend of African and Western techniques and aesthetics. These works are the result of a compositional praxis which is closely integrated with a theoretical framework that I develop in the exegesis. The purpose of the exegesis is to provide a framework from which to understand the compositions. Perspectives such as postcolonialism are immediately engaged because of the fact that two distinct world cultures are referenced by these compositions. Similarly, the musical aesthetics of the two source cultures are examined because I need to understand the ways that the value systems are expressed in musical terms, and how they might interact in cross-cultural composition. Examination of the literature reveals that there has been a trend in recent decades towards cultural analysis of cross-cultural music but very little work has been done on the technical analysis of such works (Utz 2003). A preliminary list of issues is developed from a survey of ten relevant composers&#8217; works and these issues are categorised into three analytic dimensions: the contextual (cultural), aesthetic and technical. African &#8220;musics&#8221; and musical cultures are discussed with regard to issues of Western interpretation (Agawu 2003) and appropriate representation, social and cultural preferences and aesthetic values. Likewise Western musical culture is examined in order to understand its colonial impact, its stylistic consistency and ideas that have emerged about aesthetic preferences and the interpretation of meaning (Cone 1972; Kivy 2001). Four frameworks are developed to address each of these analytical dimensions. The first deals with cultural identity and the appropriation of musical ideas, the second with the sensitivity of certain materials. The third framework enables the examination of the aesthetic preferences for each of the cultures involved and the fourth framework provides a taxonomy and vocabulary of terms for use in analysis of the structural and other technical features of cross-cultural Western/African musics. These four frameworks are applied to the eleven compositions that I have completed for this project. I identify distinct approaches to appropriation, aesthetic preferences, the predominance of rhythmic structure and the performative embodiment and narrative transformational processes in my compositions. I conclude by categorising the technical and stylistic preferences embodied in my work, and identifying possible future directions for my compositions and the development of the analytical frameworks.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">African musics</field><field name="subject">analysis</field><field name="subject">appropriation</field><field name="subject">aesthetics</field><field name="subject">blending</field><field name="subject">composition</field><field name="subject">cross-cultural</field><field name="subject">culture</field><field name="subject">difference</field><field name="subject">embodiment</field><field name="subject">ethnomusicology</field><field name="subject">expectancy</field><field name="subject">identity</field><field name="subject">metatheory</field><field name="subject">multivalence</field><field name="subject">participation</field><field name="subject">performance</field><field name="subject">polyrhythm</field><field name="subject">postcolonialism</field><field name="subject">repetition</field><field name="subject">simultaneity</field><field name="subject">syncretism</field><field name="subject">transformation</field><field name="subject">ubuntu</field><field name="subject">variation</field><field name="subject">Western music</field><field name="identifier">http://eprints.qut.edu.au/16694/</field><field name="validLink">True</field></doc><doc><field name="title">Robust adaptive control of rigid spacecraft attitude maneuvers</field><field name="creator">Dando, Aaron John</field><field name="description">In this thesis novel feedback attitude control algorithms and attitude estimation algorithms are developed for a three-axis stabilised spacecraft attitude control system. The spacecraft models considered include a rigid-body spacecraft equipped with (i) external control torque devices, and (ii) a redundant reaction wheel configuration. The attitude sensor suite comprises a three-axis magnetometer and three-axis rate gyroscope assembly. The quaternion parameters (also called Euler symmetric parameters), which globally avoid singularities but are subject to a unity-norm constraint, are selected as the primary attitude coordinates. There are four novel contributions presented in this thesis. The first novel contribution is the development of a robust control strategy for spacecraft attitude tracking maneuvers, in the presence of dynamic model uncertainty in the spacecraft inertia matrix, actuator magnitude constraints, bounded persistent external disturbances, and state estimation error. The novel component of this algorithm is the incorporation of state estimation error into the stability analysis. The proposed control law contains a parameter which is dynamically adjusted to ensure global asymptotic stability of the overall closedloop system, in the presence of these specific system non-idealities. A stability proof is presented which is based on Lyapunov's direct method, in conjunction with Barbalat's lemma. The control design approach also ensures minimum angular path maneuvers, since the attitude quaternion parameters are not unique. The second novel contribution is the development of a robust direct adaptive control strategy for spacecraft attitude tracking maneuvers, in the presence of dynamic model uncertainty in the spacecraft inertia matrix. The novel aspect of this algorithm is the incorporation of a composite parameter update strategy, which ensures global exponential convergence of the closed-loop system. A stability proof is presented which is based on Lyapunov's direct method, in conjunction with Barbalat's lemma. The exponential convergence results provided by this control strategy require persistently exciting reference trajectory commands. The control design approach also ensures minimum angular path maneuvers. The third novel contribution is the development of an optimal control strategy for spacecraft attitude maneuvers, based on a rigid body spacecraft model including a redundant reaction wheel assembly. The novel component of this strategy is the proposal of a performance index which represents the total electrical energy consumed by the reaction wheel over the maneuver interval. Pontraygin's minimum principle is applied to formulate the necessary conditions for optimality, in which the control torques are subject to timevarying magnitude constraints. The presence of singular sub-arcs in the statespace and their associated singular controls are investigated using Kelley's necessary condition. The two-point boundary-value problem (TPBVP) is formulated using Pontrayagin's minimum principle. The fourth novel contribution is an attitude estimation algorithm which estimates the spacecraft attitude parameters and sensor bias parameters from three-axis magnetometer and three-axis rate gyroscope measurement data. The novel aspect of this algorithm is the assumption that the state filtering probability density function (PDF) is Gaussian distributed. This Gaussian PDF assumption is also applied to the magnetometer measurement model. Propagation of the filtering PDF between sensor measurements is performed using the Fokker-Planck equation, and Bayes theorem incorporates measurement update information. The use of direction cosine matrix elements as the attitude coordinates avoids any singularity issues associated with the measurement update and estimation error covariance representation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">spacecraft attitude control system</field><field name="subject">spacecraft attitude manevers</field><field name="subject">spacecraft attitude estimation</field><field name="subject">Lyapunov stability theory</field><field name="subject">adaptive control theory</field><field name="subject">optimal control theory</field><field name="subject">state estimation theory</field><field name="identifier">http://eprints.qut.edu.au/16695/</field><field name="validLink">True</field></doc><doc><field name="title">Lost in translation?  Language policy, media and community in the EU and Australia : some lessons from the SBS</field><field name="creator">Podkalicka, Aneta Monika</field><field name="description">Cultural diversity is a central issue of our times, although with different emphases in the European and Australian context. Media and communication studies have begun to draw on work in translation studies to understand how diversity is experienced across hybrid cultures. Translation is required both for multilingual (multicultural) societies such as Australia and for trans-national entities such as the European Union. Translation is also of increasing importance politically and even emotionally as individual nations and regions face the challenge of globalisation, migration, and the Americanisation of media content.   The thesis draws on cultural and media policy analysis. Programming strategies are reviewed and 'conversational' interviews conducted with broadcasting managers and staff at SBS Australia and across multilingual public broadcasters in the EU (BBC WS, Deutsche Welle, ARTE, Radio Multikulti Berlin, Barcelona Televisi&#243;). These are used to investigate the issues, challenges, and uses of the multilingual broadcasting logic for Australia's and Europe's cultural realities.   This thesis uses the concept of 'translation' as a key metaphor for bridging differences and establishing connections among multicultural citizens in the context of the European Union and Australia. It is proposed that of the two versions of translation - institutional in the EU and mediated in Australia respectively - the mediated version has achieved higher success in engaging ordinary citizens in more affective, informal and everyday forms of cross-cultural communication. Specifically, the experience of the Special Broadcasting Service (Australia's multilingual and multicultural public broadcaster) serves as a model to illuminate the cultural consequences of the failure of the EU to develop translation practices beyond the level of official, institutional and political communication. The main finding is the identification of a need for more mediated interlingual exchange; that is a translation of language policy in Europe into media experience for ordinary citizen-consumers, at both institutional and textual levels.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">language</field><field name="subject">translation</field><field name="subject">policy</field><field name="subject">public service broadcasting</field><field name="subject">cultural citizenship</field><field name="subject">TV programming</field><field name="identifier">http://eprints.qut.edu.au/16696/</field><field name="validLink">True</field></doc><doc><field name="title">Locally significant content on regional television : a case study of North Queensland commercial television before and after aggregation</field><field name="creator">Flynn, John Michael</field><field name="description">This thesis is an exploration of the fate which has befallen the regional commercial television industry in North Queensland in the wake of the aggregation policy introduced by the Federal Labor Government in 1990.  More specifically, it examines the effectiveness of policy outcomes which stem from the Australian Broadcasting Authority's 2001 inquiry into the adequacy of regional and rural commercial television news and information services.    The research is primarily concerned with the quality of local content provided by regional commercial broadcasters in response to the implementation of the Australian Communications and Media Authority's points system for broadcast of matters of local significance.  The policy outcomes are balanced against an historical context, which traces the regional commercial television industry in North Queensland back to its very beginning.  Regulatory reform has resulted in a basic level of news content being maintained. However the significance of elements of this news content to local viewers is minimal.  The reduction in local information content, despite being identified in the earliest stages of the ABA investigation, has not been adequately addressed by the reform process.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">commercial television</field><field name="subject">local content</field><field name="subject">news and information services</field><field name="subject">government policy</field><field name="subject">Australian Broadcasting Authority</field><field name="identifier">http://eprints.qut.edu.au/16697/</field><field name="validLink">True</field></doc><doc><field name="title">Factors influencing academics' development of interactive multimodal technology-mediated distance higher education courses</field><field name="creator">Birch, Dawn P.</field><field name="description">Advances in technology and the continued emergence of the Web as a major source of global information have encouraged tertiary educators to take advantage of this growing array of resources and move beyond traditional face-to-face and distance education correspondence modes toward a rich technology-mediated learning environment. Moreover, ready access to multimedia at the desk-top has provided an opportunity for educators to develop flexible, engaging and interactive learning resources incorporating multimedia and hypermedia. This study investigates pedagogical, individual and institutional factors influencing the adoption and integration of educational technology by academics at a regional Australian university for the purpose of developing interactive multimodal technology-mediated distance education courses. These courses include a range of multimodal learning objects and multiple representations of content in order to cater for different learning styles and modal preferences. The findings of this study revealed that a range of pedagogical, individual and institutional factors influence academics' development of interactive multimodal technology-mediated distance education courses.  Implications for distance education providers and individual academics arising from these factors and subsequent recommendations are presented.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">distance education</field><field name="subject">educational technology</field><field name="subject">interactive</field><field name="subject">interactivity</field><field name="subject">learning modalities</field><field name="subject">learning styles</field><field name="subject">multimedia</field><field name="subject">multimodal</field><field name="subject">multiple representations</field><field name="subject">technology-mediated</field><field name="identifier">http://eprints.qut.edu.au/16698/</field><field name="validLink">True</field></doc><doc><field name="title">The T'En Exiles : an exploration of discrimination and persecution in High Fantasy novels</field><field name="creator">Lindquist, Rowena Cory</field><field name="description">High Fantasy is extremely popular, with publication and sales of High Fantasy titles outnumbering Science Fiction for thirty years, yet Fantasy is less respected by reviewers of the Speculative Fiction genre. One reason for this is that High Fantasy often fails to adequately address culturally or politically significant issues. Respected Science Fiction writers, such as Octavia Butler, on the other hand, use the issues such as discrimination and persecution on the basis of race and gender. In my exegesis I explore the ways in which High Fantasy has explored the problems of discrimination and persecution.   In my novel, The T'En Exiles, I create a world populated by differently abled races. The ' ordinary ' people resent and fear the gifted people, who are less numerous and marginalised. Among the gifted there are those who are aware of mystical powers and those who can manipulate them; because of this a strict hierarchy has evolved. There is also a divide between the genders because the power of the females is expressed differently to that of the males.   In The T'En Exiles I use the device of cognitive estrangement, a technique common in both Fantasy and Science Fiction, to examine discrimination and persecution. In particular in terms of how it affects individuals. In the exegesis I examine the ways in which issues of discrimination and persecution are dealt with in contemporary High Fantasy and Science Fiction, and the ways in which a more comprehensive and sensitive treatment of these issues in High Fantasy can address some concerns about the marginalisation of the sub-genre.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Fantasy</field><field name="subject">High Fantasy</field><field name="subject">Tolkien</field><field name="subject">Lord of the Rings</field><field name="subject">Ursula K Le Guin</field><field name="subject">Earth Sea</field><field name="subject">Glenda Larke</field><field name="subject">Heart of the Mirage</field><field name="subject">feminism</field><field name="subject">racism</field><field name="subject">persecution</field><field name="subject">discrimination</field><field name="identifier">http://eprints.qut.edu.au/16699/</field><field name="validLink">True</field></doc><doc><field name="title">Everyday encounters of everyday midwives : tribulation and triumph for ethical practitioners</field><field name="creator">Kinnane, Joanne H.</field><field name="description">Midwifery is a dynamic, ever changing, specialised field of nursing involving the care of women and childbearing families. Clients are central to the practice of midwifery and thus their well-being is the main focus of midwives. So, it is not surprising that much of the relatively small body of midwifery research is client focused. As a result, client perspectives have been studied in a number of ways, regarding several aspects of midwifery care.    This research, however, aimed to consider midwifery from the midwives' perspective by exploring the everyday encounters of everyday midwives who are working in institutional settings, and identifying the ethical aspects of those encounters. From the researcher's standpoint, it is clear that midwives' everyday encounters are ethical encounters and have potential to be either beneficent or harmful. There was, however, uncertainty that midwives recognized this "everydayness" of ethics. This research sought to clarify the place of ethics within midwives' everyday activities. A further purpose was to ascertain how the ethics that entered into the encounters and activities midwives participated in on a daily basis had affected their practise, their profession and/ or themselves. In doing this, the intent was to broaden the understandings of the ethical dimension of the practice. A particular ethical approach was adopted for this project. It is a view of ethics where persons have regard for, and responsibility toward, each other (Isaacs, 1998). The fact that midwifery is a social practice was expected to be significant in both the everyday encounters that midwives experienced and the ethical responses to those encounters. Members of social practices share an overall purpose and have a moral obligation or desire to practise ethically. As they share a culture and a covenantal commitment to care for those the profession seeks to serve - in a context of gift, fidelity and trust (Isaacs, 1993; Langford, 1978), it was anticipated that midwives would, generally, work in an ethically laden "world".  Narrative research offered an appropriate framework for investigating these dimensions of midwifery practice. Many authors have noted the value of story-telling for making sense, and illuminating the ethical features, of our lives. It is, Kearney says, "an open-ended invitation to ethical ... responsiveness" (2000, p. 156). By enabling the participants to tell their stories, rich, contextual narrative material was obtained. The researcher was able to engage with both the participants and the stories as audience.    An introduction to the study is provided in Chapter One, while Chapter Two explains both why narrative inquiry was chosen for this research project and the framework that was utilised. The insights from the study are presented in Chapters Three through Six. Each chapter considers the issues and concepts arising from stories that involve midwives' relationships and interactions with a different group of people: midwives, institutions and administration ("them"), doctors and families.    In Chapter Three different types of interactions between midwives and their colleagues are explored. Some of the issues that arise are the importance of understanding one's own values and the place of ethics in practice, as well as the need to "do ethics-on-the-run". Many ethical concepts are evident including autonomy, integrity and professional identity. Participants had many negative experiences, and some conveyed feeling a lack of support, threatened or overwhelmed. Conversely, some stories share very positive images of mutual understanding where midwives worked together empathetically.    Chapter Four looks at how managers' interactions with midwives impacted upon them and their practice. Unfortunately, this seems to be mostly negative. The midwives convey a sense of feeling undervalued both professionally and personally. Doctors have their turn to interact with the midwives in Chapter Five. In this chapter it becomes evident that doctors and midwives view birth from different perspectives. The participants' stories tell of challenging situations that alert us to the fact that normal, in the context of birth, is not as simple and common place as one might think when doctors and midwives have to work together. Wonderful, positive stories of midwives and doctors working together told of the symbiotic relationship that these two groups of professionals can have when the client is the focus.    The last of the insights chapters, Chapter Six, focuses on the relationships midwives have with families. Interestingly, these are the people they spoke of least, even though they are the people for whom the profession exists. Here the concept of midwife as friend is discussed. Then, through their stories some of the participants help us to learn how midwives work together with their clients, care about them, not just for them, and how their past experience has had a lasting impact on their practice.    Professionalism (or a lack of it) was implicated as a possible cause of some of the participants' concerns, as was the improper use of power. Both of these concepts arose many times throughout the project. Chapter 7 discusses these issues in some depth.    The final chapter provides an overview of midwives situated within their practice. An account is offered of how the participants see the future of their practice and it is questioned if midwifery is, in fact, a social practice with common goals. The thesis draws attention to the embeddedness of ethics in the everyday practice of midwives, and to the vital role that relationships play in midwifery practice. This suggests the need for a relational, contextual ethics approach if the practice is to flourish.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">ethics</field><field name="subject">midwifery</field><field name="subject">midwives</field><field name="subject">midwives&#146; stories</field><field name="subject">morals</field><field name="subject">narrative</field><field name="subject">narrative research</field><field name="subject">midwifery ethics</field><field name="subject">profession</field><field name="subject">social practice</field><field name="identifier">http://eprints.qut.edu.au/16700/</field><field name="validLink">True</field></doc><doc><field name="title">Gas detection by use of Sagnac interferometer</field><field name="creator">McConnell, Sean R.</field><field name="description">Gas composition and analysis forms a large field of research whose requirements demand that measurement equipment be as affordable, uncomplicated and convenient as possible. The precise quantitative composition of an atmospheric, industrial or chemically synthesised sample of gas is of utmost importance when inferring the properties and nature of the environment from which the sample was taken, or for inferring how a prepared sample will react in its application. The most popular and widely used technique to achieve this is Gas Chromatography-Mass Spectrometry (GCMS) and, without a doubt, this technique has set the standard for gas analysis. Despite the accuracy of the GCMS technique, the equipment itself is bulky, expensive and cannot be applied readily to field work. Instead, most field work is conducted using a single gas detector, capable only of detecting one particular molecule or element at a time. Presented here is an interferometric technique that theoretically, has the ability to address all three issues of bulkiness, affordability and convenience, whilst not being limited to one particular element or molecule in its analysis. Identifying the unknown constituents of a gaseous mixture using the proposed method, employs the optical refractive properties of the mixture to determine its composition. A key aspect of this technique is that the refractive index of an arbitrary mixture of gases will vary depending on pressure and wavelength1. The Lorentz-Lorenz formula and the Sellmeier equations form the foundation of the theoretical background. The optical refractive properties of air and other atmospheric gases have been well established in the literature. The experimental investigations described here have been conducted based on this, insofar as no analysis has been conducted on gases that do not naturally occur in reasonable abundance in the atmosphere. However this does not in any way preclude the results and procedure developed from applying to a synthesised gas mixture. As mentioned, the platform of this technique relies on the pressure and wavelength dependence of the refractivity of the gas. The pressure dependence of the system is easily accounted for, in making this claim however it is still imperative the mixture be impervious to contamination from the wider atmosphere. Wavelength dependence however is perhaps slightly more difficult to accommodate. Multiple lasers, of differing wavelength form the radiative sources which underpin the method developed. Laser sources were chosen because of their coherence, making it easy to produce interference, when combined with the inherent stability of the Sagnac interferometer, provides for a very user friendly system that is able to quickly take results. The other key part of the experimental apparatus is the gas handling system, the gas(es) of interest need to be contained within an optical medium in the path of one of the beams of the interferometer. Precise manipulation of the pressure of the gas is critical in determining concentration, this has been achieved through the use of a gas syringe whose plunger is moved on a finely threaded screw, and measured on a digital manometer. The optical setup has also been explored, specifically in ruling out the use of such radiative sources as passing an incandescent source through a monochromator or the use of LED's to produce interference before settling on lasers to produce the required interference. Finally, a comprehensive theoretical background has been presented using classical electromagnetic theory as well as confirmation from a quantum perspective. The theoretical background for this study relies upon the Lorentz-Lorenz formula. It is commonly presented either from a classical or quantum perspective, in this work both classical and quantum mechanical treatments are given whilst also showing how each confirms the other. Furthermore, a thorough investigation into the dispersion functions of each of the major components of the atmosphere has been compiled from the study of refractivity on individual gases from other authors, in some cases, where no work has been done previously, this has been derived. The technique developed could be considered an ample addition to gas analysis techniques in certain circumstances in terms of expense, convenience and accuracy. The system can predict relative quantities of constituents of the atmosphere to at least 3%. The method described here would allow researchers more time to concentrate on actual results and more resources to allocate to broadening intellectual horizons. This would certainly justify further development.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Sagnac</field><field name="subject">interferometer</field><field name="subject">interferometry</field><field name="subject">gas analysis</field><field name="subject">gas analyser</field><field name="subject">polarizability</field><field name="subject">dynamic polarizability</field><field name="subject">Lorentz-Lorenz equation</field><field name="subject">optical dispersion</field><field name="identifier">http://eprints.qut.edu.au/16701/</field><field name="validLink">True</field></doc><doc><field name="title">The synthesis of novel profluorescent nitroxide probes</field><field name="creator">Keddie, Daniel Joseph</field><field name="description">A number of novel isoindoline nitroxides have been synthesised using a variety of synthetic techniques. Several carbon-carbon bond forming methodologies, including the first examples of Heck and Sonogashira coupling applied to the isoindoline nitroxide class, were utilised to give novel robust aromatic frameworks. Palladium-catalysed Heck coupling of brominated nitroxides and ester-substituted olefins generates novel nitroxides possessing extended conjugation. Hydrolysis of the nitroxide esters gave the corresponding carboxylic acids, which showed enhanced water solubility. Sonogashira coupling of an iodo-isoindoline nitroxide gave several novel alkynesubstituted nitroxides in high yield. Subsequent coupling of a deprotected ethynyl nitroxide with aromatic iodides gave acetylene-linked nitroxides and an acetylene linked nitroxide dimer. A butadiyne linked dinitroxide was successfully synthesised via Eglinton oxidative coupling of two ethynyl nitroxides. The synthesis of a novel water-soluble dicarboxy nitroxide was achieved by base hydrolysis of a dinitrile. Functional group interconversion furnished anhydride and imide substituted nitroxides from the diacid. Subjecting the imide to the Hofmann rearrangement gave an unexpected brominated amino-carboxy nitroxide. The dicarboxy nitroxide and the brominated amino-carboxy nitroxide were both shown to have a protective effect on Ataxia-Telangiectasia cells, indicating a possible role as antioxidants in the treatment of this disease. A fluorescein nitroxide was successfully synthesised through the condensation of the anhydride substituted nitroxide and resorcinol. After limited success using a variety of other techniques, Buchwald-Hartwig amination was able to furnish a rhodamine nitroxide, via a triflate-fluorescein nitroxide. The extended aromatic nitroxides possess suppressed fluorescence and we have described these systems as profluorescent. The profluorescent nitroxides were found to have significantly lower quantum yields than the non-radical analogues and displayed a substantial increase in fluorescence intensity upon radical trapping, making them useful probes for free radical reactions.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">alkenylation</field><field name="subject">alkynylation</field><field name="subject">Buchwald-Hartwig amination</field><field name="subject">cyanation</field><field name="subject">fluorescein</field><field name="subject">fluorescence</field><field name="subject">fluorophore</field><field name="subject">free radical</field><field name="subject">Heck coupling</field><field name="subject">hydroxylamine</field><field name="subject">isoindoline</field><field name="subject">methoxyamine</field><field name="subject">nitroxide</field><field name="subject">oxidation</field><field name="subject">oxoammonium</field><field name="subject">palladium- catalysis</field><field name="subject">paramagnetic</field><field name="subject">profluorescent</field><field name="subject">reduction</field><field name="subject">redox</field><field name="subject">rhodamine</field><field name="subject">Sonogashira coupling</field><field name="subject">synthesis</field><field name="subject">water soluble</field><field name="subject">xanthene</field><field name="identifier">http://eprints.qut.edu.au/16702/</field><field name="validLink">True</field></doc><doc><field name="title">Super-resolution image processing with application to face recognition</field><field name="creator">Lin, Frank Chi-Hao</field><field name="description">Subject identification from surveillance imagery has become an important task for forensic investigation. Good quality images of the subjects are essential for the surveillance footage to be useful. However, surveillance videos are of low resolution due to data storage requirements. In addition, subjects typically occupy a small portion of a camera's field of view. Faces, which are of primary interest, occupy an even smaller array of pixels. For reliable face recognition from surveillance video, there is a need to generate higher resolution images of the subject's face from low-resolution video. Super-resolution image reconstruction is a signal processing based approach that aims to reconstruct a high-resolution image by combining a number of low-resolution images. The low-resolution images that differ by a sub-pixel shift contain complementary information as they are different "snapshots" of the same scene. Once geometrically registered onto a common high-resolution grid, they can be merged into a single image with higher resolution. As super-resolution is a computationally intensive process, traditional reconstruction-based super-resolution methods simplify the problem by restricting the correspondence between low-resolution frames to global motion such as translational and affine transformation. Surveillance footage however, consists of independently moving non-rigid objects such as faces. Applying global registration methods result in registration errors that lead to artefacts that adversely affect recognition. The human face also presents additional problems such as selfocclusion and reflectance variation that even local registration methods find difficult to model. In this dissertation, a robust optical flow-based super-resolution technique was proposed to overcome these difficulties. Real surveillance footage and the Terrascope database were used to compare the reconstruction quality of the proposed method against interpolation and existing super-resolution algorithms. Results show that the proposed robust optical flow-based method consistently produced more accurate reconstructions. This dissertation also outlines a systematic investigation of how super-resolution affects automatic face recognition algorithms with an emphasis on comparing reconstruction- and learning-based super-resolution approaches. While reconstruction-based super-resolution approaches like the proposed method attempt to recover the aliased high frequency information, learning-based methods synthesise them instead. Learning-based methods are able to synthesise plausible high frequency detail at high magnification ratios but the appearance of the face may change to the extent that the person no longer looks like him/herself. Although super-resolution has been applied to facial imagery, very little has been reported elsewhere on measuring the performance changes from super-resolved images. Intuitively, super-resolution improves image fidelity, and hence should improve the ability to distinguish between faces and consequently automatic face recognition accuracy. This is the first study to comprehensively investigate the effect of super-resolution on face recognition. Since super-resolution is a computationally intensive process it is important to understand the benefits in relation to the trade-off in computations. A framework for testing face recognition algorithms with multi-resolution images was proposed, using the XM2VTS database as a sample implementation. Results show that super-resolution offers a small improvement over bilinear interpolation in recognition performance in the absence of noise and that super-resolution is more beneficial when the input images are noisy since noise is attenuated during the frame fusion process.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">super-resolution</field><field name="subject">face recognition</field><field name="subject">optical flow</field><field name="subject">image processing</field><field name="subject">surveillance video</field><field name="subject">computer vision</field><field name="subject">pattern recognition</field><field name="subject">biometrics</field><field name="subject">principal components analysis</field><field name="subject">elastic bunch graph matching</field><field name="identifier">http://eprints.qut.edu.au/16703/</field><field name="validLink">True</field></doc><doc><field name="title">Identification of early cardiac decompensation and the management of intraaortic balloon counterpulsation weaning</field><field name="creator">Lewis, Peter Andrew</field><field name="description">Intraaortic balloon counterpulsation (IABP) is the most widely used mechanical support in the assistance of a failing heart.1 Despite extensive research in this field no experimental or clinical studies have been undertaken to evaluate the most effective manner to wean IABP.2 The research reported in this thesis examines early recognition of cardiac decompensation and the management of IABP weaning. Conducted in three phases, the aim of this research programme was to determine the best manner by which to wean IABP.    Phase 1 utilised a comparative descriptive design to examine IABP practice at a single cardiothoracic tertiary referral hospital. The majority of data collection was prospective, however, the required sample size saw inclusion of some retrospective data. This single centre data were than compared with an international registry to contrast IABP management and outcome. Phase 2 utilised a questionnaire survey to audit all Australasian intensive care units. Survey results were combined and statistically analysed to describe Australasian IABP management, weaning and outcome. Phase 3 utilised a quasi-experimental, one-group, posttest-only design to clinically validate a tool designed to monitor a patient's cardiac function - the 'cardiac decompensation tool'.    Phase 1 saw data collected for 669 IABP insertions over an 11 year period at a single Australian hospital. This cohort was compared against the 38,606 patient dataset of The Benchmark Counterpulsation Outcomes Registry. Australian IABP practice saw later application of the device in a higher acuity patient. Australian practice demonstrated a prejudice toward intraoperative use (34.2% versus 16.6%; p=&lt; 0.0001) and an aversion to catheter laboratory support (10.6% versus 19%; p=&lt; 0.0001). Australian mortality while slightly higher, remained comparable (22% versus 20.8%; p=ns). Phase 2 response rate was 60%. The most common Australasian method of IABP support withdrawal was ratio reduction only (61%). Units with a documented weaning policy were less likely to require balloon reinsertion or pharmacologic escalation following IABP removal (p=0.06). Indicators most likely to demonstrate a patient's readiness for IABP weaning were blood pressure (92%), heart rate (76%) and wedge pressure (59%). Phase 3 revealed cardiac decompensation tool scores to increase immediately prior to a treatment escalation (p=0.022) and decrease immediately following this escalation in therapy (p=0.0096). There was also some indication of decreasing scores prior to treatment minimisation (p=0.005). Tool scores demonstrated a corresponding treatment fluctuation up to three hours prior to the treatment intervention. With Phase 1 and 2 revealing many aspects of IABP practice to vary, the need for some direction regarding weaning is evident. Timely recognition of cardiac decompensation during IABP weaning allows an opportunity for the earlier escalation of treatment and consequent provision of increased cardiac support. Application of the Phase 3 cardiac decompensation tool can only assist in ensuring the best manner by which to support IABP weaning.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">heart decompensation</field><field name="subject">heart failure</field><field name="subject">IABP</field><field name="subject">intraaortic balloon pumping</field><field name="subject">counterpulsation</field><field name="subject">assisted circulation</field><field name="subject">weaning</field><field name="subject">cardiac output</field><field name="subject">low</field><field name="subject">shock</field><field name="subject">myocardial ischaemia</field><field name="subject">thoracic surgery</field><field name="subject">records</field><field name="subject">questionnaires</field><field name="identifier">http://eprints.qut.edu.au/16704/</field><field name="validLink">True</field></doc><doc><field name="title">Biotechnology as Media: A Critical Study of the Movement of Meanings Associated with Contemporary Biotechnology</field><field name="creator">Sunderland, Naomi Louise</field><field name="description">This thesis purports to make two contributions to understandings of biotechnology. First, it presents a novel framework through which to view biotechnology as a complex series of fundamentally social and politically economic mediations rather than a decontextualised collection of technical and scientific phenomena. Second, the thesis presents a method for analysing contemporary discourses about biotechnology within this framework. The framework presented in the first content chapter of the thesis identifies what I see to be the four primary mediating "movements" that are central to seeing Biotechnology as Media: Alienation, Translation, Recontextualisation, and Absorption. The next chapter explicates these movements more fully using a combination of social practice and discourse theory. Using these four movements and the mediation framework as a guide, I then critically analyse a corpus of seventy two exemplary texts (approximately 700,000 words) about contemporary biotechnology. Mediation, in the sense I use it here, is not concerned with one particular media form or technology. Rather, it focuses on the process of mediation as the movement of meanings (Silverstone, 1999). I argue that seeing biotechnologies as mediations can provide a deeper and more critical understanding of how ways of seeing, being, acting, and describing (discourses) associated with contemporary biotechnology are moved from micro- and macro-biological and scientific contexts into the everyday lives of citizens and ecosystems. In particular, such a view highlights the forces and voices that currently determine the path and substance of political-economic movements in biotechnology and, consequently, how everyday perceptions of biotechnology are shaped or silenced in processes of mediation. A core assumption of the thesis is that processes of mediation are not neutral. Rather, they are always inherently interpretive, politically economic, and ethically significant. Any mediation involves "filtering" processes via which "content" is transformed into a form that is appropriate for a given medium by persons who have control over the medium, and by the nature of the medium itself. This applies as much in laboratory and scientific contexts as it does in the contexts of mass consumption, whether in newspapers, policy papers, movies (such as Gattaca), or consumer goods. The same is true in the mediation of biotechnology: there are technological and discursive restrictions on what and who can "contribute to" and "come out" of biotechnology and also what is construed as being a valuable and desirable outcome of biotechnology research and development.  The three central analysis chapters of the thesis outline firstly how biotechnology can function as a time-based medium for the reproduction of already powerful discourses on, for example, the role of technology in human development and the consumer market as the moral medium between generators of new technologies and their "consumers". I identify exemplars of how the history of biotechnology and mediation (movement) is expressed in the corpus. This is followed by a more concentrated analysis of the ethical and social significance of the key "official" mediations presented in the corpus. I focus in particular on how the predominant policy evaluations of biotechnological mediations expressed in state, national, and international policy documents construct a "virtuous cycle" of product development that will ostensibly "deliver the benefits" of biotechnology to all citizens who, in the corpus, are framed predominantly as "consumers".  The final chapter of the thesis reflects on the significance of biotechnology at the macro level of social practices and systems. Apart from its direct function as a technical medium for alienating hitherto inalienable aspects of life, such as configurations of DNA, and turning them into products for sale, I argue that, as a suite of mediating movements, biotechnology has the potential to effectively, and for the most part invisibly, mediate our more general understandings and experiences of ourselves, of other species, and of the world we live in. More specifically, I argue that biotechnological mediations actively, and often forcefully, promote a narrowing of the range of evaluative resources on offer to the general community, and indeed to biotechnologists themselves. Biotechnological mediations can therefore be described as part of a broader movement away from conditions of heteroglossia or dialogue (multi language, multi voice) toward conditions of monologia (one language, one voice).  The thesis concludes with an important question: if we can identify these narrowing effects or mediations of biotechnology by using techniques such as Critical Discourse Analysis and by seeing biotechnology in a mediation framework, what can we do to interrupt them and generate movements that are more generative of heteroglossic and socially responsive ways of seeing, being, and acting? I offer a number of responses to the question in the conclusion.</field><field name="date">2004</field><field name="language" /><field name="relation" /><field name="subject">Biotechnology</field><field name="subject">Mediation</field><field name="subject">Discourse</field><field name="subject">Alienation</field><field name="subject">Translation</field><field name="subject">Recontextualisation</field><field name="subject">Absorption</field><field name="subject">Social Practice</field><field name="subject">Critical Discourse Analysis</field><field name="subject">Applied Ethics</field><field name="identifier">http://eprints.qut.edu.au/16705/</field><field name="validLink">True</field></doc><doc><field name="title">Principal Place of Residence? Long Term Caravan Park Residents in Rural Australia</field><field name="creator">Greenhalgh, Emma</field><field name="description">This thesis explores the importance of caravan parks as a provider of long term  housing in rural areas. Previous research on caravan parks in the Australian  housing system focused on the metropolitan and coastal regions, with little analysis  given over to parks in rural areas. There is a similar dearth of research on rural  housing in Australia. In previous housing studies rural housing has been discussed  as a residual of that in the capital cities. In many instances, rural areas are absorbed  into broader metropolitan/non-metropolitan constructs. This is despite the  complexity and range of housing issues in rural places. This research has brought  these two fields together, particularly to determine whether the problems in the  rural housing market are a factor for people living in caravan parks.  Previous studies on caravan parks have demonstrated that caravan park residents  have socio-economic characteristics that would make it difficult for them to access  housing. They have low incomes, a reliance on government benefits and higher  mobility rates compared to the general population. Caravan park residents have a  greater propensity to poverty. Thus for these residents, caravan parks offer housing  that is affordable and accessible. In many instances it is housing of last resort, or  housing used in times of crisis.  Previous research into rural housing has found that rural areas have greater  incidences of after housing poverty as a result of lower incomes. There are also  problems of housing accessibility, particularly for specific groups, such as the  aged, youth, and the disabled. Rural areas also are encountering the migration of  'urban refugees'. This group has high levels of need which creates a further strain  on a market.  The Shires of Chinchilla and Murilla in Queensland were selected as case studies  because they they have a stable caravan park industry and they are rural without  being remote. Interviews were undertaken with a variety of individuals  representing a range of organisations. This included a large sample of long-term  caravan park residents.  The residents who participated in the research were, similarly to the general profile  of park residents, disadvantaged. They also had low incomes with a reliance on  government benefits. The majority of the residents had located to the case study  region from the South-East of the State. It was also found that the majority of  residents migrated to the area and immediately moved into a caravan park.  Interestingly, there were no family households in the park, and very few young  people. Also, caravan parks were not utilised as crisis accommodation. This is  attributed to the discriminatory practices of the park operators as a form of 'risk  management'.  This research found that caravan parks play an important role in the housing  system of rural areas. Specifically, they are not a residual form of the dominant  tenures, but are a separate component of the housing market. Many residents did  not consider the broader housing market, and immediately moved into the park.  Residents did not explicitly consider their housing choice within the context of the  broader market. While housing related issues did arise, the majority of residents  individualised their experiences; that is, their housing experience is related to their  own individual situation and not because of any problems in the market.</field><field name="date">2003</field><field name="language" /><field name="relation" /><field name="subject">Caravan parks</field><field name="subject">long-term caravan park resident</field><field name="subject">rural housing</field><field name="subject">marginalised</field><field name="identifier">http://eprints.qut.edu.au/16706/</field><field name="validLink">True</field></doc><doc><field name="title">Engineering Trusted Location Services and Context-aware Augmentations for Network Authorization Models</field><field name="creator">Wullems, Christian John</field><field name="description">Context-aware computing has been a rapidly growing research area, however its uses have been predominantly targeted at pervasive applications for smart spaces such as smart homes and workplaces. This research has investigated the use of location and other context data in access control policy, with the purpose of augmenting existing IP and application-layer security to provide fine-grained access control and effective enforcement of security policy. The use of location and other context data for security purposes requires that the technologies and methods used for acquiring the context data are trusted.    This thesis begins with the description of a framework for the analysis of location systems for use in security services and critical infrastructure. This analysis classifies cooperative locations systems by their modes of operation and the common primitives they are composed of. Common location systems are analyzed for inherent security flaws and limitations based on the vulnerability assessment of location system primitives and the taxonomy of known attacks.    An efficient scheme for supporting trusted differential GPS corrections is proposed, such that DGPS vulnerabilities that have been identified are mitigated. The proposal augments the existing broadcast messaging protocol with a number of new messages facilitating origin authentication and integrity of broadcast corrections for marine vessels.    A proposal for a trusted location system based on GSM is presented, in which a model for tamper resistant location determination using GSM signaling is designed. A protocol for association of a user to a cell phone is proposed and demonstrated in a framework for both Web and Wireless Application Protocol (WAP) applications. After introducing the security issues of existing location systems and a trusted location system proposal, the focus of the thesis changes to the use of location data in authorization and access control processes. This is considered at both the IP-layer and the  application-layer.    For IP-layer security, a proposal for location proximity-based network packet filtering in IEEE 802.11 Wireless LANs is presented. This proposal details an architecture that extends the Linux netfilter system to support proximity-based packet filtering, using methods of transparent location determination through the application of a pathloss model to raw signal measurements.    Our investigation of application-layer security resulted in the establishment of a set of requirements for the use of contextual information in application level authorization.  Existing network authentication protocols and access control mechanisms are analyzed for their ability to fulfill these requirements and their suitability in facilitating context-aware authorization. The result is the design and development of a new context-aware authorization architecture, using the proposed modifications to  Role-based Access Control (RBAC). One of the distinguishing characteristics of the proposed architecture is its ability to handle authorization with context-transparency, and provide support for real-time granting and  revocation of permissions.    During the investigation of the context-aware authorization architecture, other security  contexts in addition to host location were found to be useful in application level authorization. These included network topology between the host and application server, the security of the host and the host execution environment. Details of the prototype implementation, performance results, and context acquisition services are  presented.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">Pervasive</field><field name="subject">ubiquitous</field><field name="subject">authorization</field><field name="subject">access control</field><field name="subject">location</field><field name="subject">trusted location</field><field name="subject">context</field><field name="subject">context-aware</field><field name="subject">network security</field><field name="identifier">http://eprints.qut.edu.au/16707/</field><field name="validLink">True</field></doc><doc><field name="title">Agent-based one-shot authorisation scheme in a commercial extranet environment</field><field name="creator">Au, Wai Ki Richard</field><field name="description">The enormous growth of the Internet and the World Wide Web has provided the opportunity for an enterprise to extend its boundaries in the global business environment. While commercial functions can be shared among a variety of  strategic allies - including business partners and customers, extranets appear to be  the cost-effective solution to providing global connectivity for different user groups.  Because extranets allow third-party users into corporate networks, they need to be extremely secure and external access needs to be highly controllable. Access control and authorisation mechanisms must be in place to regulate user access to information/resources in a manner that is consistent with the current set of policies  and practices both at intra-organisational and cross-organisational levels.    In the business-to-customer (B2C) e-commerce setting, a service provider faces a wide spectrum of new customers, who may not have pre-existing relationships established. Thus the authorisation problem is particularly complex. In this thesis, a new authorisation scheme is proposed to facilitate the service provider to  establish trust with potential customers, grant access privileges to legitimate users and enforce access control in a diversified commercial environment. Four modules with a number of innovative components and mechanisms suitable for distributed authorisation on extranets are developed:  * One-shot Authorisation Module - One-shot authorisation token is designed as a flexible and secure credential for access control enforcement in client/server systems;  * Token-Based Trust Establishment Module - Trust token is proposed for server-centric trust establishment in virtual enterprise environment.  * User-Centric Anonymous Authorisation Module - One-task authorisation key and anonymous attribute certificate are developed for anonymous  authorisation in a multi-organisational setting;  * Agent-Based Privilege Negotiation Module - Privilege negotiation agents are proposed to provide dynamic authorisation services with secure client agent environment for hosting these agents on user's platform</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">distributed authorisation</field><field name="subject">extranet</field><field name="subject">Intranet</field><field name="subject">smart card</field><field name="subject">personal secure device</field><field name="subject">authentication</field><field name="subject">security architecture</field><field name="subject">security server</field><field name="subject">trust establishment</field><field name="subject">trust token</field><field name="subject">credential-based authorisation</field><field name="subject">one-shot authorisation token</field><field name="subject">one-task authorisation key</field><field name="subject">anonymous attribute certificate</field><field name="subject">key binding certificate</field><field name="subject">anonymous authorisation</field><field name="subject">referee server</field><field name="subject">privilege negotiation agent</field><field name="subject">authorisation agent</field><field name="subject">secure client agent environment</field><field name="identifier">http://eprints.qut.edu.au/16708/</field><field name="validLink">True</field></doc><doc><field name="title">Innovative daylighting systems for deep-plan commercial buildings</field><field name="creator">Garcia-Hansen, Veronica Ruth</field><field name="description">The use of natural light is very beneficial in office buildings because energy consumption can be reduced, and working conditions can be enhanced, which positively affect workers' health and productivity. However, bringing natural light into deep plan office buildings is not possible with simple windows or skylights, and light transport systems are necessary to bring natural light into the deep cores of buildings. Light transport systems usually need sun-tracking devices to collect natural light that are complicated, expensive and require continual maintenance. Mirrored light pipes coupled with laser cut panels (LCP) are a passive and simpler daylight transport solution and are the focus of this PhD research. The primary aim has been to improve the technology and achieve the most efficient passive solution possible through the interactive use of theoretical modelling, experimental measurements and case studies. Applications of this technology were investigated in two case studies: 1) as horizontal light pipes for daylight illumination of a high rise building proposal in the tropics; and 2) as vertical light pipes for daylight illumination of a middle-rise deep plan building proposal in a subtropical environment. In both cases, quantitative system performance under best (clear sunny sky) and worst (overcast) case scenarios was undertaken via scale model testing and mathematical modelling. The major conclusion for both case studies was that mirrored light pipe technologies, when coupled with LCP, were effective in introducing sufficient ambient light levels inside buildings and over distances &gt; 20 m from the fa&#231;ade or roof. Average lux levels achieved in the space were 150 to 350 lux for the horizontal light pipes and 50 to 300 lux for vertical light pipes. However, as a passive solution, this technology has two major limitations: 1) the dependence on sun azimuth and elevation angles, which result in variations in illuminance levels during the day and the year; and potentially 2) pipe size, as pipes with a large diameter (e.g. 2 m in diameter for 20 m long pipes) are required for optimal performance, such that the large pipes may limit integration in building design. Two other solutions were assessed to circumvent these limitations to the mirrored light pipe technology: 1) a passive collector that concentrate natural light by using a fluorescent panel to reduce the size of the pipe, and 2) an active collector comprising a LCP rotating 360 degrees in a 24 hour cycle to reduce system dependence on sun azimuth and elevation angles. The low light-to-light efficiency of the fluorescent panels made them inappropriate for collecting sufficient amounts of daylight necessary for daylighting of large buildings. In contrast, the rotating LCP is a very simple active system that by rotating constantly at 15 degrees per hour, reduces the deviation angle between the panel orientation and sun azimuth angle, and significantly increased the system performance. The performance was generally better (e.g. 2.5 times better for light collection under low sun elevation angles) than the passive light pipe system with fixed LCP. However, active systems raise other issues in terms of cost-benefit in constructing, operating and maintaining such systems.  Passive mirrored light pipes coupled with LCPs or simple active systems with rotating LCPs have great potential as daylight solutions for deep plan buildings as they can contribute to lowering overall energy consumption, improve workplace health and become an architectural design element. Research is still required on the implementation of the technology into buildings, but the growing trend towards 'green buildings', sustainable design and government regulations or building codes will require more daylighting use in buildings, and will motivate designers to increasingly consider and incorporate such daylighting strategies into future building designs.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">daylighting</field><field name="subject">mirrored light pipes</field><field name="subject">laser cut panels</field><field name="subject">fluorescent panels</field><field name="subject">office buildings</field><field name="subject">scale model testing</field><field name="identifier">http://eprints.qut.edu.au/16709/</field><field name="validLink">True</field></doc><doc><field name="title">Alternative Brisbane masculinities : fictional representations within recent Brisbane narratives</field><field name="creator">Holliday, Penelope Ann</field><field name="description">This thesis considers and critically analyses literary representations of what I have called &#8220;alternative masculinities&#8221; within a selection of texts by male writers from the turn of the millennium.  The novels chosen for this analysis are Last Drinks by Andrew McGahan (2000), World of Chickens (2001) by Nick Earls and Sushi Central by Alasdair Duncan (2003).  The work of R.W. Connell, Doreen Massey and Bruce Bennett will inform a framework blending theories of masculinities, spatiality theories and critical regionalism, providing the tools to conduct a reading of the spaces fictional representations of alternative masculinities engage with.  Applying Connell&#8217;s hierarchy of masculinities (1995) I examine the emerging textual constructions of alternative masculinities that correspond with the changing cityscape of Brisbane.  Within the above texts I argue there is a strong emphasis on the connections between identity and place.  This is expressed through references to Brisbane&#8217;s social and historical identity and the gendered alignment of Brisbane spaces with particular masculinities.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">masculinities, Brisbane fiction, regionalism, space and place, narrative, alternative, Nick Earls, World Of Chickens, Andrew McGahan, Last Drinks, Alasdair Duncan, Sushi Central</field><field name="identifier">http://eprints.qut.edu.au/16754/</field><field name="validLink">True</field></doc><doc><field name="title">Behaviour and design of cold-formed steel hollow flange sections under axial compression</field><field name="creator">Zhao, Wen-Bin</field><field name="description">The use of cold-formed steel structures is increasing rapidly around the world due to the many advances in construction and manufacturing technologies and relevant standards. However, the structural behaviour of these thin-walled steel structures is characterised by a range of buckling modes such as local buckling, distortional buckling or flexural torsional buckling. These buckling problems generally lead to severe reduction and complicated calculations of their member strengths. Therefore it is important to eliminate or delay these buckling problems and simplify the strength calculations of cold-formed steel members. 
 
 The Hollow Flange Beam with two triangular hollow flanges, developed by Palmer Tube Mills Pty Ltd in the mid-1990s, has an innovative section that can delay the above buckling problems efficiently. This structural member is considered to combine the advantages of hot-rolled I-sections and conventional cold-formed sections such as C- and Z-sections (Dempsey, 1990). However, this structural product was discontinued in 1997 due to the complicated manufacturing process and the expensive electric resistance welding method associated with severe residual stresses (Doan and Mahendran, 1996). In this thesis, new fastening methods using spot-weld, screw fastener and self-pierced rivet were considered for the triangular Hollow Flange Beams (HFBs) and the new rectangular hollow flange beams (RHFBs). The structural behaviour of these types of members in axial compression was focused in this research project. The objective of this research was to develop suitable design models for the members with triangular and rectangular hollow flanges using new fastening methods so that their behaviour and ultimate strength can be predicted accurately under axial compression. 
 
 In the first stage of this research a large number of finite element analyses (FEA) was conducted to study the behaviour of the electric resistance welded, triangular HFBs (ERW-HFBs) under axial compression. Experimental results from previous researchers were used to verify the finite element model and its results. Appropriate design rules based on the current design codes were recommended. Further, a series of finite element models was developed to simulate the corresponding HFBs fastened using lap-welds (called LW-HFBs) and screw fasteners or spot-welds or self-piercing rivets (called S-HFBs). Since the test specimens of LW-HFBs and S-HFBs were unavailable, the finite element results were verified by comparison with the experimental results of ERW-HFB with reasonable agreement. 
 
 In the second stage of this research, a total of 51 members with rectangular hollow flanges including the RHFBs made from a single plate and 3PRHFBs made from three plates fastened with spot-welds and screws was tested under axial compression. The finite element models based on the tests were then developed that included the new fasteners, contact simulations, geometric imperfections and residual stresses. The improved finite element models were able to simulate local buckling, yielding, global buckling and local/global buckling interaction failure associated with gap opening as agreed well with the corresponding full-scale experimental results. Extensive parametric studies for the RHFBs made from a single plate and the 3PRHFBs made from three plates were undertaken using finite element analyses. The analytical results were compared with the predictions using the current design rules based on AS 4100, AS/NZS 4600 and the new direct strength method. Appropriate design formulae based on the direct strength method for RHFBs and 3PRHFBs were developed. This thesis has thus enabled the accurate prediction of the behaviour and strength of the new compression members with hollow flanges and paved the way for economical and efficient use of these members in the industry.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">structural engineering, steel structures, cold-formed steel, axial compression, design</field><field name="identifier">http://eprints.qut.edu.au/16909/</field><field name="validLink">True</field></doc><doc><field name="title">Design, development and evaluation of centrifugal ventricular assist devices</field><field name="creator">Timms, Daniel Lee</field><field name="description">Heart disease is the developed world's biggest killer, and the shortage of donor hearts has accelerated the development of mechanical alternatives. 
 
 Scientists, engineers and clinicians have attempted to replicate the human heart with a mechanical device for over 50 years. Although a number of pulsating devices have been developed, and in some cases worked briefly, they have invariably failed to match the success of heart transplantation.
 
 In an attempt to produce a suitable alternative, current research is focused on devices that do not replace the heart; but rather work along side it to assist its function. Many of these devices help the failing left ventricle; however some patients require the additional implantation of a second device to assist a failing right ventricle. This increases implantation time and associated risk, and because of the size of the current devices, reduces the access of smaller patients to this vital technology.
 
 The overall thesis objective focuses on the progressive design, development and preliminary evaluation of two novel centrifugal type ventricular assist devices, a bi-left ventricular device (Bi-LVAD) and a single bi-ventricular assist device (Bi-VAD). The devices have the respective capability to assist either the left ventricle, or both ventricles of a failing heart. The current concept for each VAD employs both magnetic and hydrodynamic suspension techniques to float a rotating double impeller, a technique that aims to reduce blood damage and component wear, two of the major problems encountered with current generation devices.  
 
 Each VAD design was developed by conducting experimentation and drawing conclusions from a variety of engineering research fields, such as flow visualization, rotary pump design and testing, fluid dynamics, hemodynamics and heart failure, and magnetic motor bearing design.
 
 In order to evaluate pump prototype designs, it was necessary to design and develop a novel pulsatile systemic and pulmonary mock circulation loop capable of reproducing the hemodynamics of heart failure in the systemic and pulmonary circuits. The investigation then specifically examined the static hydraulic forces on the impeller of a centrifugal blood pump during operation in this mock circulation loop. The recorded magnitude and direction of radial and axial thrust then influenced the selection of magnetic and hydrodynamic bearing configurations to minimise impeller touchdown in the intended hemodynamic environment. This research required the development of correctly designed impeller (semi-open/closed) and volute (single, double, circular) components for each ventricular assist application and a unique test facility to isolate impeller hydraulic forces in addition to the mock circulation loop.
 
 The proposed Bi-LVAD incorporates symmetrical blade designs on each side of the double sided impeller. The device assists the function of the left ventricle only with symmetrical axial pressure distribution and elimination of stagnant regions beneath the impeller. These features improve axial touchdown capacity and reduce thrombus formation respectively. The proposed Bi-VAD incorporates different blade designs on each side of the double impeller to augment the function of both the left and right cardiac chambers.  The design has the additional potential to act as a total artificial heart (TAH). To date there is no Bi-VAD/TAH system available that incorporates an LVAD and RVAD in one rotary pump.
 
 Successful development of each innovative VAD will provide an alternative to heart transplantation, potentially saving lives of many terminal heart patients each year. No longer would heart transplant candidates need to wait for the untimely death of a donor to provide a suitable heart. Instead, this new generation device would be available immediately, and be almost universally compatible with all patients.  It has the potential to dramatically increase a patient&#8217;s expected lifetime, and to deliver them a higher quality of life.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">left-right-bi-ventricular assist device, mock circulation loop, centrifugal pump design, impeller hydraulic force and performance</field><field name="identifier">http://eprints.qut.edu.au/16917/</field><field name="validLink">True</field></doc><doc><field name="title">A critical analysis of the relationship between health promoting behaviours, an individual's health risk, asthma severity and control, and patient centred asthma education in the emergency department</field><field name="creator">Smith, Sheree Margaret Stewart</field><field name="description">Asthma affects over 2.2 million people in Australia. Asthma morbidity is increasing while mortality is decreasing. People with asthma experience shortness of breath as their airways narrow and become inflamed. After an episode of acute asthma many patients experience a relapse requiring further emergency department care. Numerous studies have been undertaken to identify the determinants of asthma morbidity and these studies have primarily used asthma oriented and co-morbidity scales such as anxiety and depression indices. Other studies in this area have indicated psychosocial factors such as coping, asthma attitudes and beliefs that may be linked to people with asthma who are non-compliant or adherent to treatment. Currently, there is no research available that has examined the link between general health promoting behaviours, an individual&#8217;s risk behaviour assessment and a brief asthma education encounter that is patient-centred. This study provides a description of the health promoting and risk taking behaviours of people who attend the emergency department with acute asthma. Secondly, it examines the effectiveness of patient-centred education compared with standard education. One hundred and forty-six people with acute asthma who attended the emergency departments of the Princess Alexandra and Mater Adult Public Hospitals were enrolled in this study. Participants self-reported health promoting and risk taking behaviours by completing the questionnaire that contained the Health Promoting Lifestyle Profile (HPLPII) and the Health Risk Appraisal (HRA) instruments. The Hospital Anxiety and Depression Scale (HADS) was also incorporated into the questionnaire to ascertain levels of anxiety and depression in this acute asthma group of people.  The asthma education curriculum had the same topics for both the standard education and the patient-centred groups. However, the patient-centred group were able to prioritise the order of the topics according to their identified need. Secondly, the patient-centred group were asked two questions to ascertain the most important issue and asthma issue for them at that point in time. Both groups of participants were educated using the Asthma Foundation Leaflet &#8220;Asthma - Basic Facts&#8221; during the individual education session. There were 56% females and 44% males with a mean age (+SD) of 34 (13.8) years with 70.3% reported year 12 or above education and 49% of participants earned less that $20,000. Nearly half of the participants were admitted to a hospital ward following emergency department assessment and care. A large proportion of the participants had either moderate or severe asthma. The health behaviour findings from this study suggest people with acute asthma follow preventive health recommendations and safety guidelines more so than the wider community. However, they did not self-initiate home based health actions such as breast self-examination. At the time of attendance to the emergency department with acute asthma there were no statistical difference between the patient-centred education and standard format education groups for age, gender, education, income, asthma control and previous emergency department attendances. The patient-centred education group had fewer re-attendances in the four months after the education intervention when compared with prior emergency department attendances than the control group (p=0.057; p=0.486). In conclusion, people with acute asthma report undertaking a number of preventive health behaviours and actions according to national guidelines and safety recommendations. They report a lack of self-initiated home based health behaviours. Further research is required to investigate the impact on the National Asthma Council&#8217;s recommendations of the importance of asthma action plans on people who follow preventive health guidelines and who lack self-initiative abilities. In terms of asthma education, patient-centred education when compared to standard format education may be useful in reducing further emergency department attendances for acute asthma. More research is required to identify other key education issues for people with acute asthma.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">asthma, emergency department, health promoting behaviours, risk-taking behaviours, asthma control, asthma severity, patient-centred education</field><field name="identifier">http://eprints.qut.edu.au/16921/</field><field name="validLink">True</field></doc><doc><field name="title">Spectroscopic studies of Maya pigments</field><field name="creator">Goodall, Rosemary Anne</field><field name="description">The Maya of Central America developed a complex society: among their many achievements they developed a writing system, complex calendar and were prolific builders.  The buildings of their large urban centres, such as Copan in Honduras, were decorated with painted stucco, moulded masks, carving and elaborate murals, using a range of coloured pigments.  In this study the paints used on the buildings of Copan and some ceramic sherds have been investigated, non-destructively, using micro-Raman spectroscopy, micro-ATR infrared spectroscopy, environmental scanning electron microscopy with energy dispersive X-ray analysis (ESEM-EDX) and FTIR-ATR imaging spectroscopy.  The paint samples come from four buildings and one tomb covering three time periods in the four hundred year history of Copan.  The main pigment used in the red paint on these samples was identified as haematite, and the stucco as a mixture of calcite particles dispersed throughout a calcite-based lime wash stucco.  The composition and physical nature of the stucco changed through time, indicating a refining of production techniques over this period.  A range of minor mineral components have been identified in each of the samples including rutile, quartz, clay and carbon.  The presence and proportion of these and other minerals differed in each sample, leading to unique mineral signatures for the paint from each time period.  
 
 Green and grey paints have also been identified on one of the buildings, the Rosalila Temple.  The green pigment was identified as a celadonite-based green earth, and the grey pigment as a mixture of carbon and muscovite.  The combination of carbon and mica to create a reflective paint is a novel finding in Maya archaeology.  The high spatial resolution of the micro-FTIR-ATR spectral imaging system has been used to resolve individual particles in tomb wall paint and to identify their mineralogy from their spectra.  This system has been used in combination with micro-Raman spectroscopy and ESEM-EDX mapping to characterize the paint, which was found to be a mixture of haematite and silicate particles, with minor amounts of calcite, carbon and magnetite particles, in a sub-micron haematite and calcite matrix.  The blending of a high percentage of silicate particles into the haematite pigment is unique the tomb sample.  The stucco in this tomb wall paint has finely ground carbon dispersed throughout the top layer providing a dark base for the paint layer.  Changing paint mixtures and stucco composition were found to correlate with changes in paint processing techniques and building construction methods over the four hundred years of site occupation.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Micro-Raman spectroscopy, Micro-ATR infrared spectroscopy, FTIR-ATR spectral imaging, environmental scanning electron microscopy, ESEM-EDX, pigments, paint, stucco, ceramics, Maya, Copan</field><field name="identifier">http://eprints.qut.edu.au/16958/</field><field name="validLink">True</field></doc><doc><field name="title">Purification and characterisation of Tex31, a conotoxin precursor processing protease, isolated from the venom duct of Conus textile</field><field name="creator">Milne, Trudy Jane</field><field name="description">The venom of cone snails (predatory marine molluscs of the genus Conus) has yielded a rich source of novel neuroactive peptides or &#8220;conotoxins&#8221;. Conotoxins are bioactive peptides found in the venom duct of Conus spp. Like other neuropeptides, conotoxins are expressed as propeptides that undergo posttranslational proteolytic processing. Peptides derived from propeptides are typically cleaved at a pair of dibasic residues (Lys-Arg, Arg-Arg, Lys-Lys or Arg-Lys) by proteases found in secretory vesicles. However, many precursor peptides contain multiple sets of basic residues, suggesting that highly substrate specific or differentially expressed proteases can determine processing outcomes. As many of the substrate-specific proteases remain unidentified, predicting new bioactive peptides from cDNA sequences is presently difficult, if not impossible. In order to understand more about the substrate specificity of conotoxin substrate-specific proteases a characterisation study of one such endoprotease isolated from the venom duct of Conus textile was undertaken. The C. textile mollusc was chosen as a good source from which to isolate the endoprotease for two reasons; firstly, these cone shells are found in great abundance on the Great Barrier Reef (Queensland, Australia) and are readily obtainable and secondly, a number of conotoxin precursors and their cleavage products have been previously identified in the venom duct. In order to purify the endoprotease an activity-guided fractionation protocol that included a para-nitroanilide (p-NA) substrate assay was developed. The p-NA substrate mimicked the cleavage site of the conotoxin TxVIA, a member of the C. textile O-superfamily of toxins. The protocol included a number of chromatographic techniques including ion exchange, size-exclusion and reverse-phased HPLC and resulted in isolation of an active protease, termed Tex31, to &gt;95% purity. The purification of microgram quantities of Tex31 made it possible to characterise the proteolytic nature of Tex31 and to further characterise the O-superfamily conopeptide propeptide cleavage site specificity. Specificity experiments showed Tex31 requires a minimum of four residues including a leucine in the P4 position (LNKR&#8595;) for efficient substrate processing. The complete sequence of Tex31 was determined from cDNA. A BLAST search revealed Tex31 to have high amino acid sequence similarity to the CAP (abbreviated from CRISP (Cysteine-rich secretory protein), Antigen 5 and PR-1 (pathogenesis-related protein)) superfamily and most closely related to the CRISP family of mammalian and venom proteins that, like Tex31, have a cysteine-rich C-terminal domain. The CAP superfamily is widely distributed in the animal, plant and fungal kingdoms, and is implicated in processes as diverse as human brain tumour growth and plant pathogenesis. This is the first report of a biological role for the N-terminal domain of CAP proteins. A homology model of Tex31 constructed from two PR-1 proteins, Antigen 5 and P14a, revealed the highly conserved and likely catalytic residues, His78, Ser99 and Glu115. These three amino acids fall within a structurally conserved N-terminal domain found in all CAP proteins. It is possible that other CAP proteins are also substrate-specific proteases. With no homology to any known proteases, Tex31 may belong to a new class of protease. The sequence alignment of five Tex31-like proteins cloned from C. marmoreus, C. litteratus, C. arentus, C. planboris, and C. omaria show very high sequence similarity to Tex31 (~80%), but only one weakly conserved serine residue was identified when the conserved residues of the new Tex31-like protein sequences were aligned with members of the CAP superfamily. Future work to identify members of catalytic diad or triad, e.g. by site-directed mutagenesis, will rely on the expression of active recombinant Tex31. In this study neither Escherichia coli nor Pichia pastoris expression systems yielded active recombinant Tex31 protein, possibly due to the number of cysteine residues hindering the expression of correctly folded active Tex31. This study has shown Tex31 to be highly sequence specific in its cleavage site and it is likely that this high substrate specificity has confounded previous attempts to identify the proteolytic nature of other CAP proteins. With the proteolytic nature of one member of the CAP protein family confirmed, it is hoped this important discovery may lead the way to discovering the role of other CAP family members.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Tex31, protease, Conus, O-superfamily, propeptide precursor, para-nitroanilide, substrate specificity, pathogenesis-related protein, CAP, PR-1, CRISP, homology model, recombinant protein expression</field><field name="identifier">http://eprints.qut.edu.au/16960/</field><field name="validLink">True</field></doc><doc><field name="title">Body composition and energy expenditure in men with schizophrenia</field><field name="creator">Sharpe, Jenny-Kay</field><field name="description">There is an increase in the prevalence of obesity among people with schizophrenia thought to be due in part to the weight enhancing side-effects of medications commonly used to treat the symptoms of schizophrenia. Despite the deleterious health effects associated with obesity and its impact on quality of life and medication compliance, little is known about body composition and energy expenditure in this clinical group. The primary purpose of this thesis was to enhance understanding of body composition and energy expenditure, particularly resting energy expenditure in men with schizophrenia who take atypical antipsychotic medications. Unique to this investigation is the evaluation of clinical tools used to predict body composition and energy expenditure against reference methodologies in men with schizophrenia. Further, given the known links between obesity and physical activity, an additional but less comprehensive component of the thesis was a consideration of total and activity energy expenditure in addition to the interaction between psychiatric symptoms, side-effects of antipsychotic medications and physical activity also occurred as part of this thesis. Collectively, the goals of this thesis were addressed through a series of studies &#8211; the first two studies were related to the measurement and characteristics of body composition in men with schizophrenia, while the third and fourth studies were related to the measurement and characteristics of resting energy expenditure in men with schizophrenia. The fifth and sixth studies the utilised doubly labelled water technique to quantify activity and total energy expenditure in a small group of men with schizophrenia and explored the use of accelerometry in this cohort. The final study briefly considered the impact of psychiatric symptoms and self-reported medication side-effects on objectively measured physical activity. In the first study, thirty-one male adults previously diagnosed with schizophrenia and sixteen healthy male controls were recruited. Estimates of body composition derived from an anthropometry-based equation and from bioelectric impedance analysis (BIA) using deuterium dilution as the reference methodology to determine total body water were compared. The study also determined the validity of equations commonly used to predict body composition from BIA in the men with schizophrenia. A further aim was to determine the superiority of either BIA or body mass index (BMI) as an indicator of obesity in this cohort. The inclusion of the control group, closely matched for age, body size and body composition demonstrated that there was no difference in the ability of body composition prediction methods to distinguish between fat and fat-free mass (FFM) in controls and men with schizophrenia when both groups had similar body composition. However this study indicated that an anthropometry-based equation previously used in people with schizophrenia was a poor predictor of body composition in this cohort, as evidenced by wide limits of agreement (25%) and systematic variation of the bias. In comparison, the best predictor of percentage body fat (%BF) in this group was gained when impedance values were used to predict percentage body fat via the equation published by Lukaski et al (1986). Although percentage body fat was underpredicted using the Lukaski et al. (1986) equation, the mean magnitude was relatively small (1.3%), with the limits of agreement approximately 13%. Linear regression analysis revealed that %BF predicted using the Lukaski et al. (1986) equation explained 25% more of the variance in percentage body fat than BMI. Further, this study also indicated that BIA was more sensitive than BMI in distinguishing between overweight and obesity in this cohort of men with schizophrenia. Because of the almost exclusive use of BMI as an indicator of obesity in people with schizophrenia, the level of excess body fat may be in excess of that previously indicated. The second study extended the examination of body composition in men with schizophrenia. In this study, the thirty-one participants with schizophrenia (age, 34.2 &#177; 5.7 years; BMI, 30.2 &#177; 5.7 kg/m2) were individually matched with sedentary controls by age, weight and BMI. Deuterium dilution was used to distinguish between FFM and fat mass. The previous study had indicated that while BIA was a suitable group measure for obesity, on an individual level the technique lacked the precision required for investigating body composition in men with schizophrenia. Waist circumference was used as an indicator of body fat distribution. The findings of this study indicated that in comparison with healthy sedentary controls of similar body size and age, men with schizophrenia had higher levels of body fat which was more centrally distributed. Percentage body fat was on average 4% higher and waist circumference, on average 5 cm greater in men with schizophrenia than the sedentary controls of the same age and BMI. Further, this study indicates that the use of BMI to predict body fat in men with schizophrenia will result in greater bias than when it is used to predict body fat in other sedentary men. Commonly used regression equations to predict energy requirements at rest are based on the relationships between weight and resting energy expenditure (REE) and in such equations, weight acts as a surrogate measure of FFM. The objectives of study three were to measure REE in a small group of men with schizophrenia who were taking the antipsychotic medication clozapine and to determine whether REE can be predicted with sufficient accuracy to substitute for the measurement of REE in the clinical and/or research settings. Body composition was determined using deuterium dilution and REE was measured using a Deltatrac Metabolic Cart via a ventilated hood. The male participants, (aged 28.0 &#177; 6.7 yrs, BMI 29.8 &#177; 6.8 kg/m2) were weight stable at the time of the study and had been taking clozapine for 20.5 &#177; 12.8 months, with doses of 450 &#177; 140 mg/day. Of the six prediction equations evaluated, the equation of Mifflin et al. (1990) with no systematic bias, the lowest bias and the lowest limits of agreement proved to be the most suitable equation to predict REE in this cohort. The overestimation of REE can be corrected for by deducting 160 kcal/day from the predicted REE value when using the Mifflin et al. (1990) equations. However, the magnitude of the error associated with the prediction of REE for an individual is 370 kcal/day. The findings of this study indicate that REE cannot be predicted with sufficient individual accuracy in men with schizophrenia, therefore it was necessary to measure rather than predict REE in subsequent studies. In the fourth study, indirect calorimetry (Deltatrac Metabolic Cart via ventilated hood) and deuterium dilution were used to accurately determine REE, respiratory quotient (RQ) and FFM in 31 men with schizophrenia and healthy sedentary controls individually matched for age and BMI. Data from this study indicated that gross REE was lower in men with schizophrenia than in healthy sedentary controls of a similar age and body size. However, there was no difference between the groups in REE when REE was adjusted for FFM using the mathematically correct method (analysis of covariance with FFM as the covariate). There was however a statistically and clinically significant difference in resting, fasted RQ between men with schizophrenia and controls, suggesting that RQ rather than REE may be an important correlate worthy of further investigation in men with schizophrenia who take antipsychotic medications. Studies five and six involved the application of the doubly labelled water (DLW) technique to accurately determine total energy expenditure (TEE) and activity energy expenditure (AEE) in a small group of men with schizophrenia who had been taking the atypical antipsychotic medication clozapine. The participants were those who took part in study three. The purpose of these studies was to assess the validity of a commercially available tri-axial accelerometer (RT3) for predicting free-living AEE and to investigate TEE and AEE in men with schizophrenia. There was poor agreement between AEE measured using DLW and AEE predicted using the RT3. However, using the RT3 to measure inactivity explained over two-thirds of the variance in AEE. This study found that the relationship between current AEE per kilogram of body weight and change from baseline weight in men taking clozapine was strong although not significant. The sedentary nature of the group of participants in this study was reflected in physical activity levels, (PAL, 1.39 &#177; 0.27), AEE (435 &#177;352 kcal/day) and TEE (2511 &#177; 606 kcal/day) that fell well short of values recommended by WHO (2000) for optimal health and to prevent weight gain. Given the increasing recognition of the importance of sedentary behaviour to weight gain in the general community, further examination of the unique contributing factors such as medication side effects and symptoms of mental illness to activity levels in this clinical group is warranted. The final study used accelerometry (RT3) to objectively measure activity in a group of 31 men with schizophrenia who had been taking atypical antipsychotic medications for more than four months. The purpose of this study was to explore the relationships between psychiatric symptomatology, side-effects of medication and physical activity. Accelerometry output was analysed to provide a measure of inactivity and moderate intensity activity (MIA). The well-validated and reliable standardised clinical interview, the Positive and Negative Syndrome Scale (PANSS) was used as a measure of psychiatric symptoms. Perceived side-effects of medication were assessed using the Liverpool University Neuroleptic Rating Side-Effects Scale (LUNSER). Surprisingly, there was no relationship reported between any measures of negative symptoms and physical inactivity. However, self-reported measures of medication side-effects relating to fatigue, sleepiness during the day and extrapyramidal symptoms explained 40% of the variance in inactivity. This study found significant relationships between some negative symptoms and moderate intensity activity. Despite the expectation that as symptoms of mental illness reduce, inactivity may diminish and moderate intensity activity will increase, it may not be surprising that in practice this is an overly simplistic view. It may be that measures of social functioning and possibly therefore cognition may be better predictors of physical activity than psychiatric symptomatology per se.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">obesity, schizophrenia, atypical antipsychotic medication, clozapine, antipsychoticinduced obesity body composition</field><field name="subject">body mass index, percentage body fat, relative body fat, fat-free mass, adiposity total energy expenditure</field><field name="subject">activity energy expenditure, resting energy expenditure, physical activity doubly labelled water, bioelectric impedance analysis</field><field name="subject">deuterium dilution, indirect calorimetry, accelerometry, prediction equation, Positive and Negative Syndrome Scale (PANSS)</field><field name="subject">Liverpool University Neuroleptic Side Effects Rating Scale (LUNSER)</field><field name="identifier">http://eprints.qut.edu.au/16961/</field><field name="validLink">True</field></doc><doc><field name="title">Encapsulation and abstraction for modeling and visualizing information uncertainty</field><field name="creator">Streit, Alexander</field><field name="description">Information uncertainty is inherent in many real-world problems and adds a layer of complexity to modeling and visualization tasks. This often causes users to ignore uncertainty, especially when it comes to visualization, thereby discarding valuable knowledge. A coherent framework for the modeling and visualization of information uncertainty is needed to address this issue In this work, we have identified four major barriers to the uptake of uncertainty modeling and visualization. Firstly, there are numerous uncertainty modeling tech- niques and users are required to anticipate their uncertainty needs before building their data model. Secondly, parameters of uncertainty tend to be treated at the same level as variables making it easy to introduce avoidable errors. This causes the uncertainty technique to dictate the structure of the data model. Thirdly, propagation of uncertainty information must be manually managed. This requires user expertise, is error prone, and can be tedious. Finally, uncertainty visualization techniques tend to be developed for particular uncertainty types, making them largely incompatible with other forms of uncertainty information. This narrows the choice of visualization techniques and results in a tendency for ad hoc uncertainty visualization. The aim of this thesis is to present an integrated information uncertainty modeling and visualization environment that has the following main features: information and its uncertainty are encapsulated into atomic variables, the propagation of uncertainty is automated, and visual mappings are abstracted from the uncertainty information data type. Spreadsheets have previously been shown to be well suited as an approach to visu- alization. In this thesis, we devise a new paradigm extending the traditional spreadsheet to intrinsically support information uncertainty.Our approach is to design a framework that integrates uncertainty modeling tech- niques into a hierarchical order based on levels of detail. The uncertainty information is encapsulated and treated as a unit allowing users to think of their data model in terms of the variables instead of the uncertainty details. The system is intrinsically aware of the encapsulated uncertainty and is therefore able to automatically select appropriate uncertainty propagation methods. A user-objectives based approach to uncertainty visualization is developed to guide the visual mapping of abstracted uncertainty information. Two main abstractions of uncertainty information are explored for the purpose of visual mapping: the Unified Uncertainty Model and the Dual Uncertainty Model. The Unified Uncertainty Model provides a single view of uncertainty for visual mapping, whereas the Dual Uncertainty Model distinguishes between possibilistic and probabilistic views. Such abstractions provide a buffer between the visual mappings and the uncertainty type of the underly- ing data, enabling the user to change the uncertainty detail without causing the visual- ization to fail. Two main case studies are presented. The first case study covers exploratory and forecasting tasks in a business planning context. The second case study inves- tigates sensitivity analysis for financial decision support. Two minor case studies are also included: one to investigate the relevancy visualization objective applied to busi- ness process specifications, and the second to explore the extensibility of the system through General Purpose Graphics Processor Unit (GPGPU) use. A quantitative anal- ysis compares our approach to traditional analytical and numerical spreadsheet-based approaches. Two surveys were conducted to gain feedback on the from potential users. The significance of this work is that we reduce barriers to uncertainty modeling and visualization in three ways. Users do not need a mathematical understanding of the uncertainty modeling technique to use it; uncertainty information is easily added, changed, or removed at any stage of the process; and uncertainty visualizations can be built independently of the uncertainty modeling technique.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">information uncertainty visualization, information uncertainty modeling, spread- sheets, visualization spreadsheets, uncertainty visualization spreadsheets, visualiza- tion tools, modeling tools, uncertainty modeling, uncertainty visualization</field><field name="subject">probability, fuzzy visualization, visualization frameworks, visualization</field><field name="identifier">http://eprints.qut.edu.au/16963/</field><field name="validLink">True</field></doc><doc><field name="title">Economic analysis of malnutrition and pressure ulcers in Queensland hospitals and residential aged care facilities</field><field name="creator">Banks, Merrilyn Dell</field><field name="description">Malnutrition is reported to be common in hospitals (10-60%), residential aged care facilities (up to 50% or more) and in free living individuals with severe or multiple disease (&gt;10%) (Stratton et al., 2003). Published Australian studies
 indicate similar results (Beck et al., 2001, Ferguson et al., 1997, Lazarus and Hamlyn, 2005, Middleton et al., 2001, Visvanathan et al., 2003), but are generally limited in number, with none conducted across multiple centres or in residential aged care facilities. In Australia, there is a general lack of awareness and recognition of the problem of malnutrition, with currently no policy, standards or guidelines related to the identification, prevention and treatment of malnutrition. Malnutrition has been found to be associated with the development of pressure ulcers, but studies are limited. The consequences of the development of pressure ulcers include pain and discomfort for the patient, and considerable costs associated with treatment and increased length of stay. Pressure ulcers
 are considered largely preventable, and the demand for the establishment of appropriate policy, standards and guidelines regarding pressure ulcers has
 recently become important because the incidence and prevalence of pressure ulcers is increasingly being considered a parameter of quality of care. The aims of this study program were to firstly determine the prevalence of malnutrition and its association with pressure ulcers in Queensland Health hospitals and residential aged care facilities; and secondly to estimate the potential economic consequences of malnutrition by determining the costs
 arising from pressure ulcer attributable to malnutrition; and the economic
 outcomes of an intervention to address malnutrition in the prevention of pressure ulcers. The study program was conducted in two phases: an epidemiological study phase and an economic modelling study phase. In phase one, a multi centre, cross sectional audit of a convenience sample of subjects was carried out as part of a larger audit of pressure ulcers in
 Queensland public acute and residential aged care facilities in 2002 and again in 2003. Dietitians in 20 hospitals and six aged care facilities conducted single day nutritional status audits of 2208 acute and 839 aged care subjects using the Subjective Global Assessment, in either or both audits. Subjects excluded were obstetric, same day, paediatric and mental health patients. Weighted average proportions of nutritional status categories for acute and residential aged care facilities across the two audits were determined and compared. The effects of gender, age, facility location and medical specialty on malnutrition were determined via logistic regression. The effect of nutritional status on the presence of pressure ulcer was also determined via logistic regression. Logistic regression analyses were carried out using an analysis of correlated data approach with SUDAAN statistical package (Research Triangle Institute, USA) to account for the potential clustering effect of different facilities in the model. In phase two, an exploratory economic modelling framework was used to estimate the number of cases of pressure ulcer, total bed days lost to pressure ulcer and the economic cost of these lost bed days which could be attributed to malnutrition in Queensland public hospitals in 2002/2003. Data was obtained on the number of relevant separations, the incidence rate of pressure ulcer, the independent effect of pressure ulcers on length of stay, the cost of a bed day, and the attributable fraction of malnutrition in the development of pressure ulcers determined using the prevalence of malnutrition, the incidence rate of developing a pressure ulcer and the odds risk of developing a pressure ulcer when malnourished (as determined previously). A probabilistic sensitivity analysis approach was undertaken whereby probability distributions to the specified ranges for the key input parameters were assigned and 1000 Monte Carlo samples made from the input parameters. In an extension of the above model, an economic modelling framework was
 also used to predict the number of cases of pressure ulcer avoided, number of bed days not lost to pressure ulcer and economic costs if an intensive nutrition support intervention was provided to all nutritionally at risk patients in Queensland public hospitals in 2002/2003 compared to standard care. In
 addition to the above input parameters, data was obtained on the change in risk in developing a pressure ulcer associated with an intensive nutrition support intervention compared to standard care. The annual monetary cost of the provision of an intensive nutrition support intervention to at risk patients was
 modelled at a cost of AU$ 3.8-$5.4 million for additional food and nutritional supplements and staffing resources to assist patients with nutritional intake. A probabilistic sensitivity analysis approach was again taken.
 A mean of 34.7 + 4.0% and 31.4 + 9.5% of acute subjects and a median of 50.0% and 49.2% of residents of aged care facilities were found to be malnourished in Audits 1 and 2, respectively. Variables found to be significantly associated with an increased odds risk of malnutrition included: older age groups, metropolitan location of facility and medical specialty, in particular oncology and critical care. Malnutrition was found to be significantly associated with an increased odds
 risk of having a pressure ulcer, with the odds risk increasing with severity of malnutrition. In acute facilities moderate malnutrition had an odds risk of 2.2 (95% CI 1.6-3.0, p&lt;0.001) and severe malnutrition had an odds risk of 4.8 (95% CI 3.2-7.2, p&lt;0.001) of having a pressure ulcer. The overall adjusted odds risk
 of having a pressure ulcer when malnourished (total malnutrition) in an acute facility was 2.6 (95% CI 1.8-3.5, p&lt;0.001). In residential facilities, where the audit results were presented separately, the same pattern applied with moderate malnutrition having an odds risk of 1.7 (95% CI 1.2-2.2, p&lt;0.001) and 2.0 (95% CI 1.5-2.8, p&lt;0.001); and severe malnutrition having an odds risk of 2.8 (95% CI1.2-6.6, p=0.02) and 2.2 (95% CI 1.5-3.1, p&lt;0.001), for Audits 1 and 2 respectively. There was no statistical difference between these odds risk
 ratios between the audits. The overall adjusted odds risk of having a pressure ulcer when malnourished (total malnutrition) in a residential aged care facility was 1.9 (95% CI 1.3-2.7, p&lt;0.001) and 2.0 (95% CI 1.5-2.7, p&lt;0.001) for Audits
 1 and 2 respectively. Being malnourished was also found to be significantly associated with an increased odds risk of having a higher stage and higher number of pressure ulcers, with the odds risk increasing with severity of malnutrition.
 The economic model predicted a mean of 3666 (Standard deviation 555) cases
 of pressure ulcer attributable to malnutrition out of a total mean of 11162 (Standard deviation 1210), or approximately 33%, in Queensland public acute hospitals in 2002/2003. The mean number of bed days lost to pressure ulcer that were attributable to malnutrition was predicted to be 16050, which represents approximately 0.67% of total patient bed days in Queensland public
 hospitals in 2002/2003. The corresponding mean economic costs of pressure ulcer attributable to malnutrition in Queensland public acute hospitals in 2002/2003 were estimated to be almost AU$13 million, out of a total mean estimated cost of pressure ulcer of AU$ 38 526 601. In the extension of the economic model, the mean economic cost of the implementation of an intensive nutrition support intervention was predicted to be a negative value ( -AU$ 5.4 million) with a standard deviation of $AU3.9 million, and interquartile range of &#8211;AU$ 7.7 million to &#8211;AU$ 2.5 million. Overall there were 951 of the 1000 re-samples where the economic cost is a negative value. This means there was a 95% chance that implementing an intensive nutrition support intervention was overall cost saving, due to reducing the cases
 of pressure ulcer and hospital bed days lost to pressure ulcer. This research program has demonstrated an independent association between malnutrition and pressure ulcers, on a background of a high prevalence of malnutrition, providing evidence to justify the elevation of malnutrition to a safety and quality issue for Australian healthcare organisations, similarly to pressure ulcers. In addition this research provides preliminary economic
 evidence to justify the requirement for consideration of healthcare policy, standards and guidelines regarding systems to identify, prevent and treat malnutrition, at least in the case of pressure ulcers in Australia.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">malnutrition, pressure ulcers, nutritional status, economic analysis, nutrition intervention</field><field name="identifier">http://eprints.qut.edu.au/16966/</field><field name="validLink">True</field></doc><doc><field name="title">Essays on asset allocation strategies for defined contribution plans</field><field name="creator">Basu, Anup K.</field><field name="description">Asset allocation is the most influential factor driving investment performance. While researchers have made substantial progress in the field of asset allocation since the introduction of mean-variance framework by Markowitz, there is little agreement about appropriate portfolio choice for multi-period long horizon investors. Nowhere this is more evident than trustees of retirement plans choosing different asset allocation strategies as default investment options for their members. This doctoral dissertation consists of four essays each of which explores either a novel or an unresolved issue in the area of asset allocation for individual retirement plan participants. The goal of the thesis is to provide greater insight into the subject of portfolio choice in retirement plans and advance scholarship in this field. The first study evaluates different constant mix or fixed weight asset allocation strategies and comments on their relative appeal as default investment options. In contrast to past research which deals mostly with theoretical or hypothetical models of asset allocation, we investigate asset allocation strategies that are actually used as default investment options by superannuation funds in Australia. We find that strategies with moderate allocation to stocks are consistently outperformed in terms of upside potential of exceeding the participant&#8217;s wealth accumulation target as well as downside risk of falling below that target by very aggressive strategies whose allocation to stocks approach 100%. The risk of extremely adverse wealth outcomes for plan participants does not appear to be very sensitive to asset allocation. Drawing on the evidence of the previous study, the second essay explores possible solutions to the well known problem of gender inequality in retirement investment outcomes. Using non-parametric stochastic simulation, we simulate iv and compare the retirement wealth outcomes for a hypothetical female and male worker under different assumptions about breaks in employment, superannuation contribution rates, and asset allocation strategies. We argue that modest changes in contribution and asset allocation strategy for the female plan participant are necessary to ensure an equitable wealth outcome in retirement. The findings provide strong evidence against gender-neutral default contribution and asset allocation policy currently institutionalized in Australia and other countries. In the third study we examine the efficacy of lifecycle asset allocation models which allocate aggressively to risky asset classes when the employee participants are young and gradually switch to more conservative asset classes as they approach retirement. We show that the conventional lifecycle strategies make a costly mistake by ignoring the change in portfolio size over time as a critical input in the asset allocation decision. Due to this portfolio size effect, which has hitherto remained unexplored in literature, the terminal value of accumulation in retirement account is critically dependent on the asset allocation strategy adopted by the participant in later years relative to early years. The final essay extends the findings of the previous chapter by proposing an alternative approach to lifecycle asset allocation which incorporates performance feedback. We demonstrate that strategies that dynamically alter allocation between growth and conservative asset classes at different points on the investment horizon based on cumulative portfolio performance relative to a set target generally result in superior wealth outcomes compared to those of conventional lifecycle strategies. The dynamic allocation strategy exhibits clear second-degree stochastic dominance over conventional strategies which switch assets in a deterministic manner as well as balanced diversified strategies.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">asset allocation, bootstrap resampling, defined contribution (DC) plan, downside risk, dynamic lifecycle strategy, expected tail loss (ETL), lifecycle fund, lower partial moment (LPM), monte carlo simulation (MCS), stochastic dominance (SD)</field><field name="subject">tail risk, terminal wealth, value at risk (VaR)</field><field name="identifier">http://eprints.qut.edu.au/16992/</field><field name="validLink">True</field></doc><doc><field name="title">Exploring the relationship of organisational culture to enterprise system success</field><field name="creator">Birbeck, Peter J.</field><field name="description">The doctoral research project is titled &#8216;An Exploration of the Relationship of Organisational Culture and Enterprise System Success and sought to address the research gap identified in the literature between organisational culture literature and Information System success literature. This is a research project which is funded by the Australian Research Council in conjunction with industry. The industry sponsors for this research were SAP AG, SAP USA and SAP ANZ.
 The research project adopted a multi-method research design, grounded in practice, in order to surface any reported relationship between Enterprise Systems Success (ESS) and Organisational Culture (OC). A critical part of the study was to identify who could report on this relationship. Partners in implementation include internal change managers, internal consultants, vendor consultants and implementation partner consultants. Representatives from each of these constituents were interviewed, covering a range of industry sectors and Enterprise Systems vendor organisations. The first phase of the research was to qualitatively assess the perception of these participants on the role of culture to Enterprise Systems Success. This phase used open, axial and selective coding of the responses obtained in a semi-structured interview.
 The next phase of the research was to gather quantitative measures of Organisational Culture and Enterprise Systems Success. The Organisational Culture Assessment Inventory (OCAI) of Cameron and Quinn was selected to gather quantitative data on Organisational Culture. The Enterprise Systems Success instrument of Gable, Sedera and Chan was selected to measure the perception of ESS because of its proven reliability and validity.
 Each of these data sets were then analysed to determine if an association existed between the cultures of organisations that achieved most success with the Enterprise System as opposed to the culture types reported of organisations that achieved the least success with the ES. These findings then assisted in the development of a model of interaction between OC and ESS.
 Finally, the relationship of OC to ESS was explored in a rich case study of one large firm, to determine if the consultant&#8217;s reported relationships could be identified in the subcultures of the organisation.
 The key findings of this study were:
 1.
 There was a relationship reported between culture type and success types. The findings a-e below represent findings using the culture definitions from Cameron &amp; Quinn&#8217;s culture instrument:
 a.
 clan cultures which emphasised the behaviours of development of others were related to reports of ESS
 b.
 hierarchical cultures which emphasised the behaviours of control and coordination were related to reports of ESS
 c.
 hierarchical cultures which were poor in the execution of control and coordination were related to reports of the least success with ES
 d.
 market cultures which emphasised (internal) competitiveness were strongly related to reports of least success with ES
 e.
 literature attributes of continuous improvement (CI), flexibility (F) and innovation (I), which are often described as antecedents to innovation success and are found in the culture type of adhocracy, were reported as strongly related to success of ES, but the culture type of adhocracy was not reported as being present in the quantitative data describing consultant experiences with enterprises which had implemented ES.
 2.
 that the literature supported theoretical reasons for the above findings
 3.
 that these patterns of association were found in the case study.
 The research supports the proposition that there is a relationship between Organisational Culture type and ESS. Certain culture types practice behaviours that correspond to reported necessary behaviours for innovation success and ESS, whilst other culture types practice behaviours that correspond to behaviours for failure of innovation and of ES failure. A model of and explanation for this relationship was proposed as a result of the findings. Future research is now required to empirically test this model.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">organisational culture, enterprise systems, enterprise systems success, measuring organisational culture, measuring enterprise system success, ES, ES implementation, information systems, multi-method research, erp</field><field name="identifier">http://eprints.qut.edu.au/16997/</field><field name="validLink">True</field></doc><doc><field name="title">Leadership development through executive coaching : the effects on leaders' psychological states and transformational leadership behaviour</field><field name="creator">Finn, Fran A.</field><field name="description">Executive coaching has been described as a multibillion dollar enterprise
 (Ennis, 2004) costing some organisations up to $15,000 (USD) a day (Berglas,
 2002). Executive coaching has also been reported as the second fastest growth
 industry (Wasylyshyn, 2003). Despite these astounding figures, empirical executive
 coaching research is still limited, thus more randomised, controlled studies are
 required (Grant, 2005). There is a fundamental need for high quality research to
 demonstrate the effects of executive coaching and provide justification for the level
 of commitment expended. The current research program addressed this need through
 three studies which together provide empirical evidence as to the psychological and
 behavioural effects of executive coaching.
 In the first study, twenty-three leaders from a year long transformational
 leadership development program volunteered to participate in six sessions of
 executive coaching. The study examined the effects of executive coaching on
 leaders&#8217; psychological states, specifically, their self-efficacy, developmental support,
 positive affect, openness to new behaviours and developmental planning. The study
 had an experimental design with random assignment of leaders to training and
 control groups which provided a rigorous basis to distinguish the effects of executive
 coaching from the effects of other leadership interventions in the program.
 Comparison of the training group (after six executive coaching sessions) with
 the control group (who had not received coaching) revealed that the training group
 reported significantly higher levels of self-efficacy, developmental support, openness
 to new behaviours, and developmental planning compared with the control group.
 No significant effects were observed for positive affect. Further analysis, however,
 revealed that the significant differences between the training group and the control
 group were due to a decrease in the control group before they commenced executive
 coaching, rather than because the training group increased on the psychological
 measures after participating in executive coaching. It was proposed that this pattern
 of results occurred because the pre-coaching measures were obtained at the end of a
 two day training workshop, when the psychological measures may have already been
 relatively high. Thus, the effect of executive coaching was to sustain the impact of
 the workshop for the training group.
 A longitudinal analysis was also carried out in Study One to examine whether
 the effects of executive coaching on the psychological variables were sustained over
 time. The pattern of change was examined at three time points: time one, prior to the
 commencement of executive coaching, time two, after the completion of six
 coaching sessions, and time three, six months after the completion of the six
 coaching sessions. This analysis was also affected by the training group&#8217;s high precoaching
 measures, but when the analyses were restricted to the control group (n=6)
 &#8211; who by this stage had received executive coaching, significant change over time was observed on all of the study measures, which was sustained up to six months
 after the completion of regular coaching sessions. However, because the control
 group sample was small, these findings were tested again in Study Two.
 The primary aim of Study Two though was to evaluate effects of executive
 coaching on transformational leadership behaviour, measured with self, supervisor
 and team member ratings. Twenty-seven leaders participated in this study. In the
 first instance, an experimental design was used to investigate whether leaders in the
 training group, who had been exposed to executive coaching, received higher ratings
 in transformational leadership behaviour compared with leaders in the control group.
 In the second instance this study examined whether there was change in
 transformational behaviour over time, observed in the area that was the focus of
 leaders&#8217; developmental efforts. Both approaches yielded similar findings in that the
 team member feedback identified significant improvement in leaders&#8217;
 transformational leadership behaviour after executive coaching. There were no
 significant changes in leaders&#8217; self or supervisor ratings after executive coaching.
 When the psychological effects of executive coaching were re-examined in
 Study Two, the expected differences were observed between the training and control
 groups. However, once again, the data from the training group failed to show the
 anticipated pattern of improvement over time. This failure was attributed to the
 small sample size and low statistical power. Consequently, a final analysis was
 conducted combining the data from leaders who participated in Study One and Study
 Two. This analysis measured change in leaders&#8217; psychological states from pre-to
 post-executive coaching and confirmed that after executive coaching leaders
 experienced effects in the five psychological states measured. Thus, overall, the data
 from the two studies supported the psychological impact of executive coaching.
 In Study Three a qualitative approach was employed to triangulate the
 quantitative results from Study One and Study Two. Eight leaders were randomly
 identified from the Study One and Study Two samples, and interviews were carried
 out with these leaders, their supervisors, two team members and their coaches (a total
 of 40 interviews). The interview data confirmed the effect of executive coaching on
 the previously investigated psychological variables and also identified coaching as
 providing leaders with a sense of greater control. In terms of transformational
 leadership behaviours, all participants in the study identified improvements in
 leaders&#8217; behaviour, particularly in communication, and the transformational
 leadership dimensions of intellectual stimulation, inspirational motivation and
 individualised consideration. One further aim of Study Three was to investigate the
 environmental conditions to determine the impact they had on the effectiveness of
 executive coaching. Constant change and high work load were most frequently
 identified as restricting participants&#8217; ability to benefit from executive coaching.
 Overall, this program of research has demonstrated leadership development
 through executive coaching. The studies revealed that executive coaching positively
 enhanced the psychological states of self-efficacy, developmental support, positive
 affect, openness to new behaviours, and developmental planning. Impressively, the
 results also showed that executive coaching had sustained effects on some of the
 psychological states, and on team members&#8217; perceptions of their leader&#8217;s transformational leadership behaviour. Practically, these findings justify the use of
 executive coaching in organisational settings. Theoretically, these outcomes
 augment the limited body of knowledge in this area.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Executive coaching, transformational leadership, leadership development, self- efficacy, developmental support, positive affect, openness to new behaviours, developmental planning, communication, greater control, sustained improvement</field><field name="identifier">http://eprints.qut.edu.au/17001/</field><field name="validLink">True</field></doc><doc><field name="title">Emergency department nurses' experience of implementing discharge planning for emergency department patients in Taiwan : a phenomenographic study</field><field name="creator">Han, Chin-Yen</field><field name="description">During recent reforms to the Taiwanese health care system, discharge planning for hospital patients has become an issue of great concern as a result of shorter hospital stays, increased health care costs and a greater emphasis on community care. There are around five million patients visiting in emergency departments (ED) per year in Taiwan with up to 85% of these, 4,250,000 emergency patients, discharged directly from the emergency department. This significant number of ED visits highlights the need to implement discharge planning in the ED. ED nurses are not only responsible for providing appropriate assessments of a patient's future care needs but also for implementing effective discharge planning as a legal obligation; discharge planning is also a patient's right in Taiwan. For ED nurses to function effectively in the role of discharge planner, it is important that they have a comprehensive understanding of implementing discharge planning. To date, no published research focuses on nurses' experience of implementing discharge planning in the ED in Taiwan. This study is the first step in identifying the experience and understanding of nurses in implementing discharge planning in the ED in Taiwan and may have implications worldwide.
 
 The purpose of this study was to identify and describe the experience and understanding of the qualitatively different ways in which ED nurses&#8217; experience of implementing discharge planning for emergency patients in Taiwan. In order to identify and describe the experience of implementing discharge planning, the qualitative approach of a phenomenography was chosen. Thirty-two ED nurses in Taiwan who matched the participant selection criteria were asked to describe their experience and understanding of the implementation of discharge planning in the ED. Semi-structured interviews were audio-taped and later transcribed verbatim. The data analysis process focused on identifying and describing ways ED nurses&#8217; experience and understanding of implementing discharge planning in the ED. There were two major outcomes of this study: six categories of description and an outcome space. These six categories of description revealed the experience and understanding of implementing discharge planning in the ED. An outcome space portraying the logical relations between the categories of description was identified.
 
 The six categories of description  were implementing discharge planning as &#8216;getting rid of my patients&#8217;; implementing discharge planning as completing routines; implementing discharge planning as being involved in patient education; implementing discharge planning as professional accountability; implementing discharge planning as autonomous practice; implementing discharge planning as demonstrating professional nursing care in ED. The outcome space mapped the three levels of hierarchical relationship between these six categories of description. The referential meaning of implementing discharge planning was the commitment to providing discharge services in the ED.  
 
 The results of this research contribute to describing the nurses&#8217; experience in the implementation of the discharge planning process in the emergency nursing field, in order to provide accurate and effective care to patients discharged from the ED. This study also highlights key insights into the provision of discharge services both in Taiwan and World-wide.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">emergency department, hospitals, nursing, Taiwan</field><field name="identifier">http://eprints.qut.edu.au/17003/</field><field name="validLink">True</field></doc><doc><field name="title">Developing palliative care models in neonatal nursing : an investigation of barriers and parameters for practice</field><field name="creator">Kain, Victoria J.</field><field name="description">The neonatal intensive care unit (NICU) is frequently occupied by newborns who are marginally viable, or critically unwell, and could be considered terminally ill. It is a busy, highly technical environment with an arsenal of life-saving medical equipment at its disposal, and advances in technology used in this field stretch the boundaries of viability. Despite technological advances, increases in the margins of viability and highly skilled healthcare delivery, some newborns will still die in the NICU. In recent years, palliative care for the neonatal population has become increasingly topical and part of the lexicon of contemporary neonatal practice. Evidence-based protocols are available to inform this model of care, yet in reality, provision of palliative care to newborns is ad hoc. The reasons why implementing a palliative model of care have been problematic are unclear. The purpose of this study was to identify the barriers and facilitators to palliative care practice in neonatal nursing, and to develop policy recommendations to improve this area of practice. This exploratory research was conducted to answer two research questions: 1) What are the barriers and facilitators to palliative care practice in neonatal nursing? 2) How can the identified issues be addressed to inform policy and clinical guidelines in the practice environment?
 Phase one of this investigation developed, pilot tested, and administered an instrument to identify the barriers and facilitators to practice. Data analysis identified three subscales that indicated facilitators and barriers to palliative care practice. The second phase of this study used a translational research approach, utilizing interpretive methods to explore and contextualise the population study findings to inform policy development to improve palliative care practice in neonatal nursing. This research has identified that the facilitators that do exist for palliative care practice are subject to caveats that impinge markedly upon these facilitators. Furthermore, the barriers that were identified pose threats to the integration of a palliative model of care into Australian neonatal nursing practice. Thus, the overall results from this research have lead to a composite understanding of the barriers and facilitators to palliative care practice in Australian neonatal nursing, which may account for the gap between support of palliative care for marginally viable and critically ill newborns, and the application of this model of care in clinical practice. Translating the survey findings into policy directives that are applicable to the clinical environment has resulted in the development of recommendations that are aimed at improving palliative care practice in the NICU.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">palliative care, neonatal nursing</field><field name="identifier">http://eprints.qut.edu.au/17012/</field><field name="validLink">True</field></doc><doc><field name="title">Food accessibility, affordability, cooking skills and socioeconomic differences in fruit and vegetable purchasing in Brisbane, Australia</field><field name="creator">Winkler, Elisabeth Amy</field><field name="description">Across Australia and other developed nations, morbidity and mortality follows a socioeconomic gradient whereby the lowest socioeconomic groups experience the poorest health.  The dietary practices of low socioeconomic groups, which are comparatively less consistent with dietary recommendations, have been thought to contribute to the excess morbidity and mortality observed among low socioeconomic groups, although this phenomenon is not well understood.  Using a socioecological framework, this thesis examines whether the local food retail environment and confidence to cook contribute to socioeconomic differences in fruit and vegetable purchasing. To achieve this, four quantitative analyses of data from two main sources were conducted.  The food retail environment was examined via secondary analysis of the Brisbane Food Study (BFS) and confidence to cook was examined in a cross-sectional study designed and carried out by the author.  
 
 The first three manuscripts were based on findings from the BFS.  Briefly, the BFS was a multilevel cross-sectional study, designed to examine determinants of inequalities, that was conducted in Brisbane in the year 2000.  A stratified random sample was taken of 50 small areas (census collection districts, CCDs) and 1003 residents who usually shopped for their households were interviewed face-to-face using a schedule that included a measure of fruit and vegetable purchasing and three socioeconomic markers: education, occupation and gross household income.  The purchasing measure was based on how often (never, rarely, sometimes nearly always or always) participants bought common fruits and vegetables for their households in fresh or frozen form, when in season.  Food shops within a 2.5 km radius of the CCDs in which survey respondents lived were identified and audited to determine their location, type, their opening hours, and their price and availability of a list of food items.  
 
 The first publication demonstrated there was minimal to no difference in the availability of supermarkets, greengrocers and convenience stores between areas that were most and least disadvantaged, in terms of the number of shops, distance to the nearest shop, or opening hours.  Similarly, the second publication showed the most disadvantaged and least disadvantaged areas had no large or significant difference in the price and availability of fruits and vegetables within supermarkets, greengrocers and convenience stores, but small differences were consistently apparent, such that on average, low socioeconomic areas had lower prices but also lesser availability than more advantaged areas.  The third submitted manuscript presents results of multilevel logistic regression analyses of the BFS data.  While there were some associations between environmental characteristics and fruit and vegetable purchasing, environmental characteristics did not mediate socioeconomic differences in purchasing the fruit and vegetable items since there was no substantial socioeconomic patterning of the price or availability of fruits and vegetables. 
 
 The fourth submitted manuscript was based on the cross-sectional study of cooking skills.  A stratified random sample of six CCDs in Brisbane was taken and 990 household members &#8216;mostly responsible&#8217; for preparing food were invited to participate.  A final response rate of 43% was achieved.  Data were collected via a self-completed questionnaire, which covered household demographics, vegetable purchasing (using the same measure employed in the BFS for continuity), confidence to prepare these same vegetables, and confidence to cook vegetables using ten cooking techniques.  Respondents were asked to indicate how confident they felt (ranging from not at all- to very- confident) to prepare each vegetable, and to use each technique. This fourth study found respondents with low education and low household income had significantly lower confidence to cook than their higher socioeconomic counterparts, and lower confidence to cook was in turn associated with less household vegetable purchasing.  
 
 Collectively, the four manuscripts comprising this thesis provide an understanding of the contribution of food accessibility, affordability and cooking skills to socioeconomic differences in fruit and vegetable purchasing, within a socioecological framework.  The evidence provided by this thesis is consistent with a contributory role of confidence to cook in socioeconomic differences in fruit and vegetable purchasing, but is not definitive.  Additional research is necessary before promoting cooking skills to improve population nutrition or reduce nutritional inequalities.  An area potentially useful to examine would be how cooking skills integrate with psychosocial correlates of food and nutrition, and socioeconomic position.  For example, whether improvement of cooking skills can generate interest and knowledge, and improve dietary behaviours, and whether a lack of interest in food and nutrition contributes to a lack of both fruit and vegetable consumption and cooking skills.  This thesis has demonstrated that an inequitably distributed food retail environment probably does not contribute to socioeconomic variation in fruit and vegetable purchasing, at least in contemporary Brisbane, Australia.  Findings are unlikely to apply to other time periods, rural and regional settings, and perhaps other Australian cities as residential and retail development, and the supply and pricing of produce vary substantially across these dimensions. Overall, the main implication for public health is that interventions targeting the food supply in terms of ensuring greater provision of shops, or altering the available food and prices in shops may not necessarily carry a great benefit, at least in major cities similar to Brisbane.  Future studies of equitable food access may need to look beyond mapping the distribution of shops and prices, perhaps to more personal and subjective facets of accessibility and affordability that incorporate individuals&#8217; perceptions and ability to access and pay for foods.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">socioeconomic inequalities, socioecological model, health risk behaviours, diet, fruits, vegetables, food accessibility, food affordability, cooking skills, associations</field><field name="identifier">http://eprints.qut.edu.au/17016/</field><field name="validLink">True</field></doc><doc><field name="title">'Fair dinkum personal grooming' : male beauty culture and men's magazines in twentieth century Australia</field><field name="creator">Burton, Jennifer Paula</field><field name="description">In this thesis, I analyse the representation of grooming in Australian men&#8217;s lifestyle magazines to explore the emergence of new masculine subjectivities constructed around narcissism and the adoption of previously feminine-coded products and practices which may indicate important shifts in the cultural meanings of Australian masculinity. However, in order to talk about &#8216;new&#8217; subjectivities and &#8216;shifts&#8217; in masculine behaviours and cultural ideals, then it is imperative to demonstrate &#8216;old&#8217; practices and ideologies, and so while the thesis is concerned with discourses of grooming and models of masculinity presented in the new genre of men&#8217;s lifestyle titles which appeared on the Australian market in the late 1990s, it frames this discussion with detailed analyses of  previously unexplored Australian men&#8217;s general interest magazines from the 1930s. According to Frank Mort consumption, traditionally associated with the feminine has now become a central part of imagining men (1996: 17-18) while the representation and sale of masculinity is an increasingly important part of the &#8216;cultural economy&#8217; (Mikosza, 2003). In this thesis I am concerned with the role of men&#8217;s lifestyle magazines and magazine representations of masculinity in the &#8216;cultural economy&#8217; of mediated male grooming cultures.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">men&#8217;s magazines, masculinity, grooming, metrosexual, representation, cultural economy, media, readerships</field><field name="identifier">http://eprints.qut.edu.au/17018/</field><field name="validLink">True</field></doc><doc><field name="title">The praxis of voluntary service : an investigation of the logic of service in Rotary and Zonta</field><field name="creator">Crichton, Merrilyn Yvonne</field><field name="description">Voluntary service is experiencing transition. This transition is marked by social,
 symbolic and policy changes that have transformed the relationship between paid
 and unpaid work, and is reordering the connection between voluntary practice and
 professional expertise. Giddens (1998) identified this as the third way. Rose (2000) sees this transformation as a strategy embodying a tacit regime around the economic transactions that implicate the agent in self-governance based on normative moral possibilities, thus ordering the moral subject. Research has not yet established the fundamental elements of this transforming logic, or the mechanisms by which oppositions such as paid and unpaid are being resolved by voluntary organisations. The thesis argues that third way commentators&#8217; view of the bureaucratic transformation of voluntary service that examines &#8220;historical and
 social conditions, professional strategies, and disciplinary stakes and
 constraints&#8230;&#8221; (Shusterman, 1999: 10) does not account for the nature of service, or the practice and logic of that service. Therefore this study interrogates the notion and logic of service for the nature of the discourse and experience of service at the time of the move toward the third way, the point that voluntary values and practices meeting economic action. This logic is examined and
 extrapolated by empirical examination of the case service in Rotary and Zonta, organisations whose members are professional and act in voluntary positions. Bourdieu&#8217;s (for example 1984[1979], 1998, 2002[1977]) work on the logic of practice (featuring field, habitus and practice) frames the theoretical exploration of the embeddedness and logic of a particular social object in the context of practice. Exploring the field, habitus and practice for aspects of service suggests a
 multidimensional approach that investigates the discourse, experience, dispositions and contextual practice of service. Thus the study of service is conducted by collecting data from codes of professional conduct and objectives of
 Rotary and Zonta (the discursive level of interpretation); professionals&#8217; experience and interpretation of volunteering (where the habitus of volunteers is made visible); and observations of practice and order at Rotary and Zonta meetings. The data was collected and analysed using Kenneth Burke&#8217;s rhetorical analysis (1969a, 1969b, 1989), Erving Goffman&#8217;s footing (Burns, 1992; Goffman, 1981), and Harvey Sacks&#8217; indexicality and membership categorisation analysis (Lepper, 2000; Sacks, 2000[1992]).
 This study examines and reports on elements and relationships in the service discourse such as expertise, judgment and discretion; aspects of the logic of service exhibited in professional agent&#8217;s experience of voluntary service, including agency and professional ethics; and the rituals practiced by professionals in the voluntary context. Many of these elements are contextual components of the opposition between economic and symbolic values in the voluntary setting. Empirical evidence presented in this study suggests that voluntary service when practiced within the new frame of economic rationales and
 bureaucratic structures does not amalgamate opposing sectors so much as expose a common logic of service.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">agency, bourdieu, bureaucracy, Burke, economic action, habitus, position taking, praxis, professional, Rotary International, service, volunteer, volunteering, Zonta International of Service</field><field name="identifier">http://eprints.qut.edu.au/17020/</field><field name="validLink">True</field></doc><doc><field name="title">Insect frugivore interactions : the potential for beneficial and neutral effects on host plants</field><field name="creator">Wilson, Alexsis Jane</field><field name="description">Frugivorous insects, specialised herbivores that consume fruit and seeds, are considered detrimental to host plant fitness. Their direct link to genetic fitness via consumption of plant reproductive tissue, and their negative socioeconomic association with agriculture exacerbates their harmful status. However, empirical testing of insect frugivore effects on host plants, and ecological research on the contribution of insect frugivores to multitrophic frugivory systems, is lacking. In the current study, direct effects of a non-mutualistic, insect frugivore/host plant system were tested and results showed variable effects. Beneficial, detrimental, but predominantly neutral effects on germination and seed production were observed between the Queensland fruit fly (Bactrocera tryoni) and tomato and capsicum plants. Significant effects on seed production were unexpected because infestation occurs after seed set. It was also found that eggplant, although a recorded host of B. tryoni, is inconsistent in its ability to sustain B. tryoni larvae through to its final instar. These results confirmed a simplification and presumption associated with insect frugivore (specifically fruit fly)/host plant interactions. Larval movement, infestation-induced fruit decay, pulp removal and germination were then investigated. For all hosts (tomato, apple and paw paw), treatments infested by B. tryoni decayed significantly quicker and to a greater extent than uninfested treatments, with obvious but variable changes to the texture and appearance. The movement of B. tryoni larvae, pattern of infestation-induced decay and pulp removal was unique and host dependent for all hosts. Only seeds from infested tomato were shown to germinate during the experiment. This indicated that host fruit characteristics are responsible, in part, for variable direct effects on host plant fitness by insect frugivores. Variable direct effects between insect frugivores and host plants, combined with the more rapid decay of infested fruits is likely to have implications for seed dispersal and seed predation by a third trophic level. The characteristics of fruit that are changed by infestation by an insect frugivore were then tested for their effect on a vertebrate frugivore, to illustrate the importance of recognising multitrophic interactions and indirect effects in frugivory. Specifically, seed predating rodents were incorporated into the study and their response to infested and uninfested fruits were recorded, as well as their reaction to the changes in fruit caused by insect frugivores (i.e. texture,
 smell, larvae presence and sound). Apple and pear infested with B. tryoni larvae were found to attract rodents, while infested tomato and paw paw had a neutral effect on the native rats. This differed from the predominant finding in the literature, which was a deterrent effect on avian seed dispersers. Vertebrate response to fruit infested with insect frugivores therefore, is variable. Assessing the indirect effect of insect frugivores on host plant fitness by attracting or deterring another trophic level requires knowledge of the direct effect between the introduced trophic level and the host plant. For example, the attraction of a seed predator may be as detrimental to host plant fitness as the deterrence of a seed disperser. This illustrates the complexity associated with assessing insect frugivore effects on host plant fitness. Results also indicated that differences in pulp texture, caused by infestation, have a significant effect on rodent preference for infested or uninfested treatments. Pulp texture is likely to effect rodent foraging efficiency, whereas the presence of B. tryoni larvae was observed to be inconsequential to rodent response to fruits. For rodents, and indeed any trophic level motivated by foraging efficiency, this finding raises the issue that for long lived fruiting plants, outside factors such as food abundance and competition for food, may cause a variable response to fruits infested by insect frugivores. From these investigations it has become apparent that insect frugivores are not consistently harmful to host plant fitness, as suggested by their negative stigma, but are likely to contribute variable effects, directly and indirectly, on multiple components of plant fitness and multitrophic frugivory systems.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Bactrocera tryoni, frugivory, host plant fitness, fitness components, insect frugivore, vertebrate frugivore, multitrophic interactions, indirect effects, direct effects, novel systems, beneficial herbivory, larval movement, decay, pulp removal</field><field name="subject">seed predator, seed disperser</field><field name="identifier">http://eprints.qut.edu.au/17023/</field><field name="validLink">True</field></doc><doc><field name="title">Automatic generation and evaluation of recombination games</field><field name="creator">Browne, Cameron Bolitho</field><field name="description">Many new board games are designed each year, ranging from the unplayable to the truly exceptional. For each successful design there are untold numbers of failures; game design is something of an art. Players generally agree on some basic properties that indicate the quality and viability of a game, however these properties have remained subjective and open to interpretation. The aims of this thesis are to determine whether such quality criteria may be precisely defined and automatically measured through self-play in order to estimate the likelihood that a given game will be of interest to human players, and whether this information may be used to direct an automated search for new games of high quality. Combinatorial games provide an excellent test bed for this purpose as they are typically deep yet described by simple welldefined rule sets. To test these ideas, a game description language was devised to express such games and a general game system implemented to play, measure and explore them. Key features of the system include modules for measuring statistical aspects of self-play and synthesising new games through the evolution of existing rule sets. Experiments were conducted to determine whether automated game measurements correlate with rankings of games by human players, and whether such correlations could be used to inform the automated search for new high quality games. The results support both hypotheses and demonstrate the emergence of interesting new rule combinations.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">combinatorial, games, design, aesthetics, evolutionary, search</field><field name="identifier">http://eprints.qut.edu.au/17025/</field><field name="validLink">True</field></doc><doc><field name="title">Direct volume illustration for cardiac applications</field><field name="creator">Mueller, Daniel C.</field><field name="description">To aid diagnosis, treatment planning, and patient education, clinicians require tools to anal- yse and explore the increasingly large three-dimensional (3-D) datasets generated by modern medical scanners. Direct volume rendering is one such tool finding favour with radiologists and surgeons for its photorealistic representation. More recently, volume illustration &#8212; or non-photorealistic rendering (NPR) &#8212; has begun to move beyond the mere depiction of data, borrowing concepts from illustrators to visually enhance desired information and suppress un- wanted clutter. Direct volume rendering generates images by accumulating pixel values along rays cast into a 3-D image. Transfer functions allow users to interactively assign material properties such as colour and opacity (a process known as classification). To achieve real-time framerates, the rendering must be accelerated using a technique such as 3-D texture mapping on commod- ity graphics processing units (GPUs). Unfortunately, current methods do not allow users to intuitively enhance regions of interest or suppress occluding structures. Furthermore, addi- tional scalar images describing clinically relevant measures have not been integrated into the direct rendering method. These tasks are essential for the effective exploration, analysis, and presentation of 3-D images. This body of work seeks to address the aforementioned limitations. First, to facilitate the research program, a flexible architecture for prototyping volume illustration methods is pro- posed. This program unifies a number of existing techniques into a single framework based on 3-D texture mapping, while also providing for the rapid experimentation of novel methods. Next, the prototyping environment is employed to improve an existing method&#8212;called tagged volume rendering &#8212; which restricts transfer functions to given spatial regions using a number of binary segmentations (tags). An efficient method for implementing binary tagged volume rendering is presented, along with various technical considerations for improving the classifi- cation. Finally, the concept of greyscale tags is proposed, leading to a number of novel volume visualisation techniques including position modulated classification and dynamic exploration. The novel methods proposed in this work are generic and can be employed to solve a wide range of problems. However, to demonstrate their usefulness, they are applied to a specific case study. Ischaemic heart disease, caused by narrowed coronary arteries, is a leading healthconcern in many countries including Australia. Computed tomography angiography (CTA) is an imaging modality which has the potential to allow clinicians to visualise diseased coronary arteries in their natural 3-D environment. To apply tagged volume rendering for this case study, an active contour method and minimal path extraction technique are proposed to segment the heart and arteries respectively. The resultant images provide new insight and possibilities for diagnosing and treating ischaemic heart disease.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">visualisation, volume illustration, direct volume rendering, tagged volume rendering, tex- ture mapping, fragment shader, fast marching, minimal path extraction, image processing, ischaemic heart disease, coronary arteries, stenosis, cardiology</field><field name="identifier">http://eprints.qut.edu.au/17028/</field><field name="validLink">True</field></doc><doc><field name="title">Towards the development of transgenic banana bunchy top virus (BBTV)-resistant banana plants : interference with replication</field><field name="creator">Tsao, Theresa Tsun-Hui</field><field name="description">Banana bunchy top virus (BBTV) causes one of the most devastating diseases of banana. Transgenic virus resistance is now considered one of the most promising strategies to control BBTV. Pathogen-derived resistance (PDR) strategies have been applied successfully to generate plants that are resistant to numerous different viruses, primarily against those viruses with RNA genomes. BBTV is a circular, single-stranded (css) DNA virus of the family Nanoviridae, which is closely related to the family Geminiviridae. Although there are some successful examples of PDR against geminiviruses, PDR against the nanoviruses has not been reported. Therefore, the aim of this thesis was to investigate the potential of BBTV genes to interfere with virus replication when used as transgenes for engineering banana plants resistance to BBTV. The replication initiation protein (Rep) of nanoviruses is the only viral protein essential for viral replication and represents an ideal target for PDR. Therefore, this thesis focused on the effect of wild-type or mutated Rep genes from BBTV satellite DNAs or the BBTV integral genome on the replication of BBTV in banana embryogenic cell suspensions.  
 A new Rep-encoding satellite DNA, designated BBTV DNA-S4, was isolated from a Vietnamese BBTV isolate and characterised. When the effect of DNA-S4 on the replication of BBTV was examined, it was found that DNA-S4 enhanced the replication of BBTV. When the replicative capabilities of DNA-S4 and the previously characterised Rep-encoding BBTV satellite, DNA-S1, were compared, it was found that the amount of DNA-S4 accumulated to higher levels than DNA-S1. The interaction between BBTV and DNA-S1 was also examined. It was found that over-expression of the Rep encoded by DNA-S1 using ubi1 maize polyubiquitin promoter enhanced replication of BBTV. However, when the Rep-encoded by DNA-S1 was expressed by the native S1 promoter (in plasmid pBT1.1-S1), it suppressed the replication of BBTV. Based on this result, the use of DNA-S1 as a possible transgene to generate PDR against BBTV was investigated. 
 The roles of the Rep-encoding and U5 genes of BBTV DNA-R, and the effects of over-expression of these two genes on BBTV replication were also investigated. Three mutants of BBTV DNA-R were constructed; plasmid pUbi-RepOnly-nos contained the ubi1 promoter driving Rep expression from DNA-R, plasmid pUbi-IntOnly-nos contained the ubi1 promoter driving expression of the DNA-R internal gene product (U5), while plasmid pUbi-R.ORF-nos contained the ubi1 promoter driving the expression of both Rep and the internal U5 gene product. The replication of BBTV was found to be significantly suppressed by pUbi-RepOnly-nos, weakly suppressed by pUbi-IntOnly-nos, but strongly enhanced by pUbi-R.ORF-nos.
 The effect of mutations in three conserved residues within the BBTV Rep on BBTV replication was also assessed. These mutations were all made in the regions in the ATPase motifs and resulted in changes from hydrophilic to hydrophobic residues (i.e. K187&#8594;M, D224&#8594;I and N268&#8594;L). None of these Rep mutants was able to initiate BBTV replication. However, over-expression of Reps containing the K187&#8594;M or N268&#8594;L mutations significantly suppressed the replication of BBTV.
 In summary, the Rep constructs that significantly suppressed replication of DNA-R and -C in banana embryogenic cell suspensions have the potential to confer resistance against BBTV by interfering with virus replication. It may be concluded that BBTV satellite DNAs are not ideal for conferring PDR because they did not suppress BBTV replication consistently. Wild-type Rep transcripts and mutated (i.e. K187&#8594;M and N248&#8594;L) Rep proteins of BBTV DNA-R, however, when over-expressed by a strong promoter, are all promising candidates for generating BBTV-resistant banana plants.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">banana bunchy top virus, nanoviruses, replication initiation protein (Rep), pathogen-derived resistance, BBTV DNA-R, BBTV DNA-S1, BBTV DNA-S3, BBTV DNA-S4, satellite DNA, ATPase, post-transcriptional gene silencing, RNA silencing suppressor</field><field name="identifier">http://eprints.qut.edu.au/17031/</field><field name="validLink">True</field></doc><doc><field name="title">The 'Lad Lit' dilemma : institutional influences on creative writing practice</field><field name="creator">Martin, Samuel James Louis</field><field name="description">This thesis consists of a novel, eighteenth, and an exegesis, The &#8216;Lad Lit&#8217; Dilemma: Institutional influences on creative writing practice. It will address my research question; how did institutional factors surrounding the publishing category of Lad Lit influence my creative practice in drafting and re-drafting the novel eighteenth?
 
 eighteenth is the story of Will Swift, a seventeen year-old Brisbane university student. Will is part of a close group of friends from high school. When he falls for Kate, family friend of his mate Simon, his first semester of study becomes more complicated than he might have expected. Will&#8217;s movement through these issues and character development is represented symbolically through four eighteenth birthday parties. The project&#8217;s exegesis then analyses the changing nature of the publishing industry in the last twenty years, and the implications of these changes for creative writers. 
 
 Together, the two elements of this practice-led research will articulate the shift in the balance between the cultural and commercial imperatives of publishers, explain the impact of this shift for the publishing category of Lad Lit, and explore the ramifications of this for creative writing practitioners.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Lad Lit, lad literature, Ladlit, publishing industry, globalization, creative writing, creative writing practice, Nick Hornby, self-reflexive practice, practice-led research</field><field name="identifier">http://eprints.qut.edu.au/17032/</field><field name="validLink">True</field></doc><doc><field name="title">Revealing the nature of interaction between designers and physical and virtual artifacts to support design reflection and discovery</field><field name="creator">Bucolo, Salvatore</field><field name="description">This thesis aims at developing a better understanding of the design process and the tools required to support it. Specifically it focuses on the early or conceptual stages of the industrial design process and the role of emerging technology based artifacts in supporting this activity. The starting point for this thesis is that industrial design focuses on discovery of new knowledge and that this process of discovery is reflective in nature. Further designers make use of artifacts throughout the design process to support them in this discovery and their reflection. To reveal the role of artifacts in this process, a study of the interaction between designers and their artifacts has been undertaken. To intensify these relationships this thesis has focused on design review activity undertaken in the early stages of industrial design process. Two ethnographic case studies were conducted which allowed for teams of final year industrial design students to be observed during a conceptual design review. The first case study focused on the student designers interacting with traditional artifacts such as sketches, form studies and illustrations as part of the design review session. In the second case study, the student designers made use of low fidelity digital models which were displayed in a highly immersive virtual reality environment to support the design review. Both case studies captured a time slice of a larger design project which the students were undertaking as part of their university studies. The design project focused on the redesign of a consumer product where the students were required to innovate on an existing design based on a number of technology and market constraints. The design review session which formed the basis of the case study was part of a weekly design critique which required the students to bring to the class all of their design development progress. Students were offered an additional review session which was held in a virtual reality facility to supplement their weekly design review session which formed the basis of the second case study. The objective of the review sessions were for the designers to discuss their progress, identify where they were having difficulty, be challenged on design decision and develop a shared understanding of their direction with the class. The case study approach has allowed for an authentic in situ account of how designers make use of artifacts within the early stages of an industrial design process. It has allowed for a comparison between traditional and technology based artifacts and has revealed how they impact on the nature of discovery and reflection. Through a detailed qualitative analysis of the video data which was captured from the case studies, this thesis makes a number of substantial contributions to the current knowledge gaps on the role of artifacts and to our understanding of this phase of design activity. It substantiates conceptual design activity as a reflective process allowing for new discoveries to be made by representing our existing knowledge and understandings in artifacts which can be reflected upon and extended to create new meaning and innovation. From this grounded perspective it has enabled further understandings into the role of the artifact in supporting the design activity. Artifacts are seen as critical in supporting early stage design activity. However it is the nature of the interaction between the designers and their artifacts within the different settings which have been revealed through this research which is of significance. The affordances of the different artifacts have been shown to alter how the students situate their activity and modify their actions within a design review. page 5 of 171 Further designers are required to make use of additional resources such as gestures and rich design language to supplement their design engagement; and they are required to adapt to the environment where the review is being undertaken to ensure that the objective of the design review can be achieved. This thesis makes its primary contribution in outlining the differences between the various types of artifacts and how they can be used to positively support early stage design activity. It is recommended that both traditional and virtual artifacts have a role in supporting activity, but future approaches should consider them as complimentary and consider ways in which they can be merged. The significance of the research is three fold. Firstly, from a pedagogical perspective, within an educational or practiced based setting, it provides a framework to consider the use of emerging technology based artifacts to support early stage design activity. Secondly, from a technology development perspective the grounded observation in authentic experience of design activity, it provides the foundation to inspire and develop new interfaces to support designer interactions with artifacts. Finally, it makes a substantial contribution to the growing body of design research substantiating and revealing new understanding between designers and their artifacts to support early stage design activity.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">design artifacts, design process, conceptual design, virtual reality, interaction design, design research</field><field name="identifier">http://eprints.qut.edu.au/17035/</field><field name="validLink">True</field></doc><doc><field name="title">Vibrational spectroscopic investigation of polymer melt processing</field><field name="creator">Moghaddam, Lalehvash</field><field name="description">A polymer is rarely used as a pure material and the baseline physical, chemical and rheological properties such as molecular weight, strength, stiffness and viscosity are often modified by the addition of fillers or by blending with another polymer. However, as many polymers are immiscible, compatibilisation and graft processing polymer blends are very important techniques to increase miscibility of the blends as well as to improve chemical, physical and mechanical properties.
 
 Reactive extrusion, or melt-state processing, is one of the most appropriate techniques for improving polymer properties. Compatibilisation and graft polymer processing are often carried out under reactive extrusion conditions. This technique is an efficient approach because it is easy, inexpensive and has a short processing time. Although reactive extrusion has numerous advantages one of the limitations is degradation of the polymer under the high temperatures and mechanical stresses encountered.
 
 In the polymer industry, because of increasing customer demand for improved product quality, optimising the polymerisation process by decreasing product costs and controlling the reaction during polymerisation has become more important. It can be said that any method used for monitoring the polymerisation process has to be fast, accurate and reliable. Both in-line and on-line methods may be involved in in-process monitoring. The primary information from in-process monitoring is used for identifying and understanding molecular structure and changes, optimising and improving process modelling and understanding whether the process is under control. This also involves considering whether the products have the required properties.
 
 This thesis describes research in a number of aspects of melt processing of polymers, including examination of extruded products, an in situ spectroscopic study of the reaction of MAH and PP, a study of the melt processing of TPU, and a study of the use of nitroxide radicals as probes for degradation reactions.
 
 As mentioned previously, a suitable method for improving polymer properties is polymer blending. Starch is a hydrophilic biodegradable polymer which may be blended with other polymers to produce biodegradable products. In spite of its benefits, it is immiscible with most synthetic polymers, such as polyesters. The main technique for improving the miscibility of starch with the other polymer is a grafting reaction. 
 
 The reactive extrusion technique was applied to the production of starch and polyester blends, the product of which was a biodegradable aliphatic polyester. In this process dicumyl peroxide (DCP) and maleic anhydride (MAH) were used as an initiator and cross-linker, respectively. Extruded samples were investigated by infrared microscopic mapping using the attenuated total reflectance (ATR) technique. Measurement of various band parameters from the spectra allowed IR maps to be constructed with semi-quantitative information about the distribution of blend components. IR maps were generated by measuring the band area ratio of O-H and C=O stretching bands which are related to starch and polyester, respectively. This was the first time this method has been used for understanding the homogeneity of a polymer blend system. This method successfully indicated that the polyester/starch blend was not a homogenised blend. It was concluded that to improve the homogeneity the reaction conditions should be modified.
 
 Another important compatibilisation reaction is the reaction between a polyolefin and MAH. This was investigated by combining a near infrared (NIR) spectrometer with a small laboratory scale extruder, a Haake Minilab. The NIR spectra were collected in situ during melt processing by the use of a fibre optic cable. In addition to this the viscosity of the polymer melt was measured continuously during processing through two pressure transducers within the Minilab extruder. The vinyl C-H stretch overtone of the MAH was clearly seen in the NIR spectra near 6100 cm-1 and diminished over time as the MAH reacted with PP. The spectra obtained were analysed by two techniques: principal component analysis (PCA); and peak area ratios. The peak area ratios were calculated using the =C-H first overtone of MAH with respect to the band observed between 6600 and 7400 cm-1. This band corresponds to a combination band of CH2 and CH3 in PP and was unchanged during the reaction. These data facilitated interpretation of the reaction kinetics and experiments at different temperatures allowed determination of the activation energy of the reaction. These results have thrown new light on the PP-MAH reaction mechanism. It was also shown that although the presence of DCP causes production of a high concentration of macro-radicals it does not have any effect on the rate and kinetics of the reaction. 
 
 As mentioned previously, one of the limitations of reactive extrusion is degradation of the polymer under high temperatures and shear rates. Hindered amine stabilisers (HAS) are often used as inhibitors to control the thermal-oxidative degradation of polymers. They are used in various polymeric materials but were primarily developed for polyolefins, particularly PP. The stabilisation mechanism of HAS involves interaction firstly with the alkyl peroxyl radicals produced during oxidative degradation so that the hindered amine converts to the corresponding nitroxide. The nitroxide is then able to capture a carbon-centred radical and so retard the subsequent degradation chain reaction.
 
 1,1,3,3- tetramethyldibenzo[e,g]isoindoline-2-yloxyl (TMDBIO) was used as a probe for investigation of PP during reactive extrusion conditions. The TMDBIO is a profluorescent compound that has been used previously to identify polymer degradation. In the radical form, there is no fluorescence since the unpaired spin on the nitroxide quenches the fluorescence of the phenanthrene moiety. When the radical is removed (by radical trapping or reduction) fluorescence is observed. As a result, the location and intensity of fluorescence can be used as a probe for identification of degradation and to determine the concentration of carbon-centred radicals produced during thermal or mechanical degradation such as occurs during reaction processing. This novel method shows that, the degradation of PP started at the early stage of processing. Also this method can be used as a useful technique to modify the processing conditions to decrease degradation of the polymer during processing.  
 
 The second system investigated using in situ monitoring via the NIR fibre optic was the melt processing of a TPU nano-composite. This was the first time that the in situ monitoring of TPU nano-composite had been examined. In this investigation the effect of temperature during processing on the TPU molecular structure and rheological behaviour was again investigated. In addition, dispersion of clay nano-particles through the TPU matrix and rheological changes due to this was investigated. This investigation was successful in that it was found that several factors affected the viscosity of the nano-composite. However, to fully understand the degradation mechanism and viscosity changes further studies must be performed.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">vibrational spectroscopy, polymer melt processing</field><field name="identifier">http://eprints.qut.edu.au/17044/</field><field name="validLink">True</field></doc><doc><field name="title">Teachers' understandings of pedagogic connectedness</field><field name="creator">Beutel, Denise Ann</field><field name="description">This thesis explores the nature of pedagogic connectedness and reveals the qualitatively different ways in which teachers in the middle years of schooling experience this phenomenon. The researcher defines pedagogic connectedness as the engagements between teacher and student that impact on student learning. The findings of this phenomenographic-related study are used to provide a framework for changes to pedagogic practices in the middle years of schooling. 
 
 Twenty teachers of years 7, 8, and 9 boys in an independent college in South-East Queensland participated in this study. Data were obtained through semi-structured interviews with these teachers and the interview transcripts were analysed iteratively. Five qualitatively different ways of experiencing pedagogic connectedness emerged from this study. These categories of description are linked hierarchically and are delimited from each other through six common dimensions of variation.  
 
 Teachers&#8217; conceptions of pedagogic connectedness range from information providing through instructing, facilitating, guided participation to mentoring. The five different conceptions may be classified broadly as teacher-centred, transitional or student-centred. In the information providing conception, pedagogic connectedness between teachers and students is limited with teachers perceiving themselves as subject experts and providing few opportunities for student-teacher engagements. The most complex conception, mentoring, is characterised by partnerships between teachers and students in which teachers view themselves as more experienced equals. These partnerships extend beyond the confines of the classroom and beyond the years of schooling. In this conception, teachers describe teaching as an emotional activity with teachers demonstrating passion for teaching and learning. The findings of this current study extend earlier understandings of teacher-student mentoring relationships in the middle years of schooling. These expanded understandings may contribute to enthusing middle years students and re-engaging them with schooling during these vital years.</field><field name="date">0000</field><field name="language" /><field name="relation" /><field name="subject">pedagogic connectedness</field><field name="subject">teacher-student relatioinship</field><field name="subject">pedagogy</field><field name="subject">teacher-student interaction</field><field name="identifier">http://eprints.qut.edu.au/17082/</field><field name="validLink">True</field></doc><doc><field name="title">Characterization of bone marrow stromal clonal populations derived from osteoarthritis patients</field><field name="creator">Mareddy, Shobha R.</field><field name="description">This work is concerned with the characterization of mesenchymal stem cells (MSC) specifically from bone marrow samples derived from patients with osteoarthritis (OA). The multilineage potential of mesenchymal stem cells as well as their ease of exvivo expansion makes these cells an attractive therapeutic tool for applications such as autologous transplantation and tissue engineering. Bone marrow is considered a source of MSC. However, there is a general assumption that the occurrence of MSCs and their activity in bone marrow diminishes with age and disease. This prompted us to isolate and identify multipotential and self-renewing cells from patients with the degenerative disease osteoarthritis, with the view of using these cells for autologous cell therapies. It is therefore of great potential benefit to investigate the isolation and characterization of stem cell/progenitors from bone marrow samples of patients with osteoarthritis in greater detail. We employed a single cell clone culture method in order to develop clonal cell populations from three bone marrow samples and characterized them based on their proliferation and differentiation capabilities. The clonal populations were grouped into fast-growing and slow-growing clones based on their proliferation rates. The fastgrowing clones displayed 20-30% greater proliferation rate than the slow-growing clones. The study also revealed that the proliferation rates were directly proportional to their differentiation capacities. Most of the fast-growing clones were found to be tripotential for osteogenic, chondrogenic and adipogenic lineages, whereas the slow growing clones were either uni or bipotential. Flow cytometry analysis for the phenotype determination using putative MSC surface markers did not reveal any difference between the two clonal populations indicating a need for further molecular studies. Two approaches were employed to further investigate the molecular processes involved in the existence of such varying populations. In the first method gene expression studies were performed between the fast-growing (n=3) and slow-growing (n=3) clonal populations to identify potential genetic markers associated with cell 'sternness' using the Stem Cell RT2 ProfilerTM PCR Array comprising a series of 84 genes related to stem cell pathways. Ten genes were identified to be commonly and significantly over represented in the fast-growing stem cell clones when compared to slow-growing clones. This included expression of transcripts beyond MSC lineage specification such as SOX2, NOTCH1 and FOXA2 which signified that stem cell maintenance requires a coordinated regulation by multiple signalling pathways. The second study involved an extensive protein expression profiling of the fast growing (n=2) and slow growing (n=2) clonal populations using off-line Two Dimensional Liquid Chromatography (2D-LC)/Matrix-Assisted Laser Desorption/Ionization (MALDI) Mass Spectrometry (MS). A total of 67 proteins were identified, of which 11 were expressed at significantly different levels between the subpopulations. Protein ontology revealed these proteins to be associated with cellular organization, cytokinesis, signal transduction, energy pathways and cell stress response. Of particular interest was the differential presentation of the proteins calmodulin, tropomyosin and caldesmon between fast- and slow-growing clones. Based on their reported roles in the regulation of cell proliferation and maintenance of cell integrity, we draw an association between their expression and the altered status in which the subpopulations exist. Based on our observations, these proteins may be prospective molecular markers to distinguish between the fast-growing and slow-growing subpopulations. In summary, this study demonstrated the existence of potential stem cells of therapeutic importance in spite of a supposedly smaller stem cell compartment in patients with osteoarthritis. Furthermore, the differentially expressed genes between the sub-populations highlight the 'sternness' of the potential clones, an observation supported by the expression of proteins which act as effective modulators in the maintenance of cell integrity and cell cycle regulation. This study provides a basis for more detailed investigations in search of selective cell surface markers</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">osteoarthritis, cell based therapy, bone marrow stromal cells, mesenchymal stem cells,.clone culture, clonal population, osteoblast, chondrocyte, adipocyte, progenitor, precursor, differentiation, population doubling, autologous, tissue engineering</field><field name="subject">flow cytometry, gene expression, proteomics, biomarker</field><field name="identifier">http://eprints.qut.edu.au/17151/</field><field name="validLink">True</field></doc><doc><field name="title">A biomechanical study of top screw pullout in anterior scoliosis correction constructs</field><field name="creator">Mayo, Andrew</field><field name="description">Top screw pullout is a significant problem in anterior scoliosis correction, with rates of 5-15% reported in the literature. The Mater Misericordiae Hospital in Brisbane currently has a series of 125 patients with scoliosis treated by thoracoscopic anterior fusion, instrumentation and correction between April 2000 and August 2007. In this series 11 top screws are known to have pulled out (a rate of 8.8%), with six occurring in the first week, and all within 6 weeks, suggesting that the problem is one of excessive static force rather than fatigue.
 
 This thesis describes a biomechanical investigation into the mechanics of vertebral body screw pullout in anterior scoliosis surgical constructs. Previous biomechanical studies of vertebral body screws have evaluated their resistance to either straight pullout or cephalo-caudad compression forces, however the aim of this study was to assess screw resistance to more realistic loading conditions, namely pullout of initially angled screws, and pullout where the motion path is an arc rather than a straight axial pullout, as would be expected in a single rod anterior construct.
 
 The first series of experiments involved straight and angled pullout tests using synthetic bone. In the angled tests, both locked and free-to-pivot configurations were tested. The second series of experiments tested the effect of cephalo-caudad pre-compression (the actual deformity correction step performed during surgery) on subsequent axial pullout strength. A third series of experiments performed arc pullouts using synthetic bone, and the final series of experiments tested the pullout resistance of a newly proposed screw position configuration against the standard screw positioning using ovine lumbar vertebrae.  
 
 Synthetic bone testing revealed that for initially angled pullout, resistance is greatest as the screw angle approaches 0&#61616; (ie a direct axial pullout). Cephalo-caudad pre-compression reduced subsequent pullout strength for cases where a staple was not used under the screw head, but if a staple was used the pre-compression did not decrease pullout force significantly. Arc pullout resistance was greatest when the screw was angled at 10&#61616; cephalad, and the mean pullout strength for the proposed screw configuration using ovine lumbar vertebrae (1864N) was almost double that of the standard screw positioning (993N). 	
 
 The clinical implication of this study is that top screw pullout resistance can be maximised by placing the top screw as close as possible to the top endplate and the bottom screw as close as possible to the bottom endplate, although this will have detrimental effects on the pullout of the second screw should the top screw pull out. Screw angulation is a less important factor but any angulation should be in a cephalad direction and around 10&#186; in magnitude. The experimental results also suggest that the use of a staple may play a role in preventing cephalo-caudad pre-compression forces from reducing screw resistance to subsequent pullout forces.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">anterior scoliosis surgery, biomechanics, bone density, bone mechanics, cancellous bone, ovine vertebra, synthetic bone, screw pullout, single rod endoscopic scoliosis correction</field><field name="subject">spine biomechanics, trabecular bone, vertebral body screw</field><field name="identifier">http://eprints.qut.edu.au/17152/</field><field name="validLink">True</field></doc><doc><field name="title">A case study of intercultural communication in a multicultural classroom in the Brisbane metropolitan area</field><field name="creator">Ko, Min-Jeong</field><field name="description">The current global and local issues of culture such as September 11, the Bali Bombings and the &#8220;Cronulla Riots&#8221; triggered a question for the researcher: &#8220;how do primary students deal with intercultural communication in multicultural Australia in times of cultural uncertainty and complexity?&#8221;  Intercultural communication studies in Australia rely heavily on those of the United States of America and the United Kingdom.  For this reason, this study was planned to investigate intercultural communication in a multicultural classroom in a primary school in Australia.       
  
 The research employs an ethnographical case study methodology with data collected from observation, interview and documentation.  56 Year 7 students and two classroom teachers from two classes and the school ESL (English as a Second Language) teacher were included in the study.  Amongst the 56 students, 24 students were interviewed along with the classroom teachers and the ESL teacher.  School documents regarding the promotion of intercultural communication were also collected during the observation period.
 
 The study found that differing language capacities of students and teachers have the greatest influence on intercultural communication.  Language was observed to influence positive and negative intercultural communication in the classroom.  The study also confirmed that the theory of Intercultural Communication Competence (Wiseman, 2002) supports the current ethos of this school&#8217;s curriculum.  
 
 Overall, the study provides a vicarious experience of intercultural communication in an Australian multicultural classroom.  Intercultural communication in this particular school did not appear to be problematic.  This could be due to the teachers&#8217; endeavours to promote intercultural communication both implicitly and explicitly.  In concluding, the study suggests that this school could be a model for promoting intercultural communication with a few modifications to its programs.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">intercultural communication, multicultural classroom, multiculturalism, promoting intercultural communication</field><field name="identifier">http://eprints.qut.edu.au/17806/</field><field name="validLink">True</field></doc><doc><field name="title">The determinants of the governance of air conditioning maintenance in Australian retail centres</field><field name="creator">Bridge, Adrian J.</field><field name="description">Retail centres are a visible sign of developed capitalist societies and make an appreciable contribution to these economies. For the firms involved in supplying air conditioning maintenance to retail centres, governance structures (that incorporate the make-or-buy decision and the decision concerning the nature of the exchange relationship) are fundamental business decisions. The absence of literature in this area creates a research opportunity to undertake a theoretical and empirical investigation into the determinants of the governance of air conditioning maintenance in Australian retail centres. The research objectives revolve around a microeconomic theory (Transaction Cost Economics) and two related theories &#8211; one from strategic management (Resource-Based Theory) and one from a power-based perspective (Resource Dependency Theory).
 
 In terms of the make-or-buy decision, an integrative framework of vertical integration is developed that aims to create a clearer understanding of the conditions under which Transaction Cost Economics (TCE) and Resource-Based Theory (RBT) are dominant. This approach is encouraged by the similarity of the assumptions made in TCE and RBT concerning rationality and which envisage a short term approach to profits. If a wider view is taken, that includes supply chains in which firms take a longer term approach to profits, then Resource Dependency Theory (RDT) can also be considered as a complementary theory to TCE. In order to test TCE on the issue of the nature of the exchange relationship, TCE's contractual schema is developed, along with a new type of asset specificity (Ongoing Asset Specificity).
 
 Case studies and a nationwide postal survey are used to collect data from multiple sources, comprising 51 interviews, the collection of documentary information, as well as 18 completed case study questionnaires and 205 useable survey questionnaires. Multiple research methods allow the relative strengths of different methods to be combined to more effectively test the hypotheses. Pattern matching and regression analysis are the main techniques used to analyse the data.
 
 The results provide a successful testing of the integrative framework of vertical integration. That is, this framework is shown to be more powerful in accounting for the make-or-buy decisions in the supply chains in this thesis, than the singular deployment of either TCE or RBT. With regard to the nature of the exchange relationship decision, the results also support the development of TCE's contractual schema and Ongoing Asset Specificity. Through the incorporation of these developments, TCE outperforms RDT across all of the internal and external exchanges in the supply chains in this thesis. In total, it is concluded that transaction costs and production costs can both be key determinants of the governance of air conditioning maintenance in the chain that supplies this activity to Australian retail centres. Moreover, and in this chain, upstream exchange relationships are not determined by downstream external exchange relationships.
 
 The implications of the results for practice - in more mainstream construction, and concerning the make-or-buy decision, particularly concern trades in close physical and intellectual proximity to the main contractor&#8217;s key activity of planning and coordinating site activity. Here, the results indicate that main contractors would benefit from focusing on the possibility of hold-up and not production cost improvements. With respect to external relationships, the results show that even when clients have an ongoing requirement for an activity, a discrete exchange can be both economical and effective. This suggests that calls by some government sponsored reports for all clients buying services from main contractors to seek a relational exchange are not justified. In terms of the firm's internal relationships and upstream external relationships, the evidence from this thesis is that these relationships should not necessarily be determined by the firm&#8217;s downstream external relationships. Here, for example, main contractors might not allow their exchanges with their staff and subcontractors to be determined by exchanges with their clients.
 
 More specifically, this thesis suggests that main contractors can prosper from developing relational exchanges with their staff, core subcontractors and suppliers despite engaging in discrete and arms-length exchanges with their clients. This finding may encourage main contractors to help move mainstream construction away from any "command and control" image.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">030600 PHYSICAL CHEMISTRY (INCL. STRUCTURAL)</field><field name="subject">transaction costs</field><field name="subject">capability and competence</field><field name="subject">power and dependency</field><field name="subject">air conditioning maintenance</field><field name="subject">retail centres</field><field name="identifier">http://eprints.qut.edu.au/17214/</field><field name="validLink">True</field></doc><doc><field name="title">My private pectus : the construction of masculinities in Australian young adult fiction</field><field name="creator">Thamm, Shane Peter</field><field name="description">In recent decades, male protagonists in Australian realist fiction for young adult readers have increasingly become more others-regarding, emotionally intelligent, and self-aware. (John Stephens 2000; Perry Nodelman 2002). Psychologist Roger Horrocks (1995) claims these protagonists are less &#8220;tendentious and more realistic&#8221; than male protagonists of the past. These boys, despite not bearing the hallmarks of hegemonic masculinity, develop subjective agency and ultimately propose new ways for young men to construct their gender identity.
 
 Using Phillip Gwynne&#8217;s (1998) Deadly Unna? and David Metzenthen&#8217;s (2000) Boys of Blood and Bone as case studies, and my own novel My Private Pectus as creative practice, I explore the construction and deconstruction of hegemonic, complicit, and alternative masculinities in Australian realist young adult fiction. I also analyse the construction of the New Age Boy&#8212;a label used by John Stephens for young male protagonists who develop positive self esteem because of their perceived gender differences compared to boys of the hegemonic masculine type.
 
 By critiquing the manner in which masculinities are constructed in each case study, and supporting my critique through the literature of leading gender theorists, I question the seemingly homogenous manner in which the New Age Boy gains agency.
 
 This question is further explored through my creative practice, as I put into dialogue a protagonist who also recognises his gender differences, but instead of proposing a new and better masculinity, he tries to adhere to and reap the rewards of hegemonic masculinity.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">young adult fiction, masculinities, complicit masculinity, hegemonic masculinity, gender, new age boy, alternative masculinity, men, boys, narrative, subjective agency</field><field name="identifier">http://eprints.qut.edu.au/17221/</field><field name="validLink">True</field></doc><doc><field name="title">The analysis of unfired propellant particles by gas chromatography - mass spectrometry : a forensic approach</field><field name="creator">Croft, Shiona Andrea</field><field name="description">In Australia, the 0.22 calibre ammunition is the most encountered ammunition type found at a crime scene [1]. Previous analysis of gun shot residue (GSR) and unfired propellant has involved studying the inorganic constituents by Scanning Electron Microscopy or similar technique. However, due to the heavy metal build up that comes with some ammunition types, manufacturing companies are now making propellant that is safer to use. Therefore, it has become appropriate to study and analyse unfired propellant by other means. One such technique is unfired propellant analysis by gas chromatography &#8211; mass spectrometry (GC-MS). This technique focuses on the organic constituent make up of the propellant paying particular attention to diphenylamine, ethyl centralite and dibutyl phthalate. It was proposed that different batches of ammunition could be discriminated or matched to each other by using this technique. However, since the main constituents of unfired propellant are highly reactive, it was not possible to accomplish batch determination of ammunition. However, by improving extraction techniques and by removing oxygen (a catalyst for the degradation of diphenylamine) a superior method was established to help in the analysis of unfired propellant. Furthermore, it was shown that whilst differentiating batches of the same ammunition was not possible, the improved methods have helped identify different types of the same brand of ammunition. With the aid of future studies to fully explore this avenue, the analysis of unfired propellant could one day become an integral part of forensic science.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">unfired propellant particles, gas chromatography, forensic approach</field><field name="identifier">http://eprints.qut.edu.au/17251/</field><field name="validLink">True</field></doc><doc><field name="title">Automated spatial information retrieval and visualisation of spatial data</field><field name="creator">Walker, Arron R.</field><field name="description">An increasing amount of freely available Geographic Information System (GIS) data
 on the Internet has stimulated recent research into Spatial Information Retrieval (SIR).
 Typically, SIR looks at the problem of retrieving spatial data on a dataset by dataset
 basis. However in practice, GIS datasets are generally not analysed in isolation. More
 often than not multiple datasets are required to create a map for a particular analysis
 task. To do this using the current SIR techniques, each dataset is retrieved one by one
 using traditional retrieval methods and manually added to the map. To automate map
 creation the traditional SIR paradigm of matching a query to a single dataset type
 must be extended to include discovering relationships between different dataset types.
 This thesis presents a Bayesian inference retrieval framework that will incorporate
 expert knowledge in order to retrieve all relevant datasets and automatically create a
 map given an initial user query. The framework consists of a Bayesian network that
 utilises causal relationships between GIS datasets. A series of Bayesian learning
 algorithms are presented that automatically discover these causal linkages from
 historic expert knowledge about GIS datasets. This new retrieval model improves
 support for complex and vague queries through the discovered dataset relationships.
 In addition, the framework will learn which datasets are best suited for particular
 query input through feedback supplied by the user.
 This thesis evaluates the new Bayesian Framework for SIR. This was achieved by
 utilising a test set of queries and responses and measuring the performance of the
 respective new algorithms against conventional algorithms. This contribution will
 increase the performance and efficiency of knowledge extraction from GIS by
 allowing users to focus on interpreting data, instead of focusing on finding which data
 is relevant to their analysis. In addition, they will allow GIS to reach non-technical
 people.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Visualisation of Spatial Data, automated Spatial Information Retrieval</field><field name="identifier">http://eprints.qut.edu.au/17258/</field><field name="validLink">True</field></doc><doc><field name="title">Making intercultural dance in Vietnam : issues of context and process from the perspective of an Australian choreographer and her colleagues from Vietnam Opera Ballet Theatre (Nh&#224; H&#225;t Nh&#7841;c Vu&#771; Ki&#803;ch Vi&#234;&#803;t Nam) 1995-1999</field><field name="creator">Stock, Cheryl F.</field><field name="description">This thesis explores the creative processes of intercultural performance in an Asian context, through projects undertaken with Vietnam Opera Ballet Theatre, the national dance company in Hanoi. Background research to the study has enabled previously elusive research areas to be made available to English-language scholars and artists - namely, contemporary preservation of Vietnamese dance traditions and professional practice of Vietnamese dance in the &#273;&#244;&#777;i m&#417;&#769;i (open door policy) period. This contextual background highlights the importance of cultural specificity in intercultural performance practice, revealing insights into how and why artistic and aesthetic sensibilities shift when choreographic processes are transferred from an Australian to a Vietnamese setting. The study began with a premise of intercultural performance practice as an equitable sharing of ideas and has ended with the experience of intercultural collaboration as a transforming process, involving cultural translation to and by the local context - in this study through a process of Vietnamisation. Transformations are seen to occur via alteration of professional practices and the metamorphosis of meaning, metaphor and myth, providing substantially new readings of the original ideas. Importantly, the study points to the body as the central site of cultural difference, cultural commonalities and complex intercultural sensibilities. A dual methodology for the research combined artistic practice with theoretical reflection, resulting in a polyphonic text of written, visual and kinetic data. From the extant practice of the researcher/choreographer, a model of intercultural performance was devised which was refined as the two research projects of the pilot and case studies progressed. Reflective analysis of the model was undertaken through the framework of intercultural performance theories, parallel to the artistic practice. Throughout the research process, privileging the voices and bodies of the Vietnamese artists in both their practice and their perceptions of that practice have been fundamental to the outcomes of the study. This is the first in-depth study of contemporary professional dance practice in Vietnam and of intercultural performance practice between Australia and Vietnam.</field><field name="date">1999</field><field name="language" /><field name="relation" /><field name="subject">artistic practice, body encoding, collaboration, creative process, dance, &#273;&#244;&#777;i m&#417;&#769;i, intercultural performance, tradition, Vietnam, Vietnamisation</field><field name="identifier">http://eprints.qut.edu.au/17527/</field><field name="validLink">True</field></doc><doc><field name="title">Vision, functional and cognitive determinants of motor vehicle incidents in older drivers</field><field name="creator">Stavrou, Eftyhia P.</field><field name="description">Background: The proportion of older individuals in the driving population is predicted to increase in the next 50 years.  This has important implications for driving safety as abilities which are important for safe driving, such as vision (which accounts for the majority of the sensory input required for driving), processing ability and cognition have been shown to decline with age.  The current methods employed for screening older drivers upon re-licensure are also vision based.  This study, which investigated social, behavioural and professional aspects involved with older drivers, aimed to determine: 
 (i)	if the current visual standards in place for testing upon re-licensure are effective in reducing the older driver fatality rate in Australia; 
 (ii)	if the recommended visual standards are actually implemented as part of the testing procedures by Australian optometrists; and
 (iii)	if there are other non-standardised tests which may be better at predicting the on-road incident-risk (including near misses and minor incidents) in older drivers than those tests recommended in the standards.
 
 Methods: For the first phase of the study, state-based age- and gender-stratified numbers of older driver fatalities for 2000-2003 were obtained from the Australian Transportation Safety Bureau database.  Poisson regression analyses of fatality rates were considered by renewal frequency and jurisdiction (as separate models), adjusting for possible confounding variables of age, gender and year.  
 
 For the second phase, all practising optometrists in Australia were surveyed on the vision tests they conduct in consultations relating to driving and their knowledge of vision requirements for older drivers. 
 
 Finally, for the third phase of the study to investigate determinants of on-road incident risk, a stratified random sample of 600 Brisbane residents aged 60 years and were selected and invited to participate using an introductory letter explaining the project requirements.  In order to capture the number and type of road incidents which occurred for each participant over 12 months (including near misses and minor incidents), an important component of the prospective research study was the development and validation of a driving diary.  The diary was a tool in which incidents that occurred could be logged at that time (or very close in time to which they occurred) and thus, in comparison with relying on participant memory over time, recall bias of incident occurrence was minimised.  Association between all visual tests, cognition and scores obtained for non-standard functional tests with retrospective and prospective incident occurrence was investigated.
 
 
 Results: In the first phase,rivers aged 60-69 years had a 33% lower fatality risk (Rate Ratio [RR] = 0.75, 95% CI 0.32-1.77) in states with vision testing upon re-licensure compared with states with no vision testing upon re-licensure, however, because the CIs are wide, crossing 1.00, this result should be regarded with caution.  However, overall fatality rates and fatality rates for those aged 70 years and older (RR=1.17, CI 0.64-2.13) did not differ between states with and without license renewal procedures, indicating no apparent benefit in vision testing legislation. 
 
 For the second phase of the study, nearly all optometrists measured visual acuity (VA) as part of a vision assessment for re-licensing, however, 20% of optometrists did not perform any visual field (VF) testing and only 20% routinely performed automated VF on older drivers, despite the standards for licensing advocating automated VF as part of the vision standard. This demonstrates the need for more effective communication between the policy makers and those responsible for carrying out the standards.  It may also indicate that the overall higher driver fatality rate in jurisdictions with vision testing requirements is resultant as the tests recommended by the standards are only partially being conducted by optometrists.  Hence a standardised protocol for the screening of older drivers for re-licensure across the nation must be established.
 
 The opinions of Australian optometrists with regard to the responsibility of reporting older drivers who fail to meet the licensing standards highlighted the conflict between maintaining patient confidentiality or upholding public safety.  Mandatory reporting requirements of those drivers who fail to reach the standards necessary for driving would minimise potential conflict between the patient and their practitioner, and help maintain patient trust and goodwill.  
 
 The final phase of the PhD program investigated the efficacy of vision, functional and cognitive tests to discriminate between at-risk and safe older drivers.  Nearly 80% of the participants experienced an incident of some form over the prospective 12 months, with the total incident rate being 4.65/10 000 km.  Sixty-three percent reported having a near miss and 28% had a minor incident.  
 The results from the prospective diary study indicate that the current vision screening tests (VA and VF) used for re-licensure do not accurately predict older drivers who are at increased odds of having an on-road incident.  However, the variation in visual measurements of the cohort was narrow, also affecting the results seen with the visual functon questionnaires.  Hence a larger cohort with greater variability should be considered for a future study.  A slightly lower cognitive level (as measured with the Mini-Mental State Examination [MMSE]) did show an association with incident involvement as did slower reaction time (RT), however the Useful-Field-of-View (UFOV)  provided the most compelling results of the study.  Cut-off values of UFOV processing (&gt;23.3ms), divided attention (&gt;113ms), selective attention (&gt;258ms) and overall score (moderate/ high/ very high risk) were effective in determining older drivers at increased odds of having any on-road incident and the occurrence of minor incidents. 
 
 Discussion: 
 The results have shown that for the 60-69 year age-group, there is a potential benefit in testing vision upon licence renewal.  However, overall fatality rates and fatality rates for those aged 70 years and older indicated no benefit in vision testing legislation and suggests a need for inclusion of screening tests which better predict on-road incidents.
 
 Although VA is routinely performed by Australian optometrists on older drivers renewing their licence, VF is not.  Therefore there is a need for a protocol to be developed and administered which would result in standardised methods conducted throughout the nation for the screening of older drivers upon re-licensure.  Communication between the community, policy makers and those conducting the protocol should be maximised.  By implementing a standardised screening protocol which incorporates a level of mandatory reporting by the practitioner, the ethical dilemma of breaching patient confidentiality would also be resolved.
 
 The tests which should be included in this screening protocol, however, cannot solely be ones which have been implemented in the past.  In this investigation, RT, MMSE and UFOV were shown to be better determinants of on-road incidents in older drivers than VA and VF, however, as previously mentioned, there was a lack of variability in visual status within the cohort.  Nevertheless, it is the recommendation from this investigation, that subject to appropriate sensitivity and specificity being demonstrated in the future using a cohort with wider variation in vision, functional performance and cognition, these tests of cognition and information processing should be added to the current protocol for the screening of older drivers which may be conducted at licensing centres across the nation.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">older drivers, incidents, near miss, driving diary, licensure, optometrists, mandatory reporting, fatality rates, vision, cognition, UFOV, reaction time, hazard perception, functional questionnaire</field><field name="identifier">http://eprints.qut.edu.au/28503/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis and reactions of organometallic porphyrins</field><field name="creator">Atefi, Farzad</field><field name="description">This thesis reports progress in three major aspects of &#963;-bonded organometallic porphyrins that are described in the published papers found in chapters 4, 5 and 6. meso-Iodoporphyrins, which were prepared in a rapid, selective and high yielding methodology from the respective &#61544;1-palladioporphyrins or bromoporphyrins, are important starting materials for further functionalisations of porphyrins. Their utility was confirmed in a palladium-catalysed coupling reaction and this novel synthetic strategy could potentially be applied for iodine/bromine exchange on other organic substrates..
 
 A &#61544;1-palladioporphyrin was also utilised to optimise the reaction conditions leading to the formation of porphyrinylphosphine oxides. This synthetic strategy simplified the challenging optimisation of the palladium-catalysed reaction and has great potential to be applied in other catalytic processes. Subsequently a suite of porphyrinylphosphine oxides was prepared under the optimised catalytic conditions. These macrocycles, which represent a new class of porphyrins, were isolated cleanly in very high yields. Detailed spectroscopic investigations as well as X-ray single crystal analysis demonstrated their structures unambiguously and established their potential as ligands for supramolecular chemistry. 
 
 The coordinating properties of phosphine oxides in general and porphyrinylphosphine oxides in particular, towards Mg(II) centred porphyrins were examined in further experiments. Triphenylphosphine oxide showed a strong affinity towards Mg(II) porphyrins and the calculated displacement constant of 5.3 &#215; 105 M-1 was two orders of magnitude larger than any other Mg(II) porphyrin-ligand binding constant reported thus far. Di- and triporphyrin arrays consisting of Mg(II) porphyrin coordinated to free base and Ni(II) porphyrinyl mono- and bis-phosphine oxides were also prepared in high yields. Spectroscopic studies indicated that these porphyrin oligomers exhibit strong inter-porphyrin electronic interaction.
 
 A Mg(II) porphyrinylphosphine oxide dimer was also isolated in a satisfactory yield. The large self-association constant of 5.5 &#215; 108 M-1 confirmed the strong affinity of porphyrinylphosphine oxides towards Mg(II) porphyrins and established these complexes as the first strongly bound synthetic Mg(II) porphyrin analogues of the "special pair" of the photosynthetic reaction centre.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">porphyrinoids, iodination, palladium, organometallic, crystal structure, ligand design, phosphine oxides, oligomers, special pair, photosynthesis</field><field name="identifier">http://eprints.qut.edu.au/17563/</field><field name="validLink">True</field></doc><doc><field name="title">The changing nature and the role of heads of department in Queensland public secondary schools</field><field name="creator">Rosenfeld, Peter</field><field name="description">In the last decade of the 20th century, organizational change in public service provision in Queensland impacted broadly upon the culture of public education. The focus of this thesis was to describe the effects of that change on the role of heads of department in public secondary schools. The approach taken was to examine those change effects, in the light of policy documents, and from the perspective of participants, that is heads of department and principals. The thesis also described the changing skills the emerging role appeared to demand and to draw implications for professional development. 
 The thesis is a descriptive multi case study. The principal and two heads of department from each of four public secondary schools in South East Queensland took part in the study. Data were collected through policy documents and semi structured interviews. The study employed Leonard-Barton's (1995) methodology which blended real time and a longitudinal study. To that end, two heads of department were reinterviewed four years after the initial interviews. Interviews focused upon the role, change, and the importance of leadership.  
 The research generated eight specific themes each of which was considered consistent with the nature of the role in a period of significant cultural change. These were the difference in perceptions regarding the head of department role, held by principals and heads of department; head of department leadership in terms of a curriculum framed department, or whole school leadership; how individuals perceived leadership, and how they learned of leadership; the impact of the changing culture upon the individual head of department; the growing influence of situational factors upon the role; the impact of managerialism; the changing nature of a secondary school department; and a growing and more complex workload, and the need for different skills. 
 The themes painted a picture of a long established role within a process of evolution. While broad cultural change underpinned change in the role, it was the change process, and the consequent structural and organizational change that individuals in the study focused upon. Consistent with the literature on heads of department and change, the study indicated a gap between the skills that the emerging role demanded, particularly leadership and management skills, and those skills which heads of department possessed. A need for a broad range professional development to bridge that gap was evident. The findings also pointed towards the need for effective change processes and a reconceptualized head of department role. 
 The study concluded with recommendations for future research. Particular focus was directed towards the nature and function of secondary school departments, and the consequent role of the heads of department. Potential exists for research that further explores the effect of cultural change upon individuals, particularly heads of department, in the area of public education.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Queensland public secondary schools, roles, heads of department</field><field name="identifier">http://eprints.qut.edu.au/17574/</field><field name="validLink">True</field></doc><doc><field name="title">Applications of finite field computation to cryptology : extension field arithmetic in public key systems and algebraic attacks on stream ciphers</field><field name="creator">Wong, Kenneth Koon-Ho</field><field name="description">In this digital age, cryptography is largely built in computer hardware or software as discrete structures. One of the most useful of these structures is finite fields. In this thesis, we explore a variety of applications of the theory and applications of arithmetic and computation in finite fields in both the areas of cryptography and cryptanalysis. First, multiplication algorithms in finite extensions of prime fields are explored. A new algebraic description of implementing the subquadratic Karatsuba algorithm and its variants for extension field multiplication are presented. The use of cy- clotomic fields and Gauss periods in constructing suitable extensions of virtually all sizes for efficient arithmetic are described. These multiplication techniques are then applied on some previously proposed public key cryptosystem based on exten- sion fields. These include the trace-based cryptosystems such as XTR, and torus- based cryptosystems such as CEILIDH. Improvements to the cost of arithmetic were achieved in some constructions due to the capability of thorough optimisation using the algebraic description. Then, for symmetric key systems, the focus is on algebraic analysis and attacks of stream ciphers. Different techniques of computing solutions to an arbitrary system of boolean equations were considered, and a method of analysing and simplifying the system using truth tables and graph theory have been investigated. Algebraic analyses were performed on stream ciphers based on linear feedback shift registers where clock control mechanisms are employed, a category of ciphers that have not been previously analysed before using this method. The results are successful algebraic attacks on various clock-controlled generators and cascade generators, and a full algebraic analyses for the eSTREAM cipher candidate Pomaranch. Some weaknesses in the filter functions used in Pomaranch have also been found. Finally, some non-traditional algebraic analysis of stream ciphers are presented. An algebraic analysis on the word-based RC4 family of stream ciphers is performed by constructing algebraic expressions for each of the operations involved, and it is concluded that each of these operations are significant in contributing to the overall security of the system. As far as we know, this is the first algebraic analysis on a stream cipher that is not based on linear feedback shift registers. The possibility of using binary extension fields and quotient rings for algebraic analysis of stream ciphers based on linear feedback shift registers are then investigated. Feasible algebraic attacks for generators with nonlinear filters are obtained and algebraic analyses for more complicated generators with multiple registers are presented. This new form of algebraic analysis may prove useful and thereby complement the traditional algebraic attacks. This thesis concludes with some future directions that can be taken and some open questions. Arithmetic and computation in finite fields will certainly be an important area for ongoing research as we are confronted with new developments in theory and exponentially growing computer power.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">algebraic attacks, clock control, cyclotomic fields, CEILIDH, extension fields, Gauss periods, Karatsuba multiplication, Pomaranch, RC4, stream ciphers, torus-based cryptography, XTR</field><field name="identifier">http://eprints.qut.edu.au/17570/</field><field name="validLink">True</field></doc><doc><field name="title">Speaker verification incorporating high-level linguistic features</field><field name="creator">Baker, Brendan J.</field><field name="description">Speaker verification is the process of verifying or disputing the claimed identity of a speaker based on a recorded sample of their speech. Automatic speaker verification technology can be applied to a variety of person authentication and identification applications including forensics, surveillance, national security measures for combating terrorism, credit card and transaction verification, automation and indexing of speakers in audio data, voice based signatures, and over-the-phone security access. The ubiquitous nature of modern telephony systems allows for the easy acquisition and delivery of speech signals for processing by an automated speaker recognition system. Traditionally, approaches to automatic speaker verification have involved holistic modelling of low-level acoustic-based features in order to characterise physiological aspects of a speaker such as the length and shape of the vocal tract. Although the use of these low-level features has proved highly successful, there are numerous other sources of speaker specific information in the speech signal that have largely been ignored. In spontaneous and conversational speech, perceptually higher levels of in- formation such as the linguistic content, pronunciation idiosyncrasies, idiolectal word usage, speaking rates and prosody, can also provide useful cues as to identify of a speaker. The main aim of this work is to explore the incorporation of higher levels of information into the verification process. Specifically, linguistic constructs such as words, syllables and phones are examined for their usefulness as features for text-independent speaker verification. Two main approaches to incorporating these linguistic features are explored. Firstly, the direct modelling of linguistic feature sequences is examined. Stochastic language models are used to model word and phonetic sequences obtained from automatically obtained transcripts. Experimentation indicates that significant speaker characterising information is indeed contained in both word and phone-level transcripts. It is shown, however, that model estimation issues arise when limited speech is available for training. This speaker model estimation problem is addressed by employing an adaptive model training strategy that significantly improves the performance and extended the usefulness of both lexical and phonetic techniques to short training length situations. An alternate approach to incorporating linguistic information is also examined. Rather than modelling the high-level features independently of acoustic information, linguistic information is instead used to constrain and aid acoustic- based speaker verification techniques. It is hypothesised that a 	ext-constrained" approach provides direct benefits by facilitating more detailed modelling, as well as providing useful insight into which articulatory events provide the most useful speaker-characterising information. A novel framework for text-constrained speaker verification is developed. This technique is presented as a generalised framework capable of using di&#174;erent feature sets and modelling paradigms, and is based upon the use of a newly defined pseudo-syllabic segmentation unit. A detailed exploration of the speaker characterising power of both broad phonetic and syllabic events is performed and used to optimise the system configuration. An evaluation of the proposed text- constrained framework using cepstral features demonstrates the benefits of such an approach over holistic approaches, particularly in extended training length scenarios. Finally, a complete evaluation of the developed techniques on the NIST2005 speaker recognition evaluation database is presented. The benefit of including high-level linguistic information is demonstrated when a fusion of both high- and low-level techniques is performed.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">speaker recognition, speaker verification, high-level features, idiolect, phonetic speaker recognition, session variability, text-constrained speaker recognition</field><field name="identifier">http://eprints.qut.edu.au/17665/</field><field name="validLink">True</field></doc><doc><field name="title">Spatio-temporal pattern discovery and hypothesis exploration using a delay reconstruction approach</field><field name="creator">Campbell, Alexander B.</field><field name="description">This thesis investigates the computer-based modelling and simulation of complex geospatial phenomena. Geospatial systems are real world processes which extend over some meaningful extent of the Earth's surface, such as cities and fisheries. There are many problems that require urgent attention in this domain (for example relating to sustainability) but despite increasing amounts of data and computational power there is a significant gap between the potential for model-based analyses and their actual impact on real world policy and planning. Analytical methods are confounded by the high dimensionality and nonlinearity of spatio-temporal systems and/or are hard to relate to meaningful policy decisions. Simulation-based approaches on the other hand are more heuristic and policy oriented in nature, but they are difficult to validate and almost always over-fit the data: although a given model can be calibrated on a given set of data, it usually performs very poorly on new unseen data sets. The central contribution of this thesis is a framework which is formally grounded and able to be rigourously validated, yet at the same time is interpretable in terms of real world phenomena and thus has a strong connection to domain knowledge. The scope of the thesis spans both theory and practice, and three specific contributions range along this span. Starting at the theoretical end, the first contribution concerns the conceptual and theoretical basis of the framework, which is a technique known as delay reconstruction. The underlying theory is rooted in the rather technical field of dynamical systems (itself largely based on differential topology), which has hindered its wider application and the formation of strong links with other areas. Therefore, the first contribution is an exposition of delay reconstruction in non-technical language, with a focus on explaining how some recent extensions to this theory make the concept far more widely applicable than is often assumed. The second contribution uses this theoretical foundation to develop a practical, unified framework for pattern discovery and hypothesis exploration in geo-spatial data. The central aspect of this framework is the linking of delay reconstruction with domain knowledge. This is done via the notion that determinism is not an on-off quantity, but rather that a given data set may be ascribed a particular 'degree' of determinism, and that that degree may be increased through manipulation of the data set using domain knowledge. This leads to a framework which can handle spatiotemporally complex (including multi-scale) data sets, is sensitive to the amount of data that is available, and is naturally geared to be used interactively with qualitative feedback conveyed to the user via geometry. The framework is complementary to other techniques in that it forms a scaffold within which almost all modelling approaches - including agent-based modelling - can be cast as particular kinds of 'manipulations' of the data, and as such are easily integrated. The third contribution examines the practical efficacy of the framework in a real world case study. This involves a high resolution spatio-temporal record of fishcatch data from trawlers operating in a large fishery. The study is used to test two fundamental capabilities of the framework: (i) whether real world spatio-temporal phenomena can be identified in the degree-of-determinism signature of the data set, (ii) whether the determinism-level can then be increased by manipulating the data in response to this phenomena. One of the main outcomes of this study is a clear identification of the influence of the lunar cycle on the behaviour of Tiger and Endeavour prawns. The framework allows for this to be 'non-destructively subtracted', increasing the detect-ability of further phenomena.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">delay reconstruction, attractor reconstruction, geospatial, spatio-temporal, time series, model selection, validation, pattern discovery, agent-based, hypothesis exploration</field><field name="identifier">http://eprints.qut.edu.au/17676/</field><field name="validLink">True</field></doc><doc><field name="title">Synchronous HMMs for audio-visual speech processing</field><field name="creator">Dean, David Brendan</field><field name="description">Both human perceptual studies and automaticmachine-based experiments have shown that visual information from a speaker's mouth region can improve the robustness of automatic speech processing tasks, especially in the presence of acoustic noise. By taking advantage of the complementary nature of the acoustic and visual speech information, audio-visual speech processing (AVSP) applications can work reliably in more real-world situations than would be possible with traditional acoustic speech processing applications. The two most prominent applications of AVSP for viable human-computer-interfaces involve the recognition of the speech events themselves, and the recognition of speaker's identities based upon their speech. However, while these two fields of speech and speaker recognition are closely related, there has been little systematic comparison of the two tasks under similar conditions in the existing literature. Accordingly, the primary focus of this thesis is to compare the suitability of general AVSP techniques for speech or speaker recognition, with a particular focus on synchronous hidden Markov models (SHMMs). The cascading appearance-based approach to visual speech feature extraction has been shown to work well in removing irrelevant static information from the lip region to greatly improve visual speech recognition performance. This thesis demonstrates that these dynamic visual speech features also provide for an improvement in speaker recognition, showing that speakers can be visually recognised by how they speak, in addition to their appearance alone. This thesis investigates a number of novel techniques for training and decoding of SHMMs that improve the audio-visual speech modelling ability of the SHMM approach over the existing state-of-the-art joint-training technique. Novel experiments are conducted within to demonstrate that the reliability of the two streams during training is of little importance to the final performance of the SHMM. Additionally, two novel techniques of normalising the acoustic and visual state classifiers within the SHMM structure are demonstrated for AVSP. Fused hidden Markov model (FHMM) adaptation is introduced as a novel method of adapting SHMMs from existing wellperforming acoustic hidden Markovmodels (HMMs). This technique is demonstrated to provide improved audio-visualmodelling over the jointly-trained SHMMapproach at all levels of acoustic noise for the recognition of audio-visual speech events. However, the close coupling of the SHMM approach will be shown to be less useful for speaker recognition, where a late integration approach is demonstrated to be superior.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">speech processing, speech recognition, speaker recognition, speaker verification,multimodal, audio-visual, data fusion, pattern recognition, hidden Markov models, synchronous hidden Markov models</field><field name="identifier">http://eprints.qut.edu.au/17689/</field><field name="validLink">True</field></doc><doc><field name="title">The morphology and structure of intercalated and pillared clays</field><field name="creator">Duong, Loc V.</field><field name="description">This thesis is submitted in a format of published papers by the candidate. Advanced methods of electron microscopy and X-ray spectroscopy have been used to study the relationship between the pillars and the silicate structure ranging from Al13 and Ga13 complexes to the final products Al- and Ga-pillared clays. The Al13 and Ga13 pillared montmorillonites have been prepared by conventional and ultrasonic methods. The ultrasonic method has been proven to be effective and showed very good catalytically activity. Transmission electron microscopy combined with elemental mapping by EDS showed the distribution of the Ga and Al pillars in the clay structure. The use of gallium allowed the independent observation of the Ga pillar distribution from the Al distribution in the clay structure.
 XPS spectra of the Ga13 pillared montmorillonites showed that the pillars has been changed from the original Keggin structure with a 7+ charge to something more stable with a lower charge upon intercalation. No direct evidence of the inverted silicon tetrahedron structure bonding to the pillar structure, as suggested by Plee in his original thesis, was observed. For comparative reasons the major aluminium hydroxide minerals in bauxite (gibbsite, bayerite and (pseudo-) boehmite) were studied. 
 Detailed information about the Al13 structure was obtained by studying the basic sulphate and nitrate salts with XPS. The XPS results of a set of starting clays in comparison to the pillared clays indicated that small changes in the binding energy could explain the changes in the pillar structure and the formation of chemical bonds to the clay tetrahedral sheets during the calcination leading to the final products.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Intercalated clays, Pillared clays, morphology and structure</field><field name="identifier">http://eprints.qut.edu.au/17707/</field><field name="validLink">True</field></doc><doc><field name="title">Arguing online : expectations and realities of building knowledge in a blended learning environment</field><field name="creator">Nykvist, Shaun S.</field><field name="description">The use of information and communication technologies (ICT) has now become all pervasive in society. There is now an expectation that educators will use ICT to support teaching and learning in their classrooms and this position is evident in many curriculum documents and educational policies where the aim is to provide each child with access to ICT. Consequently, and to realise this expectation, it is imperative that the focus on the use of information and communication technologies (ICT) in education shifts beyond learning about ICT to a focus that is aligned with the pedagogical learning experiences in which students can be immersed. There is a need for deep knowledge building to occur in these environments for our students to be active participants in a society where new technologies are constantly emerging. Hence, there is a need for learning environments that are flexible and respond to the needs of these new students and can adopt new technologies where necessary. In order to explore such an environment that encourages the development of knowledge building, an argumentative framework is necessary. The purpose of the study described in this thesis was to identify argumentation as a process of knowledge building and determine if it occurs in an online discussion forum, which is situated in a blended learning environment. This blended learning environment is typical of many classrooms and is where there is a combination of traditional face-to-face activity with online collaboration. In the case of this study, it is situated within an upper secondary private girls school located in a metropolitan area. The classroom under investigation demonstrates a blending of traditional pedagogy, that of dialectical reasoning and argument, and new technology, through an online discussion forum. The study employed a research design methodology over a six week period, while the analysis was based on an existing social argumentation schema and a new customised schema. As part of the analysis, descriptive statistics were used to determine the students' activity within the online discussion forum and to ascertain how this varied accordingly when certain criteria were changed. This was consistent with the cyclic approach of design research. Pedagogical recommendations were presented which demonstrated the importance that appropriate scaffolding and the role of the teacher plays in the successfulness of a forum. The study also recognised the need for purposeful teaching of argumentation as a process of knowledge building and the need for starter statements that are personally motivating to the students and are authentic and relevant. Argumentation and consequently knowledge building were evident in the findings, though were constrained by the habituated practices of schooling. Similarly the notion of community, while evident, was constrained by the time- and space- dependence of the school environment.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">asynchronous communication, blended learning, knowledge building, argumentation, scaffolding, community</field><field name="identifier">http://eprints.qut.edu.au/17710/</field><field name="validLink">True</field></doc><doc><field name="title">Motorist behaviour at railway level crossings : the present context in Australia</field><field name="creator">Wallace, Angela M.</field><field name="description">Railway level crossing collisions in Australia are a major cause of concern for both rail and road authorities. Despite the fact that the number of railway crash fatalities in Australia has fallen in recent years, level crossing collisions constitute a significant proportion of the national rail toll. Although rail transport is presently one of the safest forms of land transport, collisions at level crossings are three times more likely to involve fatalities as compared to all other types of road crashes (Afxentis, 1994). With many level crossing fatalities and injuries resulting in coronial inquests, litigation and negative media publicity, the actions of rail and road infrastructure providers and the behaviour of motorists, pedestrians and rail users, come under close scrutiny. Historically, research in this area has been plagued by the rail/road interface and the separation of responsibilities between rail and road authorities reflecting the social and political context in which they are contained. With the recent rail reform in Australia, safety at level crossings has become a key priority area. Accordingly, there is a need to better understand the scope and nature of motorist behaviour at level crossings, in order to develop and implement more effective countermeasures for unsafe driving behaviour. However, a number of obstacles have hindered research into the area of level crossing safety. As with many road crashes, the contributing causes and factors are often difficult to determine, however a recent investigation of fatal collisions at level crossings supports the notion that human fault is a major contributor (Australian Transport Safety Bureau, 2002a). Additionally, there is a lack of reliable data available relating to the behavioural characteristics and perceptions of drivers at level crossings. Studies that do exist have lacked a strong theoretical base to guide the interpretation of results. Due to the lack of financial viability of continuing to approach risk management from an engineering perspective, the merits of human factor research need to be examined for suitability. In Australia, there has been considerable recognition regarding the importance of human factor approaches to level crossing safety (Australian Transport Council, 2003). However, little attempt has been made by authorities to scientifically develop and measure the effectiveness of road safety educational interventions. Therefore, there exists a significant need for developing targeted road safety educational interventions to improve current risk management solutions at level crossings. This research program is the first of its kind in investigating motorist behaviour at level crossings and the measuring the effectiveness of educational interventions for improving driving safety. Although other &#8216;educational&#8217; campaigns exist in this field, no campaign or intervention has been guided by empirical research or theory. This thesis adopted a multidisciplinary approach to theory, reviewing perspectives from psychology, sociology and public health to explain driver behaviour at level crossings. This array of perspectives is necessary due to the variety of behaviours involved in collisions and near-misses at level crossings. The motivation underlying motorist behaviour determines to a large extent how successful behaviour change strategies (e.g. educational interventions) may be. Fishbein&#8217;s Integrated Model of Behaviour Change (IM) based largely on the health belief model, theory of reasoned action and theory of planned behaviour (Fishbein, 2000), assisted in the planning and development of a &#8216;oneoff&#8217; targeted educational intervention specific for three different road user groups and in questionnaire development to ascertain the present context of motorist behaviour at level crossings. As no known research has been conducted that utilizes any psychosocial model to explain or predict level crossing behavior within different road user groups, this research program used this model as an exploratory tool rather than a tool to asses the model&#8217;s capacity in explaining such behaviour. The difference between this model and others is the inclusion of two important constructs in driving: skills (or abilities) and environmental factors. Fishbein (2003) suggests that the model recognises the lack of skills (or abilities) and/or environmental constraints may prevent a person from acting on their intentions, in light of the fact that intention is viewed as the primary determinant of behaviour. While the majority of behaviour change theories are limited by a range of conceptual and contextual factors (Parker, 2004), the IM was used to assist this research program as it appeared to be the most applicable model to examining level crossing safety. A variety of data collection methods were used in this research program as much of what is currently known about level crossing collisions is derived from coroner&#8217;s findings and statistics. The first study (Study One) was designed to extend this knowledge by undertaking a more thorough examination of contributing factors to level crossing crashes and the road user groups at risk. This study used the method of &#8216;triangulation&#8217; (i.e. combining research methods to give a range of perspectives) whereby both qualitative (focus groups) and quantitative (modified Delphi technique) research designs were utilised (Barbour, 1999, Bryman, 1992). With the discipline of road safety research requiring methodological strategies that will enhance efforts to conceptualise the multi-faceted nature of motorist behaviour at level crossings, this application provided the robustness required. Results from the Delphi technique indicated that older, younger and heavy vehicle drivers are considered to be three of the highest risk road user groups by experts in the field. For the older driver group, experts agreed that errors in judgment were the most important issue for this group when driving at level crossings. Risk taking by younger drivers, such as trying to beat the train across the crossing, was viewed as the central issue for the younger driver group. Like the younger driver group, a concern by experts with the heavy vehicle group was intentional risk taking at level crossings. However, experts also rated the length of heavy vehicles a major concern due to the possibility of a truck over-hanging a crossing. Results from focus groups with train drivers in Study One indicated that there are unique problems associated with crossings in rural/regional areas compared to urban areas. The metropolitan train drivers generally experienced motorist behaviour at active crossings with flashing lights and boom gates while the regional train drivers experienced behaviours at active crossings with boom gates, crossings with lights only and passive crossings with stationary signs. In the metropolitan train driver group, experiences of motorist behaviour at level crossings included: motorists driving around boom gates, getting stuck under boom gates, queuing over congested crossings and driving through the crossing after the red lights commence flashing. The behaviour of motorists driving around boom gates was noted to occur quite regularly. The majority of metropolitan train drivers reported that it was a common occurrence for motorists to drive through a crossing when the lights are flashing both before and after the booms were activated and some crossings were named as &#8216;black spots&#8217; (locations where motorists repeatedly violate the road rules). Vehicles protruding into the path of the train and motorists entering congested crossings and then panicking and driving backwards into the boom gates were also mentioned. Regional train drivers indicated that motorists not stopping or giving way to trains is a continual problem at passively controlled crossings (i.e. no boom gates or flashing lights). Regional train drivers generally agreed that the majority of motorists obey protection systems; however some motorists drive through flashing lights or drive around boom gates. Other high risk behaviours included motorists attempting to beat the train across the crossing, speeding up to go through flashing lights, and general risk taking by younger drivers in particular. Motorists not allowing enough time to cross in front of the train or hesitating (stopstarting) at crossings were also noted to be at high risk. There was a general perception by regional train drivers that motorists are unable to judge the speed and distance of an approaching train to determine a safe gap during which to cross. Local motorists were also reported to be a problem at level crossings for regional train drivers. A theme common to regional and metropolitan train drivers was the risk of catastrophic consequence associated with level crossing collisions. The reasons given for this were the threat of derailment, serious property damage, the high risk of a fatality, personal injury and, most earnestly, the potential for enduring psychological consequences. Drivers uniformly spoke about the continual fear they had of being involved in a collision with a heavy vehicle, and many spoke of the effects that such collisions had on train drivers involved. For this reason, train drivers were said to consider any near-miss incident involving trucks particularly serious. The second study undertaken as part of this research program (Study Two), involved formative research as part of the planning, development and delivery of behavioural interventions for each of the three road user groups identified in Study One. This study also used both qualitative and quantitative data collection methods to provide methodological triangulation and ensure reliability of the data. The overall objective of the qualitative data collection was to obtain rich data using a qualitative mode of inquiry, based on the key variables of attitudes, norms, self-efficacy (perceived behavioural control), perceived risk, environmental constraints and the skills/abilities of drivers. The overall objective of the quantitative data collection was to prioritise the issues identified in order to direct and allocate project resources for intervention planning, development and delivery. This combined recruitment strategy was adopted as it was an appropriate and practical data collection strategy within the qualitative and exploration methodology. Information obtained from each of the groups was critical in assisting, guiding, and identifying priority areas for message and material development. The use of focus groups and one-on-one interviews provided insights into why drivers think or do what they do at level crossings. The qualitative component of this study found that for the older driver group, regional drivers hold a greater perception of risk at level crossings than urban older drivers, with many recalling near-misses. Participants from the urban older driver group indicated that level crossings are not as dangerous as other aspects of driving, with many participants being doubtful that motorists are killed while driving at level crossings. Both urban and regional younger drivers tended to hold a low perception of risk for driving at level crossings, however many participants reported having great difficulty in judging the distance a train is from a crossing. Impatience for waiting at level crossings was reported to be the major reason for any risk taking at level crossings in the younger driver group. Complacency and distraction were viewed by heavy vehicle participants as two of the major driver factors that put them at risk at level crossings, while short-stacking (when the trailer of the truck extends onto the crossing), angle of approach (acute or obtuse angle) and lack of advance warning systems were seen as the major engineering problems for driving a truck at level crossings. The quantitative component of this study involving research with train drivers found that at the aggregate train driver level, it is apparent that train drivers consider motorists&#8217; deliberate violations of the road rules and negligently lax approach to hazard detection as the predominant causes of dangerous driving at level crossings. Experts were observed to rank risk taking behaviours slightly lower than train drivers, although they agreed with train drivers that &#8216;trying to beat the train&#8217; is the single most critical risk taking behaviour observed by motorists. The third study (Study Three) involved three parts. The aim of Part One of this study was to develop targeted interventions specific to each of the three road user groups by using Fishbein&#8217;s theoretical model (Integrated Model of Behaviour Change) as a guide. The development of interventions was originally seen as being outside of the scope of this project, however it became intertwined in questionnaire development and thus deemed to be within the realms of the current mode of inquiry. The interventions were designed in the format of a pilot radio road safety advertisement, as this medium was found to be one of the most acceptable to each of the road user groups as identified in the formative research undertaken in Study Two. The interventions were used as a &#8216;one-off&#8217; awareness raising intervention for each road user group. Part Two involved the investigation of the present context of unsafe driving behaviour at level crossings. This second part involved the examination of the present context of motorist behaviour at level crossings using key constructs from Fishbein&#8217;s Integrated Model of Behaviour Change (IM). Part Three involved trialing a pilot road safety radio advertisement using an intervention and control methodology. This part investigated the changes in pre and post-test constructs including intentions, self-reported behaviour, attitudes, norms, selfefficacy/ perceived behaviour control, perceived risks, environment constraints and skills/ability. Results from this third study indicated that younger drivers recognise that level crossings are potentially a highly dangerous intersection yet are still likely to engage in risk taking behaviours. Additionally, their low levels of self-efficacy in driving at level crossings pose challenges for developing interventions with this age group. For the older driver sample, this research confirms the high prevalence of functional impairments such as increasing trouble adjusting to glare and night-time driving, restricted range of motion to their neck and substantial declines in their hearing. While factors contributing to the over-representation of older drivers in collisions at level crossings are likely to be complex and multi-faceted, such functional impairments are expected to play a critical role. The majority of heavy vehicle drivers reported driving safely and intending to drive safely in the future, however, there is a sub-set of drivers that indicate they have in the past and will in the future take risks when traversing crossings. Although this sub-set is relatively small, if generalised to the larger trucking industry it could be problematic for the rail sector and greater public alike. Familiarity was a common factor that was found to play a role in driving intention at level crossings for all three road user groups. This finding supports previous research conducted by Wigglesworth during the 1970&#8217;s in Australia (Wigglesworth, 1979). Taken together, the results of the three studies in this research program have a number of implications for level crossing safety in Australia. Although the ultimate goal to improve level crossing safety for all motorists would be to have a combination of engineering, education and enforcement countermeasures, the small number of fatalities in comparison to the national road toll limits this. It must be noted though that the likelihood of creating behavioural change would be increased if risk taking at level crossings by all motorists was detected and penalised, or alternatively, if perceptions of such detection were increased. The instilling of fear in drivers with the threat of punishment via some form of sanction can only be achieved through a combination of a mass media campaign and increasing police presence. Ideally, the aim would be to combine fear of punishment with the guilt associated with the social non-acceptability of disobeying road rules at level crossings. Such findings have direct implications for improving the present context of motorist behaviour at level crossings throughout Australia.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">level crossings, railway collisions, road users, heavy vehicles, older drivers, younger drivers, human factors, risk management, road safety, educational interventions</field><field name="identifier">http://eprints.qut.edu.au/17831/</field><field name="validLink">True</field></doc><doc><field name="title">Informed statistical modelling of habitat suitability for rare and threatened species</field><field name="creator">O'Leary, Rebecca A.</field><field name="description">In this thesis a number of statistical methods have been developed and applied to habitat suitability modelling for rare and threatened species. Data available on these species are typically limited. Therefore, developing these models from these data can be problematic and may produce prediction biases. To address these problems there are three aims of this thesis. The _rst aim is to develop and implement frequentist and Bayesian statistical modelling approaches for these types of data. The second aim is develop and implement expert elicitation methods. The third aim is to apply these novel approaches to Australian rare and threatened species case studies with the intention of habitat suitability modelling. The _rst aim is ful_lled by investigating two innovative approaches for habitat suitability modelling and sensitivity analysis of the second approach to priors. The _rst approach is a new multilevel framework developed to model the species distribution at multiple scales and identify excess zeros (absences outside the species range). Applying a statistical modelling approach to the identi_cation of excess zeros has not previously been conducted. The second approach is an extension and application of Bayesian classi_cation trees to modelling the habitat suitability of a threatened species. This is the _rst `real' application of this approach in ecology. Lastly, sensitivity analysis of the priors in Bayesian classi_cation trees are examined for a real case study. Previously, sensitivity analysis of this approach to priors has not been examined. To address the second aim, expert elicitation methods are developed, extended and compared in this thesis. In particular, one elicitation approach is extended from previous research, there is a comparison of three elicitation methods, and one new elicitation approach is proposed. These approaches are illustrated for habitat suitability modelling of a rare species and the opinions of one or two experts are elicited. The _rst approach utilises a simple questionnaire, in which expert opinion is elicited on whether increasing values of a covariate either increases, decreases or does not substantively impact on a response. This approach is extended to express this information as a mixture of three normally distributed prior distributions, which are then combined with available presence/absence data in a logistic regression. This is one of the _rst elicitation approaches within the habitat suitability modelling literature that is appropriate for experts with limited statistical knowledge and can be used to elicit information from single or multiple experts. Three relatively new approaches to eliciting expert knowledge in a form suitable for Bayesian logistic regression are compared, one of which is the questionnaire approach. Included in this comparison of three elicitation methods are a summary of the advantages and disadvantages of these three methods, the results from elicitations and comparison of the prior and posterior distributions. An expert elicitation approach is developed for classi_cation trees, in which the size and structure of the tree is elicited. There have been numerous elicitation approaches proposed for logistic regression, however no approaches have been suggested for classi_cation trees. The last aim of this thesis is addressed in all chapters, since the statistical approaches proposed and extended in this thesis have been applied to real case studies. Two case studies have been examined in this thesis. The _rst is the rare native Australian thistle (Stemmacantha australis), in which the dataset contains a large number of absences distributed over the majority of Queensland, and a small number of presence sites that are only within South-East Queensland. This case study motivated the multilevel modelling framework. The second case study is the threatened Australian brush-tailed rock-wallaby (Petrogale penicillata). The application and sensitivity analysis of Bayesian classi_cation trees, and all expert elicitation approaches investigated in this thesis are applied to this case study. This work has several implications for conservation and management of rare and threatened species. Novel statistical approaches addressing the _rst aim provide extensions to currently existing methods, or propose a new approach, for identi _cation of current and potential habitat. We demonstrate that better model predictions can be achieved using each method, compared to standard techniques. Elicitation approaches addressing the second aim ensure expert knowledge in various forms can be harnessed for habitat modelling, a particular bene_t for rare and threatened species which typically have limited data. Throughout, innovations in statistical methodology are both motivated and illustrated via habitat modelling for two rare and threatened species: the native thistle Stemmacantha australis and the brush-tailed rock wallaby Petrogale penicillata.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">habitat suitability modelling, threatened Australian brush-tailed rock-wallaby Petrogale penicillata, rare Australian thistle Stemmacantha australis, rare events, multilevel modelling, multiple scales, naughty noughts</field><field name="subject">classi_cation and regression trees (CART), logistic regression, model evaluation, accuracy measures, Bayesian statistical modelling, reversible jump Markov chain Monte Carlo, convergence, prior sensitivity analysis, expert elicitation, mixture modelling</field><field name="subject">variable selection</field><field name="identifier">http://eprints.qut.edu.au/17779/</field><field name="validLink">True</field></doc><doc><field name="title">Bioimpedance mapping of the cervix</field><field name="creator">Smith, Jye Geoffrey</field><field name="description">Bioimpedance spectroscopy has shown potential as a method for characterising biological tissue with the use of a tetrapolar electrode configuration. Brown et al. (2000) demonstrated that the configuration is capable of distinguishing between normal squamous epithelium and Cervical Intra-epithelial Neoplasia (CIN). However little has been done to identify the volumes of tissue that contribute to the measured impedance. Brown et al. employed a probe with a single tetrapolar electrode set thus analysing single points of tissue. The probe was required to be moved in order to "sample" other areas of tissue. This method provides no spatial information of the lesion boundaries. The overall objective of this research was to design and construct an impedance mapping system (IMS) for objective virtual biopsy of lesions by bioimpedance spectroscopy (BIS). Initially freshly excised cervical tissue was to be tested however as the study progressed this proved problematic and bovine blood was chosen as a suitable substitute. Specific aims were to; 
 -	.Investigate the spatial sensitivity distribution of the tetrapolar electrode configuration via finite element analysis (FEA). 
 -	Design a novel front end multiplexing system and multi-electrode array for mapping the impedance of the tissue of interest. 
 -	.Experimentally confirm the efficacy of the approach to identify regions of different impedances and their boundaries using bioimpedance mapping. 
 The present study used finite element analysis (FEA) to investigate the spatial variation in sensitivity of the tetrapolar electrode configuration and identify which volumes of tissue were included in the measured impedance. An impedance mapping device was also designed and constructed utilising the tetrapolar electrode configuration in an expanded array of 25 electrodes. This array allowed the surface of an area of tissue to be mapped and lesion boundaries identified in an objective manner. FEA was also used to model lesions in healthy tissue and the sensitivity fields associated with the tetrapolar configuration. The FEA indicated that anomalous results would be obtained when a lesion was located between a drive and measurement electrode pair. In this case the lesion resulted in an increase in impedance with respect to the impedance of healthy tissue, whereas a lesion should result in a decrease in measured impedance relative to that of healthy tissue. The anomaly was found to produce false negative results for small lesions up to 0.4 mm and even a lesion with radius of approximately 0.75 mm could be undetected as the measured impedance spectrum for such a lesion is similar to that of healthy tissue. Modelling also provided insight into the sensitivity fields for an electrode array and its efficacy in accurately measuring the surface impedance of tissue and lesions of interest. The impedance mapping system (IMS) developed used an array of 25 (5x5) electrodes. The array allows 64 individual tetrapolar measurements to be obtained at 16 locations, providing an impedance map of 49 mm2 on the surface of a tissue sample. Multiple measurements at each location reduce the chance of anomalous results since these can be identified and excluded. Software was developed to display the measured impedance maps and regions of different impedance were easily identified Testing of the IMS using bovine blood showed separation of the measured impedance for a range of haematocrit between 0 - 80%. Introduced volumes of red blood cells (RBC) or clots (to mimic lesions) to the plasma (haematocrit 0%) were also clearly identified using the IMS. It was seen that measurements made at the boundary of 2 different haematocrits (ie 2 volumes of different impedance) resulted in an anomalous result as indicated by the FEA modelling. However it was demonstrated that these anomalies can be used to objectively identify the introduced RBC (lesion) boundaries. A more efficient electrode stepping sequence was also developed taking advantage of the reciprocal nature of the tetrapolar electrode configuration. This development allows for the electrode array to be doubled in size using the same components, and to sample twice the surface area in the same time taken using the initially developed system. In summary, an impedance mapping system has been modelled, designed and developed for tissue characterisation by bioimpedance measurements. The technique has been shown experimentally to be able to detect regions of differ- ent impedance and is in agreement with the finite element analysis performed. Further development of the IMS will allow progressive monitoring of suspect lesions in-vivo and better identification of their spatial distribution for biopsy.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">bioimpedance, mulitifrequency, impedance, cervical cancer, bovine blood,</field><field name="subject">haematocrit, tetrapolar, finite element analysis, impedance mapping</field><field name="subject">multiplexer</field><field name="identifier">http://eprints.qut.edu.au/17782/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation into my career chapter : a dialogical autobiography</field><field name="creator">McIlveen, Peter F.</field><field name="description">This dissertation is a report on research into the development and evaluation of a career assessment and counselling procedure that falls under the aegis of the constructivist, narrative approach:  My Career Chapter: A Dialogical Autobiography.  My Career Chapter enables an individual to construct a holistic understanding of his or her career. The procedure facilitates an individual writing and reflecting on an autobiographical account of his or her career that is contextualised amidst systems of career influences.  The resulting autobiographical text can be used in career counselling, including co-constructive dialogue between client and counsellor.  The literature underpinning the research project is described with a wide-ranging discussion of issues that critically pertain to the research endeavour and essentially provide a primary base for the work.  Two theoretical frameworks that exemplify constructivism in vocational psychology underpin the research: the Systems Theory Framework and the Theory of Career Construction.  From the base of those two theoretical frameworks, narrative career counselling is explicated and exemplars are described.  The Theory of Dialogical Self is introduced to inform the design of My Career Chapter and, ultimately, the theory and practice of narrative career counselling.  The research is predominantly positioned within a paradigm of constructivism/interpretivism and the results of the studies are collectively interpreted accordingly; but postpositivism and critical ideological paradigms are present in a secondary form due to the mixture of research methods used in the project as a whole.  Six empirical studies investigate the experience of My Career Chapter from the perspective of the developer, the counsellor-user, and the client-user; each explicated with two studies respectively.  Research methods include autoethnography for the developer's experience, interpretative phenomenological analysis and focus group for the counsellor-users' experience, and quasi-experiment and interpretative phenomenological analysis for the client-users' experience.  The studies of the developer's experience of My Career Chapter comprehensively explicate how and why the procedure was developed and emphasise the importance of reflexive science and practice.  Crucially, the autoethnographies revealed a nexus of theory-practice-person which underpins the production of My Career Chapter, and critically influences the entire research project.  The studies involving counsellor-users affirmed My Career Chapter's alignment with recommendations for the development and application of qualitative career assessment and counselling procedures.  These studies also raised questions pertaining to the characteristics of client-users that may mediate the efficacy of the procedure (e.g., age, language ability).  Studies of client-users firstly support the conclusion that My Career Chapter is a safe career assessment and counselling procedure, with minimal attendant risk of inducing psychological harm or distress.  The procedure was experienced as being helpful as a tool for personal reflection, through its theoretically-derived processes of facilitating clients writing, reading, and hearing and talking their autobiographical manuscripts through in the interpretation phase.  There are four dimensions of significance associated with this research project.  Firstly, the divide between theory and practice has indeed been much lamented in vocational psychology and counselling psychology.  Thus, the overall significance of the research reported upon in this dissertation is significant because it attempts to bring theory and practice together through a reflexive and theoretically informed research process into a career assessment and counselling procedure.  Secondly, the research and development process produced a new career assessment and counselling product which will add to the limited range of techniques that fall under the aegis of constructivist career assessment and counselling broadly, and the narrative approach specifically.  My Career Chapter complements other procedures. Thirdly, two of the research methods used in the project (viz., autoethnography and interpretative phenomenological analysis) demonstrated their potential as additional qualitative methods for research within vocational psychology.  Finally, the research process has enabled the articulation of the Theory of Dialogical Self&#8212;from another branch of psychology&#8212;into the extant corpus of literature on career development theory and practice.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">vocational psychology, career counselling, career assessment, narrative, constructivism, constructionism, My Career Chapter, Systems Theory Framework, STF, Theory of Career Construction, dialogical self, qualitative research, reflexive practice</field><field name="subject">autoethnography, interpretative phenomenological analysis</field><field name="identifier">http://eprints.qut.edu.au/17787/</field><field name="validLink">True</field></doc><doc><field name="title">Enhancing ethical practice in prenatal screening : facilitating women's ethical choices</field><field name="creator">Milligan, Eleanor</field><field name="description">Informed consent, based on patient autonomy, is seen as necessary if medical interventions are to be seen as legally and ethically acceptable. While 'informed consent' protocols within antenatal care, including prenatal screening regimes are presumed to be robust, emerging research outside of Australia suggests most women do not adequately understand the medical purpose, limitations or potential ethical implications, such as selective termination, of the medical procedures 'consented' to. While the consent given in these situations may well fulfil the minimal legal criteria for informed consent, the required level of knowledge and understanding necessary to meet the ethical standards informed or understood consent often appears not be met. The presumption that legally informed consent equates to morally informed consent inherent within institutional protocols for screening must therefore be questioned, and the ethical integrity of these increasingly routine interventions demand further scrutiny.
 
 The purpose of this research was to explore whether the problems identified in research overseas might also exist locally. Underpinned by a phenomenological philosophical approach to understanding the ethical dimensions of clinical practice, the research sought to engage with a small cohort of mothers and practitioners locally. The study adopted a qualitative narrative methodology, analysing individual in-depth interviews using the Listening Guide (Gilligan et al, 2003). The experiences of mothers and health practitioners interviewed exposed a range of institutional, social, personal and philosophical constraints that mirrored the overseas research findings and also illuminated how informed consent may be unintentionally undermined in the clinical setting. 
 
 A positive outcome of the study was that it provided a locally informed and contextually sensitive basis from which to strengthen existing organisational informed consent protocols and thus support women's ethical decision making. As the process of becoming 'informed' to consent is largely educational, promoting patient learning in the clinical context is an ethical imperative. However, there seems limited awareness at either the clinical or theoretical level of the critical link between patient education and ethically robust medical intervention. Hence a significant contribution of this research was to explore this underdeveloped but practically important link.
 
 As the process of gaining informed consent has far reaching applications across a broad spectrum of medical interventions, the contextual and educational insights offered throughout this research may have significant relevance beyond the immediate context of this research.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">ethics, prenatal screening, informed consent, education</field><field name="identifier">http://eprints.qut.edu.au/17790/</field><field name="validLink">True</field></doc><doc><field name="title">Child abuse and neglect reporting among nurses in Taiwan : professional knowledge, perceptions, attitudes, and self-efficacy</field><field name="creator">Lee, Pei-Yu</field><field name="description">According to the Children's Bureau of Taiwan (2007), the number of Taiwanese children abused and neglected sharply increased from 6,059 to 10,094 between 2000 and 2006. Reports of abused and neglected children also rose from 8,494 to 13,986 in that period. This followed enactment of the Children and Youth Welfare Law in 2003 imposing a range of health, education and social welfare professionals, including nurses, the statutory duty to report suspected child abuse and neglect. Previous studies in Taiwan have indicated that despite the legislation, a range of factors continue to act against nurses reporting child abuse and neglect (CAN) cases according to the law. Previous research had examined factors that influence CAN reporting by health, education, and welfare professionals including registered nurses in Taiwan. The study herein sought to extend knowledge of these factors by identifying and assessing nurses' self-efficacy as a prime factor influencing professional commitment to legal reporting of CAN. The aims of this research were to: (1) examine influencing factors of nurses' likelihood to report CAN in Taiwanese health care settings, and (2) develop and test a new instrument Child Abuse and Neglect Reporting Self Efficacy (CANRSE) to measure nurses' self-efficacy in CAN reporting. The research was conducted in two phases. Phase one investigated nurses' experience with CAN reporting and examined relationships between nurses' perceptions, attitudes, knowledge, and likelihood to report CAN cases. Two hundred and thirty-eight nurses from emergency departments, paediatric units and community centres in Taiwan completed a survey. The results showed that using a series of vignettes, a significant relationship existed between the likelihood to report CAN and perception, attitude, and knowledge. Notably, perception was the most significant variable in predicting nurses' likelihood to report CAN cases. Findings indicated nurses had poor perceptions of recognizing and reporting CAN and lacked faith in child protection services. Knowledge of Taiwanese CAN reporting laws was poor. In general, most nurses believed that they needed more training courses on the recognition and reporting of CAN. These findings, in particular the importance of perceptions of legal reporting behaviour, were worthy of further investigation. In Phase two, a measure of CANRSE was developed and tested. Data were collected from 496 nurses working in Taiwanese health care settings. Development of the CANRSE was guided by an extensive literature review, findings from Phase one of the study and by an expert panel. The CANRSE consisted of five sections: (1) demographic information, (2) efficacy-expectation for suspected cases, (3) efficacy-expectation for known cases, (4) outcome-expectation of CAN reporting, and (5) likelihood to report CAN. The influence of nurses' self-efficacy on their likelihood to report CAN cases was also analysed. Structure of the CANRSE was supported by structural equation modeling using AMOS 6.0. Additionally, correlation and regression analyses were applied to investigate the validity and reliability of the CANRSE. CANRSE met accepted psychometric standards for reliability and validity in this study. Nurses' CAN self-efficacy yielded strong prediction over personal characteristics, experience as a nurse, experience as a parent, and age. Thus, the research provides an important contribution to the literature relating to mandatory reporting by professional groups in particular nurses. It was the first research to successfully develop a new instrument to evaluate nurses' selfefficacy in CAN reporting. The findings provide a basis for understanding the influence of Taiwanese nurses' decision making for CAN reporting. Further research can extend the scope of CAN training programs and their evaluation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">child abuse, child neglect, mandatory reporting, professional behaviour, self-efficacy, Taiwanese nurses</field><field name="identifier">http://eprints.qut.edu.au/17800/</field><field name="validLink">True</field></doc><doc><field name="title">Outside school hours care and schools</field><field name="creator">Cartmel, Jennifer Leigh</field><field name="description">Outside school hours programs provide recreation, play and leisure-based programs for children aged 5 to 12 years in before- and after-school settings, and in the vacation periods.  Over the past ten years, the number of programs has grown rapidly due to women&#8217;s increasing participation in the workforce. At the same time, critical changes for the operation and administration of Queensland outside school hours care services were occurring following the introduction of mandatory standards and quality assurance. This study is a critical ethnography investigating the circumstances for two Outside School Hours Care (OSHC) services located on school sites at this time of change. The services were responding to the introduced legislative and accreditation requirements, the burgeoning numbers of students in the programs, and the requirements by parents for care for their school-aged child. The findings of this study show the complexity of the dualities of purpose and the operational administration of OSHC services, an area that has been little identified and discussed to date. This study illuminated not only aspects of OSHC services, it provided an opportunity for the co-ordinators of the two OSHC services to reflect on the operational structures. 
 As the majority of OSHC services in Queensland (and other Australian states) are located in school sites, a closer examination of the relationship between OSHC and schools provided insights into some issues concerning the sector. Habermas&#8217; Theory of Communicative Action was used to investigate the state of affairs and analyse the consensual and coercion meaning-making that occurred in the interactions between the stakeholders, specifically between the OSHC coordinators and school principals. Critical ethnographic research techniques, including participant observations and semi-structured interviews, were used to investigate what appears below the surface of social existence in the OSHC settings. 
 On the surface, the interactions between the coordinators and principals appeared congenial. However, the study found that the vulnerability of the OSHC services for alienation and marginalisation was linked to the lack of legitimacy and reduced sense of social membership endowed by the ambience of the school setting in which the services were located. The study found that the distorted communicative action that took place within the OSHC settings exhibited the pathologies of alienation, withdrawal of legitimation and lack of collective identity. Examining the relationships of the key stakeholders within the outside school hours care services offers conceptual understandings of existing institutional relationships and practices, This critical ethnography pinpoints sources of power and unease contributing to the concerns for the outside school hours sector and recommends ways to develop these programs.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">outside school hours care, school age care, child care; critical ethnography, communicative action</field><field name="identifier">http://eprints.qut.edu.au/17810/</field><field name="validLink">True</field></doc><doc><field name="title">The relationship between glycemic intake and insulin resistance in older women</field><field name="creator">O'Sullivan, Therese Anne</field><field name="description">Glycemic intake influences the rise in blood glucose concentration following consumption of a carbohydrate containing meal, known as the postprandial glycemic response. The glycemic response is a result of both the type and amount of carbohydrate foods consumed and is commonly measured as the glycemic index (GI) or glycemic load (GL), where the GI is a ranking in comparison to glucose and the GL is an absolute value encompassing both the GI and amount of carbohydrate consumed. Evidence from controlled trials in rat models suggests that glycemic intake has a role in development of insulin resistance, however trials and observational studies of humans have produced conflicting results. As insulin resistance is a precursor to type 2 diabetes mellitus, lifestyle factors that could prevent development of this condition have important public health implications. Previous observational studies have used food frequency questionnaires to assess usual diet, which could have resulted in a lack of precision in assessment of individual serve sizes, and have been limited to daily measures of glycemic intake. Daily measures do not take fluctuations in glycemic intake on a per meal basis into account, which may be a more relevant measure for investigation in relation to disease outcomes. This PhD research was conducted in a group of Brisbane women aged 42 to 81 years participating in the multidisciplinary Brisbane Longitudinal Assessment of Ageing in Women (LAW study). Older women may be at particular risk of insulin resistance due to age, hormonal changes, and increases in abdominal obesity associated with menopause, and the LAW study provided an ideal opportunity to study the relationship between diet and insulin resistance. Using the diet history tool, we aimed to assess the glycemic intake of the population and hypothesised that daily GI and daily GL would be significantly positively associated with increased odds of insulin resistant status. We also hypothesised that a new glycemic measure representing peaks in GL at different meals would be a stronger predictor of insulin resistant status than daily measures, and that a specially designed questionnaire would be an accurate and repeatable dietary tool for assessment of glycemic intake. To address these hypotheses, we conducted a series of studies. To assess glycemic intake, information on usual diet was obtained by detailed diet history interview and analysed using Foodworks and the Australian Food and Nutrient (AUSNUT) database, combined with a customised GI database. Mean &#177; SD intakes were 55.6 &#177; 4.4% for daily GI and 115 &#177; 25 for daily GL (n=470), with intake higher amoung younger participants. Bread was the largest contributor to intakes of daily GI and GL (17.1% and 20.8%, respectively), followed by fruit (15.5% and 14.2%, respectively). To determine whether daily GI and GL were significantly associated with insulin resistance, the homeostasis model assessment of insulin resistance (HOMA) was used to assess insulin resistant status. Daily GL was significantly higher in subjects who were insulin resistant compared to those who were not (134 &#177; 33 versus 114 &#177; 24 respectively, P&lt;0.001) (n=329); the odds of subjects in the highest tertile of GL intake being insulin resistant were 12.7 times higher when compared with the lowest tertile of GL (95% CI 1.6-100.1, P=0.02). Daily GI was not significantly different in subjects who were insulin resistant compared to those who were not (56.0 &#177; 3.3% versus 55.7 &#177; 4.5%, P=0.69). To evaluate whether a new glycemic measure representing fluctuations in daily glycemic intake would be a stronger predictor of insulin resistant status than other glycemic intake measures, the GL peak score was developed to express in a single value the magnitude of GL peaks during an average day. Although a significant relationship was seen between insulin resistant status and GL peak score (Nagelkerke&#8217;s R2=0.568, P=0.039), other glycemic intake measures of daily GL (R2=0.671, P&lt;0.001) and daily GL per megajoule (R2=0.674, P&lt;0.001) were stronger predictors of insulin resistant status. To develop an accurate and repeatable self-administered tool for assessment of glycemic intake, two sub-samples of women (n=44 for the validation study and n=52 for the reproducibility study) completed a semi-quantitative questionnaire that contained 23 food groupings selected to include the top 100 carbohydrate foods consumed by the study population. While there were significant correlations between the glycemic intake questionnaire and the diet history for GL (r=0.54, P&lt;0.01), carbohydrate (r=0.57, P&lt;0.01) and GI (r=0.40, P&lt;0.01), Bland-Altman plots showed an unacceptable difference between individual intakes in 34% of subjects for daily GL and carbohydrate, and 41% for daily GI. Reproducibility results showed significant correlations for daily GL (r=0.73, P&lt;0.001), carbohydrate (r=0.76, P&lt;0.001) and daily GI (r=0.64, P&lt;0.001), but an unacceptable difference between individual intakes in 25% of subjects for daily GL and carbohydrate, and 27% for daily GI. In summary, our findings show that a significant association was observed between daily glycemic load and insulin resistant status in a group of older women, using a diet history interview to obtain precise estimation of individual carbohydrate intake. Both the type and quantity of carbohydrate are important to consider when investigating relationships between diet and insulin resistance, although our results suggest the association is more closely related to overall daily glycemic intake than individual meal intake variations. A dietary tool that permits precise estimation of carbohydrate intake is essential when evaluating possible associations between glycemic intake and individual risk of chronic diseases such as insulin resistance. Our results also suggest that studies using questionnaires to estimate glycemic intake should state degree of agreement as well as correlation coefficients when evaluating validity, as imprecise estimates of carbohydrate at an individual level may have contributed to the conflicting findings reported in previous studies.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Australia, carbohydrate, diabetes, diet history, dietary intake, food frequency questionnaire, glycemic (or glycaemic) index, glycemic intake, glycemic load, hyperglycemic peak, insulin resistance, insulin sensitivity, postmenopausal women</field><field name="identifier">http://eprints.qut.edu.au/17814/</field><field name="validLink">True</field></doc><doc><field name="title">Investigation of circuit breaker switching transients for shunt reactors and shunt capacitors</field><field name="creator">Ramli, Mohd Shamir</field><field name="description">Switching of shunt reactors and capacitor banks is known to cause a very high rate of rise of transient recovery voltage across the circuit breaker contacts. With improvements in circuit breaker technology, modern SF6 puffer circuits have been designed with less interrupter per pole than previous generations of SF6 circuit breakers. This has caused modern circuit breakers to operate with higher voltage stress in the dielectric recovery region after current interruption. Catastrophic failures of modern SF6 circuit breakers have been reported during shunt reactor and capacitor bank de-energisation. In those cases, evidence of cumulative re-strikes has been found to be the main cause of interrupter failure.
 Monitoring of voltage waveforms during switching would provide information about the magnitude and frequency of small re-ignitions and re-strikes. However, measuring waveforms at a moderately high frequency require plant outages to connect equipment. In recent years, there have been increasing interests in using RF measurements in condition monitoring of switchgear. The RF measurement technique used for measuring circuit breaker inter-pole switching time during capacitor bank closing is of particular interest. 
 In this thesis, research has been carried out to investigate switching transients produced during circuit breaker switching capacitor banks and shunt reactors using a non-intrusive measurement technique. The proposed technique measures the high frequency and low frequency voltage waveforms during switching operations without the need of an outage. The principles of this measurement technique are discussed and field measurements were carried out at shunt rector and capacitor bank installation in two 275 kV air insulated substations. Results of the measurements are presented and discussed in this thesis. 
 The proposed technique shows that it is relatively easy to monitor circuit breaker switching transients and useful information on switching instances can be extracted from the measured waveforms. Further research works are discussed to realise the full potential of the measuring technique.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">antenna, arcing time, capacitor bank, capacitive coupling, circuit breaker, condition monitoring, controlled switching, current interruption, high frequency, high voltage, non-intrusive, on-line monitoring, overvoltages, prestrike, restrike, reignition</field><field name="subject">shunt reactor, switching, timing, transients, voltage sensor</field><field name="identifier">http://eprints.qut.edu.au/17822/</field><field name="validLink">True</field></doc><doc><field name="title">Exercise intensity, exercise training and energy metabolism in overweight and obese males</field><field name="creator">Roffey, Darren M.</field><field name="description">The primary objective of this PhD program was to investigate the impact of training at a constant-load moderate-intensity (FATmax) compared to work-matched high-intensity intervals (HIIT) on the metabolic, physiological and psychosocial health profiles of sedentary overweight and obese men.  This study was unique in that it was the first time the effect of exercise intensity had been investigated to examine concurrently the components of whole-body energy metabolism and body composition as measured using gold standard techniques.  
 
 Based upon the positive alterations in blood lipids, body composition, cardiorespiratory fitness and substrate oxidation, it appears that training at FATmax can positively impact health parameters as well as, or if not better than, high-intensity training.  Furthermore, there are ramifications for public health messages and obesity management strategies arising from these findings, primarily attributable to the increased exercise adherence and the reduction in health risks stemming from the significant loss of abdominal visceral adipose tissue after FATmax training.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">obesity, substrate utilisation, fat oxidation, resting metabolic rate, maximum aerobic power, physical activity, FATmax, energy expenditure, non-exercise activity thermogenesis, body composition, accelerometry, heart rate monitoring, exercise prescription</field><field name="subject">dietary intake</field><field name="identifier">http://eprints.qut.edu.au/17823/</field><field name="validLink">True</field></doc><doc><field name="title">Fabrication and properties of diamond-like carbon films in discharge plasmas</field><field name="creator">Rybachuk, Maksym</field><field name="description">This thesis presents theoretical and experimental study of properties of amorphous diamond-like carbon (DLC) coatings synthesised using discharge plasma methods. There were two objectives in this study. 
 The first objective was to investigate the formation mechanism of hydrogenated DLC films (a-C:H) in an open hydrocarbon plasma source. The inductively coupled plasma (ICP) reactor was used to synthesise the films and the formation of sp2 and sp3 hybridised phases and the combination of these phases in the ICP plasma environment was studied.  It was found that for a-C:H films with narrow distribution of the sp3 content the mechanical properties are determined by the degree of disorder of the sp2 fraction. The relationship between the sp3 content in fabricated films and hardness and Young's modulus was established. Raman and multi-wavelength (Vis &#8211; UV range) Raman spectroscopy was primarily used together with other suitable analytical methods to examine a-C:H films and it was found that films fabricated at higher ion energies displayed higher degree of clustering and bonding disorder than films produced at lower ion energies. All as fabricated a-C:H films were also found contain basic &#960;-conjugated polymer inclusions as of trans-polyacetylene. The Raman results also reveal that the magnitude of Rayleigh scattered light is related to the relative density of the films, a feature that can be useful for monitoring film growth in-situ. The use of X-ray photoelectron spectroscopy (XPS) as a suitable method for measuring the sp3 content of the bulk DLC was also established. 
 The second objective was to develop a fabrication technique that would allow fabrication of DLC films using graphite target sputtering with a single focused ion beam source and producing films with medium-high sp3 content. This research was motivated by the industrial partner of the project Laserdyne Pty Ltd that required a simple DLC deposition apparatus to be integrated into a standard, stand alone, optical thin film deposition chamber. Such technique was developed on the basis of a conventional ion beam target sputtering. In our experiments hydrogen-free DLC films with medium sp3 content were produced using a single, Kaufmann type ion source operated at low energies. The fabrication technique, denoted a reactive ion beam sputter deposition (RIBSD), was based on sputtering a graphite target at low incident angles and positioning the substrate at the grazing angles to the incoming ions, thus the incident ions (Ar and Xe ions were used) were simultaneously bombarding the target and the growing film. The effect of angle of incidence of an ion beam to the target and to the substrate in creating the sp3 content in DLC was investigated.  It was found that the infringement bombardment of the substrate was not favourable for DLC growth as it essentially provided for a secondary re-sputtering process. Quality DLC films with approximately 40 % of the sp3 content were fabricated at the optimal angle of the ion flux to the target of 30&#186; and to the substrate of 0&#186; (parallel to the ion bema axis). The increased ion energy contributed to structural changes in DLC from predominantly sp2 graphitic like bonding to tetrahedral sp3 bonding arrangement.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">diamond-like carbon films, discharge plasmas</field><field name="identifier">http://eprints.qut.edu.au/17827/</field><field name="validLink">True</field></doc><doc><field name="title">Levels and patterns of genetic diversity in wild and cultured populations of mulloway (argyrosomus japonicus) using mitochondrial DNA and microsatellites</field><field name="creator">Archangi, Bita</field><field name="description">Mulloway are a large native inshore marine fish that are currently being evaluated by NSW Fisheries for their potential in aquaculture. The current study developed and applied molecular genetic markers to assess the geographical scale at which future hatcheries should be developed for the species. In addition, it evaluated the impact that current breeding practices in NSW have had on genetic diversity in culture cohorts. The study showed that wild Australian populations of this species constitute a single management unit (genetic stock), but that current hatchery practices employed in NSW are eroding natural genetic diversity. Thus a single hatchery could provide cultures stock to the whole Australian industry without compromising wild populations but that hatchery management practices will need to be modified in the future, to minimise levels of inbreeding.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">genetic diversity, Mulloway, mitochondrial DNA, microsatellites</field><field name="identifier">http://eprints.qut.edu.au/18195/</field><field name="validLink">True</field></doc><doc><field name="title">Confocal microscopic examination of the conjunctiva</field><field name="creator">Al Dossari, Munira</field><field name="description">This project has provided a better understanding of the human conjunctiva, the glistening tissue covering the white of the eye, at the cellular level.  The observations of this study may serve as a useful marker against which changes in conjunctival tissue due to disease, surgery, drug therapy or contact lens wear can be assessed.
 Laser scanning confocal microscopy was used to observe and measure characteristics the conjunctiva of healthy human volunteer subjects. It was concluded that this technique is a powerful tool for studying the human conjunctiva and assessing key aspects of the structure of this tissue.  The effects of contact lens wear on the conjunctiva can be investigated effectively at a cellular level using this technology.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">confocal microscopy, conjunctiva, contact lenses, bulbar conjunctiva, palpebral conjunctiva, Langerhans cells, goblet cells</field><field name="identifier">http://eprints.qut.edu.au/18316/</field><field name="validLink">True</field></doc><doc><field name="title">Reducing uncertainty in new product development</field><field name="creator">Higgins, Paul Anthony</field><field name="description">Research and Development engineering is at the corner stone of humanity&#8217;s evolution. It is perceived to be a systematic creative process which ultimately improves the living standard of a society through the creation of new applications and products. The commercial paradigm that governs project selection, resource allocation and market penetration prevails when the focus shifts from pure research to applied research. Furthermore, the road to success through commercialisation is difficult for most inventors, especially in a vast and isolated country such as Australia which is located a long way from wealthy and developed economies. 
 
 While market leading products are considered unique, the actual process to achieve these products is essentially the same; progressing from an idea, through development to an outcome (if successful). Unfortunately, statistics indicate that only 3% of &#8216;ideas&#8217; are significantly successful, 4% are moderately successful, and the remainder &#8216;evaporate&#8217; in that form (Michael Quinn, Chairman, Innovation Capital Associates Pty Ltd). 
 This study demonstrates and analyses two techniques developed by the author which reduce uncertainty in the engineering design and development phase of new product development and therefore increase the probability of a successful outcome. This study expands the existing knowledge of the engineering design and development stage in the new product development process and is couched in the identification of practical methods, which have been successfully used to develop new products by Australian Small Medium Enterprise (SME) Excel Technology Group Pty Ltd (ETG). 
 Process theory is the term most commonly used to describe scientific study that identifies occurrences that result from a specified input state to an output state, thus detailing the process used to achieve an outcome. The thesis identifies relevant material and analyses recognised and established engineering processes utilised in developing new products. The literature identified that case studies are a particularly useful method for supporting problem-solving processes in settings where there are no clear answers or where problems are unstructured, as in New Product Development (NPD). 
 This study describes, defines, and demonstrates the process of new product development within the context of historical product development and a &#8216;live&#8217; case study associated with an Australian Government START grant awarded to Excel Technology Group in 2004 to assist in the development of an image-based vehicle detection product.  This study proposes two techniques which reduce uncertainty and thereby improve the probability of a successful outcome.  
 The first technique provides a predicted project development path or forward engineering plan which transforms the initial &#8216;fuzzy idea&#8217; into a potential and achievable outcome. This process qualifies the &#8216;fuzzy idea&#8217; as a potential, rationale or tangible outcome which is within the capability of the organisation. Additionally, this process proposes that a tangible or rationale idea can be deconstructed in reverse engineering process in order to create a forward engineering development plan. A detailed structured forward engineering plan reduces the uncertainty associated with new product development unknowns and therefore contributes to a successful outcome. This is described as the RETRO technique. The study recognises however that this claim requires qualification and proposes a second technique.  
 The second technique proposes that a two dimensional spatial representation which has productivity and consumed resources as its axes, provides an effective means to qualify progress and expediently identify variation from the predicted plan. This spatial representation technique allows a quick response which in itself has a prediction attribute associated with directing the project back onto its predicted path. This process involves a coterminous comparison between the predicted development path and the evolving actual project development path. A consequence of this process is verification of progress or the application of informed, timely and quantified corrective action. This process also identifies the degree of success achieved in the engineering design and development phase of new product development where success is defined as achieving a predicted outcome. This spatial representation technique is referred to as NPD Mapping.  The study demonstrates that these are useful techniques which aid SMEs in achieving successful new product outcomes because the technique are easily administered, measure and represent relevant development process related elements and functions, and enable expedient quantified responsive action when the evolving path varies from the predicted path. These techniques go beyond time line representations as represented in GANTT charts and PERT analysis, and represent the base variables of consumed resource and productivity/technical achievement in a manner that facilitates higher level interpretation of time, effort, degree of difficulty, and  product complexity in order to facilitate informed decision making. This study presents, describes, analyses and demonstrates an SME focused engineering development technique, developed by the author, that produces a successful new product outcome which begins with a &#8216;fuzzy idea&#8217; in the mind of the inventor and concludes with a successful new product outcome that is delivered on time and within budget.  Further research on a wider range of SME organisations undertaking new product development is recommended.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">new product development, technical specification development, product development specification, NPD Map, RETRO, process engineering, linear process, concurrent process, adaptive process, research and development, R&amp;D, design and development</field><field name="subject">engineering process, engineering development, forward engineering, reverse engineering, new product concept, fuzzy idea, innovative idea, product complexity, degree of difficulty, SME, Startup, Excel Technology Group, ETG, QUT, PERT, GANTT</field><field name="subject">spatial representation, predicted development plan, alignment theory, process theory, milestone, performance measurement, quantifying design and development engineering, technical achievement, consumed resource, self learning, compounding knowledge, QA</field><field name="subject">quality management, technical specification, informed decision making, spatial variation, responsive action, spinoff project, vehicle detection, technical risk, non-existent rational outcome, process review, video detector, image-based vehicle detector</field><field name="identifier">http://eprints.qut.edu.au/20273/</field><field name="validLink">True</field></doc><doc><field name="title">The use of technology to automate the registration process within the Torrens system and its impact on fraud : an analysis</field><field name="creator">Low, Rouhshi</field><field name="description">Improvements in technology and the Internet have seen a rapid rise in the use of technology in various sectors such as medicine, the courts and banking. The conveyancing sector is also experiencing a similar revolution, with technology touted as able to improve the effectiveness of the land registration process. In some jurisdictions, such as New Zealand and Canada, the paper-based land registration system has been replaced with one in which creation, preparation, and lodgement of land title instruments are managed in a wholly electronic environment. In Australia, proposals for an electronic registration system are under way. The research question addressed by this thesis is what would be the impact on fraud of automating the registration process. This is pertinent because of the adverse impact of fraud on the underlying principles of the Torrens system, particularly security of title. This thesis first charts the importance of security of title, examining how security of title is achieved within the Torrens system and the effects that fraud has on this. Case examples are used to analyse perpetration of fraud under the paper registration system. Analysis of functional electronic registration systems in comparison with the paper-based registration system is then undertaken to reveal what changes might be made to conveyancing practices were an electronic registration system implemented. Whether, and if so, how, these changes might impact upon paper based frauds and whether they might open up new opportunities for fraud in an electronic registration system forms the next step in the analysis. The final step is to use these findings to propose measures that might be used to minimise fraud opportunities in an electronic registration system, so that as far as possible the Torrens system might be kept free from fraud, and the philosophical objectives of the system, as initially envisaged by Sir Robert Torrens, might be met.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Torrens system, fraud, internet, information technology, computer security, Internet security, identity fraud - conveyancing, registration process, land registration system, National Electronic Conveyancing System, NECS, digital signatures</field><field name="subject">security of title, electronic registration system, public key cryptography, public key infrastructure, digital certificates, indefeasibility of title</field><field name="identifier">http://eprints.qut.edu.au/18301/</field><field name="validLink">True</field></doc><doc><field name="title">Blue Horses and Illuminating the Shadow : a novel manuscript and exegesis</field><field name="creator">Bongers, Christine Mary</field><field name="description">The novel manuscript Blue Horses (published as Dust, by Random House Australia under its Woolshed Press Imprint, July 2009) focuses on a dusty corner of 1970&#8217;s Queensland in this evocative tale of family, shadows that hang over from childhood and beauty found in unexpected places.  Its protagonist, Cecilia Maria, was named after saints and martyrs to give her something to live up to. &#8220;Over my dead body,&#8221; she vows. Her battles with a six-pack of brothers and the despised Kapernicke girls from the farm next door teach her an unforgettable lesson that echoes down through the years. Now she&#8217;s heading back to where it all began, with teenagers Jed and Jenna reluctantly in tow. She plans to dance on a grave and track down some ghosts. Instead she learns a new lesson at the gravesite of an old enemy.
 The exegesis examines Jung&#8217;s concept of the Shadow Archetype as a catalyst for individuation in writing for young adults. It discusses the need to re-vision Jung&#8217;s work within a feminist framework and contrasts it to Julia Kristeva&#8217;s work on the abject. Alyssa Brugman&#8217;s Walking Naked and Sonya Hartnett&#8217;s Sleeping Dogs are analysed in relation to these concepts and lead into my own creative reflections on, and justification for, use of the Shadow conceptual framework. In following my shadow and establishing a creative dialogue between my conscious intent and unconscious inspirations, I have discovered a writing self that is &#8220;other&#8221; to the professional writer persona of my past.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Carl Gustav Jung, shadow archetype, individuation, collective unconscious, Julia Kristeva, abject, young adult literature, creative writing, thesis, masters</field><field name="identifier">http://eprints.qut.edu.au/18312/</field><field name="validLink">True</field></doc><doc><field name="title">Novel methodologies for three-dimensional modelling of subject specific biomechanics : application to lumbopelvic mechanics in sitting and standing</field><field name="creator">Cargill, Sara C.</field><field name="description">This project presented a biomechanical model of the lumbosacral spine and pelvis, including novel methodologies associated with the measurement of human mechanics. This research has, for the first time, produced accurate three-dimensional geometric models of the human skeleton from living subjects using magnetic resonance imaging technology, enabling the prediction of physiological muscle action within individuals.
 The model was used to examine changes in the mechanics of the lumbopelvic musculoskeletal system between the standing and seated postures due to the increasing prevalence of the seated posture in the work and home environment.
 The outcomes of this research included a novel bone wrapping algorithm used to describe the effect of muscle-bone interactions. a novel method for creating three-dimensional in vivo spinal reconstructions using MRI, three dimensional in vivo helical axis measurements and subject specific normalised moment data.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">biomechanical modelling, spine, pelvis, joint rotation, positional MRI seated posture, wrapping, muscle line of action, lumbar</field><field name="identifier">http://eprints.qut.edu.au/18321/</field><field name="validLink">True</field></doc><doc><field name="title">Innovation implementation effectiveness : a multiorganizational test of Klein Conn and Sorra's model</field><field name="creator">Sawang, Sukanlaya</field><field name="description">Implementing innovations is a challenging, high-risk task for many organizations. Dr Sawang examines the implementation of various innovations in manufacturing and non-manufacturing contexts. This thesis used the current best practice in structural equation modelling techniques to empirically test the model of implementation effectiveness in both Australian and Thai firms. Commitment from top managers, provision of implementation policies and practices, positive climate and skilful and talented staff enhanced successful implementation. Dr Sawang&#8217;s research contributes to a more rigorously tested and comprehensive model of implementation effectiveness.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">innovation, implementation, effectiveness, multiorganizational test, Klein Conn, Sorra, model</field><field name="identifier">http://eprints.qut.edu.au/18323/</field><field name="validLink">True</field></doc><doc><field name="title">Dan Kelly danced into the shadows : large-scale personas in small-scale stories</field><field name="creator">Acworth, Elaine Elizabeth</field><field name="description">Using an analysis of the creation of the character Dan Kelly in my play, risk, I argue that fairytale characters work as more than personage representations.  They function on a big canvas for the audience; they carry large chains of association.  Given this, I then propose that the human response is to infer additional meaning, meaning beyond the scope of plot and immediate character interaction - the audience infers symbolic meaning, &#8216;amplifying&#8217; what is there into more.  They enter a &#8216;generative empty space&#8217; within the play where they infer or &#8216;unfold&#8217; more meaning.  In creating this &#8216;greater tale&#8217;, they are engaged beyond their personal &#8216;horizon of understanding&#8217;, and so, &#8216;take in&#8217; the work through a heightened perceptual acuity.
 
 Therefore, I pursued the idea of making space for the operation of this process, of leveraging the creation of meaning around a character.  My inquiry led me to believe that a powerful way to do this was through absence rather than presence and silence rather than sound; and this had a profound impact on my choice of form for Dan Kelly: he progressed, through a number of stages, from reportage to a digital representation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">theatre, fairytale, psychological function of fairytales, socio-historical context of fairytales, Bruno Bettelheim, Jack Zipes, chains of association, Jung&#8217;s amplification, amplification of meaning, unfold more meaning, Entviklungsfahigkeit</field><field name="subject">audience co-creation, &#8216;horizon of understanding&#8217;, narrative function, Vladimir Propp, digital representation, liminality, Victor Turner</field><field name="identifier">http://eprints.qut.edu.au/18342/</field><field name="validLink">True</field></doc><doc><field name="title">The query based learning system for lifetime prediction of metallic components</field><field name="creator">Ge, Esther</field><field name="description">This research project was a step forward in developing an efficient data mining method for estimating the service life of metallic components in Queensland school buildings. The developed method links together the different data sources of service life information and builds the model for a real situation when the users have information on limited inputs only. A practical lifetime prediction system was developed for the industry partners of this project including Queensland Department of Public Works and Queensland Department of Main Roads. The system provides high accuracy in practice where not all inputs are available for querying to the system.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">data mining, learning system, predictive model, lifetime prediction, corrosion prediction, feature selection, civil engineering</field><field name="identifier">http://eprints.qut.edu.au/18345/</field><field name="validLink">True</field></doc><doc><field name="title">From the refrigerator door to the art gallery floor : young children's experiences with the display of their own visual artwork</field><field name="creator">Boone, Danielle J.</field><field name="description">The practice of displaying young children&#8217;s visual artwork in early childhood classrooms poses a number of questions about the child and his or her work. Following Giorgi&#8217;s approach to phenomenological research, this thesis focused on children&#8217;s lived experiences of art display. 13 children between the ages of 4 and 6 years attending an independent school outside metropolitan Detroit, Michigan (USA) disclosed their experiences of seeing their artwork on display.  Dr Boone&#8217;s study revealed that, despite clear evidence of children&#8217;s strong views, decisions about the display of artwork continue to rest with adults.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">early childhood, young child, art, art education, children&#8217;s art, artwork display, early childhood education, phenomenology, existential phenomenological psychology</field><field name="identifier">http://eprints.qut.edu.au/18346/</field><field name="validLink">True</field></doc><doc><field name="title">Hydrogeology and groundwater flow model, central catchment of Bribie Island, Southeast Queensland</field><field name="creator">Jackson, Joanne M.</field><field name="description">Bribie Island is a large, heterogeneous, sand barrier island that contains groundwater aquifers of commercial and environmental significance. Population growth has resulted in expanding residential developments and consequently increased demand for water. Caboolture Shire Council (CSC) has proposed to increase groundwater extraction by a new borefield. Two aquifers exist within the Quaternary sandmass which are separated by an indurated sand layer that is ubiquitous in the area. A shallow aquifer occurs in the surficial, clean sands and is perched on the indurated sands. Water levels in the shallow water table aquifer follow the topography and groundwater occurs under unconfined conditions in this system. A basal aquifer occurs beneath the indurated sands, which act as a semi-confining layer in the island system. The potentiometric surface of the basal aquifer occurs as a gentle groundwater mound. The shallow groundwater system supports water-dependent ecosystems including wetlands, native woodlands and commercial pine plantations. Excessive groundwater extraction could lower the water table in the shallow aquifer to below the root depth of vegetation on the island. Groundwater discharge along the coastline is essential to maintain the position of the saline water - fresh groundwater boundary in this island aquifer system. Any activity that changes the volume of fresh water discharge or lowers the water table or potentiometric surface below sea level will result in a consequent change in the saline water &#8211; freshwater interface and could lead to saline water intrusion. Groundwater level data was compared with the residual rainfall mass curve (RRMC) on hydrographs, which revealed that the major trends in groundwater levels are related to rainfall. Bribie Island has a sub-tropical climate, with a mean annual rainfall of around 1358mm/year (Bongaree station). Mean annual pan evaporation is around 1679mm/year and estimates of the potential evapotranspiration rates range from 1003 to 1293mm/year. Flows from creeks, the central swale and groundwater discharged from the area have the potential to affect water quality within the tidal estuary, Pumicestone Passage. Groundwater within the island aquifer system is fresh with electrical conductivity ranging from 61 to 1018&#236;S/cm while water near the coast, canals or tidal creeks is brackish to saline (1596 to 34800&#236;S/cm). Measurements of pH show that all groundwater is acidic to slightly acidic (3.3-6.6), the lower values are attributed to the breakdown of plant material into organic acids.
 Groundwater is dominated by Na-Cl type water, which is expected in a coastal island environment with Na-Cl rainfall. Some groundwater samples possess higher concentrations of calcium and bicarbonate ions, which could be due to chemical interactions with buried shell beds while water is infiltrating to depth and due to the longer residence times of groundwater in the basal aquifer. A steady-state, sub-regional groundwater flow model was developed using the Visual MODFLOW computer package. The 4 layer, flow model simulated the existing hydrogeological system and the dominant groundwater processes controlling groundwater flow. The numerical model was calibrated against existing data and returned reasonable estimates of groundwater levels and hydraulic parameters. The model illustrated that: .. The primary source of groundwater recharge is infiltration of rainfall for the upper, perched aquifer (Layer 1). Recharge for the lower sand layers is via vertical leakage from the upper, perched aquifer, through the indurated sands (Layers 2 and 3) to the semi-confined, basal aquifer (Layer 4). .. The dominant drainage processes on Bribie Island are evapotranspiration (15070m3/day) and groundwater seepage from the coast, canals and tidal creeks (9512m3/day). Analytical calculations using Darcy&#8217;s Law estimated that approximately 8000m3/day of groundwater discharges from central Bribie Island, approximately 16% less than the model. .. As groundwater flows preferentially toward the steepest hydraulic gradient, the main direction of horizontal groundwater flow is expected to be along an eastwest axis, towards either the central swale or the coastline. The central swale was found to act as a groundwater sink in the project area.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">hydrogeology, groundwater, flow model, central catchment, Bribie Island, Southeast Queensland</field><field name="identifier">http://eprints.qut.edu.au/18347/</field><field name="validLink">True</field></doc><doc><field name="title">A dark new world : anatomy of Australian horror films</field><field name="creator">Ryan, Mark David</field><field name="description">After experimental beginnings in the 1970s, a commercial push in the 1980s, and an underground existence in the 1990s, from 2000 to 2007 contemporary Australian horror production has experienced a period of strong growth and relative commercial success unequalled throughout the past three decades of Australian film history. This study explores the rise of contemporary Australian horror production: emerging production and distribution models; the films produced; and the industrial, market and technological forces driving production. Australian horror production is a vibrant production sector comprising mainstream and underground spheres of production. Mainstream horror production is an independent, internationally oriented production sector on the margins of the Australian film industry producing titles such as Wolf Creek (2005) and Rogue (2007), while underground production is a fan-based, indie filmmaking subculture, producing credit-card films such as I know How Many Runs You Scored Last Summer (2006) and The Killbillies (2002). Overlap between these spheres of production, results in &#8216;high-end indie&#8217; films such as Undead (2003) and Gabriel (2007) emerging from the underground but crossing over into the mainstream. Contemporary horror production has been driven by numerous forces, including a strong worldwide market demand for horror films and the increasing international integration of the Australian film industry; the lowering of production barriers with the rise of digital video; the growth of niche markets and online distribution models; an inflow of international finance; and the rise of international partnerships. In light of this study, a &#8216;national cinema&#8217; as an approach to cinema studies needs reconsideration &#8211; real growth is occurring across national boundaries due to globalisation and at the level of genre production rather than within national boundaries through pure cultural production. Australian cinema studies &#8211; tending to marginalise genre films &#8211; needs to be more aware of genre production. Global forces and emerging distribution models, among others, are challenging the &#8216;narrowness&#8217; of cultural policy in Australia &#8211; mandating a particular film culture, circumscribing certain notions of value and limiting the variety of films produced domestically.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Australian horror films, horror films, horror genre, movie genres, globalisation of film production, internationalisation, Australian film industry, independent film, fan culture</field><field name="subject">Mark Ryan</field><field name="identifier">http://eprints.qut.edu.au/18351/</field><field name="validLink">True</field></doc><doc><field name="title">Neo-dandy : wearability, design innovation and the formal white dress shirt for men</field><field name="creator">Brough, Dean McGregor</field><field name="description">This practice-led research creates innovative menswear designs for formal white dress shirts, within boundaries of contemporary mainstream wearability. As a result of an historical analysis, a conceptual spectrum is developed to scope the possibilities of the contemporary white dress shirt, from the orthodox menswear shirt to the many variations of the women&#8217;s blouse. Within this spectrum for the white shirt, the possibilities for innovation are discussed in terms of a threshold position between the shirt and the blouse - a position that parallels that of the dandy figure who subversively confronts dress norms of the day. This position is then explored in relation to an acceptable/ &#8216;wearable&#8217; aesthetic which I have labelled &#8216;Neo-Dandy&#8217;. White shirts from contemporary menswear designers are then examined relative to this aesthetic. In doing so, this examination highlights the white dress shirt as a garment that is ripe for experimentation. My own creative design process is then described as taking up the challenge of Neo-Dandy design innovation for the contemporary white dress shirt. On this archetypal garment, different styles and varying degrees of detailing were tested. A range of &#8216;concept shirts&#8217; were produced, tested and documented, with each shirt succeeding to various degrees in achieving a Neo-Dandy aesthetic. Based on this range, a list of design principles for achieving this aesthetic are identified. The weighting is 60% for the design objects (a collection of men&#8217;s white dress shirts that explore wearability and design innovation within a Neo-Dandy aesthetic) and 40% for the design discussion (exegesis and supporting appendices).</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">fashion, design, menswear, dress shirt, white shirt, blouse, wearability, practiceled research, innovation, Neo-Dandy, dandy, gendered object</field><field name="identifier">http://eprints.qut.edu.au/18355/</field><field name="validLink">True</field></doc><doc><field name="title">Power network in the loop : subsystem testing using a switching amplifier</field><field name="creator">Goyal, Sachin</field><field name="description">&#8220;Hardware in the Loop&#8221; (HIL) testing is widely used in the automotive industry. The sophisticated electronic control units used for vehicle control are usually tested and evaluated using HIL-simulations. The HIL increases the degree of realistic testing of any system. Moreover, it helps in designing the structure and control of the system under test so that it works effectively in the situations that will be encountered in the system. Due to the size and the complexity of interaction within a power network, most research is based on pure simulation. To validate the performance of physical generator or protection system, most testing is constrained to very simple power network. This research, however, examines a method to test power system hardware within a complex virtual environment using the concept of the HIL. The HIL testing for electronic control units and power systems protection device can be easily performed at signal level. But performance of power systems equipments, such as distributed generation systems can not be evaluated at signal level using HIL testing. The HIL testing for power systems equipments is termed here as &#8216;Power Network in the Loop&#8217; (PNIL). PNIL testing can only be performed at power level and requires a power amplifier that can amplify the simulation signal to the power level. A power network is divided in two parts. One part represents the Power Network Under Test (PNUT) and the other part represents the rest of the complex network. The complex network is simulated in real time simulator (RTS) while the PNUT is connected to the Voltage Source Converter (VSC) based power amplifier. Two way interaction between the simulator and amplifier is performed using analog to digital (A/D) and digital to analog (D/A) converters. The power amplifier amplifies the current or voltage signal of simulator to the power level and establishes the power level interaction between RTS and PNUT. In the first part of this thesis, design and control of a VSC based power amplifier that can amplify a broadband voltage signal is presented. A new Hybrid Discontinuous Control method is proposed for the amplifier. This amplifier can be used for several power systems applications. In the first part of the thesis, use of this amplifier in DSTATCOM and UPS applications are presented. In the later part of this thesis the solution of network in the loop testing with the help of this amplifier is reported. The experimental setup for PNIL testing is built in the laboratory of Queensland University of Technology and the feasibility of PNIL testing has been evaluated using the experimental studies. In the last section of this thesis a universal load with power regenerative capability is designed. This universal load is used to test the DG system using PNIL concepts. This thesis is composed of published/submitted papers that form the chapters in this dissertation. Each paper has been published or submitted during the period of candidature. Chapter 1 integrates all the papers to provide a coherent view of wide bandwidth switching amplifier and its used in different power systems applications specially for the solution of power systems testing using PNIL.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">DSTATCOM, discontinuous current, hybrid control, LC output filter, UPS, power flow control, real-time simulator, hardware-software simulation, VSC, harmonics, bandwidth, virtual grid and universal load</field><field name="identifier">http://eprints.qut.edu.au/26521/</field><field name="validLink">True</field></doc><doc><field name="title">Young children's social organisation of peer interactions</field><field name="creator">Cobb-Moore, Charlotte</field><field name="description">Young children&#8217;s peer interactions involve their use of interactional resources to organise, manage and participate in their social worlds. Investigation of children&#8217;s employment of interactional resources highlights how children participate in peer interaction and their social orders, providing insight into their active construction and management of their social worlds. Frequently, these interactions are described by adults as &#8216;play&#8217;. The term play is often used to describe children&#8217;s activities in early childhood education, and constructed in three main ways: as educative, as enjoyable, and as an activity of children. Play in educational settings is often constructed, and informed by, adult agendas such as learning and is often part of the educational routine. This study shows how children work with a different set of agendas to those routinely ascribed by adults, as they actively engage with local education orders, and use play for their own purposes as they construct their own social orders. By examining children&#8217;s peer interactions, and not describing these activities as play, the focus becomes the construction and organisation of their social worlds. In so doing, this study investigates some interactional resources that children draw upon to manage their social orders and organise their peer interactions.
 
 This study was conducted within an Australian, non-government elementary school. The participants were children in a preparatory year classroom (children aged 4 &#8211; 6 years). Over a one month period, children&#8217;s naturally occurring peer interactions within &#8216;free play&#8217; were video-recorded. Selected video-recorded episodes were transcribed and analysed, using the approaches of ethnomethodology, conversation analysis and membership categorization analysis. These methodologies focus on everyday, naturalistic data, examining how participants orient to and produce social action. The focus is on the members&#8217; perspectives, that of the children themselves, as they interact. Ethnomethodology, conversation analysis and membership categorization analysis allow for in-depth examination of talk and action, and are used in this study to provide a detailed account of the children&#8217;s interactional strategies. 
 
 Analysis focused on features of children&#8217;s situated peer interaction, identifying three interactional resources upon which the children drew as they constructed, maintained, and transformed their social orders. The interactional resources included: justification; category work, in particular the category of mother; and the pretend formulation of place. The children used these interactional resources as a means of managing peer participation within interactions. First, the children used justification to provide reasons for their actions and to support their positions. Justifications built and reinforced individual children&#8217;s status, contributing to the social organisation of their peer group. Second, the children negotiated and oriented to categories within the pretend frame of &#8216;families&#8217;. The children&#8217;s talk and actions jointly-constructed the mother category as authoritative, enabling the child, within the category of mother, to effectively organise the interaction. Third, pretense was used by the children to negotiate and describe places, thus enabling them to effectively manage peer activity within these places. For a successful formulation of a place as something other than it actually was, the children had to work to produce shared understandings of the place. Examining instances of pretense demonstrated the highly collaborative nature of the children&#8217;s peer interactions.
 
 The study contributes to sociological understandings of childhood. By analysing situated episodes of children&#8217;s peer interaction, this study contributes empirical work to the sociology of childhood and insight into the interactional work of children organising their social worlds. It does this by closely analysing social interactions, as they unfold, among children. This study also makes a methodological contribution, using ethnomethodology, conversation analysis, and membership categorization analysis in conjunction to analyse children&#8217;s peer interactions in an early childhood setting. In so doing, the study provides alternative ways for educators to understand children&#8217;s interactions. For example, adult educational agendas, such as the educative value of play, can be applied to examine children&#8217;s family play, highlighting the learning opportunities provided through pretend role play, or indicating children&#8217;s understanding of adult roles. Alternatively, the children&#8217;s interaction could be subjected to fine-grained analysis to explicate how children construct shared understandings of the category of mother and use it to organise their interaction. Rather than examining the interaction to discern what children are learning, the interaction is examined with a focus on how children are accomplishing everyday social practices. Close analysis of children&#8217;s everyday peer interaction enables the complex interactional work of managing, and participating in, social order within an early childhood setting to be explicated. This offers educators insight into children&#8217;s social worlds, described not as play, but as the construction and negotiation of social order.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">children, early years, peer interaction, social interaction, talk, gesture, social order, ethnomethodology, conversation analysis, membership categorization analysis, sociology of childhood, justification, place formulation, mother category, pretend</field><field name="subject">authority, play</field><field name="identifier">http://eprints.qut.edu.au/18357/</field><field name="validLink">True</field></doc><doc><field name="title">Constructing and fracturing alliances : actant stories and the Australian xenotransplantation network</field><field name="creator">Cook, Peta S.</field><field name="description">Xenotransplantation (XTP; animal-to-human transplantation) is a controversial technology of contemporary scientific, medical, ethical and social debate in Australia and internationally. The complexities of XTP encompass immunology, immunosuppression, physiology, technology (genetic engineering and cloning), microbiology, and animal/human relations. As a result of these controversies, the National Health and Medical Research Council (NHMRC), Australia, formed the Xenotransplantation Working Party (XWP) in 2001. The XWP was designed to advise the NHMRC on XTP, if and how it should proceed in Australia, and to provide draft regulatory guidelines. During the period 2001-2004, the XWP produced three publicly available documents one of which, &#8216;Animal-to-Human Transplantation Research: A Guide for the Community&#8217; (2003), was specifically designed to introduce the general public to the major issues and background of XTP. This thesis examines XTP in Australia as guided and influenced by this community document. Explicitly, drawing upon actor (actant)- network theory, I will reveal the Australian XTP network and explore, describe and explain XTP problematisations and network negotiations by the enrolled actants on two key concepts and obligatory passage points - animals and risk. These actants include those providing regulatory advice (members of the XWP and the associated Animal Issues Subcommittee), those developing and/or critiquing XTP (official science and scientists), and those targeted by the technology (people on dialysis, with Type-1 diabetes, Huntington&#8217;s disease, Parkinson&#8217;s disease, pre-or post-human-tohuman transplantation, and their partner/spouse). The stories are gathered through focus groups, semi-structured interviews and document analysis. They reveal ambiguous and sometimes contradictory stories about animals and risk, which influence and impact the problematisations of XTP and its networks. Therefore, XTP mobilises tension; facilitating both support and apprehension of the XTP network and its construction by both the sciences and the publics.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">sociology, xenotransplantation, transplantation, allotransplantation, actor-network theory, science and technology studies, public understanding of science (PUS), critical public understanding of science (critical PUS), scientific knowledge</field><field name="subject">public consultation, risk, animals</field><field name="identifier">http://eprints.qut.edu.au/18359/</field><field name="validLink">True</field></doc><doc><field name="title">The male fashion bias</field><field name="creator">Neighbour, Mark Lyle</field><field name="description">Since the establishment of the first European fashion houses in the nineteenth century the male wardrobe has been continually appropriated by the fashion industry to the extent that every masculine garment has made its appearance in the female wardrobe. For the womenswear designer, menswear&#8217;s generic shapes are easily refitted and restyled to suit the prevailing fashionable silhouette. This, combined with a wealth of design detail and historical references, provides the cyclical female fashion system with an endless supply of &#8220;regular novelty&#8221; (Barthes, 2006, p.68). Yet, despite the wealth of inspiration and technique across both male and female clothing, the bias has largely been against menswear, with limited reciprocal benefit. Through an exploration of these concepts I propose to answer the question; how can I use womenswear patternmaking and construction technique to implement change in menswear design?</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">male fashion, clothing design, gender, tailoring, clothing construction, dress reform, innovation, design process , contemporary menswear, fashion exhibition</field><field name="identifier">http://eprints.qut.edu.au/18362/</field><field name="validLink">True</field></doc><doc><field name="title">Troubling empowerment: An evaluation and critique of a feminist action research project involving rural women and interactive communication technologies</field><field name="creator">Lennie, June</field><field name="description">Participatory research methodologies and the use of interactive communication technologies (ICTs) such as email are increasingly seen by many researchers, including feminists, as offering ways to enhance women&#8217;s inclusion, participation and empowerment. However, from critical and poststructuralist perspectives, some researchers suggest the need for greater caution about claims that participatory methodologies and certain communication technologies automatically enhance inclusion and empowerment. These researchers argue that issues of power, agenda and voice in the research context require greater attention (LeCompte, 1995). The major argument made in this thesis is that feminist researchers need to adopt a more critical and rigorous yet pragmatic approach to evaluating women&#8217;s empowerment, inclusion and participation, and that this approach needs to include an analysis of diversity and difference, macro and micro contexts, power-knowledge relations, and the contradictory effects of participation. The outcomes of this study suggest that this approach can create new knowledge and understanding that will enable the development of more effective strategies for women&#8217;s empowerment and inclusion. To explore and support this argument, findings are presented from a detailed evaluation and critique of a major feminist action research project that involved women in rural, regional and remote Queensland, Australia and elsewhere, a university research team and several government and industry partners. The project made extensive use of ICTs, including email and the Internet, and aimed to be empowering and inclusive. Given the many contradictory discourses of empowerment that currently circulate, empowerment is seen as a problematic concept. The multiple meanings and discourses of empowerment are therefore identified and considered in the analysis. With the increasing importance of communication technologies in rural community development, this study also evaluates the effectiveness of ICTs as a medium for empowering rural women. The &#8216;politics of difference&#8217; (Young, 1990) that underpins attempts to include a diversity of rural women in feminist research projects presents many challenges to feminist praxis. Chapters 1 and 2 propose that, in evaluating such projects, researchers need to take diversity and difference into account to avoid reproducing stereotyped images of rural women, and to identify those who are included and excluded. This is because of the complex nature of the identity &#8216;rural woman&#8217;, the multiple barriers to women&#8217;s participation, and the diverse needs, agendas and ideologies of participants and stakeholders. The concept of seriality (Young, 1994) is used in this study to avoid reproducing &#8216;rural women&#8217; and feminist researchers as women with a singular identity. Chapters 1 and 2 argue that a comprehensive and critical analysis of these complex issues requires an eclectic, transdisciplinary approach, and that this can be fruitfully achieved by using a combination of two feminist frameworks of theory and epistemology: praxis feminism and feminist poststructuralism. While there are commonalities between these frameworks, the feminist poststructuralist framework takes a much more cautious and critical approach to claims for empowerment than praxis feminism. The praxis feminist framework draws on feminist theories that view power as social, cooperative and enabling. Women&#8217;s diverse needs, values, issues and experiences are taken into account, and the analysis aims to gives voice to women. The purpose of this is to better understand the processes that meet women&#8217;s diverse needs and could be empowering and inclusive for women (or otherwise). In contrast, the feminist poststructuralist framework uses Foucault&#8217;s (1980) analytic of power as positive and strategic, exercised in all our interactions, and intimately connected to knowledge. The power-knowledge relations, and the multiple and shifting discourses and subject positions that were taken up in various research contexts are identified and analysed. The purpose of this is to highlight the contradictions and dangers inherent in feminist practices of empowerment that often go unnoticed. To achieve its practical and critical aims, this study uses two different, but complementary, research methodologies: participatory feminist evaluation and feminist deconstructive ethnography, and multiple research methods, which are outlined in Chapter 3. This eclectic approach is argued to provide maximum flexibility and creativity in the research process, and to enable the complexity and richness of the data to be represented and understood from a diversity of perspectives. Triangulation of the multiple methods and sources of data is employed to increase the validity and rigour of the analysis. Assessing how well feminist projects that use ICTs have met the aim of including a diversity of women requires an analysis of a wide range of complex social, economic, cultural, technological, contextual and methodological issues related to women&#8217;s participation. Analysing these issues also requires giving voice to a diversity of participants&#8217; and stakeholders&#8217; assessments and meanings of &#8216;diversity&#8217; and &#8216;inclusion&#8217;. The results of this analysis, set out in Chapter 4, suggest that differences in perceptions of diversity and inclusion are strongly related to participants&#8217; and stakeholders&#8217; political and ideological beliefs and values, and their degree of commitment to social justice issues. The evaluation found that a limited diversity of women participated in the project, and identified many barriers to their participation. Feminists argue that women-only activities are often more empowering than mixed gender activities. The evaluation findings detailed in Chapter 5 suggest that the project&#8217;s women-centred activities, particularly the workshops and online groups, were very successful in meeting the multiple needs of most participants. However, contradictory or undesirable effects of the project&#8217;s activities were also identified. This analysis demonstrates the need to consider the various groups of participants and their diverse needs in assessing how well feminist methods and activities have met women&#8217;s needs or are empowering. Chapter 6 identifies various forms and features of empowerment and disempowerment and categorises them as social, technological, political and psychological. A model is developed that illustrates the interrelationships between these four forms of empowerment. Technological empowerment is identified as a new under-theorised form of empowerment that is seen as increasingly important as ICTs become more central to women&#8217;s networking and participation. However, the findings suggest that the extent to which participants want to be empowered needs to be respected. While many participants were found to have experienced the four forms of empowerment, their participation was also shown to have had various disempowering effects. The project&#8217;s online group welink (women&#8217;s electronic link), which linked rural and urban women, including government policy-makers, was assessed as the most empowering project activity. The discourse analysis and deconstructions, undertaken in Chapter 6, identify competing and contradictory discourses of new communication technologies and feminist participatory action research. The various discourses taken up by the researchers and participants were shown to have both empowering and disempowering effects. The analysis demonstrates the intersection between empowerment and disempowerment and the shifting subject positions that were taken up, depending on the research context. It was argued that the discourses of feminist action research operated as a &#8216;regime of truth&#8217; (Foucault, 1980) that regulated and constrained the discourses and practices of this form of research. An analysis of a highly contentious welink discussion challenges feminist assumptions that giving voice to women will lead to empowerment, and suggests that silence can, in some circumstances, be empowering. This analysis highlights the intersection of voice and silence, the limitations of the gendered discourse of care and connection, and how this discourse, and other factors, regulated the use of more critical discourses. Critical reflections on the study are made in Chapter 7. They include the suggestion that an &#8216;impossible burden&#8217; was placed on the project&#8217;s feminist researchers who used an egalitarian feminist discourse that produced expectations of &#8216;equal relations&#8217; between participants and researchers. However, these relations had to be established in the context of a university-based project that involved senior academic, government and industry staff. Drawing on the new knowledge and understandings developed, this study proposes several principles and strategies for feminist participatory action research projects that seek the inclusion and empowerment of rural women and use ICTs. They include the suggestion that feminists need an awareness of the limits to the politics of difference discourse when power-knowledge relations are ignored. A further principle is that there is value in adopting a Foucauldian analytic of power, since this enables a better understanding of the complex, multifaceted and dynamic nature of power-knowledge relations in the research context. This approach also provides an awareness of how processes that attempt to empower will inevitably produce disempowerment at certain moments. Principles and strategies for undertaking participatory feminist evaluations are also suggested.</field><field name="date">2001</field><field name="language" /><field name="relation" /><field name="subject">deconstruction, discourse analysis, diversity and difference, empowerment, feminist action research, feminist ethnography, inclusion, interactive communication technologies, needs, participation, participatory evaluation, power, poststructuralist feminism</field><field name="subject">praxis feminism, rural women</field><field name="identifier">http://eprints.qut.edu.au/18365/</field><field name="validLink">True</field></doc><doc><field name="title">Organisational slack and industry level executive discretion</field><field name="creator">Niven, Anthony Miles</field><field name="description">This thesis examines the associations between organisational slack, that pool of actual or potential cushion of resources of an organisation, and executive discretion - the executives&#8217; latitude for strategic action. 
 
 Bourgeois and Singh (1983), George (2005), Sharfman et al. (1988) and Sharma (2000) have referred to slack as having a discretionary dimension because its &#8216;ease of recovery&#8217; varies depending on where it is gained from. For the obverse of this association, slack contributes to resource availability in the task environment and therefore executive discretion (Hambrick &amp; Finkelstein, 1987). However until now, this bi-direction association has been largely unexplored empirically. This thesis contributes to both fields by bringing them together to examine and measure aspects of these interactions. 
 
 These constructs are applied to the annual reports of U.S. firms by measuring industry level discretion using content analysis of presidents&#8217; letters to shareholders and industry average slack using financial ratios. Correlations show that industries with higher levels of slack enjoy greater industry level discretion. However the associations between slack types and industry level discretion are not uniform suggesting that the discretionary dimension of slack is influenced by the task environment and industry context. The present study replicated Keegan and Kabanoff&#8217;s (2007) method to examine slack within industries but could not extend their results to available and recoverable slack, which suggest a curvilinear relationship between potential slack and executive discretion.
 
 The limited sub-industry results offer opportunity for further research as does the idea of applying the same research question to the organisational and individual level studies of different cohorts of firms and industries. Future efforts should also improve the measurement of the slack construct.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">organisational slack, executive discretion, industry level discretion</field><field name="identifier">http://eprints.qut.edu.au/18367/</field><field name="validLink">True</field></doc><doc><field name="title">Interactions between GABAergic, dopaminergic and cholinergic neurotransmitter systems in form deprived myopic chick</field><field name="creator">Tripathy, Srikant</field><field name="description">Myopia is a refractive defect of the eye in which collimated light produces images focused in front of the retina. Myopia can be artificially induced in animal models by form deprivation (form deprivation myopia, FDM) or by application of negative lenses (lens induced myopia, LIM). In this study myopia was induced using diffusers. The project had two main aims:
 
 1.	To determine if there is an interaction between the GABAergic system and dopaminergic system in the retina in terms of myopia?
 2.	To determine if there is an interaction between the GABAergic system and cholinergic system in the retina in terms of myopia?
 
 Firstly, an experiment focusing on the interaction between dopaminergic receptors antagonists and GABAC receptor antagonist was developed. Comparison of the different drug treated eye with the control was found and the effects of combination injections were compared to individual drug injections. Use of different blockers for various subtype of receptors simplified the understandings the underlying pharmacological interventions for GABAC receptor antagonist TPMPA. The D1 subtype of receptors was found to be involved in transmission of signals from GABAC receptors. Our results showed that D1 receptor antagonist SCH-23390 antagonizes the actions of TPMPA. In addition to this it was also found that possibly 5HT receptor may also play an important role in modulation of signaling from GABA receptor to dopaminergic receptors in the retina. These results were consistent with the drug combination effects for agonists. GABA A/C receptor agonist muscimol negativate the efficacy of D1 receptor agonist SKF-38393 but the activity of D2/4 receptor agonist quinpirole was not affected by muscimol. 
 
 Although dopaminergic receptors are found to interact with GABAergic signaling, but an alternative interaction with anticholinergic (most widely studied antimyopic agents) could not be ruled out. This problem led to a follow-up experiment, in which GABA receptors intervention in anticholinergic agents was studied.
 
 The GABAergic receptor agonist muscimol when injected with anticholinergics (atropine and pirenzepine) showed a moderate interaction. As muscimol interacted with atropine to a lesser extent a more specific M1/5 receptor antagonist pirenzepine (earlier found to inhibit myopia) was used under these circumstances. The second aim to study the interaction between muscimol and pirenzepine showed more interaction with GABAA/C receptor agonist. There were data suggesting that there is a muscarinic and GABAergic interaction in retina, such that each modulation of each receptor had an effect on FDM. However, a drug combination treatment helped in understanding the underlying mechanism. Several previous studies have indicated that there exist a strong interaction between excitatory neurotransmitter acetylcholine and inhibitory transmitter GABA in retina. The results of this study indicate a similar finding. 
 
 Thus results of this study may be summarized as: 1. D1 antagonists and not D2 antagonists blocks the antimyopic effects of GABAC antagonist TPMPA 2. GABA A/C agonist muscimol partially blocks the antimyopic activity of anticholinergics (e.g. atropine and pirenzepine).</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">acetylcholine, cholinergic receptors, dopamine, dopaminergic receptors, form deprivation myopia , gamma-amino butyric acid, GABAergic receptors, refractive errors, axial length, aqueous chamber depth, lens thickness, vitreous chamber depth</field><field name="identifier">http://eprints.qut.edu.au/18385/</field><field name="validLink">True</field></doc><doc><field name="title">Second skin : Annette Kellerman, the modern swimsuit, and an Australian contribution to global fashion</field><field name="creator">Schmidt, Christine Margaret</field><field name="description">The aim of this thesis is to explore the evolution and global dissemination of fashion values, both aesthetic and commercial, in the interfaces between fashion, media, celebrity, sport, and the cultivation of the modern body. In particular, it traces the career of the modern swimsuit, showing how an inventive individual, Annette Kellerman, and a peripheral nation, Australia, influenced the design direction of the swimsuit in the 20th century and beyond to create a distinctly Australian niche in global fashion. Annette Kellerman, an Australian long-distance swimmer, diver, vaudeville performer and silent movie star, was a modern woman shaped for speed. She achieved success across a number of related fields &#8211; in fashion, film, sport, and as a role-model for women, encouraging self-motivation and self-development. Kellerman achieved global fame and recognition for popularising the one-piece swimsuit, and for her innovations as an aquatic performer, entertainer, and fitness writer. As a prototypical Hollywood star she prefigured the celebrity culture focused on the body that has predominated since then. Australia has continued to be associated with the values championed by Kellerman. It is also a launching pad for a number of international swimwear and surfwear companies, from iconic brands like Speedo, Quiksilver, and Billabong through to a new breed of contemporary swimsuit designers who tap into fashion trends while maintaining an Australian handwriting. This is exemplified by the Zimmermann and Tigerlily fashion labels.
 This study demonstrates the fluidity of fashion as a result of geographic and cultural influences, and the convergence and cross-pollination between individuals and global currents. Using a combination of historical and archival research, interviews, textual analysis, and the author&#8217;s own experience as a fashion designer, this thesis explores the shaping of the modern swimsuit and its eventual incorporation into global high fashion. It shows how a garment and a nation have migrated from the periphery to the centre of international attention by combining popular culture and high fashion to embody the values of modernity for women.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">swimsuit, Australian fashion, Annette Kellerman</field><field name="identifier">http://eprints.qut.edu.au/18391/</field><field name="validLink">True</field></doc><doc><field name="title">Wear reducing additives for lubricants containing solid contaminants</field><field name="creator">Sharma, Subhash Chandra</field><field name="description">Machines operating in dusty environments, such as mining and civil works, are prone to premature failure, leading to production losses. To address this problem, this research project examines the interaction between solid contaminants and the bearing micro-geometry, in lubricated surface contacts. In particular, it seeks to identify anti-wear additives that are effective in reducing wear under abrasive conditions, making machine elements more dirt tolerant. 
 In general, the influence of antiwear additive is so small that it is difficult to isolate it. Manufactures often make claims about their antiwear products, which are difficult to verify. Hence, there is a need to characterising the antiwear additives available with a well-defined parameter, making it easier for consumers to compare the efficacy of various additives, and be able to select the most suitable additive for a given environment.  
 Effect of micro-geometry parameters such as radial clearance, out-of-roughness and surface roughness was examined and a Film Shape Factor (FSF) &#8211; also termed gamma ratio &#8211; has been proposed for ensuring adequate separation of journal bearings operating in hydrodynamic lubrication regime, where the out-of-roundness values are higher than the surface roughness values. 
 In this research, an experimental study has been conducted on journal bearings, to examine the influence of five antiwear additives on the bearing wear and micro-geometry. The test additives were provided by the industry partner without revealing their chemical identity or composition; however, these included some of the most commonly used antiwear additives. The tests were performed under three conditions: pure base oil, base oil containing contaminants, and base oil containing contaminants treated with five different additives. 
 The experiments were aimed at choosing one wear measuring technique that evaluates the performance of an individual additive reliably, and based on this technique the additives were characterised. To achieve these objectives, a multi-wear parameter approach (MWPA) was developed, which employed three main wear measurement methodologies, i.e. weight loss, micro-geometry and particle counts &#8211;to examine the effect of the antiwear additives. Minimum oil film thickness was also measured to study the lubrication status in the bearing contacts. The MWPA helped in comparing different wear measuring methods, and in selecting the most reliable one. This approach also helped in developing short duration wear tests, thereby saving time, while still getting reliable results without repeating these. 
 Wear experiments were performed on seven sets of bronze bearings and steel sleeve shafts. The test contaminant was 16 micron Aluminium oxide Al2O3 powder mixed in oil with 4% concentration by weight. These solid contaminants were treated with five different antiwear additives to study their influence on the bearings. Bearings were operated such that the minimum oil film thickness in the bearing was equal to the size of the contaminants. These tests were run for a constant sliding distance of 7536m.
 The results showed that most of the wear measuring techniques do not suit heavily contaminated test conditions. However, the out-of-roundness technique proved to be the most reliable and practical. Based on this technique a methodology was developed which gave a wear characteristic number (N). A unique value of N can be derived for each additive, thereby ranking the additives for their efficacy.
 The finding of this research provides a better understanding of the methodologies used for measuring wear in journal bearings subjected to dusty environments, and examines the efficacy of each one of these. The wear characteristic number (N) can be used by manufacturers with support from international standards organisations, so that the users can confidently choose the most appropriate antiwear additive for their application. 
 Machines operating in a dusty environment, such as mining industry and civil works are prone to premature failure with subsequent production losses. In response to this problem, this research project examines the interaction between solid contaminant particles and the lubricant film micro-geometry in lubricated surface contacts. In particular, it seeks to identify lubricant anti-wear additives, which are effective in reducing wear under abrasive conditions and thus making machine elements more dirt tolerant.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">journal bearing, contaminants, antiwear additives, worn journal bearings, bearing metrology, hydrodynamic lubrication, sliding bearing wear, micro-geometry, specific film thickness</field><field name="identifier">http://eprints.qut.edu.au/20661/</field><field name="validLink">True</field></doc><doc><field name="title">Interface adaptation for conversational services</field><field name="creator">Wang, Kenneth W.S.</field><field name="description">The proliferation of services on the web is leading to the formation of service ecosystems wherein services interact with one another in ways not foreseen during their development or deployment. This means that over its lifetime, a service is likely to be reused across multiple interactions, such that in each of them a different interface is required from it. Implementing, testing, deploying, and maintaining adapters to deal with this multiplicity of required interfaces can be costly and error-prone. The problem is compounded in the case of services that do not follow simple request-response interactions, but instead engage in conversations comprising arbitrary patterns of message exchanges. A key challenge in this setting is service mediation: the act of retrofitting existing services by intercepting, storing, transforming, and (re-)routing messages going into and out of these services so they can interact in ways not originally foreseen. This thesis addresses one aspect of service mediation, namely service interface adaptation. This problem arises when the interface that a service provides does not match the interface that it is expected to provide in a given interaction. Specifically, the thesis focuses on the reconciliation of mismatches between behavioural interfaces, that is, interfaces that capture ordering constraints between message exchanges. We develop three complementary proposals. Firstly, we propose a visual language for specifying adapters for conversational services. The language is based on a an algebra of operators that are composed to define links between provided-required interfaces. These expressions are fed into an execution engine that intercepts, buffers, transforms and forwards messages to enact the adapter specification. Secondly, we endow such adapter specifications with a formal semantics defined in terms of Petri nets. The formal semantics is used to statically check the correctness of adapter specifications. Finally, we propose an alternative approach to service interface adaptation that does not require hard-wired links between provided and required interfaces. This alternative approach is based on the definition of mapping rules between message types, and is embodied in an adaptation machine. The adaptation machine sits between pairs of services and manipulates the exchanged messages according to a repository of mapping rules. The adaptation machine is also able to detect deadlocks and information loss at runtime.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">service-oriented architecture, web services, conversational services, service mediation, service adaptation, behavioural/protocol adaptation, adapter formalisation, operational semantics</field><field name="identifier">http://eprints.qut.edu.au/18465/</field><field name="validLink">True</field></doc><doc><field name="title">Bayesian mixture modelling for characterising environmental exposures and outcomes</field><field name="creator">Wraith, Darren</field><field name="description">Environmental exposure and outcomes assessment is a great challenge to scientists. Increasingly more and more detailed data are becoming available to understand the nature and complexity of the relationships involved. The methodology of mixture models provides a means to understand, quantify and describe features and relation- ships within complex data sets. In this thesis, we focussed on a number of applied problems to characterise complex environmental exposure and outcomes, including: assessing the interaction between environmental exposures as risk factors for health outcomes; identifying di&#174;ering environmental outcomes across a region; and estab- lishing patterns in the size and concentration of aerosol particles over time. Mixture model approaches to address these problems are developed and examined for their suitability in these contexts.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Bayesian mixture modelling, environmental exposure</field><field name="identifier">http://eprints.qut.edu.au/18467/</field><field name="validLink">True</field></doc><doc><field name="title">Feasibility and design considerations for the use of lifts as an emergency exit in apartment buildings</field><field name="creator">Sharma, Than Singh</field><field name="description">Emergency evacuation in high-rise apartment building is a challenge for fire safety professionals. Lift evacuation is a controversial issue because the safe operation of lift is not ensured under the existing design and operating conditions. Lifts are not permitted for public evacuation in apartment buildings during fire emergencies as per the provisions of building codes and regulations. However, the concept of using lifts for emergency evacuation has been gaining considerable attention during recent years. The lift evacuation can be considered as an alternative facility if it is efficient, reliable and readily accessible. It can also provide a safer means of evacuation for the aged and disabled persons, who may not be able to evacuate promptly, efficiently and unassisted using the exit stairs during fire emergencies. Moreover, lifts can enable building corporate management to easily and promptly access the fireaffected floor and commence fire fighting. The work on the use of lifts for emergency evacuation was initiated in the early 1990s at the National Institute of Standards and Technology (NIST, USA) in which pros and cons were analysed in order to develop suitable guidelines. This research project examines the feasibility of using lifts along with design modifications as an alternative facility for a safer and more efficient emergency evacuation. The scope of this research is limited to apartment buildings where occupant load is low and fire load is generally confined to dwelling compartment units. This research project analysed the important issues in relation to the use of lifts for emergency evacuation. The issues were divided into three categories: human behavioural response, fire hazards and lift operational mechanism. Output variables relating to human behavioural response were modelled and analysed as a stochastic process. Residents&#8217; choice for using evacuation routes was determined using a survey. The issues of fire hazards (fire, smoke and toxic gases) were analysed for occupant safety under variable conditions using the concept of fire safety index. The issues of lift operational mechanism such as lift malfunctioning due to excessive temperature, electric power failure and water damage were considered for developing probabilistic models. An integrated approach of risk assessment for the issues of human behavioural response and fire hazards (such as &#8216;decision uncertainty&#8217;, &#8216;panic&#8217;, &#8216;nonfatal and fatal injuries&#8217;) was developed based on the Multi-Objectives Decision Analysis method. The results for lift and stair systems were compared and the feasibility of using lift with design modifications was analysed for alternative designs and evacuation strategies. The outcomes of this research have shown that using lifts with a protected lobby for up to one-fourth of the building population (who may be aged and disabled) has huge potential as an alternative evacuation facility with enhanced level of safety. Lifts with protected lobby for one-fourth of the building population showed an improved level of fire safety from exposure to fire effluents. The reliability of lift operational mechanism is also improved in protected lift shafts. Lifts with protected lobby for up to one-fourth of the building population and stairs for up to three-fourth of the building population showed an improved evacuation safety. The risks in combined evacuation systems (protected lifts and stairs) are found to be lower when compared to using stairs or protected lifts. Lifts with double lobby protection (for example, two levels of compartmentation with fire and smoke doors for lift lobby) showed further improvements. This research has proposed alternative designs for lifts and developed models for analyzing evacuation effectiveness based on risks related to human behaviour, fire hazards and operational mechanism. It has shown that a combined use of lifts and stairs has significant advantages. The performance based lift evacuation system is achievable in apartment buildings. These research findings are based on uncertainty analysis, which can be further extended to other types of buildings in the future.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">lifts, elevators, design, apartment buildings, emergency exits</field><field name="identifier">http://eprints.qut.edu.au/18536/</field><field name="validLink">True</field></doc><doc><field name="title">Factors influencing self-directed learning readiness amongst Taiwanese nursing students</field><field name="creator">Huang, Mei-hui</field><field name="description">Rapid scientific and technological advances in health care mean that nurses need to keep learning and engage in professional education so that they can continue to provide safe and quality care. Education programs which prepare nurses for practice as a registered nurse have a vital role to play in ensuring that graduates are self-directed in responding to the need for ongoing learning throughout their professional career. In many countries, improving students&#8217; readiness for self-directed learning has thus gained increasing recognition as being an important goal of nursing education programs. This level of interest in developing self-directedness in learning is evident in many policy documents and research in Taiwan. The aim of this study was to investigate factors influencing self-directed learning readiness amongst Taiwanese nursing students. A conceptual framework adopted from Biggs&#8217;s &#8216;3P model of teaching and learning&#8217; was constructed to guide this study&#8217;s investigation. This study employed a two-staged mixed-method design to obtain a better understanding of Taiwanese students&#8217; experience of SDL in undergraduate nursing programs. Stage one of the present study was a qualitative approach using semi-structured interview to explore students&#8217; experiences with learning activities which they perceived to be self-directed in their undergraduate programs. Eight students were interviewed. Findings from this stage reveal that participants perceived a shift in teaching and learning styles between their previous nursing programs and the university. The more frequent use of student-directed learning activities, in which students were encouraged to be active and to take responsibility for their learning tasks, was one of the changes in teaching and learning approaches perceived by participants. Participants further suggested a number of factors that influenced the outcomes of these learning activities, including teacher-student interaction, facilitation process and learning resources. Stage two of this study used a quantitative approach consisting of two phases: instrument pilot testing and a cross-sectional survey. In the first phase, the instruments were translated into Chinese through a rigorous translation process and tested with a convenience sample of nursing students in Taiwan. Results indicated the translated instruments were reliable and stable. The second phase, a cross-sectional survey, was conducted to examine the conceptual framework of this study. A total of 369 undergraduate nursing students completed the questionnaire. Results of data analysis provides support for the conceptual framework proposed for this study, suggesting that students&#8217; achievement goals and their perceptions of the learning environment significantly influence their adoption of learning approaches and the development of SDL readiness. Based on the results, this study provides practical implications that nurse educators may adopt to enhance students&#8217; SDL readiness. This study also provides theoretical implications and recommendations for future research. It is envisaged that these recommendations may help future researchers focus their research design and further understandings of how to help students develop their ability to become self-directed learners.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">self-directed learning (SDL), self-directed learning readiness, approaches to learning, 3P model of teaching and learning, course experience questionnaire (CEQ), revised two-factor study process questionnaire (R-2F-SPQ)</field><field name="subject">self-directed learning readiness scale (SDLRS), mastery, performance and alienation goal scales</field><field name="identifier">http://eprints.qut.edu.au/20709/</field><field name="validLink">True</field></doc><doc><field name="title">Acculturation and health outcomes among Vietnamese immigrant women in Taiwan</field><field name="creator">Yang, Yung-Mei</field><field name="description">Background Recently, Taiwan has been faced with the migration of numbers of women from Southeast Asian (SEA) countries. It was estimated that the aggregate number of SEA wives in Taiwan was more than 131,000 in 2007 (Ministry of Foreign Affairs, 2006).These women are often colloquially called, &#8220;foreign brides&#8221; or &#8220;alien brides&#8221;; most of them are seen as commodities of the marriage trade, whose marriages are arranged by marriage brokers. Some women can be regarded as being sold for profit by their families. These young Vietnamese immigrant women come to Taiwan alone, often with a single suitcase, and are culturally and geographically distinct from Taiwanese peoples; the changes in culture, interpersonal relationships, personal roles, language, value systems and attitudes exert many negative impacts on their health, so greater levels of acculturation stress can be expected. This particular group of immigrant women are highly susceptible and vulnerable to health problems, due to language barriers, cultural conflicts, social and interpersonal isolation, and lack of support systems. The aims of this study were to examine the relationships between acculturation and immigrantspecific distress and health outcomes among Vietnamese transnational married women in Taiwan. This study focuses on Vietnamese intermarriage immigrants, the largest immigrant group in the period from1994 through to 2007.
 
 Methodology The quantitative study was divided into two phases: the first was a pilot study and the second the main study. This study was conducted in a communitybased health centre in the south of Taiwan, targeting Taiwanese households with Vietnamese wives, including the Tanam, Kaohsiung, and Pentong areas. This involved convenience sampling with participants drawn from registration records at the Public Health Centre of Kaohsiung and used the snowball technique to recruit 213 participants. The instruments included the following measures: (1) Socio-demographic information (2) Acculturation Scale (3) Acculturative Distress Scale, and (4) HRQOL. Questions related to immigrant women&#8217;s acculturation level and health status were modified. Quantitative data was coded and entered into the SPSS and SAS program for statistical analysis. The data analysis process involved descriptive, bivariate, multivariate multiple regression, and classification and regression trees (CART). Results Six hypotheses of this study were validated. Demographic data was presented and it revealed that there are statically significant differences between levels of acculturation and years of residency in Taiwan, number of children, marital status, education, religion of spouse, employment status of spouse and Chinese ethnic background by Pearson correlation and Kendall&#8217;s Tau-b or Spearman test. The correlations of daily activity, language usage, social interaction, ethnic identity, and total of acculturation score with DI tend to be negatively significant. In addition, the result of the one-way ANOVA supported the hypothesis that the different types of acculturation had a differential effect on immigrant distress. The marginalized group showed a greater immigrant distresses in comparison with the integrated group. Furthermore, the comparison t-test revealed that the Vietnamese immigrant women showed a lower score than Taiwanese women in HRQOL. The result showed higher acculturative stress associated with lower score of HRQOL on bodily pain, vitality, social functioning, mental health, and mental component summary. The CART procedure to the conclusion that the predictive variables for the physical component of the SF-36 (PCS) were: alienation, occupation, loss, language, and discrimination (predicted 28.8% of the total variance explained). The predictive variables for the mental component of the SF-36 (MCS) were: alienation, occupation, loss, language, and novelty (predicted 28.4% of the total variance explained). Conclusion As these Vietnamese immigrant women become part of Taiwanese communities and society, the need becomes apparent to understand how they acculturate to Taiwan and to the health status they acquire. The findings have implications for nursing practice, research, and will assist the Taiwanese government to formulate appropriate immigrant health policies for these SEA immigrant women. Finally, the application of this research will positively contribute to the health and well being of thousands of immigrant women and their families.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">acculturation, immigrant women, foreign brides, women&#8217;s health, short form 36 (SF-36), Health Related Quality of Life (HRQOL)., the Suinn-Lew Asian Self-Identity Acculturation Scale (SL-ASIA)., The Demand of Immigration Specific Distress Scale (DIS)</field><field name="subject">Classification and Regression Trees (CART)</field><field name="identifier">http://eprints.qut.edu.au/20647/</field><field name="validLink">True</field></doc><doc><field name="title">Characterisation of proteases involved in proteolytic degradation of haemoglobin in the human hookworm Necator americanus</field><field name="creator">Ranjit, Najju</field><field name="description">With over a billion people infected world wide, hookworms are considered as important human pathogens, particularly in developing countries which have the highest rates of infections. Hookworms reside in the gastrointestinal tract of the host where they continuously feed on blood, leading to conditions such as chronic irondeficiency anaemia. The majority of blood-feeding parasites rely on proteins found in blood to provide many of their nutritional requirements for growth, reproduction and survival. Of the numerous proteins found in blood, haemoglobin (Hb) is one of the most abundant. In order to acquire amino acids for protein synthesis, it is thought that haematophagous parasites degrade Hb using various classes of endo- and exoproteases, in a manner similar to that which occurs in catabolism of proteins in mammalian cellular lysosomes. This study identified and characterised proteases involved in the Hb degradation process in the human hookworm, Necator americanus, in order to identify potential candidate antigens for a vaccine that interrupts blood-feeding. Red blood cells ingested by hookworms are lysed to release Hb, which is cleaved by various proteases into dipeptides or free amino acids and these are taken up through the gut membrane by amino acid transporters. Proteases expressed in the intestinal tract of hookworms are thought to play a major role in this process and would therefore make good targets for vaccine candidates aimed at interrupting blood-feeding. To identify these proteases, adult hookworms (both N. americanus and Ancylostoma caninum) were sectioned and intestinal tissue was dissected via laser microdissection microscopy. RNA extracted from the dissected tissue was used to generate gut-specific cDNA, which then was used to create plasmid libraries. Each library was subjected to shotgun sequencing, and of the 480 expressed sequence tags (ESTs) sequenced from each species, 268 and 276 contigs were assembled from the N. americanus and A. caninum libraries, respectively. Nine percent of N. americanus and 6.5% of A. caninum contigs were considered novel as no homologues were identified in any published/accessible database. The gene ontology (GO) classification system was used to categorise the contigs to predicted biological functions. Only 17% and 38% of N. americanus and A. caninum contigs, respectively, were assigned GO categories, while the rest were classified as being of unknown function. The most highly represented GO categories were molecular functions such as protein binding and catalytic activity. The most abundant transcripts encoded fatty acid binding proteins, C-type lectins and activation associated secreted proteins, indicative of the diversity of functions that occur in this complex organ. Of particular interest to this study were the contigs that encoded for cysteine and metalloproteases, expanding the list of potential N. americanus haemoglobinases. In the N. americanus cDNA library, four contigs encoding for cathepsin B cysteine proteases were identified. Three contigs from the A. caninum and one contig from the N. americanus cDNA libraries encoded for metalloproteases, including astacin-like and O-sialoglycoprotein endopeptidases, neither of which had previously been reported from adult hookworms. Apart from haemoglobinases, other mRNAs encoding potential vaccine candidate molecules were identified, including anti-clotting factors, defensins and membrane proteins. This study confirmed that the gut of hookworms encodes a diverse range of proteases, some of which are likely to be involved in Hb digestion and have the potential to be hidden (cryptic) vaccine antigens. Four cysteine proteases (Na-CP-2, -3, -4 and -5) were identified from the gut cDNA library of N. americanus. All four proteases belong to the clan CA, family C1, share homology with human cathepsin B and possess a modified occluding loop. Real-time PCR indicated that all transcripts were up-regulated in the adult stage of the hookworm parasite with high levels of mRNA expression detected in gut cDNA. All four proteases were expressed in recombinant form, but only Na-CP-3 was successfully expressed in soluble form in the yeast Pichia pastoris. Proteolytic activity for Na-CP-3 was detected on a gelatin zymogen gel, however no catalytic activity was detected against the class-specific fluorogenic peptides Z-Phe-Arg-AMC and Z-Arg-Arg-AMC. Mass spectrometry analysis of the purified protein suggested that the pro-region had not been processed in trans when the protein was secreted by yeast. Incubation of Na-CP-3 in salt buffers containing dextran sulfate resulted in autoprocessing of the pro-region as detected by Western blot and catalytic activity was detected against Z-Phe-Arg-AMC. Activated Na-CP-3 did not digest intact tetrameric human Hb. The other three cysteine proteases (Na-CP-2, -4, and -5) were expressed in insoluble form in Escherichia coli. Antibodies to all four proteins (Na- CP-2 to 5) immunolocalised to the gut region of the adult worm, supporting mRNA amplification results and strongly indicated that they might play a role in nutrient acquisition. Hb digestion in blood feeding parasites such as schistosomes and Plasmodium spp. occurs via a semi-ordered cascade of proteolysis involving numerous enzymes. In Plasmodium falciparum, at least three distinct mechanistic classes of endopeptidases have been implicated in this process, and at least two classes have been implicated in schistosomes. A similar process is thought to occur in hookworms. An aspartic protease, Na-APR-1, was expressed in P. pastoris and purified protein was shown to cleave the class-specific fluorogenic peptide 7- Methoxycoumarin-4-Acetyl-GKPILFFRLK(DNP)-D-Arg-Amide. Recombinant Na- APR-1 was able to cleave intact human Hb and completely degrade the 16 kDa monomer and 32 kDa dimer within one hour. Recombinant Na-CP-3 was not able to cleave intact Hb, but was able to further digest globin fragments that had previously been digested with Na-APR-1. A clan MA metalloprotease, Na-MEP-1, was identified in gut tissue of N. americanus and was expressed in recombinant form in Hi5 insect cells using the baculovirus expression system. Recombinant Na-MEP-1 displayed proteolytic activity when assessed by gelatin zymography, but was incapable of cleaving intact Hb. However, Na-MEP-1 did cleave globin fragments which had previously been incubated with Na-APR-1 and Na-CP-3. Hb digested with all three proteases was subjected to reverse phase HPLC and peptides were analysed using Liquid Chromatography-Mass Spectrometry (LC-MS). A total of 74 cleavage sites were identified within Hb &#402;&#191; and &#402;&#192; chains. Na-APR-1 was responsible for cleavage of Hb at the hinge region, probably unravelling the molecule so that Na- CP-3 and Na-MEP-1 could gain access to globin peptides. All three proteases were promiscuous in their subsite specificities, but the most common P1-P1&#129;&#338; residues were hydrophobic and/or bulky in nature, such as Phe, Leu and Ala. Antibodies to all three proteins (Na-APR-1, -CP-3, -MEP-1) immunolocalised to the gut region of the worm, further supporting their roles in Hb degradation. These results suggest that Hb degradation in N. americanus follows a similar pattern to that which has been described in Plasomdium falciparum. Studies conducted in this project have identified a number of potential haemoglobinases and have demonstrated that the gut region of the hookworm contains a multitude of proteases which could be targeted for production of new chemotherapies or as vaccine candidates. Results presented here also suggest that the Hb degradation process occurs in an ordered cascade, similar to those which have been reported in other haematophagous parasites. More importantly, it has been confirmed that Na-APR-1 plays a crucial role in the initiation of the Hb degradation process and therefore targeting this molecule as a vaccine candidate could provide high levels of protection against hookworm infection.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Necator americanus, hookworm, laser microscopy microdissection, haemoglobin degradation, haemoglobinases, cysteine protease, aspartic protease, metalloprotease, intestinal proteases, vaccine candidates</field><field name="identifier">http://eprints.qut.edu.au/20651/</field><field name="validLink">True</field></doc><doc><field name="title">Recycled organic products to reduce the negative impact of salinity and sodicity on acidic soil properties and plant growth</field><field name="creator">Raue, Judith Doris</field><field name="description">Salt affected soils and their effects on land and water resources have been identified as one of the most severe environmental problems facing Australia. This current study focused on the incorporation of recycled organic products (RO) into an acidic saline soil that had been irrigated with an industrial effluent (IE), specifically to investigate the potential for these organics to be used in rehabilitation. Compost incorporated into the acidic saline soil was able to raise pH to more favourable levels required for plant growth (pH 6 &#8211; 7.5). Plant growth was however dependent on the input material of the compost as well as the irrigation scheme. The soils amended with this compost generally showed higher and more rapid microbial activity, measured by CO2 emissions, in all amendment rates than the plant derived compost. Overall it could be concluded that the application of RO on saline soils improved the establishment and growth of plants and alleviated to some degree the negative effects of IE. However great care should be taken at the selection of the input material, as high rates of ammonium, calcium and other soluble salts can increase the EC of an amended soil further.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">recycling, organic products, salinity, sodicity, acidic soil, plant growth</field><field name="identifier">http://eprints.qut.edu.au/20652/</field><field name="validLink">True</field></doc><doc><field name="title">Impacts of climate, topography, and weathering profile on vadose zone hydrology and coastal pine plantation management : a multi-scale investigation, Southeast Queensland, Australia</field><field name="creator">Wang, Qing</field><field name="description">Exotic pine plantations are a major landuse within the coastal lowlands of southeast Queensland, extending from close to the shoreline to the hinterland ranges. These plantations are within a sub-tropical climatic zone, and in most years, the summers are appreciably wetter than the winters. This terrain, in general, has been highly weathered and the soils are poor in nutrients. Environmental factors such as the climate, topography and weathering profile (including soil) are found to be important controls on vadose zone hydrology, which, in turn, has a great impact on tree growth and consequently on the design of management practices. This research project takes a holistic approach to investigate the influence of these environmental factors at different scales, and is designed to fulfil the following objectives:
 (1)	To build a spatial model of forest productivity for the entire Tuan Toolara State Forest (TTSF), southeast Queensland, by analysing the spatial patterns of many environmental variables that may have controls on soil water distribution.
 (2)	To determine how some of these environmental factors are responsible for the development of water-logging and soil salinisation by examining in detail an area of low site index that is severely affected by these two processes.
 (3)	To develop a model to assess the risks of water-logging spatially and temporally.
 A multiple regression model was constructed to predict the forest productivity (measured by the value of site index, the average dominant tree height at 25 years of age). The independent variables were derived from a digital elevation model (elevation, slope, curvature, hillshade, flow accumulation and distance to streams), &#947;-ray spectrometry (potassium, thorium and uranium), and interpolated rainfall. The model explained up to 60% of the variance in the site indices and produced predictive maps of site index for two species: P. elliottii Engelm. and Queensland hybrid, a P. elliottii &#215; P. caribaea Morelet hybrid. The model also identified the lowest site index area at the northern Tuan State Forest (NTSF), likely due to a greater risk of water-logging and salinisation.  
 The NTSF area is of low relief and, therefore, the focus has been on the vertical controls of deep weathering profile. The methodology included setting up a network of groundwater bores screened at different depths within the weathering profile, characterising the profile (mineralogy, EC, and pH) and the groundwaters within it (water levels, physico-chemical parameters, major and minor ions). It is found that water-logging is caused by perched groundwater formed on top of the ferricrete or mottled saprolite after prolonged rainfall. Localised salinisation is related to the discharge of brackish groundwater occurring within the mottled saprolite. The deep aquifer within the coarse saprolite is fresh and not responsible for salinisation, a situation that differs from many other settings in Australia. 
 The ability of using the Soil and Water Assessment Tool (SWAT) computer model to simulate soil water balance and to assess the risks of water-logging was tested in a selected catchment in the TTSF. The model successfully simulated stream flow at 2 weirs for a period of 6 years; the achieved R2 were 0.752 and 0.858, respectively. Long-term simulation for a 30-year period showed that there are pronounced seasonal patterns in rainfall and evapotranspiration as well as in soil water. For mature plantation with slopes of 3-15%, the mean annual duration of water-logging ranged from 161 days in the humus podzols, to 110 days in the gleyed podzolic, and to 90 days in the yellow podzolics. 
 The outcomes of this research suggest that forest management can be strongly supported by understanding the impacts of these environmental factors (e.g. climate, topography and weathering profile) on vadose zone hydrological processes; the selection of optimum approach will depend on the research objective or purpose. The models and analytical tools that were developed or tested here have the potential to be successfully applied elsewhere if the input data are available.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">pine plantations, coastal lowland, southeast Queensland, climate, topography, weathering profile, vadose zone hydrology, groundwater, forest productivity, water-logging, salinisation, GIS, gamma-ray spectrometry, multiple regression, SWAT</field><field name="identifier">http://eprints.qut.edu.au/20657/</field><field name="validLink">True</field></doc><doc><field name="title">Exercise and dietary behaviour change in a sample of midlife Australian women</field><field name="creator">Anderson, Rhonda Laurelle</field><field name="description">The purpose of this study was to understand the factors that encourage midlife women to make exercise and dietary changes, the prevalence of those changes, the process by which women make them, the factors that support or impede them, and how we can enhance women&#8217;s capacity to make health behaviour changes in midlife. Since the literature highlighted the importance of self-efficacy in changing health behaviour, and of health-related quality of life as a widely recognized measure of women&#8217;s mental and physical wellbeing, the study sought to understand the relationship between exercise and dietary self-efficacy, health behaviour change and health-related quality of life (SF-36), by testing a modified version of Bandura&#8217;s 1977 and 2002/2004b models of self-efficacy. 
 
 The methodology involved postal surveys as well as semi-structured interviews with a subsample of the women who completed the survey. Surveys were sent to 866 women aged 51-66 years from rural and urban locations in Queensland, Australia. Five hundred and sixty-four (69%) were completed and returned.  Survey data was analysed using descriptive and bivariate statistics and structural equation modeling. Thematic analysis was used to analyse interviews.
 
 The results confirmed that midlife is a significant time for women to make positive health behaviour changes. Almost 40% of women made a change to their exercise and around 60% made a dietary change since turning 40. The main exercise change was doing more walking and the most common dietary change was reducing fat intake. Self-efficacy was shown to be a key influence on whether women made positive changes to their health in midlife. In the relationship between health behaviour change and health-related quality of life, making a positive change to exercise was significantly related to physical but not mental health, and making a dietary change was not related to either physical or mental health. Body mass index was shown to be an important influence on both self-efficacy and health-related quality of life (particularly physical health).
 
 Interviews were conducted with 29 of the participants. Interview data reinforced that the main motivations to make a positive health behaviour change among midlife women were being overweight, having an injury or being diagnosed with an illness or health condition. Witnessing the hardship experienced by others with a degenerative disease could also prompt a positive behaviour change. Successful changes mainly involved modifying existing practices and repeating new behaviours until they became part of the daily routine. The main facilitators of health behaviour change were having positive role models, having more time due to retirement, and having support from significant others (such as husbands), health professionals and organizations such as Weight Watchers. The main obstacles to making changes were work, care giving, illness and injury. 
 
 Bandura&#8217;s (1977, 2000/2004b) model was partially supported, but the cross-sectional nature of the study may have been a limitation in demonstrating all aspects of the self-efficacy process.
 
 In summary, women are willing to make positive health behaviour changes in midlife, but they need education and support to have those changes be effective.  It is anticipated that this research will lead to a greater understanding of the significance of midlife as a time for making healthy lifestyle changes that have the potential to improve women&#8217;s health and quality of life in later years.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">midlife women, middle-age, healthy ageing, exercise, diet, self-efficacy, Bandura, health behaviour change, health-related quality of life, SF-36, exercise and dietary behaviour change, obesity</field><field name="identifier">http://eprints.qut.edu.au/18573/</field><field name="validLink">True</field></doc><doc><field name="title">Improved strategies for the cultivation of human limbal epithelial (HLE) grafts</field><field name="creator">Ainscough, Sarah Louise</field><field name="description">The limbal stem cell population is located in the limbal junctional zone between the cornea and the conjunctiva, and is responsible for maintaining the corneal epithelium. Damage to the limbal stem cell population results in a condition known as limbal stem cell deficiency (LSCD), which is characterised by conjunctivalisation of the cornea, visual impairment and persistent irritation. To treat LSCD, an alternative source of human limbal epithelial (HLE) cells must be transplanted back onto the diseased cornea. Limbal tissue grafts have had a moderate degree of success. However, autologous grafts risk damage to the healthy eye, whilst allogeneic grafts are susceptible to immunological rejection. Cultured HLE grafts offer a promising alternative to whole tissue grafts. The production of cultured HLE grafts involves the removal of a small (1-2 mm2) biopsy from the patient&#8217;s healthy limbus, followed by ex vivo expansion to produce an epithelial sheet, which is subsequently transplanted onto the damaged corneal surface. However, the production of cultured HLE grafts usually requires the addition of animal-derived products during cell culture. Animal-derived components, such as foetal bovine serum (FBS) and murine 3T3 feeder cells, introduce the patient to potential crossspecies infection and immune responses to xenogeneic antigens. Consequently, the overall aim of this project has been to develop a culture technique free of xenogeneic products for the establishment and propagation of HLE cells. To achieve this aim, alternatives to FBS in the culture medium and 3T3 feeder cells were pursued. A defined serum-free medium (SFM) containing vitronectin (VN), insulin-like growth factor binding protein 3 (IGFBP3), insulin-like growth factor-I (IGF-I), and epidermal growth factor (EGF) was investigated as an alternative to serumsupplemented medium (SSM) for HLE cell culture. Initial studies focused on the effects of these growth factors on HLE cell metabolic activity and migration. Metabolic activity was primarily stimulated by IGF-I and EGF, with the combination of IGF-I and EGF in solution stimulating metabolic activity to a significantly greater extent than the SSM positive control (p = 0.006). HLE cell migration was also effected by combinations of VN, IGFBP3, IGF-I and EGF. Migration was stimulated above the SFM negative control by the combination of IGFBP3 and IGF-I either with or without the addition of EGF. However, the presence of VN was required for optimal migratory responses (p &lt; 0.003). Hepatocyte growth factor (HGF) and keratinocyte growth factor (KGF) were also investigated as additional components to the SFM formulation. HGF significantly stimulated HLE cell metabolic activity and migration (p &lt; 0.02). In contrast, KGF did not significantly stimulate either HLE cell metabolic activity or migration. The addition of either HGF or KGF to the SFM supplemented with VN, IGFBP3, IGF-I and EGF did not significantly enhance the metabolic activity of HLE cells. Therefore, HGF and KGF were no longer pursued as additional components to the SFM formulation. Additional studies were conducted to examine the efficacy of replacing murine 3T3 feeder cells with human ocular stromal cells during HLE cell culture. Initially, stromal cells were isolated from the cornea, limbus and sclera to determine whether there were differences between these stromal cell populations. The results indicated that scleral stromal cells had a significantly larger area and perimeter than either corneal or limbal stromal cells (p &lt; 0.001). Scleral stromal cells were also significantly more rounded than either corneal or limbal stromal cells, as determined by the elliptical factor equation (p &lt; 0.001). Immunocytochemistry also revealed that scleral stromal cells expressed significantly more of the myofibroblast marker ..- smooth muscle actin than either corneal or limbal stromal cells (p &lt; 0.001), and significantly less of the fibroblast/myofibroblast marker Thy-1 than corneal or limbal stromal cells (p &lt; 0.001). Therefore, scleral stromal cells were identified as different in comparison to corneal and limbal stromal cells. Primary HLE cells were cultured with irradiated corneal, limbal and scleral stromal cells. HLE cultures established with either corneal or limbal stromal feeder cells contained more cellular protein (as measured by rhodamine B dye absorbance) than cultures established without feeder cells (p &lt; 0.001). The colony forming efficiency (CFE) of HLE cells established with corneal or limbal stromal feeder cells was also significantly greater than HLE cells established without feeder cells (p &lt; 0.001). In contrast, HLE cultures established with scleral stromal feeder cells contained low levels of cellular protein and had a low CFE, which was not significantly different to the HLE cultures established without feeder cells. Immunocytochemistry indicated that HLE cultures established with scleral feeder cells also showed lower expression of the stem cell markers ABCG2 and C/EBP ... These results suggest that freshly isolated HLE cells can be cultured with irradiated corneal or limbal stromal cells as a replacement for murine 3T3 feeder cells. Finally, the SFM supplemented with VN+IGFBP3+IGF-I+EGF was combined with limbal stromal feeder cells, and examined as a culture technique free of animalderived products. Freshly isolated HLE cells established in SFM supplemented with VN+IGFBP3+IGF-I+EGF and limbal feeder cells contained a similar amount of cellular protein (as measured by crystal violet dye absorbance) when compared to the SSM+3T3 positive control. In addition, the CFE of freshly isolated HLE cells established in VN+IGFBP3+IGF-I+EGF and limbal feeder cells was significantly higher than the SSM+3T3 positive control (p = 0.004). However, a live/dead assay revealed a reduced HLE cell viability in SFM supplemented with VN+IGFBP3+IGFI+ EGF and limbal feeder cells after seven days in culture. In addition, immunocytochemistry demonstrated a lower expression of the stem cell markers ABCG2 and C/EBP .. in the SFM treatment with limbal feeder cells. Therefore, freshly isolated HLE cells can be cultured in SFM supplemented with VN+IGFBP3 +IGF-I+EGF and limbal feeder cells. However, this culture technique is less likely to support the growth of immature limbal stem cells when compared to the SSM+3T3 positive control. Overall, this research has attempted to create a culture system free of animal-derived products for the production of cultured HLE grafts to treat limbal stem cell deficiency. The results show that HLE cells respond to a serum-free medium formulation containing VN+IGFBP3+IGF-I+EGF. In addition, this culture medium can be combined with irradiated stromal cells isolated from the limbus to support HLE culture production. However, the combination of VN+IGFBP3+IGF-I+EGF and limbal feeder cells demonstrated a reduced viability, which indicates that further refinement of the formulation is required. This thesis has also demonstrated differences between stromal cells isolated from the cornea, limbus, and sclera, and has generated knowledge which may impact on the understanding of stromalepithelial regulation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">cell culture, cornea, growth factors, limbal stem cell deficiency, limbus, stem cells, stroma, fibroblasts, keratocytes</field><field name="identifier">http://eprints.qut.edu.au/18575/</field><field name="validLink">True</field></doc><doc><field name="title">Nutrition and feeding behaviour in two species of mud crabs Scylla serrata and Scylla paramamosain</field><field name="creator">Truong, Phuong Ha</field><field name="description">Mud crabs of the genus Scylla are widely exploited for aquaculture in the Asia- Pacific region. In the current study, a series of in vivo experiments were carried to assess the protein requirement, protein sparing effects of starch and the capacity of Scylla serrata to digest diets that contained different animal and plant-based feed meals and different levels and types of starch. Results from a protein requirement study indicated that juvenile S. serrata fed diets containing 45% or 55% protein demonstrated significantly higher growth responses than those fed the diet containing 25% protein. The subsequent study was carried out to determine if responses to dietary protein could be influenced by using purified wheat, potato, rice or corn starch to manipulate the gross energy level of fishmeal- based diets (18 or 15.5 MJ kg-1), i.e., to see if starch had a protein sparing effect in these animals. Overall, growth responses in this study appeared to be positively correlated with the level of protein in the diet with the highest growth rates achieved using diets containing 45% protein, regardless of the energy level of the diet. In addition, at a dietary protein level of 40% there was no evidence that the source of starch had any significant impact on growth performance or feed utilisation suggesting it had no protein sparing effect. By contrast, it was found that growth of juvenile S. serrata was strongly correlated with the intake of digestible dietary protein. The investigation of the capacity of sub-adult S. serrata to digest different animal and plant- based feed meals showed that apparent dry matter digestibility (ADMD) and apparent gross energy digestibility (AGED) values were not significant different for most selected feed meals (cotton seed, poultry, canola, fishmeal, soybean, and lupin meal). Apparent crude protein digestibility (ACPD) for all test feed meals were relatively high (86-96%). A subsequent study was carried out to determine if purified starch from different sources influenced the digestibility of fishmeal based diets. Overall, most diets containing starch were readily digested by mud crabs. In particular, there were no negative impacts on the digestibility of major nutrients (e.g. protein) observed following the inclusion of wheat, rice or corn starch in formulated feeds. Nevertheless, the apparent starch digestibility (ASD) of wheat starch decreased significantly as the inclusion level was increased from 15% to 60%, although there was no significant effect on ACPD values. At a 30% inclusion level, the ASD of diets containing different starches decreased in the order corn &gt; wheat &gt; potato = rice. Moreover, ACPD values were significantly higher for diets containing corn or rice starch than for those containing wheat or potato starch. The capacity of another species of mud crab commonly exploited for aquaculture in South East Asia, S. paramamosain, to digest the local plant-based ingredients (defatted soybean meal, rice bran, cassava and corn flour) was also conducted in Vietnam. Overall, the findings of this study showed that at a 30% inclusion level diets containing soybean meal or rice bran were well digested by mud crabs. In particular, the ACPD and AGED values for all diets containing soybean meal were not significantly different from the fishmeal based reference diet. Likewise, all digestibility values for the diet containing 30% rice bran were relatively high and not significantly different from the reference diet. By contrast, diets containing cassava flour appeared to be poorly utilised since their digestibility values for all parameters were lower than those from other testingredients. In summary, the apparent digestibility of dry matter, protein and energy was in the following order (from most to least digestible) soybean meal ~ rice bran &gt; corn flour &gt; cassava flour. In the next study the effects of attractants in diets (chicken meal, betaine, tuna oil and bait enhancer), temperature (26.5oC, 28.5oC and 30.5oC), sex (female and male) and size (small, medium and large) on feeding responses of S. serrata were investigated. Significant differences were observed in the behavioral responses of mud crabs to diets containing different attractants. Specifically, consumption of diets with chicken meal or betaine was significantly higher than for other treatments. With the exception of betaine, no significant difference in food consumption was observed when attractant inclusion levels were raised from 2% to 5%. Overall, small crabs consumed significantly more of the ration (as a percentage of body weight) than larger crabs. Temperature showed a significant impact on most behaviour of mud crabs, excepting continuation response and there was some evidence that females were significantly more active than males. Light intensity was considered as a main factor effect to crab response since there were extremely high percentage time of crab spent in half-shaded of the Y &#8211;maze which valued at 95.6%, 93.8 and 94.4% (corresponded to small, medium and large size respectively) in comparison to those of crabs spent in the unshaded side. Overall, the findings from these studies demonstrated that mud crabs have a high capacity to digest a range of plant based feed ingredients. In particular, soybean meal appeared to be well digested by both species of mud crabs examined. It was also shown that a range of purified starches were well digested by S. serrata although starch inclusion in diets did not appear to reduce the requirement for protein to promote growth. Subsequent attractant studies demonstrated that chicken meal and betaine produced significantly elevated feeding responses and food consumption when added to diets. Based on these results we propose that these ingredients can be utilised to increase the attractiveness and consumption of artificial mud crab feeds.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">aquaculture, mud crab, Scylla serrata, Scylla paramamosain, starch, plant ingredients, protein, energy, digestibility, video behaviour analysis, chemo-attractants</field><field name="identifier">http://eprints.qut.edu.au/20700/</field><field name="validLink">True</field></doc><doc><field name="title">Algorithmic approaches for playing and solving Shannon games</field><field name="creator">Rasmussen, Rune K.</field><field name="description">The game of Hex is a board game that belongs to the family of Shannon games, which are connection-oriented games where players must secure certain connected components in graphs. The problem of solving Hex is a decision problem complete in PSPACE, which implies that the problem is NP-Hard. Although the Hex problem is difficult to solve, there are a number of problem reduction methods that allow solutions to be found for small Hex boards within practical search limits. The present work addresses two problems, the problem of solving the game of Hex for small board sizes and the problem of creating strong artificial Hex players for larger boards. Recently, a leading Hex solving program has been shown to solve the 7x7 Hex board, but failed to solve 8x8 Hex within practical limits. This work investigates Hex-solving techniques and introduces a series of new search optimizations with the aim to develop a better Hex solver. The most significant of these new optimization techniques is a knowledge base approach that stores and reuses search information to prune Hex-solving searches. This technique involves a generalized form of transposition table that stores game features and uses such features to prove that certain board positions are winning. Experimental results demonstrate a knowledge base Hex solver that significantly speeds up the solving of 7x7 Hex. The search optimization techniques for Hex solvers given here are highly specialized. This work reports on a search algorithm for artificial Hex players, called Pattern Enhanced Alpha-Beta search that can utilize these optimization techniques. On large board positions, an artificial Hex player based on the Pattern Enhanced Alpha- Beta search can return moves in practical times if search depths are limited. Such a player can return a good move provided that the evaluated probabilities of winning on board positions at the depth cut-offs are accurate. Given a large database of Hex games, this work explores an apprenticeship learning approach that takes advantage of this database to derive board evaluation functions for strong Hex playing policies. This approach is compared against a temporal difference learning approach and local beam search approach. A contribution from this work is a method that can automatically generate good quality evaluation functions for Hex players.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Shannon games, algorithmic approaches</field><field name="identifier">http://eprints.qut.edu.au/18616/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis and characterization of poly &#949;-caprolactone on functionalised silica substrates</field><field name="creator">Khan, Javaid Hasan</field><field name="description">Aliphatic polyesters prepared by the ring opening polymerization of lactones and lactides, are versatile polymers having good hydrolyzability, mechanical properties and biocompatibility. These characteristics make them a leading material in biomedical and pharmaceutical industries as a resorbable implant and a vehicle for controlled drug delivery. An extensive research effort has been made to develop new initiators, catalysts for the ring opening polymerization of cyclic esters. Many effective initiators based on alkali metals, metal oxides have been developed for anionic polymerization of lactones. The main objectives of this project were to develop a novel catalyst by utilizing fully biocompatible and non-toxic reagents for the synthesis of polycaprolactone (PCL) by ring opening polymerization of cyclic esters at reasonably low temperature and a synthesis of hybrid silica nano-composite for biomedical applications and its characterization. Silica and dry calcium hydride reagents were used to successfully prepare heterogeneous catalysts for the ring opening polymerization of cyclic ester monomer &#229;-caprolactone at reasonably low temperature of 100 oC. Two kinds of catalyst were prepared with non-functionalized and silane functionalized silica. The GP silane functionalized silica catalyst showed higher activity and higher product yield as compared to non-functionalized catalyst during polymerization at the same temperature. The in-situ polymerization kinetics of both reactions was studied using Raman spectroscopy. A silica based nano-composite was also synthesized which has a potential application in bone tissue engineering and possible drug delivery. The synthesized polyester and hybrid silica nano-composite were characterized with different analytical techniques to confirm required product formation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">poly &#229;-caprolactone, functionalised silica substrates</field><field name="identifier">http://eprints.qut.edu.au/18619/</field><field name="validLink">True</field></doc><doc><field name="title">Pan-Arab satellite television phenomenon : a catalyst of democratisation and socio-political change</field><field name="creator">Abusalem, Ali</field><field name="description">In less than ten years, Aljazeera television has become the most popular satellite news service in the Arab world. Regimes around the region have regarded Aljazeera as a threat, while Aljazeera has consistently claimed that it is simply reporting the truth. Notwithstanding this, Aljazeera has successfully established its presence in the media world despite the controversies surrounding its professional approach and the hammering criticism that has been directed to it in both the Middle East and the West.
 This research explores the thesis that Aljazeera is a catalyst of democratisation and social and political change in the Arab world. As a recent media phenomenon, Aljazeera has been playing a critical role in changing the social and political values of societies in the Arab world and viewers&#8217; perceptions of a range of social and cultural topics relating to human rights, equality, diversity, gender, employment and exploitation. It is said that through its persistent campaigns to raise the awareness of its increasingly broadening viewer base to these issues, Aljazeera has created a new public sphere in the Arab countries that are traditionally and historically non-democratic in the least and despotic and dictatorial in the extreme. It became &#8220;[the] arena within which debate occurs...&#8221; (Hartley, 2002, p.191) between viewers who share in the process of discourse to communicate and debate. In this context Aljazeera provided a public forum for Arab viewers to express their views and address a range of sensitive and controversial issues. Consequently, it is the perception of democracy that Aljazeera seems to be fostering in the Arab world, which is leading to a sense of empowerment at the individual level. 
 The research sought to examine this phenomenon through a field study that garnered vital data from a representative sample of 600 viewers of Aljazeera, including 100 media professionals, in four Arab countries: Egypt, Jordan, United Arab Emirates, and Qatar, and amongst the Arab diaspora (with the Australian Arabs as a focus group). The data was analysed against a media model that was developed specifically for that purpose. The findings support the research hypothesis that Aljazeera is a catalyst of democratisation and socio-political change.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">pan-Arab satellite television, democratisation, socio-political change, transnational satellite media, mass media</field><field name="identifier">http://eprints.qut.edu.au/18637/</field><field name="validLink">True</field></doc><doc><field name="title">Hoods : creating political theatre for young audiences</field><field name="creator">Betzien, Angela Jane</field><field name="description">My first exposure to Brecht and his theories was as a high school drama student. One of our year twelve assessment tasks was to write and perform our own Brechtian drama using three or more alienation techniques. I wrote a piece about Religion and Fundamentalism, an issue that I felt strongly about at the time. By carefully following my teacher&#8217;s instructions and adhering to the assessment criteria I received a VHA. I concluded from this experience that political theatre could be made by following a simple recipe and combining key ingredients. As my knowledge of theatre and my own creative practice developed I came to understand the great complexity of Brechtian theory and the extreme difficulty of creating effective political theatre, that is, theatre that changes the world. Brecht&#8217;s theories have been so thoroughly absorbed into contemporary theatre practice that we no longer identify the techniques of Epic Theatre as necessarily political, nor do we acknowledge its radical origins. I have not yet seen a professional production of a Brechtian play but I&#8217;ve absorbed on countless occasions the brilliant reinterpretations of Brecht&#8217;s theories within the work of contemporary dramatists. My approach to creating political drama is eclectic and irreverent and I&#8217;m prepared to beg borrow and steal from the cannon of political theatre and popular media to create a drama that works, a drama that is both entertaining and provocative. Hoods is an adaptation for young audiences of my original play Kingswood Kids (2001). The process of re-purposing Kingwood Kids to Hoods has been a long and complex one. The process has triggered an analysis of my own creative practice and theory, and demanded an in-depth engagement with the theories and practice of key political theatre makers, most notably Brecht and Boal and more contemporary theatre makers such as Churchill, Kane, and Zeal Theatre. The focus of my exegesis is an inquiry into how the dramatist can create a theatre of currency that challenges the dominant culture and provokes critical thinking and political engagement in young audiences. It will particularly examine Brecht&#8217;s theory of alienation and argue its continued relevance, exploring how Brechtian techniques can be applied and re-interpreted through an in-depth analysis of my two works for young people, Hoods and Children of the Black Skirt. For the purposes of this short exegesis I have narrowed the inquiry by focusing on four key areas: Transformation, Structure, Pretext, Metatext.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">theatre for young people, political theatre, Brecht, Boal, Epic Theatre, Forum Theatre, play structure, transformation, pretext, metatext, alienation effect, Living Newspaper</field><field name="identifier">http://eprints.qut.edu.au/19238/</field><field name="validLink">True</field></doc><doc><field name="title">Lesbian detective fiction : the outsider within</field><field name="creator">Simpson, Inga Caroline</field><field name="description">Lesbian Detective Fiction: the outsider within is a creative writing thesis in two parts: a draft lesbian detective novel, titled Fatal Development (75%) and an exegesis containing a critical appraisal of the sub-genre of lesbian detective fiction, and of my own writing process (25%). Creative work: Fatal Development -- It wasn&#8217;t the first time I&#8217;d seen a dead body, but it didn&#8217;t seem to get any easier. -- When Dirk and Stacey discover a body in the courtyard of their Brisbane woolstore apartment, it is close friend and neighbour, Kersten Heller, they turn to for support. The police assume Stuart&#8217;s death was an accident, but when it emerges that he was about to take legal action against the woolstore&#8217;s developers, Bovine, Kersten decides there must be more to it. Her own apartment has flooded twice in a month and the builders are still in and out repairing defects. She discovers Stuart was not alone on the roof when he fell to his death and the evidence he had collected for his case against Bovine has gone missing. Armed with this knowledge, and fed up with the developer&#8217;s ongoing resistance to addressing the building&#8217;s structural issues, Kersten organises a class action against Bovine. Kersten draws on her past training as a spy to investigate Stuart&#8217;s death, hiding her activities, and details of her past, from her partner, Toni. Her actions bring her under increasing threat as her apartment is defaced, searched and bugged, and she is involved in a car chase across New Farm. Forced to fall back on old skills, old habits and memories return to the surface. When Toni discovers that Kersten has broken her promise to leave the investigation to the police, she walks out. The neighbouring &#8211; and heritage-listed &#8211; Riverside Coal development site burns to the ground, and Kersten and Dirk uncover evidence of a network of corruption involving developers and local government officials. After she is kidnapped in broad daylight, narrowly escaping from the boot of a moving car, Kersten is confident she is right, but with Toni not returning her calls, and many of the other residents selling up, including Dirk and Stacey, Kersten begins to question her judgment. In a desperate attempt to turn things around, Kersten calls on an old Agency contact to help prove Bovine was involved in Stuart&#8217;s death, her kidnapping, and ongoing corruption. To get the evidence she needs, Kersten plays a dangerous game: letting Bovine know she has uncovered their illegal operations in order to draw them into revealing themselves on tape. Hiding alone in a hotel room, Kersten is finally forced to confront her past: When Mirin didn&#8217;t come home that night, I was ready to go out and find her myself, disappear, and start a new life together somewhere far away. Instead they pulled me in before I could finish making arrangements, questioned me for hours, turned everything around. It was golden child to problem child in the space of a day. This time, she&#8217;s determined, things will turn out differently. Exegesis: The exegesis traces the development of lesbian detective fiction, including its dual origins in detective and lesbian fiction, to compare the current state of the sub-genre with the early texts and to establish the dominant themes and tropes. I focus particularly on Australian examples of the sub-genre, examining in detail Claire McNab&#8217;s Denise Cleever series and Jan McKemmish&#8217;s A Gap in the Records, in order to position my own lesbian detective novel between these two works. In drafting Fatal Development, I have attempted to include some of the political content and complexity of McKemmish&#8217;s work, but with a plot-driven narrative. I examine the dominant tropes and conventions of the sub-genre, such as: lesbian politics; the nature of the crime; method of investigation; sex and romance; and setting. In the final section, I explain the ways in which I have worked within and against the subgenre&#8217;s conventions in drafting a contemporary lesbian detective novel: drawing on tradition and subverting reader expectations.  Throughout the thesis, I explore in detail the tradition of the fictional lesbian detective as an outsider on the margins of society, disrupting notions of power and gender. While the lesbian detective&#8217;s outsider status grants her moral agency and the capacity to achieve justice and generate change, she is never fully accepted. The lesbian detective remains an outsider within. For the lesbian detective, working within a system that ultimately discriminates against her involves conflict and compromise, and a sense of double-play in being part of two worlds but belonging to neither. I explore how this double-consciousness can be applied to the lesbian writer in choosing whether to write for a mainstream or lesbian audience.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">lesbian detective fiction, crime fiction, detective fiction, mystery, lesbian fiction, feminist detective fiction, Australian detective fiction, hard-boiled, spy fiction, gay detective fiction, pulp fiction, Jan McKemmish, Claire McNab, Dorothy Porter</field><field name="subject">Raymond Chandler, Dashiell Hammett, John Le Carr&#233;, creative writing, practice-led research</field><field name="identifier">http://eprints.qut.edu.au/20120/</field><field name="validLink">True</field></doc><doc><field name="title">Dreams and adjustment following marital separation : implications for the function of dreaming</field><field name="creator">Sacre, Sandra M.</field><field name="description">Arguably the most popular current theories of dreaming are the functional theories, including the emotional adaptation or problem-solving theory. These theories revolve around the idea that dreams may serve an independent adaptive function, helping us to adjust to, cope with, or resolve emotionally difficult life circumstances, problems and concerns. Contrary to these theories, other researchers have argued that dreams may have no function of their own, but are an epiphenomenon of REM sleep. The cognitive theories of dreaming suggest that dream content is continuous with waking concerns and preoccupations, and that dreaming about waking concerns is not adaptive but reflective, in a similar way that waking thought or daydreaming is reflective, of what is uppermost in the mind of the dreamer. A relatively small body of research (e.g., Barrett, 1993; Cartwright, 1991; Kramer, 1993) relating to individuals who have experienced major stressful life events, is often cited as support for the theory that dreams serve the specific function of helping us to adjust or adapt to current events. Until recently, this body of work has gone largely unexamined and unreplicated, though some have questioned the findings and their implications for the function of dreaming. The research presented in this thesis examined whether dream content reflects a process of adjustment in people who had recently experienced a marital separation, by investigating the relationship between their dream content in relation to measures of adjustment over time. In Study 1, 97 recently separated participants and 93 married controls were tested on personality and coping factors, asked to answer questions about their dream content, and then monitored over 12 months for change in their adjustment. In Study 2, a subset of 42 separated participants kept dream logs for a period of four weeks. Their dream reports were subjected to a qualitative analysis of thematic content, including threat and threat mastery, and analyses were conducted to explore the relationship between threat content, mastery and adjustment. In Study 3, a subset of eight Study 2 participants participated in a case study analysis which investigated contextual information about their individual situations in relation to their dream content and adjustment, in order to explore, in a more detailed way, the relationship between dream themes, adjustment, and waking concerns. Study 4 was designed to compare the findings of the previous studies with a separate sample, using three different methodologies for the collection of dream content data. This study was carried out to replicate the previous studies with the addition of a laboratory-based data collection technique. In Study 4, 18 separated participants spent one night in the sleep laboratory, monitored with a Nightcap, which allowed dream data to be collected from them via questionnaires, dream logs, and REM awakenings. Across all of the studies, and regardless of the method used to measure dream recall and content, there was a significant concurrent relationship between better adjustment and fewer dreams relating to participants&#8217; marital situations. Those with the most distress were the same ones who were dreaming excessively about their separation. These findings suggest that dreams are continuous with waking preoccupation, and do not function to aid adjustment. As such, they did not support the functional adaptation theories of dreaming. The findings were more consistent with the cognitive theories of dreaming, including the theory that dreams have meaning, but no independent function of their own. A significant relationship was, however, found between ego strength, coping style and adjustment, highlighting the greater influence of internal personal resources in adjusting to difficult life circumstances. While these findings do not discount the suggestion that individuals derive significant personal meaning from their dreams, nor the possibility that dreams may reflect something of the function of REM sleep, they do suggest that &#8220;adaptationist&#8221; assumptions of functional theories of dreaming may be unfounded.</field><field name="date">2006</field><field name="language" /><field name="relation" /><field name="subject">dream function, dream theory, marital separation, emotional adjustment, emotional adaptation, cognitive theories of dreaming, continuity theory, problem-solving, functional theories of dreaming, adjustment, personality, coping style</field><field name="identifier">http://eprints.qut.edu.au/20472/</field><field name="validLink">True</field></doc><doc><field name="title">The role of online networks in supporting young people's digital inclusion and the implications for Australian government policies</field><field name="creator">Notley, Tanya M.</field><field name="description">This study examines young people&#8217;s internet access and use in nine locations in Queensland, Australia. The primary aim of the research is to assess if internet use supports young people&#8217;s social inclusion: that is, if internet use supports young people to participate in society in ways they have most reason to value.
 
 The research findings demonstrate that the digital divide in Queensland &#8211; the gap between citizens with and without access to ICTs &#8211; continues to inhibit young people&#8217;s ability to participate online. This divide is embedded within historic, economic, social and cultural inequalities. To address this, this study proposes that a digital inclusion framework, founded on the concept of social inclusion, offers the Australian federal and state governments an opportunity to extend digital divide policies so that they connect with and complement broader social policy goals.
 
 The research outcomes also illustrate that creative uses of online networks provide a powerful means through which young people can participate in a networked society. While young people&#8217;s access to a range of ICTs impacts on their ability to use online networks, gradations of use, social networks and informal learning contexts frequently act as mediators to support effective internet use. This study contends that by understanding the social benefits of young people&#8217;s online network use and the role that mediators play in different environments, we can move towards a policy framework that supports equitable opportunities for young people&#8217;s digital inclusion.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">internet, youth, young people, new media, information and communication technologies, ICTs, internet, digital inclusion, digital divide, social inclusion, social policy, online networks, network society, social benefits, Queensland, Australia</field><field name="identifier">http://eprints.qut.edu.au/19097/</field><field name="validLink">True</field></doc><doc><field name="title">Managing variability in process-aware information systems</field><field name="creator">La Rosa, Marcello</field><field name="description">Configurable process models are integrated representations of multiple variants of a process model in a given domain, e.g. multiple variants of a shipment-to-delivery process in the logistics domain. Configurable process models provide a basis for managing variability and for enabling reuse of process models in Process-Aware Information Systems. Rather than designing process models from scratch, analysts can derive process models by configuring existing ones, thereby reusing proven practices. This thesis starts with the observation that existing approaches for capturing and managing configurable process models suffer from three shortcomings that affect their usability in practice. Firstly, configuration in existing approaches is performed manually and as such it is error-prone. In particular, analysts are left with the burden of ensuring the correctness of the individualized models. Secondly, existing approaches suffer from a lack of decision support for the selection of configuration alternatives. Consequently, stakeholders involved in the configuration of process models need to possess expertise both in the application domain and in the modeling language employed. This assumption represents an adoption obstacle in domains where users are unfamiliar with modeling notations. Finally, existing approaches for configurable process modeling are limited in scope to control-flow aspects, ignoring other equally important aspects of process models such as object flow and resource management. Following a design science research method, this thesis addresses the above shortcomings by proposing an integrated framework to manage the configuration of process models. The framework is grounded on three original and interrelated contributions: (i) a conceptual foundation for correctness-preserving configuration of process models; (ii) a questionnaire-driven approach for process model configuration, providing decision support and abstraction from modeling notations; (iii) a meta-model for configurable process models covering control-flow, data objects and resources. While the framework is language-independent, an embodiment of the framework in the context of a process modeling language used in practice is also developed in this thesis. The framework was formally defined and validated using four scenarios taken from different domains. Moreover, a comprehensive toolset was implemented to support the validation of the framework.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">business process management, process-aware information systems, configurable process model, process configuration, reference model, variability, staged configuration, questionnaire, software family, Petri net, workflow net, configurable workflow net</field><field name="subject">EPC, C-EPC, YAWL, C-YAWL</field><field name="identifier">http://eprints.qut.edu.au/20531/</field><field name="validLink">True</field></doc><doc><field name="title">The influence of Islamic political ideology on the design of state mosques in West Malaysia (1957-2003)</field><field name="creator">Ismail, Alice S.</field><field name="description">This research begins with the assumption that the political ideology of Malaysian leaders influences the design of state mosques and seeks to investigate the relationship between Malaysian leaders political ideas of Islam and their influence on the design of state mosques in Malaysia. Even though studies undertaken of state mosque in other Muslim countries show a relationship between state mosque and politics, there are no studies that describe the influence of politics on the state mosques in Malaysia. To date, the research on the state mosque in Malaysia focuses on six main aspects: these are descriptions of the state mosque in regard to its historical development; documentation of the state mosque in the form of measured drawings; classification of state mosque styles; theory for designing the state mosque based on religious sources; discussion on the technical aspects of the state mosque design; and discourse on the role and function of the state mosque in relation to social aspects. In contrast, the aim of this research is to determine: How are the leaders political ideas of Islam expressed through the design of state mosques in West Malaysia? A case study approach as defined by Yin (2003) was applied. Evidence for the case studies has been collected from archival records to gather data regarding political development and building policy which relates to three prominent leaders in Malaysia &#8211;Tunku Abdul Rahman, Tun Abdul Razak and Tun Mahathir Mohamad - while on-site observation, state mosque documents and interview were methods to collect evidence for three state mosques in Malaysia, which are the National Mosque, Penang State Mosque and Putra Mosque. Since this research deals with specific interpretations of the state mosque as a social-physical phenomenon and the need to understand how the structural relationship exists between the state mosques and social culture, a multi-disciplinary logic of inquiry combining the interpretive and structuralist paradigms was adopted. In association, a framework incorporating both semiotics and hermeneutics were developed to analyse, firstly, the symbolic meaning embedded in the design of the state mosques and their mundane settings and, secondly, to reveal the leaders intentions and associated actions during the creation of the state mosques. An analysis of the data exposed that there is a dialectic relationship between the leaders and the design of the state mosque in the period of post-independence in Western Malaysia. The investigation of the three state mosques also suggested that the political ideas of Islam as propounded by Malaysian leaders have a profound effect on determining the design of the state mosque. This study, therefore, offers new insights, which not only add to knowledge in this field by widening and strengthening the understanding of political and architectural historical theory in Malaysia, but also are valuable for range of associated fields including architectural semiotics and non verbal communication. This is because this research reveals deep understandings of the built form and material environment operating as a sign in a cultural and social context.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">state mosque, West Malaysia, political ideology, Islam, Tunku Abdul Rahman, Tun Abdul Razak, Tun Mahathir Mohamad, National Mosque, Penang State Mosque, Putra Mosque, semiotics, state mosque design</field><field name="identifier">http://eprints.qut.edu.au/19371/</field><field name="validLink">True</field></doc><doc><field name="title">Reliability and availability analysis of a multistate repairable system with dependent deteriorations and redundancy</field><field name="creator">Mu, Dekui</field><field name="description">Maintenance management is to design, operate, and maintain the reliability and availability of assets at a required performance level using the lowest possible cost. The standby redundancy is one of the means to achieve highly reliable system with less dependable units. As commonly used performance indicator, the reliability and availability should be precisely analysed for a repairable standby system. The reliability of a standby system is mainly studied in the framework of lifetime approach. Most existing models are developed for a two-unit standby system and a Kout- of-N system with identical units. The system units are assumed to be binary-state and the failures of system units are modelled as sudden failures. The deteriorations of units are modelled as time-dependent failure rate and are assumed to be independent. In addition, most of the existing models do not consider maintenance is carried out on the system. In reality, the deteriorations and the resultant failures in real-world systems are often interactive with each other. The systems normally experience several, often imperfect, restorations before a complete renewal. Therefore, the study of different repair policies, such as opportunistic and individual policies, in multi-unit systems need also be investigated. To address the problem, the reliability and availability models for a 2-out-of-3 cold standby system will be studied in a multi-state system reliability framework. A multistate multi-path failure mode is proposed to model the interactive deteriorations. The concept of repair matrix will be adopted to model the effect of unit level restorations on system reliability. The availabilities under individual repair policy and opportunistic repair policy will be developed.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">multistate repairable system, dependent deteriorations, redundancy</field><field name="identifier">http://eprints.qut.edu.au/19149/</field><field name="validLink">True</field></doc><doc><field name="title">Germinant design practice : a do-it-yourself narrative</field><field name="creator">Smith, Catherine Dorothy</field><field name="description">This thesis is concerned with architectural and design practitioners involved in areas outside of their training: specifically, with the way designers embrace a do-it-yourself or DIY ethic to create experimental, ephemeral, collaborative environments not usually considered &#8220;architecture&#8221; in the professional sense. This happens because they become directly involved with a variety of methods, construction activities, project types and materials normally associated with amateur building. The thesis does not aim to contribute to more comprehensive solutions for architectural production (say, commercial practice), but rather focuses on a particular production opportunity. It attempts to draw forth qualities of process, practice and conceptualisation that are of relevance to architecture and could be the basis of future exploration in architecture. With this intent, this thesis outlines a conceptual explanation for why these designers sometimes background their training in, and knowledge of, building procurement, in favour of amateur building activities. This design approach raises questions about the way architecture is understood, discussed and practiced. In philosophy and architectural theory, architecture is usually described as a device for ordering and framing the world, an opposition to the unfolding, unpredictable process of the evolving, natural world. Yet there are things that some designer-maker-inhabitants do in practice to thwart their environmental control and influence, thus introducing a degree of unpredictability into projects. This unusual design approach has the potential to inform discussions about architecture and architectural practice beyond this thesis. There is a plethora of technical information about DIY in the popular media, yet little investigation of how professionally-trained designers creatively engage with DIY. The experimental approach to building and space studied in this research is different to self-building or simple DIY because it does not adhere to a set of design plans or set approaches. This approach is also different to outsider architecture or vernacular building because it is initiated by people with design knowledge and training, even if they put aside some of their knowledge. To clarify this latter approach to architecture and space, the research describes a space of blurring between professional and non-professional building, architectural control and spontaneity; a space of germinant practice, based on the precepts and proposals manifest in germinant philosophy. The thesis includes speculations about ways to encourage germinancy in design practice. This practice-led study involved preliminary fieldwork studies through critical analysis of my own, and others, sitespecific installation art practice. These preliminary studies led to two major fieldwork projects in Brisbane: both are homes to artists and architecturally- trained designers working outside of commercial, professional practice.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">germinant design practice, Deleuze &amp; Guattari, do-it-yourself, site-specific installation art, experimental making</field><field name="identifier">http://eprints.qut.edu.au/19153/</field><field name="validLink">True</field></doc><doc><field name="title">Levels of pollutants on the surfaces of children's playgrounds situated in public parks</field><field name="creator">Mostert, Maria M. R.</field><field name="description">Small children have been shown to be vulnerable to environmental contaminants, because of their developing nervous systems and small body size. Children may be exposed to environmental contaminants both indoors and outdoors. They are also more likely to ingestion of such pollutants because of the proximity to the pollutants to the surface, their hand-to-mouth behaviour and their tendency to eat soil. The aim of this study was to determine to which degree children may be exposed to pollutants in their outdoor playing areas. Most small children in urban areas spend their outdoor playing time in playgrounds situated in public parks. This study therefore investigated the level of pollutants in 50 playgrounds of public parks from two urban areas in south-east Queensland. The chemicals of interest were both heavy and light metals and polycyclic aromatic hydrocarbons (PAHs), which are known to be detrimental to human health. This is the first study of its kind in Queensland and the first to investigate both metals and PAHs in Australia.. All of the playgrounds investigated contained both metals and PAHs, but none of these exceeded threshold values as determined by the Queensland Department of Health. The highest concentrations of the chemicals were found in the finest particles contained in the playground covers. Moisture played an important role in limiting the concentration of chemicals. More moisture was generally associated with lower concentrations of chemicals. The natural background contributed most of the metals, while most of the PAHs derived from various types of vehicular emissions through atmospheric deposition. Exposure levels for small children were estimated using three different models for calculating the possible exposure equivalent to a recognised reference PAH compound. All estimated values were below threshold exposure levels as provided for under Queensland guidelines. The practice of covering the playground surfaces with fresh bark chips was found to limit the concentrations of metals in playground covers. It is recommended that the practice of covering playground surfaces with bark be continued, and that, further, these surfaces should regularly be sprayed with water, especially in dry areas.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">pollutants, children's playgrounds, public parks</field><field name="identifier">http://eprints.qut.edu.au/19202/</field><field name="validLink">True</field></doc><doc><field name="title">A first kiss is still a first kiss : romancing the mid-life reader and heroine</field><field name="creator">Barletta, Sandra Anne</field><field name="description">Through its depiction of heroines, romance fiction has the capacity to reflect the attitudes and concerns women face in society. However, the depiction of heroines in romance novels is bound by the constraints publishers place upon them. A vibrant, passionate mid-life heroine gets pushed into a subgenre where romance no longer exists as an option, while a mid-life reader in search of a romance heroine to identify with is relegated to novels where romance is a marginal issue, rather than the main impetus that leads the story. This study, and the novel A Basic Renovation, addresses a neglected demographic of reader and heroine who are marginalised within the romance genre. As well, it gives reasons why heroines need not be characterised in particular roles or situations as they age, and a rationale for why their underrepresentation as romance heroines should end.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">ageing, fiction, publishing, romance, romance novels, romance writing, women and ageing, women and fiction</field><field name="identifier">http://eprints.qut.edu.au/19205/</field><field name="validLink">True</field></doc><doc><field name="title">The rebels shout back : subaltern theory and the writing of 'A Christmas Game'</field><field name="creator">Hayden, Cheryl Joy</field><field name="description">The cultures and stories of peripheral populations and conquered peoples, which have largely been drowned out by the accepted discourse of the nation states that colonised them, have begun to be recouped and re-told.The subaltern school of post-colonial theory provides the writer of fiction with a range of theories from which to devise the means of voicing the unvoiced.  Among these, Ranajit Guha&#8217;s work on the prose of counter-insurgency provides the author with the key to finding lost voices, in particular those of the vanquished peasant rebel.   
 
 &#8220;A Christmas Game&#8221; is a fictional account of the 1549 Prayer Book Rebellion, in which the commons of Cornwall and Devon rebelled against the abolition of the mass and the introduction of the English language prayer book.  By analysing the language and detail contained in the substantial historical record, identifying that which is missing, and examining sources that detail the religious, cultural and &#8220;folk&#8221; elements of daily life, it is possible to see this event and re-tell it through the eyes of those characters whose stories have never been told and thereby create a new place from which to further debate and research.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">subaltern theory</field><field name="identifier">http://eprints.qut.edu.au/19211/</field><field name="validLink">True</field></doc><doc><field name="title">Ocular occupations : painting and other spatio-visual strategies for making and inhabiting architecture</field><field name="creator">Paine, Ashley I.</field><field name="description">Many writers have suggested that our capacity to occupy space meaningfully has been undermined by our contemporary ocular-centric culture, which distances us from reality and corrupts our physical and embodied experience of the world. This study challenges these claims within an architectural context, by examining the fundamentally visual nature of architecture and inhabitation as well as the spatio-visual practices, acts and strategies that we use to occupy space. Drawing on theory and practice-based methods from outside the professional limits of architectural practice, the study implements visual acts of occupation to establish a new and expanded conception of architecture as a performative spatio-visual practice &#8211; a conception that engages and connects its practice with the purportedly ocular-centric spatial conditions in which it is made and occupied.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">architecture, social space, occupation, visual space, virtual space, physical space, real space, psychical space, visual arts, painting, installation, visual culture, surface, image</field><field name="identifier">http://eprints.qut.edu.au/19222/</field><field name="validLink">True</field></doc><doc><field name="title">The new lows : representing Asian-Australians on television</field><field name="creator">Law, Benjamin Yuk Nung</field><field name="description">This project utilises creative practice as research, and involves writing and discussing four sample episodes of a proposed six-part dramatic, black-comedy1 television mini-series titled The New Lows. Combined, the creative project and accompanying exegesis seeks to illuminate and interrogate some of the inherent concerns, pitfalls and politics encountered in writing original Asian-Australian characters for television. Moreover, this thesis seeks to develop and deliberate on characters that would expand, shift and extend concepts of stereotyping and authenticity as they are used in creative writing for television. The protagonists of The New Lows are the contemporary and dysfunctional Asian-Australian Lo family: the Hong Kong immigrants John and Dorothy, and their Australian-born children Wendy, Simon and Tommy. Collectively, they struggle to manage the family business: a decaying suburban Chinese restaurant called Sunny Days, which is stumbling towards imminent commercial death. At the same time, each of the characters must negotiate their own personal catastrophes, which they hide from fellow family members out of shame and fear. Although there is a narrative arc to the series, I have also endeavoured to write each episode as a selfcontained story. Written alongside the creative works is an exegetical component. Through the paradigm of Asian-Australian studies, the exegesis examines the writing process and narrative content of The New Lows, alongside previous representations of Asians on Australian and international television and screen. Concepts discussed include stereotype, ethnicity, otherness, hybridity and authenticity. However, the exegesis also seeks to question the dominant cultural paradigms through which these issues are predominantly discussed. These investigations are particularly relevant, since The New Lows draws upon a suite of characters commonly considered to be stereotypical in Asian-Australian representations.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Asian-Australians on television, screenplay</field><field name="identifier">http://eprints.qut.edu.au/29272/</field><field name="validLink">True</field></doc><doc><field name="title">Fact or fiction? : photography merging genres in children's picturebooks</field><field name="creator">McKelvey, Bridgette</field><field name="description">This paper explores photography in children&#8217;s picturebooks and its ability to extend image-making and reading by creating a hybrid genre that merges real and non-real worlds. In analysing the use of photography in such a hybrid genre, the work of Lauren Child (2006, 2001a, 2001b, 2000), Polly Borland (2006), Shaun Tan (2007, 2000, 1998) and Dave McKean (2004a, 2004b, 1995) is deconstructed. These artists utilise photography in contemporary picturebooks that are fictional. In addition, David Doubilet&#8217;s images (1990, 1989, 1984, 1980) are discussed, which fuse underwater photojournalism with art, for factual outputs. 
 
 This research uncovers a gap in picturebook literature and creates a new hybrid by merging genres to produce a work that is both factual and fictional. The research methodology in this study includes a brief overview of photography and notions of truth, contemporary picturebook trend theory, use of a student focus group, industry collaborations and workshops, and environmental education pedagogy. This thesis outlines summaries of research outcomes, not the least of which is the capacity for photography to enrich narrative accounts by providing multilayered information, character perspectives and/ or a metafictive experience. These research outcomes are then applied to the process of creating such a hybrid children&#8217;s picturebook.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">picturebooks, photorealism, mixed media, photography, metafiction, pedagogy</field><field name="identifier">http://eprints.qut.edu.au/19232/</field><field name="validLink">True</field></doc><doc><field name="title">Training of traditional birth attendants : an examination of the influence of biomedical frameworks of knowledge on local birthing practices in India</field><field name="creator">Saravanan, Sheela</field><field name="description">Pregnancy and childbirth complications are a leading cause of death and disability among women of reproductive age in developing countries. Worldwide data shows that, by choice or out of necessity, 60 percent of births in the developing world occur outside a health institution and 47 percent are assisted by Traditional Birth Attendants (TBAs), family members, or without any assistance at all. This thesis argues that TBAs in India have the capacity to disseminate knowledge of beneficial maternal practices to the community. Since the 1970s the training of TBAs has been one of the primary single interventions encouraged by World Health Organisation (WHO) to address maternal mortality. However, since the 1990s international funding for TBAs has been reduced and the emphasis has shifted to providing skilled birth attendants for all births due to evidence that the maternal mortality rate (MMR) in developing countries had not reduced. Researchers have observed that the shift in policy has taken place without adequate evidence of training (in)effectiveness and without an alternative policy in place. This thesis argues further that two main types of birthing knowledge co-exist in India; western biomedicine and traditional knowledge. Feminist, anthropological, and midwifery theorists contend that when two knowledge paradigms exist, western knowledge tends to dominate and claim authority over local ways of knowing. The thesis used such theories, and quantitative and qualitative methods, to assess whether the local TBA training programmes in Ahmednagar District in India have been successful in disseminating biomedical knowledge in relation to the birthing practices of local TBAs and in incorporating local knowledge into the training. The data revealed that some biomedical knowledge had been successfully disseminated and that some traditional practices continue to be practiced in the community. There is a top-down, one-sided imposition of biomedical knowledge on TBAs in the training programme but, at the local level, TBAs and mothers sometimes follow the training instructions and sometime do not, preferring to adapt to the local perceptions and preferences of their community. The thesis reveals the significance of TBA training in the district but queries the effectiveness of not including local TBA practices into the training programmes, arguing this demonstrates the hierarchical authority of biomedicine over local traditional practices. The thesis highlights the significance of community awareness that accompanies TBA training and makes recommendations in order to enhance training outcomes.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">authoritative knowledge, birthing practices, biomedical practices, developing countries, maternal and child health, traditional birth attendant's training programme, traditional birth attendants (TBAS), traditional practices</field><field name="identifier">http://eprints.qut.edu.au/19234/</field><field name="validLink">True</field></doc><doc><field name="title">A porous field: immersive inter-media installation and blurring the boundaries of perception</field><field name="creator">Verban, Alison Jane</field><field name="description">Through creative and theoretical research, this practice-led PhD project investigates the conditions that facilitate embodied sensory awareness within digital inter-media installation. Central to this exploration are questions concerning &#8216;immersion.&#8217; The research uses this term to describe a transformation in perception that allows us to shake off representational and symbolic meaning in favour of embodied, sensory and intuitive awareness within an installation space. Drawing from embodied memories of immersion in natural and spiritual environments, I consider the elements that contributed to these experiences and ask whether it is possible to create this sense of immersion in art. I then consider the elements that produce immersive, inter-media environments including space, sound, light, and projected moving images. Drawing on theoretical and artistic precedents, I propose a set of principles for producing a sense of embodied sensory immersion. The practical outcomes of the research - three digital inter-media installations included in the exhibition, in an other light - incorporate different combinations and treatments of these material elements to investigate and test the proposed principles.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">immersion, embodied awareness, sensory perception, multi-sensory, phenomenology, Maurice Merleau-Ponty, art and spirituality, time-based art, sound art, sound installation, projected moving image, installation, digital inter-media art</field><field name="subject">minimalist sculpture/installation, post-minimalist installation, Robert Irwin, James Turrell, Wassily Kandinsky, Fourth dimension, Pierre Schaeffer, Brian Eno, Michael Brewster, Maryanne Amacher, Bernhard Leitner, Bill Viola, Steiner Vasulka</field><field name="subject">creative practice, practice-led research</field><field name="identifier">http://eprints.qut.edu.au/19237/</field><field name="validLink">True</field></doc><doc><field name="title">Host B cells produce IL-10 following TBI and attenuate acute GVHD after allogeneic bone marrow transplantation</field><field name="creator">Rowe, Vanessa Robyn</field><field name="description">Host antigen presenting cells (APC) are known to be critical for the induction of graft versus host disease (GVHD) after allogeneic bone marrow transplantation (BMT) but the relative contribution of specific APC subsets remains unclear. We have studied the role of host B cells in GVHD by using B cell deficient (&#236;MT) mice as bone marrow transplant recipients in a model of CD4 T cell-dependent GVHD to major histocompatibility antigens. We demonstrated that acute GVHD is initially augmented in &#236;MT recipients relative to wild-type (WT) recipients (mortality: 85% v 44%, P&lt;0.01) and that this was the result of an increase in donor T cell proliferation, expansion and inflammatory cytokine production early after BMT. Recipient B cells were depleted 28-fold at the time of BMT by total body irradiation (TBI) administered 24 hours earlier and we demonstrated that TBI rapidly induced sustained IL-10 generation from B cells but not dendritic cells (DC) or other cellular populations within the spleen. Finally, recipient mice in which B cells were unable to produce IL-10 due to homologous gene deletion developed more severe acute GVHD than recipient mice in which B cells are WT. Thus the induction of interlukin-10 (IL-10) in host B cells during TBI attenuates experimental acute GVHD.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">B cells, interleukin-10, acute GVHD, antigen presenting cells</field><field name="identifier">http://eprints.qut.edu.au/19239/</field><field name="validLink">False</field></doc><doc><field name="title">Bayesian model estimation and comparison for longitudinal categorical data</field><field name="creator">Tran, Thu Trung</field><field name="description">In this thesis, we address issues of model estimation for longitudinal categorical data and of model selection for these data with missing covariates. Longitudinal survey data capture the responses of each subject repeatedly through time, allowing for the separation of variation in the measured variable of interest across time for one subject from the variation in that variable among all subjects. Questions concerning persistence, patterns of structure, interaction of events and stability of multivariate relationships can be answered through longitudinal data analysis. Longitudinal data require special statistical methods because they must take into account the correlation between observations recorded on one subject. A further complication in analysing longitudinal data is accounting for the non- response or drop-out process. Potentially, the missing values are correlated with variables under study and hence cannot be totally excluded. Firstly, we investigate a Bayesian hierarchical model for the analysis of categorical longitudinal data from the Longitudinal Survey of Immigrants to Australia. Data for each subject is observed on three separate occasions, or waves, of the survey. One of the features of the data set is that observations for some variables are missing for at least one wave. A model for the employment status of immigrants is developed by introducing, at the first stage of a hierarchical model, a multinomial model for the response and then subsequent terms are introduced to explain wave and subject effects. To estimate the model, we use the Gibbs sampler, which allows missing data for both the response and explanatory variables to be imputed at each iteration of the algorithm, given some appropriate prior distributions. After accounting for significant covariate effects in the model, results show that the relative probability of remaining unemployed diminished with time following arrival in Australia. Secondly, we examine the Bayesian model selection techniques of the Bayes factor and Deviance Information Criterion for our regression models with miss- ing covariates. Computing Bayes factors involve computing the often complex marginal likelihood p(y|model) and various authors have presented methods to estimate this quantity. Here, we take the approach of path sampling via power posteriors (Friel and Pettitt, 2006). The appeal of this method is that for hierarchical regression models with missing covariates, a common occurrence in longitudinal data analysis, it is straightforward to calculate and interpret since integration over all parameters, including the imputed missing covariates and the random effects, is carried out automatically with minimal added complexi- ties of modelling or computation. We apply this technique to compare models for the employment status of immigrants to Australia. Finally, we also develop a model choice criterion based on the Deviance In- formation Criterion (DIC), similar to Celeux et al. (2006), but which is suitable for use with generalized linear models (GLMs) when covariates are missing at random. We define three different DICs: the marginal, where the missing data are averaged out of the likelihood; the complete, where the joint likelihood for response and covariates is considered; and the naive, where the likelihood is found assuming the missing values are parameters. These three versions have different computational complexities. We investigate through simulation the performance of these three different DICs for GLMs consisting of normally, binomially and multinomially distributed data with missing covariates having a normal distribution. We find that the marginal DIC and the estimate of the effective number of parameters, pD, have desirable properties appropriately indicating the true model for the response under differing amounts of missingness of the covariates. We find that the complete DIC is inappropriate generally in this context as it is extremely sensitive to the degree of missingness of the covariate model. Our new methodology is illustrated by analysing the results of a community survey.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">longitudinal data analysis, generalized linear models, Bayesian hierarchical models, Bayesian model choice, Bayes factors, deviance information criterion, missing data</field><field name="identifier">http://eprints.qut.edu.au/19240/</field><field name="validLink">True</field></doc><doc><field name="title">The entrepreneurial playwright : a relational approach to marketing plays in the regions</field><field name="creator">Ainsworth, Rodney Phillip</field><field name="description">This exegesis examines the proposition that playwriting is an entrepreneurial activity when combined with the role of producer. The thesis demonstrates that, when a playwright combines the two roles and considers the development of a network of relationships in the process, positive steps can be made towards the marketing of a work and the career progression of the playwright. The issues of marketing and career progression are considered in a regional context.
 The thesis comprises the creation of a full-length theatrical work through the MA (Research) Program at Queensland University of Technology and an analysis of that journey in the context of regional theatre practice in Queensland.  Nicolas Bourriaud&#8217;s theory of the Relational Aesthetic is used as a way of charting my practice and of examining how this approach might be appropriate to theatre-making in regional Australia. The paper establishes strategies by which the playwright, when also undertaking the role of producer, might manage the complex set of circumstances and interactions between the work, the community and the industry. 
 Using practice-led research methodologies, the exegesis examines the process of the creation of a new play, Sinking, and explores, through the use of an autobiographical case study, what the process has meant to the author&#8217;s development as a playwright over a fifteen month period. The paper uses a network map to explore the interactions created through a rehearsed reading of the first draft of the play in October 2006 and, in doing so, demonstrates how a close engagement with the community formed the basis of the entrepreneurial strategy. 
 The exegesis demonstrates that Bourriaud&#8217;s work connects very closely with the author&#8217;s practice and examines how the approach might be useful for other regional arts practitioners, particularly those in the early stages of their careers. The research aims to identify how the creation of the play, and the subsequent interactions generated within a regional community, can lead to opportunities to create connections both within the author&#8217;s place of residence and in broader theatre industry contexts, nationally and internationally, in order to provide commercial and professional outcomes.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">regional, theatre, marketing, relational aesthetic, relationship marketing, playwriting, theatre, practice-led research, creative industries, entrepreneur, entrepreneurship, animateur, network weaver, network mapping, producer, business, preface</field><field name="subject">autobiography, networks, systems, Queensland, Australia</field><field name="identifier">http://eprints.qut.edu.au/19241/</field><field name="validLink">True</field></doc><doc><field name="title">Asset management data warehouse data modelling</field><field name="creator">Mathew, Avin D.</field><field name="description">Data are the lifeblood of an organisation, being employed by virtually all business functions within a firm. Data management, therefore, is a critical process in prolonging the life of a company and determining the success of each of an organisation&#8217;s business functions. The last decade and a half has seen data warehousing rising in priority within corporate data management as it provides an effective supporting platform for decision support tools. A cross-sectional survey conducted by this research showed that data warehousing is starting to be used within organisations for their engineering asset management, however the industry uptake is slow and has much room for development and improvement. This conclusion is also evidenced by the lack of systematic scholarly research within asset management data warehousing as compared to data warehousing for other business areas. This research is motivated by the lack of dedicated research into asset management data warehousing and attempts to provide original contributions to the area, focussing on data modelling. Integration is a fundamental characteristic of a data warehouse and facilitates the analysis of data from multiple sources. While several integration models exist for asset management, these only cover select areas of asset management. This research presents a novel conceptual data warehousing data model that integrates the numerous asset management data areas. The comprehensive ethnographic modelling methodology involved a diverse set of inputs (including data model patterns, standards, information system data models, and business process models) that described asset management data. Used as an integrated data source, the conceptual data model was verified by more than 20 experts in asset management and validated against four case studies. A large section of asset management data are stored in a relational format due to the maturity and pervasiveness of relational database management systems. Data warehousing offers the alternative approach of structuring data in a dimensional format, which suggests increased data retrieval speeds in addition to reducing analysis complexity for end users. To investigate the benefits of moving asset management data from a relational to multidimensional format, this research presents an innovative relational vs. multidimensional model evaluation procedure. To undertake an equitable comparison, the compared multidimensional are derived from an asset management relational model and as such, this research presents an original multidimensional modelling derivation methodology for asset management relational models. Multidimensional models were derived from the relational models in the asset management data exchange standard, MIMOSA OSA-EAI. The multidimensional and relational models were compared through a series of queries. It was discovered that multidimensional schemas reduced the data size and subsequently data insertion time, decreased the complexity of query conceptualisation, and improved the query execution performance across a range of query types. To facilitate the quicker uptake of these data warehouse multidimensional models within organisations, an alternate modelling methodology was investigated. This research presents an innovative approach of using a case-based reasoning methodology for data warehouse schema design. Using unique case representation and indexing techniques, the system also uses a business vocabulary repository to augment case searching and adaptation. The system was validated through a case-study where multidimensional schema design speed and accuracy was measured. It was found that the case-based reasoning system provided a marginal benefit, with a greater benefits gained when confronted with more difficult scenarios.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">asset management, data warehousing, conceptual data model, multidimensional model, star schemas, case-based reasoning</field><field name="identifier">http://eprints.qut.edu.au/19310/</field><field name="validLink">True</field></doc><doc><field name="title">Strongly localised plasmons in metallic nanostructures</field><field name="creator">Vernon, Kristy C.</field><field name="description">Strongly localised plasmons in metallic nano-structures offer exciting characteristics for guiding and focusing light on the nano-scale, opening the way for the development of new types of sensors, circuitry and improved resolution of optical microscopy. The work presented in this thesis focuses on two major areas of plasmonics research - nano-focusing structures and nano-sized waveguides. Nano-focusing structures focus light to an area smaller than the wavelength and will find applications in sensing, efficiently coupling light to nano-scale devices, as well as improving the resolution of near field microscopy. In the past the majority of nano-focusing structures have been nano-scale cones or tips, which are capable of focusing light to a spot of nano-scale area whilst enhancing the light field. The alternatives are triangular nano-focusing structures which have received far less attention, and only one type of triangular nano-focusing structure is known &#8211; a sharp V-groove in a metal substrate. This structure focuses light to a strip of nano-scale width, which may lead to new applications in microscopy and sensing. The difficulty with implementing the V-groove is that the structure is not robust and is quite difficult to fabricate. This thesis aims to develop new triangular nano-focusing devices which will overcome these difficulties, whilst still producing an intense light source on the nano-scale. The two proposed structures presented in this thesis are a metallic wedge submerged in uniform dielectric and a tapered metal film lying on a dielectric substrate, the latter being the easier to fabricate and the more structurally sound and robust. The investigation is performed using the approximation of continuous electrodynamics, the geometrical optics approximation and the zero-plane method. The second aim of this thesis is to investigate plasmonic waveguides and couplers for the development of nano-optical circuitry, more compact photonic devices and sensors. The research will attempt to fill the gaps in the current knowledge of the V-groove waveguide, which consists of a sharp triangular groove in a metal substrate, and the gap plasmon waveguide, which consists of a rectangular slot in a thin metal film. The majority of this work will be performed using the author&#8217;s in house finite-difference time-domain algorithm and FEMLAB as well as the effective medium method and geometric optics approximation. The V-groove may be used as either a nano-focusing or waveguiding device. As a waveguide the V-groove is one of the most promising plasmonic waveguides in the optical regime. However, there exist quite a number of gaps in the current knowledge of V-groove waveguides which this thesis will attempt to fill. In particular, the effect of rounded groove tip on plasmon propagation has been assessed for the V-groove. The investigation of rounded groove tip is important, as due to modern fabrication processes it&#8217;s not possibly to produce an infinitely sharp groove, and the existing literature has not considered the impact of this problem. The thesis will also investigate the impacts of the inclusion of dielectric filling in the groove on plasmon propagation parameters. This research will be important for optimising the propagation characteristics of the mode for certain applications, but it may also lead to easier methods of fabricating the V-groove device and prevent oxidation of the metal film. The gap plasmon waveguide is easier to fabricate than the V-groove, and is a new type of sub-wavelength waveguide which displays many advantages over other types of plasmon waveguides, including ease of fabrication, almost 100% transmission around sharp bends, sub-wavelength localisation and long propagation distances of the guided mode, etc. This waveguide may prove invaluable in the development of compact photonic devices. In the past the modes supported by this structure were not thoroughly analysed and the possibility of using this structure to develop sub-wavelength couplers for sensing and nano-optical circuits was not considered in detail. This thesis aims to resolve these issues. In conclusion, the results of this thesis will lead to a better understanding of Vgroove and gap plasmon waveguide devices for the development of nano-optical circuits, compact photonic devices and sensors. This thesis also proposes two new nano-focusing structures which are easier to fabricate than the V-groove structure and will lead to applications in sensing, coupling light efficiently into nano-scale devices and improving the resolution of near-field microscopy.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">nano-optics, plasmon, nano-focusing, sub-wavelength waveguides, wedge, film plasmon, gap plasmon, gap plasmon waveguide, V-groove, sub-wavelength coupler, finite-difference time-domain, geometric optics approximation, effective medium method</field><field name="subject">zero plane method</field><field name="identifier">http://eprints.qut.edu.au/19318/</field><field name="validLink">True</field></doc><doc><field name="title">A future in the past : urban agroforestry systems in future planned urban settlements in Kiribati, a Pacific case study</field><field name="creator">East, Andrew John</field><field name="description">In the last 50 years, Pacific Island Countries (PICs) have experienced unprecedented levels of urban development. During this time, the general failure of traditional industrialised planning models to be successfully adapted in PICs has resulted in the need to explore alternative models for urban settlement in the Pacific. In this way, the incorporation of tree based agricultural systems (agroforestry) into urban settlements has considerable potential to address many of the problems associated with rapid urbanisation such as food security, waste management, environmental degradation and unemployment. Research in the Pacific has already shown how urban agroforestry systems can improve food security, increase access to nutritional foods, recycle organic waste, create employment and protect fragile ecological systems. However, in Pacific towns and cities urban agroforestry systems are rarely developed beyond a homegarden setting. The growth of urban centres in the Republic of Kiribati is an example of the challenges confronting many rapidly urbanising PICs. With infertile soils, severely restricted land and water resources and an emerging economy, Kiribati is a developing nation where sustainable development faces some of its greatest challenges. Due to rapidly expanding urban populations, the Kiribati Government is currently investigating the development of future planned urban settlements. In such a scenario, potential exists to extend urban agroforestry systems beyond a homegarden setting and explore alternative models for sustainable urbanisation in the Pacific. This research uses a mixed methods case study approach to investigate the potential role of food producing urban agroforestry systems in future planned urban settlements in Kiribati. More specifically, qualitative procedures are used to explore issues surrounding the promotion and development of urban agroforestry systems in future planned urban settlements while quantitative procedures are used to analyse the nutritional contribution of these systems. Findings from this study show that although urban agroforestry is a highly sustainable land use it faces two main challenges in Kiribati: (i) people&#8217;s perception that urban agroforestry systems are a relatively low value land use and (ii) the general inability of the Kiribati Government to effectively regulate urban land uses. However, in the event that urban agroforestry systems were deliberately included at a settlement wide scale beyond a homegarden setting, this study highlights the initial importance of equally allocating productive lands to individual households. Furthermore, the results emphasise the value of simple on-site composting technologies as components of the broader urban agroforestry system. Finally, the marginal nature of the atoll environment is evident in findings on the nutritional contribution of urban agroforestry species in future planned urban settlements. In summary, while considerable constraints must be overcome to ensure the long term viability of planned urban agroforestry systems at a whole of settlement scale, it is argued that such an approach is one of the most cost effective, culturally acceptable and environmentally responsible methods for addressing a range of urban issues in the Pacific and is therefore an essential component to the design of future planned urban settlements in Kiribati.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Pacific Islands, agroforestry, Kiribati, homegardening, sustainable development</field><field name="identifier">http://eprints.qut.edu.au/19333/</field><field name="validLink">True</field></doc><doc><field name="title">Investigation of fisheye lenses for small UAV aerial photography</field><field name="creator">Gurtner, Alex</field><field name="description">Aerial photography obtained by UAVs (Unmanned Aerial Vehicles) is an emerging market for civil applications. Small UAVs are believed to close gaps in niche markets, such as acquiring airborne image data for remote sensing purposes. Small UAVs will be able to fly at low altitudes, in dangerous environments and over long periods of time. However, the small lightweight constructions of these UAVs lead to new problems, such as higher agility leading to more susceptibility to turbulence and limitations in space and payload for sensor systems. This research investigates the use of low-cost fisheye lenses to overcome such problems which theoretically makes the airborne imaging less sensitive to turbulence. The fisheye lens has the benet of a large observation area (large field of view) and doesn't add additional weight to the aircraft, like traditional mechanical stabilizing systems. This research presents the implementation of a fisheye lens for aerial photography and mapping purposes, including theoretical background of fisheye lenses. Based on the unique feature of the distortion being a function of the viewing angle, methods used to derive the fisheye lens distortion are presented. The lens distortion is used to rectify the fisheye images before these images can be used in aerial photography. A detailed investigation into the inner orientation of the camera and inertial sensor is given, as well as the registration of airborne collected images. It was found that the attitude estimation is critical towards accurate mapping using low quality sensors. A loosely coupled EKF filter applied to the GPS and inertial sensor data estimated the attitude to an accuracy of 3-5&#176; (1-sigma) using low-cost sensors typically found in small UAVs. However, the use of image stitching techniques may improve the outcome. On the other hand, lens distortion caused by the fisheye lens can be addressed by rectification techniques and removed to a sub-pixel level. Results of the process present image sequences gathered from a piloted aircraft demonstrating the achieved performance and potential applications towards UAVs. Further, an unforeseen issue with a vibrating part in the lens lead to the need for vibration compensation. The vibration could be estimated to &#177;1 pixel in 75% of the cases by applying an extended Hough transform to the fisheye images.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">fisheye lenses, unmanned aerial vehicles (UAV), aerial photography</field><field name="identifier">http://eprints.qut.edu.au/19323/</field><field name="validLink">True</field></doc><doc><field name="title">The Mt. Marcella volcanics : middle Triassic convergent margin volcanism in Southeast Queensland</field><field name="creator">Buck, Adrian</field><field name="description">Triassic igneous rocks in southeast Queensland show a number of subduction related geochemical characteristics. Extensive calc-alkalic granitoids chains characterise the region and define the ancient arc setting. Despite good evidence that an arc was present, Triassic volcanic rocks are relatively sparse in southeast Queensland. The Mt Marcella Volcanics, of the northern Esk Trough are a previously poorly understood piece of the Middle Triassic convergent margin of southeast Queensland. A three stage model is proposed for the eruptive development of the Middle Triassic (245- 230Ma) volcanic succession that involves; 1) The Middle Triassic basalt, comprising coalesced lava flows covering as much as 500km2 with an estimated eruptive volume in the order of 50km3. 2) The Penwhaupell Volcanic Centre, a concentration of inter-bedded lavas and pyroclastic rocks dominated by dacite that forms a volcanic pile exceeding 2km stratigraphic thickness and representing an eruptive volume of approximately 48km3. 3) The Ettiewyn Caldera, representing the catastrophic culmination of the Mt Marcella Volcanics event, with a sequence of caldera out-flow and in-fill andesite ignimbrites and post-caldera lavas with a total eruptive volume in the order of 130km3. The &#8220;Penwhaupell Volcanic Centre&#8221; and the &#8220;Ettiewyn Caldera&#8221; are two new sub-divisions and the proposed names, for the lower and upper sequences of the previously undifferentiated Mt Marcella Volcanics. The Mt Marcella Volcanics magma compositions show cogenetic characteristics that define three evolutionary pathways; 1) a mildly alkali series, from basaltic-andesite to trachy-dacite related through fractionation dominated by plagioclase and clinopyroxene 2) an amphibole series, basaltic-andesite to hornblende dacite through fractionation dominated by plagioclase and hornblende under hydrous conditions, and 3) a pyroxene series, from basaltic-andesite to pyroxene andesite through fractionation dominated by plagioclase and pyroxene. Quantitative petrogenetic models generally support the proposed fractional crystallisation pathway, however weaknesses are acknowledged, with good results for the major elements and REE off-set by generally poor results for the LILE. Despite the inconclusive trace element results for the modelled fractionation, strong geochemical similarities and cogenetic relationships have been established. A typical arc-like geochemical signature including a pronounced Nb depletion characterises the Mt Marcella Volcanics. However, the geochemical character within the Middle Triassic volcanic succession reveals an unusual transition from an OIB character of the Middle Triassic basalts, to the Andean arc character of later Mt Marcella Volcanics. The implications of this could have profound impact on our understanding of how southeast Queensland&#8217;s Triassic tectonic setting operated by providing support for hotspot activity rather than subduction-driven activity.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">volcanism, Southeast Queensland, Triassic, Mt. Marcella</field><field name="identifier">http://eprints.qut.edu.au/20171/</field><field name="validLink">True</field></doc><doc><field name="title">Who are the MySpace generation and how can they be represented in a work of fiction?</field><field name="creator">Duncan, Alasdair John</field><field name="description">This document contains a creative work &#8211; the text of a young adult novel, The girl and the sea &#8211; and an exegesis examining the MySpace Generation through the methodological prisms of online ethnography and literature review.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">social networking, MySpace, online ethnography, young adult novel, Schoolies Week, Australian</field><field name="identifier">http://eprints.qut.edu.au/20176/</field><field name="validLink">True</field></doc><doc><field name="title">But what I really want to do is write : adapting the Mike Leigh Method for writers for the stage</field><field name="creator">Irvine, Ian Kyle</field><field name="description">This thesis, comprised of a stage play and exegesis, asks whether the Mike Leigh Method, commonly used by Auteur directors could be adapted to benefit a playwright during the redrafting and development process. I seek to answer this question by examining differing methodologies of drama creation and charting my process as I work to redraft my character driven stage play Deceased Estate through the adaptation and application of the Mike Leigh Method. I contend that Leigh&#8217;s method affords a set of honed and proven guidelines that can help the playwright get to the heart of the character driven drama and offer an adapted method template that can be used and furthered by other Playwrights wishing to develop their work in this manner.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Mike Leigh Method, improvise, improvisation, Mike Leigh, development, playwriting, performance, theatre, play, script, workshop, redraft, rewrite</field><field name="identifier">http://eprints.qut.edu.au/20126/</field><field name="validLink">True</field></doc><doc><field name="title">The development of rapid genotyping methods for methicillin-resistant Staphylococcus aureus</field><field name="creator">Stephens, Alex J.</field><field name="description">Methicillin-resistant Staphylococcus aureus (MRSA) is an important human pathogen that is endemic in hospitals all over the world. It has more recently emerged as a serious threat to the general public in the form of community-acquired MRSA. MRSA has been implicated in a wide variety of diseases, ranging from skin infections and food poisoning to more severe and potentially fatal conditions, including; endocarditis, septicaemia and necrotising pneumonia. Treatment of MRSA disease is complicated and can be unsuccessful due to the bacterium's remarkable ability to develop antibiotic resistance. 
 
 The considerable economic and public health burden imposed by MRSA has fuelled attempts by researchers to understand the evolution of virulent and antibiotic resistant strains and thereby improve epidemiological management strategies. Central to MRSA transmission management strategies is the implementation of active surveillance programs, via which unique genetic fingerprints, or genotypes, of each strain can be identified. Despite numerous advances in MRSA genotyping methodology, there remains a need for a rapid, reproducible, cost-effective method that is capable of producing a high level of genotype discrimination, whilst being suitable for high throughput use. Consequently, the fundamental aim of this thesis was to develop a novel MRSA genotyping strategy incorporating these benefits. 
 
 This thesis explored the possibility that the development of more efficient genotyping strategies could be achieved through careful identification, and then simple interrogation, of multiple, unlinked DNA loci that exhibit progressively increasing mutation rates. The baseline component of the MRSA genotyping strategy described in this thesis is the allele-specific real-time PCR interrogation of slowly evolving core single nucleotide polymorphisms (SNPs). The genotyping SNP set was identified previously from the Multi-locus sequence typing (MLST) sequence database using an in-house software package named Minimum SNPs. As discussed in Chapter Three, the genotyping utility of the SNP set was validated on 107 diverse Australian MRSA isolates, which were largely clustered into groups of related strains as defined by MLST. To increase the resolution of the SNP genotyping method, a selection of binary virulence genes and antimicrobial resistance plasmids were tested that were successful at sub typing the SNP groups. 
 
 A comprehensive MRSA genotyping strategy requires characterisation of the clonal background as well as interrogation of the hypervariable Staphylococcal Cassette Chromosome mec (SCCmec) that carries the &#946;-lactam resistance gene, mecA. SCCmec genotyping defines the MRSA lineages; however, current SCCmec genotyping methods have struggled to handle the increasing number of SCCmec elements resulting from a recent explosion of comparative genomic analyses. Chapter Four of this thesis collates the known SCCmec binary marker diversity and demonstrates the ability of Minimum SNPs to identify systematically a minimal set of binary markers capable of generating maximum genotyping resolution. A number of binary targets were identified that indeed permit high resolution genotyping of the SCCmec element. Furthermore, the SCCmec genotyping targets are amenable for combinatorial use with the MLST genotyping SNPs and therefore are suitable as the second component of the MRSA genotyping strategy.
 
 To increase genotyping resolution of the slowly evolving MLST SNPs and the SCCmec binary markers, the analysis of a hypervariable repeat region was required. Sequence analysis of the Staphylococcal protein A (spa) repeat region has been conducted frequently with great success. Chapter Five describes the characterisation of the tandem repeats in the spa gene using real-time PCR and high resolution melting (HRM) analysis. Since the melting rate and precise point of dissociation of double stranded DNA is dependent on the size and sequence of the PCR amplicon, the HRM method was used successfully to identify 20 of 22 spa sequence types, without the need for DNA sequencing.
 
 The accumulation of comparative genomic information has allowed the systematic identification of key MRSA genomic polymorphisms to genotype MRSA efficiently. If implemented in its entirety, the strategy described in this thesis would produce efficient and deep-rooted genotypes. For example, an unknown MRSA isolate would be positioned within the MLST defined population structure, categorised based on its SCCmec lineage, then subtyped based on the polymorphic spa repeat region. Overall, by combining the genotyping methods described here, an integrated and novel MRSA genotyping strategy results that is efficacious for both long and short term investigations. Furthermore, an additional benefit is that each component can be performed easily and cost-effectively on a standard real-time PCR platform.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Methicillin-resistant Staphylococcus aureus, MRSA, single nucleotide polymorphism, SNP, Multi-locus sequence typing, MLST, genotyping, high resolution melt, HRM, Minimum SNPs, real-time PCR, Staphylococcal cassette chromosome mec, SCCmec</field><field name="subject">Staphylococcal protein A, spa, comparative genomics, bioinformatics, binary markers</field><field name="identifier">http://eprints.qut.edu.au/20172/</field><field name="validLink">True</field></doc><doc><field name="title">TRAD. : an examination of narrative adaptation across popular media</field><field name="creator">May, Anthony</field><field name="description">'Trad.' is a collection of short stories and a critical essay that explores a number of issues involved in the adaptation of stories from one popular medium to another. Some problems of adaptation involve questions of the integrity or authenticity of both the original and adapted works. These problems are often made more difficult when the adaptation is made across different media forms. This thesis explores the transformation from popular song to short story in a popular mode in two ways. The first way is based on the recognition of the problems of determining authenticity when the processes of transmission are subject to such great variety as in popular song. The second way is to explore the question of the available popular forms of narrative for the adapted product. In each case, this thesis attempts its investigation in a practical mode through the variety of stories and the way in which they utilise contemporary narrative strategies.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">folk song, short stories, adaptation, popular media, cross-media</field><field name="identifier">http://eprints.qut.edu.au/20187/</field><field name="validLink">True</field></doc><doc><field name="title">Techniques for automated and interactive note sequence morphing of mainstream electronic music</field><field name="creator">Wooller, Ren&#233; William</field><field name="description">Note sequence morphing is the combination of two note sequences to create a &#8216;hybrid transition&#8217;, or &#8216;morph&#8217;. The morph is a &#8216;hybrid&#8217; in the sense that it exhibits properties of both sequences. The morph is also a &#8216;transition&#8217;, in that it can segue between them. An automated and interactive approach allows manipulation in realtime by users who may control the relative influence of source or target and the transition length. The techniques that were developed through this research were designed particularly for popular genres of predominantly instrumental electronic music which I will refer to collectively as Mainstream Electronic Music (MEM). The research has potential for application within contexts such as computer games, multimedia, live electronic music, interactive installations and accessible music or &#8220;music therapy&#8221;. Musical themes in computer games and multimedia can morph adaptively in response to parameters in realtime. Morphing can be used by electronic music producers as an alternative to mixing in live performance. Interactive installations and accessible music devices can utilise morphing algorithms to enable expressive control over the music through simple interface components. 
 I have developed a software application called LEMorpheus which consists of software infrastructure for morphing and three alternative note sequence morphing algorithms: parametric morphing, probabilistic morphing and evolutionary morphing. Parametric morphing involves converting the source and target into continuous envelopes, interpolation, and converting the interpolated envelopes back into note sequences. Probabilistic morphing involves converting the source and target into probability matrices and seeding them on recent output to generate the next note. Evolutionary morphing involves iteratively mutating the source into multiple possible candidates and selecting those which are judged as more similar to the target, until the target is reached. 
 I formally evaluated the probabilistic morphing algorithm by extracting qualitative feedback from participants in a live electronic music situation, benchmarked against a live, professional DJ. The probabilistic algorithm was competitive, being favoured particularly for long morphs. The evolutionary morphing algorithm was formally evaluated using an online questionnaire, benchmarked against a human composer/producer. For particular samples, the morphing algorithm was competitive and occasionally seen as innovative; however, the morphs created by the human composer typically received more positive feedback, due to coherent, large scale structural changes, as opposed to the forced continuity of the morphing software.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">morph, morphing, interpolation, morphology, mutation, computer music, algorithmic composition, algorithmic music, interactive music, adaptive music, adaptive audio, game music, live electronic music, sound installation, compositional, key modulation</field><field name="subject">temporal modulation, metric modulation, modulation, topology, note-level, note sequence, MIDI, medley, transition, mash-up, mix, remix, DJ, evolutionary art, evolutionary computing, Markov, conditional probability, generative music, transformational</field><field name="subject">jMusic, Java, Midishare, realtime, reacTIVision, morph table</field><field name="identifier">http://eprints.qut.edu.au/20232/</field><field name="validLink">True</field></doc><doc><field name="title">In the gaps left unfilled : historical fantasy and the past</field><field name="creator">McArthur, Maxine Elisabeth</field><field name="description">The thesis consists of the novel The Fox and the Mirror and an accompanying exegesis. The novel is an historical fantasy set in a world based on early medieval (12-13th century) Japan. The main characters are a young female shaman, Hatsu, and a young warrior&#8217;s assistant, Sada, who is a Buddhist believer. When Hatsu&#8217;s village and shrine are destroyed by warriors and her summoning mirror is stolen, she is abandoned by her kami . To experience the kami&#8217;s presence again, she must follow the thief and retrieve the mirror before it can be used to resurrect an ancient evil. Sada must capture Hatsu and bring her back to his lord, or his family will suffer. Yet he is entranced by Hatsu and feels guilt at the destruction of her village. He must choose whether to abandon his former life and stay with Hatsu, or betray her. 
 In the novel I have tried to invoke the feel of a place and time where the supernatural is as real as the physical world; I also try to imagine how a religion as alien to Japanese native beliefs as Buddhism became a part of that country&#8217;s spiritual culture. 
 In the exegesis I reflect upon how I used various kinds of history, both written and unwritten, to build the world, characters and narratives of The Fox and the Mirror, and thereby explore some ways in which historical fantasy, as a sub-genre of historical fiction, is capable of presenting an &#8216;authentic&#8217; view of the past, in spite of its non-realistic nature. I identify three main ways historical fantasy writers can provide an authentic view of the past: by using telling details from an historical era; by incorporating documented events and persons into the story; and by portraying the world as people in the past believed it to be. Historical fantasy is different from realistic historical fiction in that it can more easily incorporate elements belonging to shared cultural heritage, such as beliefs regarding the dead and the supernatural. This characteristic involves writers in research using material that involves other ways of knowing the past&#8212;in particular the expressions of belief such as religion, popular customs, folk tales, and oral history. With the broadening of our historiological perspectives in the postmodern climate, historical fantasy based on non-documentary forms of history may come to be seen as another way of knowing the past.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">historical fantasy, historical fiction, Japan, supernatural, religious beliefs, history and the past, historical fantasy writers, Japanese Buddhism, Shinto, history and fiction, fiction and the past, religious syncretism in Japan, angry ghosts</field><field name="subject">shamans in Japan, spirit summoning, Salmonson, Tezuka, Hughart, Princess Mononoke, kami</field><field name="identifier">http://eprints.qut.edu.au/20297/</field><field name="validLink">True</field></doc><doc><field name="title">Statistical model development to identify the best data pooling for early stage construction price forecasts</field><field name="creator">Tai Yeung, Kam Lan (Daisy)</field><field name="description">In the early feasibility study stage, the information concerning the target project is very limited. It is very common in practice for a Quantity Surveyor (Q.S.) to use the mean value of the historical building price data (with similar characteristics to the target project) to forecast the early construction cost for a target project. Most clients rely heavily on this early cost forecast, provided by the Q.S., and use it to make their investment decision and advance financial arrangement. The primary aim of this research is to develop a statistical model and demonstrate through this developed model how to measure the accuracy of mean value forecast. A secondary aim is to review the homogeneity of construction project cost. The third aim is to identify the best data pooling for mean value cost forecast in early construction stages by making the best use of the data available. Three types of mean value forecasts are considered: (1) the use of the target base group (relating to a source with similar characteristics to the target project), (2) the use of a non-target base group (relating to sources with less or dissimilar characteristics to the target project) and (3) the use of a combined target and non-target base group. A formulation of mean square error is derived for each to measure the forecasting accuracy. To accomplish the above research aims, this research uses cost data from 450 completed Hong Kong projects. The collected data is clustered into two levels as: (1) Level one - by project nature (i.e. Residential, Commercial centre, Car parking, Social community centre, School, Office, Hotel, Industrial, University and Hospital), (2) Level two -by project specification and construction floor area.  In this research, the accuracy of mean value forecast (i.e. mean square error) for a total number of 10,539 of combined data groups is measured. From their performance, it may reasonably be concluded that (1) the use of a non-target base group (relating to sources with less or dissimilar characteristics to the target project) never improves the forecasting performance, (2) the use of a target base group (relating to a source with similar characteristics to the target project) cannot always provide the best forecasting performance, (3) the use of a combined target and non-target base group in some cases can furnish a better forecasting performance, and (4) when the cost data groups are clustered into a more detailed level, it can improve the forecasting performance.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">contruction, price forecasts, statistical model development</field><field name="identifier">http://eprints.qut.edu.au/20300/</field><field name="validLink">True</field></doc><doc><field name="title">Health-related quality of life among breast cancer survivors : town and country experiences</field><field name="creator">Di Sipio, Tracey</field><field name="description">Due to advances in detection and treatment, increasing numbers of women are diagnosed with, and surviving, breast cancer each year, making women with breast cancer one of the largest groups of cancer survivors. Hence, ensuring good healthrelated quality of life (HRQoL) following treatment has become a focal point of cancer research and clinical interest. While our understanding about the impact of breast cancer is improving, little is known about the HRQoL among survivors in non-urban areas. This is important locally, as 45% of breast cancer survivors in Queensland, Australia, live outside major metropolitan areas. Therefore, this study investigated the HRQoL and accompanying correlates among regional and rural breast cancer survivors, and made comparisons with urban breast cancer survivors as well as women from the general population without a history of breast cancer. Three population-based studies comprise this project. Original data were collected by way of self-administered questionnaire from 323 women, diagnosed with a first, primary, invasive, unilateral breast cancer during 2006/2007 and residing in regional or rural areas of Queensland, 12 months following diagnosis. HRQoL was assessed using the Functional Assessment of Cancer Therapy, Breast plus additional concerns (FACT-B+4) questionnaire. Data from two existing data sources were also utilised. Women diagnosed with a first, primary, invasive, unilateral breast cancer in 2002 and residing within 100kms of Brisbane provided information on HRQoL, measured by the FACT-B+4, via self-administered questionnaire at six (n=287), 12 (n=277) and 18 (n=272) months post-diagnosis. Data at 12 months post-diagnosis was utilised for comparison with region and rural women with breast cancer. General population data for HRQoL, collected by self-administered questionnaire in 2004 using the Functional Assessment of Cancer Therapy-General (FACT-G) questionnaire, were derived from a subgroup of female residents without a history of breast cancer from urban (n=675), regional (n=184) and rural (n=281) Queensland. The two studies involving women with breast cancer were recruited sequentially through the Queensland Cancer Registry, whereas the study involving the general population used telephone survey methods initially to identify participants. Women who participated in all studies were aged between 30 and 74 years. Raw scores for overall HRQoL (FACT-B+4, FACT-G) and subscales were computed. According to developers of the instrument, raw score differences of eight points between groups on the FACT-B+4 scale and five points on the FACT-G scale reflect a clinically meaningful differences in HRQoL. Age-adjusted, mean HRQoL was similar between regional and rural women with breast cancer 12 months following diagnosis (e.g., FACT-B+4: 122.9 versus 123.7, respectively, p=0.74). However, younger regional and rural survivors reported lower HRQoL scores compared with their older counterparts (e.g., FACT-B+4: 112.0 and 115.8 versus 129.3 and 126.2, respectively, p&lt;0.05 for all). In addition to age, other important correlates of lower overall HRQoL (FACT-B+4) among regional/rural breast cancer survivors included: receiving chemotherapy, reporting complications post-surgery, poorer upper-body function than most, higher amounts of stress, reduced coping, being socially isolated, not having a confidante for social-emotional support, unmet healthcare needs, and low self-efficacy. Multiple linear regression analysis was used to address the hypothesis regarding similarity of HRQoL following breast cancer among women residing in regional and rural locations. After adjusting for the above factors, there was no statistically significant or clinically important difference in overall HRQoL (FACT-B+4) between regional and rural women with breast cancer 12 months following diagnosis (122.1 versus 125.1, respectively, p=0.07). Data from regional and rural women were pooled, based on the above analyses, and compared with urban women. Multiple linear regression analysis was used to test the hypothesis that HRQoL following breast cancer among women residing in regional/rural locations would be lower than that reported by women residing in urban locations. Potential confounders of the association between overall HRQoL (FACT-B+4) and place of residence included: marital status, upper-body function, amount of stress and perceived handling of stress. After adjusting for factors that differed between urban and regional/rural survivors, overall HRQoL (FACT-B+4) was lower among younger regional/rural survivors than their urban peers, and the findings were both statistically significant and clinically important (115.3 versus 123.7, respectively, p=0.001). Older women reported similar mean HRQoL, regardless of regional/rural or urban residence (128.2 versus 131.6, respectively, p=0.03). Further multiple linear regression analyses were undertaken to investigate whether women with breast cancer would report HRQoL equivalent to that reported by similarly-aged women in the general population. After adjusting for potential confounding factors that are known or suspected risk factors for breast cancer (age, marital status, education level, private health insurance, smoking status, physical activity, body mass index, co-morbidities), overall HRQoL (FACT-G) among breast cancer survivors was comparable to the general population 12 months following diagnosis (urban: 88.0 versus 86.9, respectively, p=0.28; regional/rural: 86.2 versus 85.8, respectively, p=0.79). However, 26% of survivors experienced worse overall HRQoL (FACT-G) compared with normative levels. HRQoL subscales contributing most to this deficit were physical well-being, with 29% of breast cancer survivors reporting scores below the norm, and emotional well-being among younger women, with 46% reporting scores below the norm. Logistic regression analysis was used to identify subgroups of breast cancer survivors who reported HRQoL below normative levels; reporting poorer upper-body function than most and not handling stress well increased the odds of reporting overall HRQoL (FACT-G: odds ratios (ORs) = 4.44 and 4.24, respectively, p&lt;0.01 for both), physical well-being (ORs = 5.93 and 2.92, respectively, p&lt;0.01 for both) and emotional well-being (among younger women: ORs = 2.81 and 5.90, respectively, p&lt;0.01 for both) below normative levels. The cross-sectional nature of the study design for regional and rural breast cancer survivors, and the potential selection and response biases in all three studies, represent the main limitations of this work. The cross-sectional design precludes causal inference about observed associations, but even characterising relevant correlates allows for adjustment of potential confounding and provides insight into factors that may be important in contributing to HRQoL among breast cancer survivors. Moreover, the potential impact of the latter limitations is in the conservative direction, whereby differences in HRQoL between groups will be more difficult to identify. Since these biases are expected to be present to a similar degree across all study groups, the absolute difference in HRQoL by residence and cancer status observed are likely to exist. In contrast, the work is supported by a population based, state-wide sample of breast cancer survivors, comparisons with the general population, and use of standardised instruments. Therefore, the conclusions derived from this research are likely to be generalisable to the wider population of women in Queensland with unilateral breast cancer, aged 74 years or younger, and perhaps to similar women in other western countries, depending on variations in healthcare systems and the provision of oncology services. This research supports the initial supposition that while some findings may generalise to all breast cancer survivors, non-urban breast cancer survivors also have distinct experiences that influence their HRQoL. Results from this work highlight the HRQoL domains and characteristics of breast cancer survivors most in need of assistance to facilitate recovery following diagnosis and treatment. Characteristics include some already established and reconfirmed here, namely, emotional wellbeing among younger women, and other novel subgroups, including regional/rural survivors who receive chemotherapy or have a low self-efficacy and all survivors, regardless of residence, with upper-body problems or a low perception of handling stress. These results demonstrate the potential for identifying subgroups of women with breast cancer at risk for low HRQoL who may benefit from additional attention and possible tailored recovery interventions to increase their overall HRQoL. As such, researchers and clinicians need to consider the role of these factors when designing interventions to assist women as they deal with the challenges imposed upon them by their breast cancer. However, it was found here that the FACT-G instrument has ceiling effects. This means that positive changes reflecting improved status, such as those achieved through recovery interventions, will often fail to be measured appropriately if there is no room to indicate improvements. Overall HRQoL results indicated that there is room for improvement past 12 months following treatment, with a significant proportion of breast cancer survivors reporting HRQoL below normative levels. HRQoL concerns 12 months following diagnosis are likely to be distinct from the more acute issues reported earlier on in the literature. Therefore, the development of a cancer survivorship module to accompany the FACT-G would be useful to counteract the ceiling effects observed as well as to capture issues distinct to cancer survivorship.  This is the first study to describe in detail the HRQoL of breast cancer survivors across all areas of Queensland and to compare it to the HRQoL reported by the general population of Queensland. Therefore, it represents a unique and substantial contribution to the existing knowledge on survivorship issues following diagnosis and treatment for breast cancer in Australia. Through this research, a number of questions remain that could be addressed by relevant investigations and which are likely to be important in the future to ultimately guide practice. Specifically, implementation of the concept of HRQoL in practice is the next important step forward. Furthermore, the development of a survivorship care plan that incorporates guidelines on HRQoL recovery could provide options for referral and support.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">breast cancer, cancer recovery, epidemiology, health-related quality of life, public health, regional and rural health, women&#8217;s health</field><field name="identifier">http://eprints.qut.edu.au/20339/</field><field name="validLink">True</field></doc><doc><field name="title">Audience connectivity in orchestral performances</field><field name="creator">Lindblom, Shari</field><field name="description">With the general global decline in the popularity and profitability of traditional orchestras, ways to build new audiences, develop new repertoires and create new networks and business partnerships are being explored. The aim of this thesis is to analyse the various elements of a proposed Orchestral Sustainability Framework and determine if and how these elements contribute to an increased audience connection with the music performance experience. Three main elements are explored in this Orchestral Sustainability Framework: 1. Social aspects of audience connection such as performer/audience interaction and ways of emotional engagement 2. Artistic aspects of audience connection such as the impact of poly-stylistic genres, blend of instruments and sounds and the importance of inter-sensory perception using visuals, theatre and music 3. Economic aspects of audience connection such as networking with business partnerships, impact of branding and marketing and the importance of distribution channels Audience reactions are central to this approach. Audiences from a variety of existing orchestral models have been researched through case studies, interviews, surveys, focus groups and participant observation. An orchestra, formed specifically for this project, performed to selected audiences and at the Brisbane Festival of Arts in 2006 and is now achieving commercialisation. The style of this orchestra is characterised by audience and performer interactivity, theatrical staging, visuals, spontaneity and less formality. Research has been conducted on this orchestral model, with contributions from the musicians, directors, producers, promoters and audiences. The research hypothesis proposes that a greater connectivity with the audience results in a more sustainable product, where sustainability is indicated by the orchestras&#8217; ability to generate a sufficient amount of box office revenue and sponsorship. A variety of different models are considered which demonstrate orchestras that can achieve their mission of satisfying their audience, while being financial viable. The findings from the literature and the case studies clearly demonstrate the importance of many elements in the sustainability framework to achieve a greater level of audience connection with the orchestra.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">orchestra, audience, connectivity, sustainability, performance, music</field><field name="identifier">http://eprints.qut.edu.au/20533/</field><field name="validLink">True</field></doc><doc><field name="title">The adoption of open source software by Singaporean companies</field><field name="creator">Koh, Ker Yuan (Edmund)</field><field name="description">Based on collaboration rather than competition, Open Source Software provides a new dynamic in the development and use of software systems. As such it has the potential to make a significant legal, social and economic impact on the industry. While its origins trace back to the start of the software industry, the recent success of the Linux operation system, Apache web server or the Mozilla Firefox Internet Browser provide impetus to the growth of interest in this movement. However, while a number of studies have been conducted on its development, few have provided empirical evidence of its adoption within the South East Asian context. This study aims to investigate factors leading to the adoption of Open Source Software in Singaporean Organisations. The research has found that the adoption of Open Source Software is driven by the perception of a cost advantage. The organisations interviewed have acknowledged cost as being one of their biggest concerns and top priorities. While costs were stated to be of major concern to the organisations, objective measures of cost such as Total Cost of Ownership (TCO) and Return on Investment (ROI) were rarely used by the organisations studied. This perception of cost saving is found to be led by industry sources such as publications, conferences and websites. The next significant finding is the need for increased open source software skills in the industry. One of the major drivers of Open Source Software Adoption in the organisations is that they posses pre-existing skills in Open Source Software use. This enables them to better mitigate risk and to lower their training costs. The final principal finding is that Open Source Software appears to be used mainly in systems infrastructure applications. Organisations reported a large degree of satisfaction including increased stability, scalability and cost effectiveness. Issues remain with Open Source Software&#8217;s manageability, its quality of support and ease of use.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">open source, software, companies, Singapore</field><field name="identifier">http://eprints.qut.edu.au/20496/</field><field name="validLink">True</field></doc><doc><field name="title">An examination of investigative interviewing techniques using road crash incidents as stimuli</field><field name="creator">Roos, Colette R.</field><field name="description">The investigative interviewing of eyewitnesses is an important part of the judicial system and is essential in police investigations to identify culpable parties.  However, interviewing witnesses to elicit accurate recall is not without some flaws (Ainsworth, 2002).  Researchers have acknowledged that recall of information is a complex process vulnerable to variables which impede the retrieval of accurate information (Gudjonsson, 1996; Loftus, 1979; 1992).  
 To improve witness recall, psychologists developed the Cognitive Interview (CI) procedure to help interviewers retrieve more correct information from witnesses (Fisher &amp; Geiselman, 1992).  The use of the CI has been shown to increase accuracy in many populations (Memon, Holley, Wark, Bull, &amp; Koehnken, 1996; Milne &amp; Shaw, 1999).  However, there are some criticisms of the CI.  For example, the CI may cause confusion for witnesses (Kebbell, Milne, &amp; Wagstaff, 1999), takes longer to administer than a standard police interview (Croft, 1995) and contain components which are reported to undermine the effectiveness of this procedure (Boon &amp; Noon, 1994).  This research program utilised three studies in a multimethod approach to evaluate investigative interviewing procedures, from an experimental and applied perspective.  The overarching aim of this research was to identify a parsimonious, effective and efficient interview procedure which overcame some of the limitations recognized in the CI.   
	The first study employed an experimental methodology to test the effectiveness of the CI and two alternative versions of the CI, to determine which interview procedure resulted in the most correct and least incorrect amounts of information being elicited from student witnesses to a road incident stimulus.  Results indicated that the truncated group utilizing mnemonics Tell All and Reinstate Context elicited as much correct and less incorrect information than the &#8216;Full CI&#8217; group, and took less time to administer.  
	Study Two examined the perceptions of the interview procedure from the witnesses&#8217; perspective.  Witnesses were asked to complete a questionnaire which was designed to investigate what the participants thought about how the interview was conducted.  Results indicated that, overall, the witnesses found that the interviewers engaged in practices and behaviours at a similar skill level and appreciated the rapport building and clarity of the interviewers.  A content analysis revealed that the witnesses favoured some mnemonics over others.  The qualitative statements made in regard to questions in the questionnaire are presented.
	Study Three used a triangulation methodology to determine what the Queensland Police Service officers were currently trained in and practising in the field.  Secondary sources, a questionnaire, focus group and case study methodologies were used to make this determination.  Findings indicated that there were areas where the police service could improve training of officers to help facilitate interviewing of witnesses.
	The integration of the findings from the three studies will help to inform the current state of research in the area of investigative interviewing.  In particular, this research provides a target examination of interviewing practices in a sub-section of the Queensland Police Service.  The findings from the three studies were used to identify an interview procedure which obtained more correct information, did not gain an increase in incorrect information, reduced the time required to conduct the interview, was not confusing for the witnesses, or the officers, and contained no inherent problems for the judicial system.  Further recommendations are made for the use of interview protocols for investigative interviewing of road incidents.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">cognitive interview, investigative interview, road incidents, communication, police interview, witness recall</field><field name="identifier">http://eprints.qut.edu.au/20501/</field><field name="validLink">True</field></doc><doc><field name="title">An agent-based location evaluation model</field><field name="creator">Sirikijpanichkul, Ackchai</field><field name="description">Truck transportation is considered as a favourable mode by shippers to carry freight at most ranges of distance as it has more flexibility in fleet size, capacity, scheduling, routing, and access. Although truck is considered as the popular mode for freight transportation, road-rail intermodal freight transportation becomes an attractive alternative to road only mode since the latter has no longer assured a reliable service due to traffic congestion problem. It also raises public concern in environmental and road safety impacts. Intermodal freight transportation is defined as a system that carries freight from origin to destination using two or more transportation modes where transfers between modes occur at an intermodal freight terminal. Success of the terminal depends on four major factors, namely: location, efficiency, financial sustainability, and rail level of service. Among these, the location is one of the most crucial success factors and needs to be considered carefully as it has direct and indirect impacts on a number of stakeholders including terminal users, terminal operators, transport network infrastructure providers, and community. Limitations of previous terminal location evaluation models in representing individual preference and behaviour as well as accommodating negotiation and communication between the players bring in an opportunity to develop a new model which is more flexible and capable of providing a solution that is not necessary to be optimal, but acceptable for every player without requiring explicit trade-offs. This thesis is aimed at demonstrating the feasibility of applying an agent-based approach to the evaluation of intermodal freight terminal location and investigating terminal effectiveness against stakeholder equity and some important aspects arising from the different stakeholders&#8217; viewpoints. Agent technologies were introduced to model the stakeholders as individual agents. The agent concept was adopted to develop a decentralised location evaluation system that is able to balance the terminal effectiveness with the stakeholder equity. The proposed agent-based location evaluation model was modelled as a hierarchical control system that comprises three decision levels: local level, stakeholder level and policy level. Policy level is the highest decision level, which is represented by a policy maker. Apart from the policy level, the rest can be viewed as operational decision levels. Local level is the lowest control level. At this level, each stakeholder was classified into stakeholder groups based on their characteristics and interest. The terminal scenarios were then evaluated based on benefit maximisation criteria. Stakeholder control is the higher control level than the local level. It represents the control level where negotiations and decisions between groups of people (stakeholders) with different point of views are made. At this level, negotiation process was used to determine terminal location based on preference and equity of stakeholders. The determined terminal site was then used in the evaluation against constraints to ensure that all agents are satisfied. The terminal location decision for South East Queensland (SEQ) was applied as a case study of this thesis. The SEQ strategic freight transport model was developed, calibrated, and validated to assist in providing inputs for the evaluation of terminal location. The results indicated that for the developed agent-based location evaluation model, Yatala was selected as the most appropriate terminal location that results in the highest effectiveness and equity (as measured by level of satisfaction and Gini coefficient, respectively). Other location evaluation models were also used in comparison with the developed agent-based location evaluation model. Those include P-Median, P-Centre, and maximum covering models. It was found that the agent-based location evaluation model outperformed the other location evaluation models. Finally, a sensitivity analysis was conducted in order to evaluate the consistency of model outputs against the uncertainties in the input parameters. In most cases, the terminal location decisions obtained from the developed agent-based location evaluation model was not sensitive to the changes in those parameters. However, the results suggested that when a unit cost of truck travel delay increased, the impact on the final terminal location decisions was observed. This thesis demonstrated the feasibility of applying a decentralised approach to terminal location decision problem using a multi-agent concept and evaluating it against other well-known location problems. A new framework and methodology for the planning of intermodal terminal location evaluation was also formulated. Finally, the problems of terminal location evaluation and optimisation of intermodal freight terminal operation were integrated into a single evaluation model.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">multi-agent system, agent-based, decision support system, facility, location, intermodal freight terminal, conflict resolution</field><field name="identifier">http://eprints.qut.edu.au/20672/</field><field name="validLink">True</field></doc><doc><field name="title">Investigation into submicrometer particle and gaseous emissions from airport ground running procedures</field><field name="creator">Mazaheri, Mandana</field><field name="description">Emissions from airport operations are of significant concern because of their potential impact on local air quality and human health. The currently limited scientific knowledge of aircraft emissions is an important issue worldwide, when considering air pollution associated with airport operation, and this is especially so for ultrafine particles. This limited knowledge is due to scientific complexities associated with measuring aircraft emissions during normal operations on the ground. In particular this type of research has required the development of novel sampling techniques which must take into account aircraft plume dispersion and dilution as well as the various particle dynamics that can affect the measurements of the aircraft engine plume from an operational aircraft.
 
 In order to address this scientific problem, a novel mobile emission measurement method called the Plume Capture and Analysis System (PCAS), was developed and tested. The PCAS permits the capture and analysis of aircraft exhaust during ground level operations including landing, taxiing, takeoff and idle. The PCAS uses a sampling bag to temporarily store a sample, providing sufficient time to utilize sensitive but slow instrumental techniques to be employed to measure gas and particle emissions simultaneously and to record detailed particle size distributions. The challenges in relation to the development of the technique include complexities associated with the assessment of the various particle loss and deposition mechanisms which are active during storage in the PCAS. Laboratory based assessment of the method showed that the bag sampling technique can be used to accurately measure particle emissions (e.g. particle number, mass and size distribution) from a moving aircraft or vehicle. 
 
 Further assessment of the sensitivity of PCAS results to distance from the source and plume concentration was conducted in the airfield with taxiing aircraft. The results showed that the PCAS is a robust method capable of capturing the plume in only 10 seconds. The PCAS is able to account for aircraft plume dispersion and dilution at distances of 60 to 180 meters downwind of moving a aircraft along with particle deposition loss mechanisms during the measurements. Characterization of the plume in terms of particle number, mass (PM2.5), gaseous emissions and particle size distribution takes only 5 minutes allowing large numbers of tests to be completed in a short time. The results were broadly consistent and compared well with the available data. 
 
 Comprehensive measurements and analyses of the aircraft plumes during various modes of the landing and takeoff (LTO) cycle (e.g. idle, taxi, landing and takeoff) were conducted at Brisbane Airport (BNE). Gaseous (NOx, CO2) emission factors, particle number and mass (PM2.5) emission factors and size distributions were determined for a range of Boeing and Airbus aircraft, as a function of aircraft type and engine thrust level. The scientific complexities including the analysis of the often multimodal particle size distributions to describe the contributions of different particle source processes during the various stages of aircraft operation were addressed through comprehensive data analysis and interpretation. 
 
 The measurement results were used to develop an inventory of aircraft emissions at BNE, including all modes of the aircraft LTO cycle and ground running procedures (GRP). Measurements of the actual duration of aircraft activity in each mode of operation (time-in-mode) and compiling a comprehensive matrix of gas and particle emission rates as a function of aircraft type and engine thrust level for real world situations was crucial for developing the inventory. The significance of the resulting matrix of emission rates in this study lies in the estimate it provides of the annual particle emissions due to aircraft operations, especially in terms of particle number. 
 
 In summary, this PhD thesis presents for the first time a comprehensive study of the particle and NOx emission factors and rates along with the particle size distributions from aircraft operations and provides a basis for estimating such emissions at other airports. This is a significant addition to the scientific knowledge in terms of particle emissions from aircraft operations, since the standard particle number emissions rates are not currently available for aircraft activities.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Aircraft Engine Exhaust, bag sampling technique, Plume Capture Device (PCD), Plume Capture and Analysis System (PCAS), emission factors, ultrafine particles, particle number emission, particle size distributions, nucleation, coagulation</field><field name="subject">particle mass (PM2.5) emissions, gaseous emissions, aircraft landing and takeoff (LTO) cycle, aircraft engine ground running procedure (GRP), Brisbane Airport Corporation (BAC), Brisbane Airport (BNE), annual emissions, airport emissions inventory</field><field name="identifier">http://eprints.qut.edu.au/29183/</field><field name="validLink">True</field></doc><doc><field name="title">Governmentality, pedagogy and membership categorization : a case of enrolling the citizen in sustainable regional planning</field><field name="creator">Summerville, Jennifer A.</field><field name="description">Over the past twenty years, the idea that planning and development practices should be &#8216;sustainable&#8217; has become a key tenet of discourses characterising the field of planning and development.  As part of the agenda to balance and integrate economic, environmental and social interests, democratic participatory governance arrangements are frequently purported to be necessary to achieve &#8216;sustainable development&#8217; at both local and global levels.  Despite the theoretical disjuncture between ideas of democratic civic participation, on the one hand, and civic participation as a means to achieve pre-determined sustainability goals on the other, notions of civic participation for sustainability have become integral features of sustainable development discourses.  
 
 Underpinned by a conceptual and methodological intent to perform an epistemological &#8216;break&#8217; with notions of civic participation for sustainability, this thesis explicates how citizens are enrolled in the sustainable development agenda in the discourse of policy.  More specifically, it examines how assumptions about civic participation in sustainable development policy discourses operate, and unpacks some discursive strategies through which policy language &#8216;enrols&#8217; citizens in the same set of assumptions around their normative requirement for participation in sustainable development.  Focussing in on a case study sustainable development policy document &#8211; a draft regional plan representing a case of &#8216;enrolling the citizen in sustainability&#8217; - it employs three sociological perspectives/methods that progressively highlight some of the ways that the policy language enjoins citizens as active participants in &#8216;sustainable&#8217; regional planning.  As a thesis-by-publication, the application of each perspective/method is reported in the form of an article prepared for publication in an academic journal.  
 
 In a departure from common-sense understandings of civic participation for sustainability, the first article examines the governmentality of sustainable development policy.  Specifically, this article explores how civic community &#8211; particularly community rights and responsibilities &#8211; are deployed in the policy discourse as techniques of government that shape and regulate the conduct of subjects.  In this respect, rather than seeing civic community as a specific &#8216;thing&#8217; and participation as corresponding to particular types of &#8216;activities&#8217;, this paper demonstrates how notions of civic participation are constructed and mobilised in the language of sustainable development policy in ways that facilitate government &#8216;at a distance&#8217;.  
 
 The second article begs another kind of question of the policy &#8211; one concerned more specifically with how the everyday practices of subjects become aligned with the principles of sustainable development.  This paper, therefore, investigates the role of pedagogy in establishing governance relations in which citizens are called to participate as part of the problematic of sustainability. The analysis suggests that viewing the case study policy in terms of relationships of informal pedagogy provided insights into the positioning of the citizen as an &#8216;acquirer&#8217; of sustainability principles.   In this instance, the pedagogic values of the text provide for low levels of discretion in how citizens could position themselves in the moral order of the discourse.  This results in a strong injunction for citizens to subscribe to sustainability principles in a participatory spirit coupled with the requirement for citizens to delegate to the experts to carry out these principles.  
 
 The third article represents a further breakdown of the ways in which citizens become enrolled in &#8216;sustainable&#8217; regional planning within the language of the case study policy.  Applying an ethnomethodological perspective, specifically Membership Categorization Analysis, this article examines the way &#8216;the citizen&#8217; and &#8216;civic values and obligations&#8217; are produced in the interactional context of the text.  This study shows how the generation of a substantive moral order that ties the citizen to sustainable values and obligations with respect to the region, is underpinned by a normative morality associated with the production of orderliness in &#8216;text-in-interaction&#8217;.  As such, it demonstrates how the production and positioning of &#8216;the citizen&#8217; in relation to the institutional authors of the policy, and the region more generally, are practical accomplishments that orient the reader to identify him/herself as a &#8216;citizen&#8217; and embrace the &#8216;civic values and obligations&#8217; to which he/she is bound.  
 
 Together, the different conceptual and methodological approaches applied in the thesis provide a more holistic picture of the different ways in which citizens are discursively enrolled in the sustainability agenda.  At the substantive level, each analysis reveals a different dimension of how the active citizen is mobilised as a responsible agent for sustainable development.  In this respect, civic participation for sustainability is actualised and reproduced through the realms of language, not necessarily through applied occasions of civic participation in the &#8216;taken-for-granted&#8217; sense.  Furthermore, at the conceptual and methodological level, the thesis makes a significant contribution to sociological inquiry into relationships of governance.    Rather than residing within the boundaries of a specific sociological perspective, it shows how different approaches that would traditionally be applied in a mutually exclusive manner, can complement each other to advance understanding of how governance discourses operate.  In this respect, it provides a rigorous conceptual and methodological platform for further investigations into how citizens become enrolled in programmes of government.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">sustainable development, civic participation, community consultation, participative democracy, regional planning, program theory, spontaneous sociology, epistemological break, governmentality, rights and responsibilities, pedagogic practice</field><field name="subject">classification and framing, membership categorization analysis, moral order, policy development, policy evaluation, Nikolas Rose, Basil Bernstein, Harvey Sacks, Pierre Bourdieu</field><field name="identifier">http://eprints.qut.edu.au/20508/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis and characterisation of metal (Fe, Ga, Y) doped alumina and gallium oxide nanostructures</field><field name="creator">Zhao, Yanyan</field><field name="description">It is well known that nanostructures possess unique electronic, optical, magnetic, ferroelectric and piezoelectric properties that are often superior to traditional bulk materials. In particular, one dimensional (1D) nanostructured inorganic materials including nanofibres, nanotubes and nanobelts have attracted considerable attention due to their distinctive geometries, novel physical and chemical properties, combined effects and their applications to numerous areas. Metal ion doping is a promising technique which can be utilized to control the properties of materials by intentionally introducing impurities or defects into a material.
 
 &#947;-Alumina (Al2O3), is one of the most important oxides due to its high surface area, mesoporous properties, chemical and thermal properties and its broad applications in adsorbents, composite materials, ceramics, catalysts and catalyst supports. &#947;-Alumina has been studied intensively over a long period of time. Recently, considerable work has been carried out on the synthesis of 1D &#947;-alumina nanostructures under various hydrothermal conditions; however, research on the doping of alumina nanostructures has not been forthcoming. Boehmite (&#947;-AlOOH) is a crucial precursor for the preparation of &#947;-Alumina and the morphology and size of the resultant alumina can be manipulated by controlling the growth of AlOOH.
 
 Gallium (Ga) is in the same group in the periodic table as aluminum. &#946;-Gallium (III) oxide (&#946;-Ga2O3), a wide band gap semiconductor, has long been known to exhibit conduction, luminescence and catalytic properties. Numerous techniques have been employed on the synthesis of gallium oxide in the early research. However, these techniques are plagued by inevitable problems. It is of great interest to explore the synthesis of gallium oxide via a low temperature hydrothermal route, which is economically efficient and environmentally friendly. 
 
 The overall objectives of this study were: 1) the investigation of the effect of dopants on the morphology, size and properties of metal ion doped 1D alumina nanostructures by introducing dopant to the AlOOH structure; 2) the investigation of impacts of hydrothermal conditions and surfactants on the crystal growth of gallium oxide nanostructures. To achieve the above objectives, trivalent metal elements such as iron, gallium and yttrium were employed as dopants in the study of doped alumina nanostructures. In addition, the effect of various parameters that may affect the growth of gallium oxide crystals including temperature, pH, and the experimental procedure as well as different types of surfactants were systematically investigated. 
 
 The main contributions of this study are: 1) the systematic and in-depth investigation of the crystal growth and the morphology control of iron, gallium and yttrium doped boehmite (AlOOH) under varying hydrothermal conditions, as a result, a new soft-chemistry synthesis route for the preparation of one dimensional alumina/boehmite nanofibres and nanotubes was invented; 2) systematic investigation of the crystal growth and morphology and size changes of gallium oxide hydroxide (GaOOH) under varying hydrothermal conditions with and without surfactant at low temperature; We invented a green hydrothermal route for the preparation of &#945;-GaOOH or &#946;-GaOOH micro- to nano-scaled particles; invented a simple hydrothermal route for the direct preparation of &#947;-Ga2O3 from aqueous media at low temperature without any calcination.
 
 The study provided detailed synthesis routes as well as quantitative property data of final products which are necessary for their potential industrial applications in the future. The following are the main areas and findings presented in the study:
 
 &#8226;	Fe doped boehmite nanostructures
 
 This work was undertaken at 120&#186;C using PEO surfactant through a hydrothermal synthesis route by adding fresh iron doped aluminium hydrate at regular intervals of 2 days. The effect of dopant iron, iron percentage and experimental procedure on the morphology and size of boehmite were systematically studied. Iron doped boehmite nanofibres were formed in all samples with iron contents no more than 10%. Nanosheets and nanotubes together with an iron rich phase were formed in 20% iron doped boehmite sample. A change in synthesis procedure resulted in the formation of hematite large crystals. The resultant nanomaterials were characterized by a combination of XRD, TEM, EDX, SAED and N2 adsorption analysis.
 
 &#8226;	Growth of pure boehmite nanofibres/nanotubes
 
 The growth of pure boehmite nanofibres/nanotubes under different hydrothermal conditions at 100&#186;C with and without PEO surfactant was systematically studied to provide further information for the following studies of the growth of Ga and Y doped boehmite. Results showed that adding fresh aluminium hydrate precipitate in a regular interval resulted in the formation of a mixture of long and short 1D boehmite nanostructures rather than the formation of relatively longer nanofibres/nanotubes. The detailed discussion and mechanism on the growth of boehmite nanostructure were presented. The resultant boehmite samples were also characterized by N2 adsorption to provide further information on the surface properties to support the proposed mechanism. 
 
 &#8226;	Ga doped boehmite nanostructures
 
 Based on this study on the growth of pure boehmite nanofibre/nanotubes, gallium doped boehmite nanotubes were prepared via hydrothermal treatment at 100&#186;C in the presence of PEO surfactant without adding any fresh aluminium hydrate precipitate during the hydrothermal treatment. The effect of dopant gallium, gallium percentage, temperature and experimental procedure on the morphology and size of boehmite was systematically studied. Various morphologies of boehmite nanostructures were formed with the increase in the doping gallium content and the change in synthesis procedure. The resultant gallium doped boehmite nanostructures were characterized by TEM, XRD, EDX, SAED, N2 adsorption and TGA.
 
 &#8226;	Y doped boehmite nanostructures
   
 Following the same synthesis route as that for gallium doped boehmite, yttrium doped boehmite nanostructures were prepared at 100&#186;C in the presence of PEO surfactant. From the study on iron and gallium doped boehmite nanostructures, it was noted both iron and gallium cannot grow with boehmite nanostructure if iron nitrate and gallium nitrate were not mixed with aluminium nitrate before dissolving in water, in particular, gallium and aluminium are 100% miscible. Therefore, it&#8217;s not necessary to study the mixing procedure or synthesis route on the formation of yttrium doped boehmite nanostructures in this work. The effect of dopant yttrium, yttrium percentage, temperature and surfactant on the morphology and size of boehmite were systematically studied. Nanofibres were formed in all samples with varying doped Y% treated at 100&#186;C; large Y(OH)3 crystals were also formed at high doping Y percentage. Treatment at elevated temperatures resulted in remarkable changes in size and morphology for samples with the same doping Y content. The resultant yttrium doped boehmite nanostructures were characterized by TEM, XRD, EDX, SAED, N2 adsorption and TGA.
 
 &#8226;	The synthesis of Gallium oxide hydroxide and gallium oxide with surfactant
 
 In this study, the growth of gallium oxide hydroxide under various hydrothermal conditions in the presence of different types of surfactants was systematically studied. Nano- to micro-sized gallium oxide hydroxide was prepared. The effect of surfactant and synthesis procedure on the morphology of the resultant gallium oxide hydroxide was studied. &#946;-gallium oxide nanorods were derived from gallium oxide hydroxide by calcination at 900&#186;C and the initial morphology was retained. &#947;-gallium oxide nanotubes up to 65 nm in length, with internal and external diameters of around 0.8 and 3.0 nm, were synthesized directly in solution with and without surfactant. The resultant nano- to micro-sized structures were characterized by XRD, TEM, SAED, EDX and N2 adsorption.
 
 &#8226;	The synthesis of gallium oxide hydroxide without surfactant
 
 The aim of this study is to explore a green synthesis route for the preparation of gallium oxide hydroxide or gallium oxide via hydrothermal treatment at low temperature. Micro to nano sized GaOOH nanorods and particles were prepared under varying hydrothermal conditions without any surfactant. The resultant GaOOH nanomaterials were characterized by XRD, TEM, SAED, EDX, TG and FT-IR. The growth mechanism of GaOOH crystals was proposed.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">alumina, boehmite, iron, gallium, yttrium, gallium oxide, gallium oxide hydroxide, surfactant, nanofibres, nanotubes, nanosheets, nanorods, hydrothermal treatment, x-ray diffraction, transmission electron microscopy, N2 adsorption/desorption</field><field name="subject">BET surface area, pore size distribution, thermal decomposition, thermogravimetric analysis, infrared spectroscopy, Raman spectroscopy</field><field name="identifier">http://eprints.qut.edu.au/20529/</field><field name="validLink">True</field></doc><doc><field name="title">Accompanying them home : the ethics of hospice palliative care</field><field name="creator">Wilson, Monika Anne</field><field name="description">This inquiry, which employed a narrative research approach, critically explored the ethical dimension of hospice palliative care.  Hospice palliative care is the profession specifically developed to care for the dying.  The development of this practice has grown significantly since the 1980s in Australia, yet ethical inquiry into this professional practice has largely focused on particular issues, problems or dilemmas, such as euthanasia.  Although particular ethical issues are important considerations, a broader investigation of the ethics of hospice palliative care practice has not been given sufficient consideration in the growing accumulation of the research literature in Australia.  Jennings (1997) surmises that &#8220;systematic reflection on ethics in the hospice field is curiously underdeveloped&#8221; (p. 2).  This study goes someway towards filling this gap.  In building upon the Pallium research by European scholars and integrating a social practice framework (Isaacs, 1998) this inquiry provides an alternative account of the ethical agenda and one which has privileged an internal exploration, rather than assume that the ethics would be the same as any other health care modality or to simply adopt a dominant, principles-based approach.  These internal explorations were located in the storied accounts of thirty interdisciplinary hospice palliative care professionals.  
 
 This thesis provides a thorough, textual conversation into the realm of ethical caregiving at the end of life.  Several key insights were illuminated.  Firstly, total care must be central to the philosophy underpinning hospice palliative care practice, but this concept and practice of total care was being eroded and contested.  Secondly, a predominantly modernist account of personhood was located in the narrative accounts.  This modernist account of personhood was thought to be insufficient for the practice of total care and needed to be reconceptualised. An embedded ontological account was provided which would assist with the understanding and practice of total care.  Thirdly, initially it was thought that there was no common, shared understanding of the purpose of the practice.  It was suggested that the profession was &#8220;wandering in the wilderness&#8221; when it came to the aim of its practice.  However, the professionals did share a common telos (aim towards a good) and it was overwhelmingly relational.  This led to the proposal of a new telos for hospice palliative care practice centered on the creation and maintenance of unique relationships which would assist people in their final stage of life.  Lastly, the ethical frameworks which guided practice for the professionals were presented.  In these frameworks it was significant values (acceptance of human mortality, total care and honest and open communication) and relationships (how we treat each other) which played the main role in what constituted hospice palliative care ethics. An account of a hospice palliative care ethical relationship was provided which included a proximity stance of in-between.  Overall, any ethic for hospice palliative care must have at the heart the relationship between professional caregiver and living-dying person.  The relationships in this social practice, between each other, accompanying one another, are our ethical compass.
 
 This thesis concluded that hospice palliative care, as a social practice, has a rich ethical dimension as understood and articulated by its professional members.  These insights have resulted in the construction of a new ethical framework reflecting, formalising and adapting the ethical dimension as understood by its professional members.  This ethical framework - A Relational Ethic of Accompanying - is needed to help maintain, sustain and protect the unique identity of this profession. This framework adds to the &#8220;moral vocabulary&#8221; (Jennings, 1997) and &#8220;moral specificity&#8221; (ten Have &amp; Clark, 2002) of hospice palliative care practice.  In addition, it would provide important guidance to palliateurs reflecting on how best to provide quality, compassionate and ethical care at the end of life.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">ethics, moral, narrative, story, social practice, hospice palliative care, dying, death, personhood, ontology, living-dying person and end of life care</field><field name="identifier">http://eprints.qut.edu.au/20536/</field><field name="validLink">True</field></doc><doc><field name="title">Applications of constrained non-parametric smoothing methods in computing financial risk</field><field name="creator">Wong, Chung To (Charles)</field><field name="description">The aim of this thesis is to improve risk measurement estimation by incorporating extra information in the form of constraint into completely non-parametric smoothing techniques. A similar approach has been applied in empirical likelihood analysis. The method of constraints incorporates bootstrap resampling techniques, in particular, biased bootstrap. This thesis brings together formal estimation methods, empirical information use, and computationally intensive methods. In this thesis, the constraint approach is applied to non-parametric smoothing estimators to improve the estimation or modelling of risk measures. We consider estimation of Value-at-Risk, of intraday volatility for market risk, and of recovery rate densities for credit risk management. Firstly, we study Value-at-Risk (VaR) and Expected Shortfall (ES) estimation. VaR and ES estimation are strongly related to quantile estimation. Hence, tail estimation is of interest in its own right. We employ constrained and unconstrained kernel density estimators to estimate tail distributions, and we estimate quantiles from the fitted tail distribution. The constrained kernel density estimator is an application of the biased bootstrap technique proposed by Hall &amp; Presnell (1998). The estimator that we use for the constrained kernel estimator is the Harrell-Davis (H-D) quantile estimator. We calibrate the performance of the constrained and unconstrained kernel density estimators by estimating tail densities based on samples from Normal and Student-t distributions. We find a significant improvement in fitting heavy tail distributions using the constrained kernel estimator, when used in conjunction with the H-D quantile estimator. We also present an empirical study demonstrating VaR and ES calculation. A credit event in financial markets is defined as the event that a party fails to pay an obligation to another, and credit risk is defined as the measure of uncertainty of such events. Recovery rate, in the credit risk context, is the rate of recuperation when a credit event occurs. It is defined as Recovery rate = 1 - LGD, where LGD is the rate of loss given default. From this point of view, the recovery rate is a key element both for credit risk management and for pricing credit derivatives. Only the credit risk management is considered in this thesis. To avoid strong assumptions about the form of the recovery rate density in current approaches, we propose a non-parametric technique incorporating a mode constraint, with the adjusted Beta kernel employed to estimate the recovery density function. An encouraging result for the constrained Beta kernel estimator is illustrated by a large number of simulations, as genuine data are very confidential and difficult to obtain. Modelling high frequency data is a popular topic in contemporary finance. The intraday volatility patterns of standard indices and market-traded assets have been well documented in the literature. They show that the volatility patterns reflect the different characteristics of different stock markets, such as double U-shaped volatility pattern reported in the Hang Seng Index (HSI). We aim to capture this intraday volatility pattern using a non-parametric regression model. In particular, we propose a constrained function approximation technique to formally test the structure of the pattern and to approximate the location of the anti-mode of the U-shape. We illustrate this methodology on the HSI as an empirical example.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">constraint method, expected shortfall, non-parametric approach, recovery rate density, intraday volatility, risk management, value-at-risk</field><field name="identifier">http://eprints.qut.edu.au/20537/</field><field name="validLink">True</field></doc><doc><field name="title">The experiences of teacher aides who support students with disabilities and learning difficulties : a phenomenological study</field><field name="creator">Bourke, Patricia E.</field><field name="description">Schools in Queensland, Australia, are undergoing inclusive education reform, following the report of the Ministerial Taskforce on Inclusive Education (Students with Disabilities) in 2004. The State government&#8217;s responses to the taskforce report emphasise a commitment to social justice and equity so that all students can be included in ways that enable them to achieve their potential. Teacher aides are employed in schools as ancillary staff to support students with disabilities and learning difficulties. Their support roles in schools are emerging within an educational context in which assumptions about disability, difference and inclusion of students with disabilities and learning difficulties are changing. It is important to acknowledge teacher aides as support practitioners, and to understand their roles in relation to the inclusion of students with disabilities and learning difficulties as inclusive education reform continues.
 This study used a phenomenological approach to explore the lived experiences of teacher aides as they supported students with disabilities and learning difficulties in primary schools. Four key insights into the support roles of teacher aides in primary schools in Brisbane, Queensland emerged from the study: 1) teacher aides develop empathetic relationships with students that contribute significantly to the students&#8217; sense of belonging within school communities; 2) lack of clear definition of roles and responsibilities for teacher aides has detrimental effects on inclusion of students; 3) collaborative planning and implementation of classroom learning and socialisation programs enhances inclusion; and 4) teacher aides learn about supporting students while on-the-job, and in consultation and collaboration with other members of the students&#8217; support networks.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">inclusive education, teacher aides, support for students, professional development, collaborative teaming</field><field name="identifier">http://eprints.qut.edu.au/25910/</field><field name="validLink">True</field></doc><doc><field name="title">Effectiveness of a peer-led self-management program for older people with type 2 diabetes in China</field><field name="creator">Shen, Huixia</field><field name="description">Type 2 diabetes is a common chronic disease, which has a negative health impact and results in enormous economic burden. The prevalence of type 2 diabetes is increasing dramatically and it affects older people disproportionately. The healthcare system in China is faced with an overwhelming burden due to a large ageing population, high prevalence of diabetes and limited healthcare resources. Self-management has been widely accepted as the cornerstone of the clinical management of type 2 diabetes. Since self-management usually involves complex behaviour change and can be emotionally challenging, effective education is essential to facilitate this transition. However, there has been no existing program of type 2 diabetes self-management for older patients in China until now. Furthermore, the generalisation of any health education programs is often hampered due to limited healthcare resources in China.
 
 The primary purpose of this study was to develop a socially and culturally suitable self-management program, which addressed self-efficacy and social support to facilitate behaviour change and subsequent health improvement, for older people with type 2 diabetes living in the community in China. The secondary purpose was to test a feasible delivery model of the program through involvement of peer leaders and existing community networks. 
 This study was conducted in three phases. Phase one gathered information about barriers related to self-management behaviours and help needed to address them, from the perspective of older people with type 2 diabetes and community health professionals, through focus group discussion. Data from Phase One, together with guidelines of the selected theoretical frame work, results from an extensive literature review, and experiences of previous relevant studies provided the basis for development of a peer-led type 2 diabetes self-management program (Phase Two). Phase Three involved a pre-test, post-test non-equivalent control group design to test the effectiveness of the self-management program on older people with type 2 diabetes in the community. The impact of the program on peer leaders was examined using a one group pre-test, post-test design. In addition, evaluation of the program from peer leaders&#8217; and older people&#8217;s perceptions was conducted through a post-test questionnaire.
 
 Older people with type 2 diabetes and health professionals expressed broadly the same concerns, which were: social support; confidence to practice self-management behaviours; self-management behaviours; barriers to self-management behaviours; and advice for ongoing health education. However, their points of view were not always identical and different emphases were identified.
 
 The peer-led program produced significant improvement in social support, self-efficacy, self-management behaviours and depressive status in the experimental group, as compared to the non-equivalent control group. However, there was no significant effect on quality of life nor health care utilisation. Therefore, the effectiveness of the program among older people with type 2 diabetes was partially confirmed. In addition, the participants were supportive, giving positive feedback about the program. Suggestions for future improvement were provided as well. 
 
 After receiving specific peer leader training and assisting in most of the delivery process of the program, the peer leaders improved, significantly, in overall self-management behaviours and in specific areas of social support and self-efficacy, though they did not improve in depressive status, quality of life and health care utlisation. In addition, these peer leaders enjoyed being peer leaders, and gave very positive feedback about the whole program. 
 
 In conclusion, this study has implications for understanding and facilitating self-management behaviours for older people with type 2 diabetes in China. The peer-led self-management program was effective in improving levels of self-efficacy, social support, self-management behaviours and depressive status among older people with type 2 diabetes living in the community in China. The delivery process involving peer leaders was deemed feasible to implement within the health care system in China. The program is suitable to be used by community health professionals in their practice in China. The study also has potential wider benefit to nursing practice and global health practice.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">type 2 diabetes, older people, self-management, self-efficacy, social support, peer education, intervention</field><field name="identifier">http://eprints.qut.edu.au/20671/</field><field name="validLink">True</field></doc><doc><field name="title">Evaluation of health-related outcomes following a self-management program for older people with heart failure</field><field name="creator">Shao, Jung-Hua</field><field name="description">Background. Heart failure (HF) which is a chronic, disabling disorder is mainly found in older people and is one of the leading causes of hospitalisation and readmission around the world. Unfortunately, the mortality and morbidity rates for HF remain high. HF is a complex combination of symptoms which are related to an inadequate perfusion of the body tissues caused by fluid and sodium retention. Hence, enhancing HF patients&#8217; self-efficacy to change their behaviours to perform fluid &amp; sodium control is one of the most important issues for the management of HF. A self-management program has the potential to raise self-efficacy and self-care which is a method to improve health for those with chronic illness and to decrease patients&#8217; health service utilisation and also to enhance these patients&#8217; health status. Aim. The study aims to examine the effectiveness of a self-management program, based on self-efficacy theory, in older people with heart failure in Taiwan. Methods. An experimental design was used to examine the effectiveness of a self-management program on diet and fluid control among HF patients. A total of 93 subjects from two medical centres in Taiwan were randomly assigned to the intervention and control groups. In order to examine the effectiveness of self-management, data were collected at baseline, week 4, and week 12 using the following instruments: self-efficacy for salt and fluid control, HF self-management behaviour, HF related symptoms, and body weight. Moreover, health service utilisation and patient&#8217;s evaluation of care received were collected on all patients for the 12 weeks prior to commencing the study and for the 12 week study period. Demographic and disease information was also collected including age, gender, marital state, education, and New York Heart Association (NYHA) functional classification. A structured, individualized self-management training program created by the investigator was implemented for the intervention group through home visits and telephone follow-ups. This program emphasized self-monitoring of diet control and body weight for the self-management of heart failure. The purpose was to improve patients&#8217; self-efficacy in their diet control behaviour. The &#8220;diet control&#8221; in this study focussed on sodium and fluid restriction. Outcome measures were analysed using the Statistical Package for the Social Sciences (SPSS) 15.0 version, and the level of significance (&#225;) was set at 0.05 for statistical analysis. Results. There were differences for older Taiwanese HF patients&#8217; self-efficacy for salt and fluid control, self-management behaviour, and HF related symptoms for participants who received a self-management intervention compared to those who did not. However, there were no significant differences between the two groups in weight and health serves utilization (p&gt;.001). Conclusion. The self-management program had a positive impact on the improvement of self-efficacy for salt and fluid control, HF related self-management behaviours and symptoms in older Taiwanese with HF. This program may bridge the gap between theory and practice. Health care providers need to provide older people in Taiwan with HF the appropriate skills for self-managing their condition and thereby promoting their health status. These patients with HF and their caregivers have to receive individualized education that emphasizes self-efficacy in the self-management of their disease, thus improving their quality of life.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">heart failure, older people, randomised controlled trial, intervention program, self-management, self-efficacy, self-monitoring, dietary control, behaviour change, symptoms, health service utilization, health related outcomes</field><field name="identifier">http://eprints.qut.edu.au/20702/</field><field name="validLink">True</field></doc><doc><field name="title">Capacity evaluation and retrofitting of timber bridge girders</field><field name="creator">Wilkinson, Kym</field><field name="description">Bridges form a vital link in the physical infrastructure and must be maintained in a "safe working order" at all times. It is estimated that there are currently 20,000 timber road bridges in service throughout Australia. Increasing demands on these bridges due to heavier and faster moving loads, together with deterioration are placing these aging structures at a higher risk of collapse. Unfortunately, many local governments and government departments have neglected the benefits of preventative maintenance and have opted for "just in time" repairs. This is especially true for timber bridges. This past neglect has placed bridge stock in a poor state that is only now being recognised as a significant problem. A key component of this research is to develop improvements to this current situation. This research thesis generates detailed knowledge on the load carrying capacities of timber bridges and new non destructive testing techniques that can be substituted for conventional testing procedures. For the first time guidelines have been developed for undertaking capacity assessment on timber bridges by specifying intervention levels for notched timber and limiting maximum allowable strains in timber members. This newly acquired knowledge will enable Asset Managers to more accurately determine the capacity of sniped timber bridge girders to enable appropriate retrofitting and maintenance while also allowing the safe movement of heavy vehicles. The knowledge generated through destructive testing of timber girders and the analysis of the vast amount of experimental data has enabled the first instance of developing specifications for replacement girders. These specifications detail both functional and performance related targets for three different types of replacement girders. Testing of these replacement girders also demonstrates that through some minor modifications that the specification targets can be met. The outcomes of this thesis provide an innovative approach to accessing the condition and capacity of timber girders and to increasing the safety and life of timber bridges in Queensland. By using new techniques such as Non-destructive testing, species identification and limiting maximum allowable strains, as described in this thesis, the road transport network can be safety used by heavy and permit vehicles. It is only through the effective management of timber bridge maintenance and rehabilitation that Australia can have an efficiently running road transportation network.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">timber, bridge, girder, capacity, destructive testing, replacement, specification, snipe, notch, capacity, strength</field><field name="identifier">http://eprints.qut.edu.au/20706/</field><field name="validLink">True</field></doc><doc><field name="title">Secure communications for critical infrastructure control systems</field><field name="creator">Dawson, Robert Edward</field><field name="description">In March 2000, 1 million litres of raw sewage was released into the water system of Maroochy Shire on Queensland&#8217;s sunshine coast. This environmental disaster was caused by a disgruntled ex-contractor using a radio transmitter to illicitly access the electronically controlled pumps in the control system. In 2007 CNN screened video footage of an experimental attack against a electrical generator. The attack caused the generator to shake and smoke, visually showing the damage caused by cyber attack. These attacks highlight the importance of securing the control systems which our critical infrastructures depend on. This thesis addresses securing control systems, focusing on securing the communications for supervisory control and data acquisition (SCADA) systems. We review the architectures of SCADA systems and produce a list of the system constraints that relate to securing these systems. With these constraints in mind, we survey both the existing work in information and SCADA security, observing the need to investigate further the problem of secure communications for SCADA systems. We then present risk modelling techniques, and model the risk in a simple SCADA system, using the ISM, a software tool for modelling information security risk. In modelling the risk, we verify the hypothesis that securing the communications channel is an essential part of an effective security strategy for SCADA systems. After looking at risk modelling, and establishing the value of securing communications, we move on to key management for SCADA systems. Appropriate key management techniques are a crucial part of secure communications, and form an important part of the contributions made in this work. We present a key management protocol that has been designed to run under the constraints specific to SCADA systems. A reductionist security proof is developed for a simplified version of the protocol, showing it is secure in the Bellare Rogaway model.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">SCADA security, control system security, key management, critical infrastructure, reductionist security proof, provable security, key establishment protocols, risk modelling</field><field name="identifier">http://eprints.qut.edu.au/20710/</field><field name="validLink">True</field></doc><doc><field name="title">Corona ions from high voltage powerlines : production, effect on ambient particles, DC electric field and implications on human exposure studies</field><field name="creator">Fatokun, Folasade Okedoyin</field><field name="description">Powerlines are important in the process of electricity transmission and distribution (T &amp; D) and their essential role in transmitting electricity from the large generating stations to the final consumers cannot be over emphasized.  Over the years, an increase in the demand for electrical energy (electricity) has led to the construction and inevitable use of high transmission voltage, sub-transmission voltage and distribution voltage power conducting lines, for the electricity T &amp; D process.  Along with this essential role, electricity conductors can also give rise to some electrically related effects such as interference with telecommunication circuits, electric shocks, electromagnetic fields, audible noise, corona ion discharges, etc.  
 
 The presence of powerline generated corona ions in any ambient air environment can be associated with the local modification of the earth&#8217;s natural dc electric field (e-field), while the interactions between these ions and other airborne aerosol particles can be associated with the presence of charged aerosol particles in the environment of the corona ion emitting lines.  When considering all the studies conducted to date on the possible direct and indirect effects of high voltage powerlines (HVPLs), of significant interest are those suggesting links between powerlines and some adverse human health effects &#8211; with such health effects alleged to be strongest amongst populations directly exposed to HVPLs.  However, despite the numerous studies conducted on HVPLs, to date a lack of proper scientific understanding still exist in terms of the physical characterization of the electrical environment surrounding real-world HVPLs - mostly in terms of the entire dynamics of ions and charged particles, as well as the possible links/associations between the different parameters that characterize these electrical environments.  Yet, gaining a sound understanding about the electrical environment surrounding energized real-world HVPLs is imperative for the accurate assessment of any possible human exposure or health effects that may be associated with powerlines.
 
 The research work presented in this thesis was motivated by the existing gaps in scientific understanding of the possible association between corona ions generated by real-world HVPLs and the production of ambient charged aerosol particles.  The aim of this study was to supply some much needed scientific knowledge about the characteristics of the electrical environment surrounding real-world energized HVPLs.  This was achieved by investigating the possible effects of corona ions generated by real-world overhead HVPLs on ambient aerosol particle number concentration level, ambient aerosol particle charge concentration level, ambient ion concentration level and the magnitude of the local vertical dc e-field; while also taking into consideration the possible effect of complex meteorological factors (such as temperature, pressure, wind speed wind direction, solar radiation and humidity) on the instantaneous value of these measured parameters, at different powerline sites.  The existence of possible associations or links between these various parameters measured in the proximity of the powerlines was statistically investigated using simple linear regression, correlation and multivariate (principal component, factor, classification and regression tree-CART) analysis.  The strength of the regression was tested with coefficient of determinations R2, while statistical significance was asserted at the 95 % confidence level.
 
 For the powerline sites investigated in this study, both positive and negative polarities of ions were found to be present in the ambient air environment.  The presence of these ions was associated with perturbations in the local vertical dc e-field, increased net ambient ion concentrations and net particle charge concentration levels.  The mean net ion concentration levels (with a range of 4922 ions cm-3 to -300 ions cm-3) in the ambient environment of these powerlines, were in excess of what was measured in a typical outdoor air (i.e -400 ions cm-3).  The mean net particle charge concentration levels (1469 ions cm-3 to -1100 ions cm-3) near the powerlines were also found to be statistically significantly higher than what was obtained for a mechanically ventilated indoor room (-84 &#177; 49 ions cm-3) and a typical urban outdoor air (-486 &#177; 34 ions cm-3).  In spite of all these measured differences however, the study also indicated that ambient ion concentration as well as its associated effects on ambient particle charge concentration and e-field perturbations gradually decreased with increase in distance from the powerlines.  This observed trend provided the physical evidence of the localized effect of real-world HVPL generated corona ions.  Particle number concentration levels remained constant (in the order of 103 particles cm-3) irrespective of the powerline site or the sampling distance from the lines.
 
 A close observation of the output signals of the sampling instruments used in this study consistently revealed large fluctuations in the instantaneous value of all the measured electrical parameters (i.e. non-periodic extremely high and low negative and positive polarities of ions/charged particles and e-field perturbations was recorded).  Although the reason for these observed fluctuations is not particularly known at this stage, and hence in need of further investigations, it is however being hypothesized that, since these fluctuations appear to be characteristic of the highly charged environment surrounding corona ion emitting electrical infrastructures, they may be suggestive of the possibility that the release of corona ions by ac lines are not necessarily in the form of a continuous flow of ions.
 
 The results also showed that statistically significant correlations (R2 = 74 %, P &lt; 0.05) exists between the instantaneous values of the ground-level ambient ion and the ground-level ambient particle charge concentration.  This correlation is an indication of the strong relationship/association that exists between these two parameters.  Lower correlations (R2 = 3.4 % to 9 %, P &lt; 0.05) were however found to exist between the instantaneous values of the vertical dc e-field and the ground-level ambient particle charge concentration.  These suggest that e-field measurements alone may not necessarily be a true indication of the ground-level ambient ion and particle charge concentration levels.  Similarly, low statistical correlations (R2 = 0.2 % to 1.0 %, P &lt; 0.05) were also found to exist between the instantaneous values of ambient aerosol particle charge concentration and ambient ultrafine (0.02 to 1 &#956;m sized) aerosol particle number concentration.  This low level of correlations suggests that the source contribution of aerosol particle charge and aerosol particle number concentration into the ambient air environment of the HVPLs were different.  In terms of the implication of human exposure to charged aerosol particles, the results obtained from this study suggests that amongst other factors, exposure to the dynamic mixture of ions and charged particles is a function of : (a)  distance from the powerlines;  (b)  concentration of ions generated by the powerlines; and (c) meteorology - wind turbulence and dispersal rate.  
 
 In addition to all its significant findings, during this research, a novel measurement approach that can be used in future studies for the simultaneous monitoring of the various parameters characterizing the physical environment of different ion/charged particle emission sources (such as high voltage powerlines, electricity substations, industrial chimney stack, motor vehicle exhaust, etc.) was developed and validated.  
 
 However, in spite of these significant findings, there is still a need for other future and more comprehensive studies to be carried out on this topic in order to extend the scientific contributions of in this research work.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">aerosol particles, ultrafine particles, corona ions, DC e-field, particle charge concentration, particle number concentration, high voltage powerlines, high transmission voltage powerlines, sub-transmission voltage powerlines</field><field name="identifier">http://eprints.qut.edu.au/20714/</field><field name="validLink">True</field></doc><doc><field name="title">Evaluation of molecular methods used for the rapid detection of multi-drug resistant Mycobacterium tuberculosis</field><field name="creator">Hansen, Tarrant William</field><field name="description">Tuberculosis remains a major public health issue globally, with an estimated 9.2 million new cases in 2006.  A new threat to TB control is the emergence of drug resistant strains.  These strains are harder to cure as standard anti-tuberculosis first line treatments are ineffective.  Multi Drug Resistant Tuberculosis (MDR-TB) is defined as Mycobacterium tuberculosis that has developed resistance to at least rifampicin and isoniazid, and these strains now account for greater than 5% of worldwide cases.  Mutations within the Rifampicin Resistance Determining Region (RRDR) of the rpoB gene are present in greater than 95% of strains that show rifampicin resistance by conventional drug susceptibility testing.  As rifampicin mono resistance is extremely rare, and rifampicin resistance is usually associated with isoniaizd resistance, the RRDR region of the rpoB gene is a very useful surrogate marker for MDR-TB.  Many molecular assays have been attempted based on this theory and have had varied levels of success.  The three methods evaluated in this study are DNA sequencing of the rpoB, katG and inhA genes, the Genotype MTBDRplus line probe assay (Hain Lifesciences) and a novel method incorporating Real-Time PCR with High Resolution Melt analysis targeted at the RRDR using the Rotorgene 6000 (Corbett Lifesciences).  The sensitivity for the detection of rifampicin resistance was far better using DNA sequencing or the commercially available line probe assay than detection by the Real-Time PCR method developed in this study.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Mycobacterium tuberculosis (MTB), multi-drug resistant tuberculosis (MDRTB), molecular biology, single nucleotide polymorphisms (SNP), real time PCR (RT-PCR), high resolution melt analysis (HRM), rotor gene 6000, DNA sequencing, genotype MTBDRplus</field><field name="identifier">http://eprints.qut.edu.au/20723/</field><field name="validLink">True</field></doc><doc><field name="title">The relationship between the inspectorial system and teacher professionalism : a Papua New Guinea primary school case study</field><field name="creator">Apelis, Eliakim Tokacap</field><field name="description">The inspectorial system is a legacy of the colonial era.  The functions, responsibilities and strategies of the inspectorial system in PNG schools were introduced during the colonial era and since its inception there have been insignificant changes made.  
 
 There are perceived problems being experienced due to the growth of the education system and the complex management of education services as a result of the centralized and decentralized organizational functions introduced some thirty years ago.  The multiple, conflicting and confusing roles of the inspectorial system developed over the years and the organizational cultures of agencies responsible for the inspectorial system have further complicated the work of inspectors.  Thus the question of how effectively the inspectorial system works and how it serves its functions needs to be addressed, particularly on how it enhances the teaching profession. 
 
 Although the inspectorial system was introduced as a means of quality assurance, which is still being emphasized in PNG, the analysis reveals that supervision and professional development strategies are applied by inspectors as interactive strategies to pursue better education standards and quality education.  These strategies supposedly ensure teacher professionalism is sustained and improved in order to impact on the quality of education provided by the schools.  However a lack of clear understanding of teacher professionalism, despite changes and developments within the education system, may be also having an influence on how effective the inspectorial system is.  The inspectorial system has developed into a complicated system.  Therefore the need for clear demarcations of its functions, responsibilities and strategies is investigated in this study so that the inspectorial system is improved or developed into a more functional system that may produce tangible outcomes.  
 
 The study explores the experiences, beliefs and perceptions of teachers, head teachers and inspectors about the inspectorial system, teacher professionalism and their relationships.  It does so by answering the main question, how and to what extent does the inspectorial system enhance and hinder teacher professionalism in primary schools in PNG, as well as specifically answering the following key questions:
 
 &#8226;	How does the inspectorial system operate in primary schools in PNG?  
 &#8226;	What are the dimensions of teacher professionalism that are perceived by teachers, head teachers and inspectors? 
 &#8226;	How are these dimensions of teacher professionalism linked to the interactive strategies applied by inspectors on teachers and head teachers?
 &#8226;	What redeveloped conceptual framework grounded in the realities of teachers&#8217;, head teachers&#8217; and inspectors&#8217; experiences, beliefs and perceptions about the inspectorial interactive strategies can enhance teacher professionalism?
 
 In doing so, the interactive strategies of the inspectorial system (including quality assurance, professional development and professional ethics) and the dimensions of teacher professionalism (including teacher compliance, teacher knowledge, teacher leadership, teacher professional development and teacher professional ethics) are disclosed and their linkages identified.  For example, professional development interactive strategies are linked directly to teacher professional development as experienced and perceived by teachers, head teachers and inspectors.  This is done so that the direct impacts of each inspectorial interactive strategy on the dimensions of teacher professionalism are identified, and this leads to the creation of a conceptual framework for an inspectorial system that enhances teacher professionalism.  The conceptual framework can guide supervisors, either school-based or externally based, to develop and execute an efficient supervisory system that can have a direct impact on an evolving teaching profession.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">inspectorial system, inspectorial interactive strategies, quality assurance, professional development, teacher professionalism, dimensions of teacher professionalism, professional ethics, supervision, teacher compliance, teacher knowledge</field><field name="subject">teacher leadership</field><field name="identifier">http://eprints.qut.edu.au/20731/</field><field name="validLink">True</field></doc><doc><field name="title">Plate yield slenderness criteria for structural members fabricated from high strength steels</field><field name="creator">Tang, Louis (Ruo Biao)</field><field name="description">Increasing demand from flourishing construction markets led to the successful development of high strength steels (HSS). The new structural steel has exceptional high strength, high fracture toughness, long fatigue life, high corrosion resistance, and better weldability making the material attractive for structural design applications in the modern steel buildings and bridges. With their high strength, typically in the range of 500~700 MPa, and reduced weight/dimensions, it frees imaginations of modern designers and opens up new possibilities. Although HSS cost more, this is more than offset by reduced fabrication and erection costs. The advantage of the intrinsic properties of the HSS makes it possible to achieve successful applications in a cost-effective manner. At present, the Australian steel design standard, AS 4100 (SA, 1998), is limited to conventional low strength steels (LSS) with yield stress less than 450 MPa, (i.e. fy . 450 MPa). As a result steel structural members fabricated from HSS in Australia are usually designed according to overseas specifications, such as AISC-LRFD (AISC, 2003) which allows the design for structures fabricated from HSS materials. However, the design provisions of AISC-LRFD were mainly based on experimental and analytical studies on standard LSS. HSS exhibits mechanical properties that are quite different from conventional LSS. On the other hand, the design procedure and approach of the American specifications (AISC, 2003) are unfamiliar with Australian design engineers, which explains why practising engineers in Australia are reluctant to use AISC-LRFD specification in the design of HSS members. Therefore research into the behaviour of HSS members is essential to address this shortcoming. However, since the use of HSS often leads to smaller sections, hence thinner plates, the elastic and inelastic instability of these thin-walled and HSS members become highly critical. Conservatively, the local instabilities of the constituent plate element interactions in the cross-section have been ignored in the current steel practices. Increasing the slenderness of either plate elements within a cross-section leads to a significant reduction in the section capacity of the structural member. Therefore, the interactive effects between flange and web plate elements have to be considered in the strength, stability and deformation studies of HSS members. Furthermore, the current definitions and values of the plate slenderness limits also vary among major steel design codes (AS4100, 1998; AISC, 2003; EN1993, 2003; BS5950, 2000). The main aim of this research project is to investigate the structural behaviour of Ishaped HSS members subjected to local buckling effects in the elastic and inelastic ranges. For this purpose, it will use advanced numerical analyses and laboratory experiments to study the structural behaviour of these HSS members in compression and bending, respectively. The critical review has found that various inconsistencies among the major steel design specifications (AS4100, 1998; AISC, 2003; EN1993, 2003, BS5950, 2000) in the current practice produce conflicting design predictions of section capacities. The experimental measurements of residual stress distributions have confirmed that the ECCS recommendation (1984) is inappropriate for crosssections fabricated from typical HSS materials (i.e. BISPLATE80). The experimental measurements and numerical studies carried out in this project have produced a better understanding of the structural behaviour of HSS members subjected to local instabilities. The study has enabled to provide a series of proposals for proper assessment of plate slenderness limits for structural members made of HSS materials. It may also enable the inclusion of future version of the AS4100 code for HSS materials to be used in the design of steel building and bridge constructions. It is believed that the use of HSS in building and bridge constructions will increase significantly in the very near future, and to fully-facilitate this, the future versions of national and international steel design specifications must include rational and reliable design rules for members made of all steel grades by including the effects of HSS special characteristics and true interactive local buckling behaviour of HSS members. This research project has contributed towards this.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">high strength steels, structural members, plate yield slenderness</field><field name="identifier">http://eprints.qut.edu.au/20724/</field><field name="validLink">True</field></doc><doc><field name="title">Carbon nanotubes for organic electronics</field><field name="creator">Goh, Roland Ghim Siong</field><field name="description">This thesis investigated the use of carbon nanotubes as active components in solution processible organic semiconductor devices. We investigated the use of functionalized carbon nanotubes in carbon nanotubes network transistors (CNNFET) and in photoactive composites with conjugated polymers. For CNNFETs, the objective was to obtain detailed understanding of the dependence of transistor characteristics on nanotubes bundle sizes, device geometry and processing. Single walled carbon nanotubes were functionalized by grafting octadecylamine chains onto the tubes, which rendered them dispersible in organic solvents for solution processing. To investigate the dependence of electronic properties of carbon nanotubes networks on bundle size, we developed a centrifugal fractionation protocol that enabled us to obtain nanotube bundles of different diameters. The electronic properties of networks of nanotube bundles deposited from solution were investigated within a CNNFET device configuration. By comparing devices with different degree of bundling we elucidated the dependence of key device parameters (field effect mobility and on/off ratio) on bundle sizes. We further found that, in contrast to traditional inorganic transistors, the electronic properties of the CNNFETs were dominated by the channel rather than contact resistance. Specifically, the apparent mobility of our devices increased with decreasing channel length, suggesting that the charge transport properties of CNNFETs are bulk rather than contacts dominated. This meant that charge traps in the channel of the device had a significant effect on transport properties. We found that charge traps in the channel region introduced by adsorbed oxygen and silanol groups on the SiO2 surface were responsible for the dominant p-type conductance in as-fabricated devices. Based on this understanding, we demonstrated the p-type to n-type conversion of the transistor characteristics of CNNFETs by depositing nanotubes on electron-trapfree dielectric surfaces. Finally, by combining annealing and surface treatment, we fabricated CNNFETs with high n-type mobility of 6cm2/V.s. For polymer composites, the objective was to obtain detailed understanding of the interactions between carbon nanotubes and the conjugated polymer; a prerequisite for using these composites in organic electronic devices. We fabricated well dispersed nanotube/polymer composites by using functionalized carbon nanotubes and studied the effect of nanotubes addition on the photophysical properties of the technologically important conjugated polymer poly(3-hexylthiophene) (P3HT). Measurement of the photoluminescence efficiency of nanotubes/polymer composites showed that addition of 10wt% carbon nanotubes effectively quenched the polymer emission indicating close electronic interactions. This indicated that nanotubes/polymer composites have potential in organic photovoltaic or light-sensing devices. Further analysis of the steady-state photoluminescence spectra revealed that nanotube addition resulted in increased structural disorder in the polymer. The incorporation of structural disorder into the polymer with the addition of even a small amount of carbon nanotubes may be detrimental to charge transport. UV-vis adsorption studies revealed that one-dimensional templating of P3HT chains by nanotubes resulted in a red-shifted feature in the solutionstate optical adsorption spectra of P3HT. This suggested that presence of nanotube surface templates the polymer self-organisation to produce highly ordered coating of P3HT chains around the nanotube. In order to elucidate the nanoscale origin of this phenomenon, we performed detailed STM studies on individual nanotubes adsorbed with P3HT chains. Since carbon nanotubes can be considered as rolled up sheets of graphite, we also performed STM on P3HT chains assembly on graphite for comparison. For P3HT assembly on HOPG, we found that while 2D crystals were observed when P3HT was cast onto HOPG from dilute solution, a thicker and more disordered film resulted when cast from concentrated solutions and subsequent layers were more likely to align normal to an underlying monolayer of P3HT on the HOPG surface. STM studies of nanotube/polymer mixtures revealed that the P3HT chains are adsorbed on nanotubes surface in such a way that the thiophene and hexyl moieties of the polymer associated with the nanotube surface in identical manner to P3HT monolayer depositions on graphite. This resulted in the increased order as inferred from adsorption UV-Vis spectroscopy, where the polymer chains, which are otherwise prone to chain kinks and twists in solution, adopt a planar configuration when adsorbed onto the nanotube surface.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">organic electronics, carbon nanotubes, field effect transistors, n-type, ptype, ambipolar, charge trapping, dielectric surface modification, conjugated polymers, polymer composites, polymer ordering, photoluminescence, photoluminescence efficiency</field><field name="subject">optical adsorption, scanning tunneling microscopy, self-assembly</field><field name="identifier">http://eprints.qut.edu.au/20849/</field><field name="validLink">True</field></doc><doc><field name="title">Development of a Rep-inducible, BBTV-based expression system in banana</field><field name="creator">Bolton, Clair Louise</field><field name="description">Banana bunchy top is regarded as the most important viral disease of banana, causing significant yield losses worldwide.  The disease is caused by Banana bunchy top virus (BBTV), which is a circular ssDNA virus belonging to the genus Babuvirus in the family Nanoviridae.  There are currently few effective control strategies for this and other ssDNA viruses.  &#8220;In Plant Activation&#8221; (InPAct) is a novel technology being developed at QUT for ssDNA virus-activated suicide gene expression.  The technology exploits the rolling circle replication mechanism of ssDNA viruses and is based on a unique &#8220;split&#8221; gene design such that suicide gene expression is only activated in the presence of the viral Rep. This PhD project aimed to develop a BBTV-based InPAct system as a suicide gene strategy to control BBTV.
 
 The BBTV-based InPAct vector design requires a BBTV intergenic region (IR) to be embedded within an intron in the gene expression cassette.  To ensure that the BBTV IR would not interfere with intron splicing, a TEST vector was initially generated that contained the entire BBTV IR embedded within an intron in a &#946;-glucuronidase (GUS) expression vector.  Transient GUS assays in banana embryogenic cell suspensions indicated that cryptic intron splice sites were present within the IR.  Transcript analysis revealed two cryptic intron splice sites in the Domain III sequence of the CR-M within the IR.  Removal of the CR-M from the TEST vector resulted in an enhancement of GUS expression suggesting that the cryptic intron splice sites had been removed.
 
 An InPAct GUS vector was subsequently generated that contained the modified BBTV IR, with the CR-M (minus Domain III) repositioned within the InPAct cassette.  Using transient histochemical and fluorometric GUS assays in banana embryogenic cells, the InPAct GUS vector was shown to be activated in the presence of the BBTV Rep.  However, the presence of both BBTV Rep and Clink was shown to have a deleterious effect on GUS expression suggesting that these proteins were cytotoxic at the levels expressed. Analysis of replication of the InPAct vectors by Southern hybridisation revealed low levels of InPAct cassette-based episomal DNA released from the vector through the nicking/ligation activity of BBTV Rep. However, Rep-mediated episomal replicons, indicative of rolling circle replication of the released circularised cassettes, were not observed.  
 
 The inability of the InPAct cassette to be replicated was further investigated.  To examine whether the absence of Domain III of the CR-M was responsible, a suite of modified BBTV-based InPAct GUS vectors was constructed that contained the CR-M with the inclusion of Domain III, the CR-M with the inclusion of Domain III and additional upstream IR sequence, or no CR-M.  Analysis of replication by Southern hybridisation revealed that neither the presence of Domain III, nor the entire CR-M, had an effect on replication levels.  Since the InPAct cassette was significantly larger than the native BBTV genomic components (approximately 1 kb), the effect of InPAct cassette size on replication was also investigated.  A suite of size variant BBTV-based vectors was constructed that increased the size of a replication competent cassette to 1.1 kbp through to 2.1 kbp..  Analysis of replication by Southern hybridisation revealed that an increase in vector size above approximately 1.5 - 1.7 kbp resulted in a decrease in replication.  
 
 Following the demonstration of Rep-mediated release, circularisation and expression from the InPAct GUS vector, an InPAct vector was generated in which the uidA reporter gene was replaced with the ribonuclease-encoding suicide gene, barnase.  Initially, a TEST vector was generated to assess the cytotoxicity of Barnase on banana cells. Although transient assays revealed a Barnase-induced cytotoxic effect in banana cells, the expression levels were sub-optimal.  An InPAct BARNASE vector was generated and tested for BBTV Rep-activated Barnase expression using transient assays in banana embryogenic cells. High levels of background expression from the InPAct BARNASE vector made it difficult to accurately assess Rep-activated Barnase expression. Analysis of replication by Southern hybridisation revealed low levels of InPAct cassette-based episomal DNA released from the vector but no Rep-mediated episomal replicons indicative of rolling circle replication of the released circularised cassettes were again observed. 
 
 Despite the inability of the InPAct vectors to replicate to enable high level gene expression, the InPAct BARNASE vector was assessed in planta for BBTV Rep-mediated activation of Barnase expression.  Eleven lines of transgenic InPAct BARNASE banana plants were generated by Agrobacterium-mediated transformation and were challenged with viruliferous Pentalonia nigronervosa.  At least one clonal plant in each line developed bunchy top symptoms and infection was confirmed by PCR.  No localised lesions were observed on any plants, nor was there any localised GUS expression in the one InPAct GUS line challenged with viruliferous aphids.  
 
 The results presented in this thesis are the first study towards the development of a BBTV-based InPAct system as a Rep-activatable suicide gene expression system to control BBTV. Although further optimisation of the vectors is necessary, the preliminary results suggest that this approach has the potential to be an effective control strategy for BBTV. The use of iterons within the InPAct vectors that are recognised by Reps from different ssDNA plant viruses may provide a broad-spectrum resistance strategy against multiple ssDNA plant viruses.  Further, this technology holds great promise as a platform technology for the molecular farming of high-value proteins in vitro or in vivo through expression of the ssDNA virus Rep protein.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">banana, Rep-inducible, BBTV-based expression system, banana bunchy top virus</field><field name="identifier">http://eprints.qut.edu.au/25939/</field><field name="validLink">True</field></doc><doc><field name="title">Professional development for the integration of biotechnology education</field><field name="creator">Garrett, Stephen Thomas</field><field name="description">Views on the nature and relevance of science education have changed significantly over recent decades. This has serious implications for the way in which science is taught in secondary schools, particularly with respect to teaching emerging topics such as biotechnology, which have a socio-scientific dimension and also require novel laboratory skills. It is apparent in current literature that there is a lack of adequate teacher professional development opportunities in biotechnology education and that a significant need exists for researchers to develop a carefully crafted and well supported professional development design which will positively impact on the way in which teachers engage with contemporary science. 
 
 This study used a retrospective case study methodology to document the recent evolution of modern biotechnology education as part of the changing nature of science education; examine the adoption and implementation processes for biotechnology education by three secondary schools; and to propose an evidence based biotechnology professional development model for science educators. Data were gathered from documents, one-on-one interviews and focus group discussions. Analysis of these data has led to the proposal of a biotechnology professional development model which considers all of the key components of science professional development that are outlined in the literature, as well as the additional components which were articulated by the educators studied. 
 
 This research is timely and pertinent to the needs of contemporary science education because of its recognition of the need for a professional development model in biotechnology education that recognizes and addresses the content knowledge, practical skills, pedagogical knowledge and curriculum management components.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">science education, biotechnology, socio-scientific dimension, professional development, qualitative research, retrospective case study, one-on-one interviews, focus group discussions contemporary science, science curriculum, content knowledge</field><field name="subject">practical skills, pedagogical knowledge, curriculum management</field><field name="identifier">http://eprints.qut.edu.au/25966/</field><field name="validLink">True</field></doc><doc><field name="title">Cooperation using a robotic ad hoc network made from Bluetooth, JXTA, OSGi and other commercial off the shelf (COTS) products</field><field name="creator">Robinson, Kenneth Patrick</field><field name="description">Abstract - Mobile devices in the near future will need to collaborate to fulfill their function. Collaboration will be done by communication. We use a real world example of robotic soccer to come up with the necessary structures required for robotic communication. A review of related work is done and it is found no examples come close to providing a RANET. The robotic ad hoc network (RANET) we suggest uses existing structures pulled from the areas of wireless networks, peer to peer and software life-cycle management. Gaps are found in the existing structures so we describe how to extend some structures to satisfy the design. The RANET design supports robot cooperation by exchanging messages, discovering needed skills that other robots on the network may possess and the transfer of these skills. The network is built on top of a Bluetooth wireless network and uses JXTA to communicate and transfer skills. OSGi bundles form the skills that can be transferred. To test the nal design a reference implementation is done. Deficiencies in some third party software is found, specifically JXTA and JamVM and GNU Classpath. Lastly we look at how to fix the deciencies by porting the JXTA C implementation to the target robotic platform and potentially eliminating the TCP/IP layer, using UDP instead of TCP or using an adaptive TCP/IP stack. We also propose a future areas of investigation; how to seed the configuration for the Personal area network (PAN) Bluetooth protocol extension so a Bluetooth TCP/IP link is more quickly formed and using the STP to allow multi-hop messaging and transfer of skills.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">robot soccer, robot communication, wireless networks, peer to peer protocols, software life-cycle management, messaging, skill transfer, code transfer, WiFi, Bluetooth, BlueZ, Linux, Java, OSGi, JXTA</field><field name="identifier">http://eprints.qut.edu.au/26038/</field><field name="validLink">True</field></doc><doc><field name="title">A framework for fully decentralised cycle stealing</field><field name="creator">Mason, Richard S.</field><field name="description">Ordinary desktop computers continue to obtain ever more resources &#8211; in-creased processing power, memory, network speed and bandwidth &#8211; yet these resources spend much of their time underutilised. Cycle stealing frameworks harness these resources so they can be used for high-performance computing. Traditionally cycle stealing systems have used client-server based architectures which place significant limits on their ability to scale and the range of applica-tions they can support. By applying a fully decentralised network model to cycle stealing the limits of centralised models can be overcome.
 Using decentralised networks in this manner presents some difficulties which have not been encountered in their previous uses. Generally decentralised ap-plications do not require any significant fault tolerance guarantees. High-performance computing on the other hand requires very stringent guarantees to ensure correct results are obtained. Unfortunately mechanisms developed for traditional high-performance computing cannot be simply translated because of their reliance on a reliable storage mechanism. In the highly dynamic world of P2P computing this reliable storage is not available. As part of this research a fault tolerance system has been created which provides considerable reliability without the need for a persistent storage.
 As well as increased scalability, fully decentralised networks offer the ability for volunteers to communicate directly. This ability provides the possibility of supporting applications whose tasks require direct, message passing style communication. Previous cycle stealing systems have only supported embarrassingly parallel applications and applications with limited forms of communication so a new programming model has been developed which can support this style of communication within a cycle stealing context.
 In this thesis I present a fully decentralised cycle stealing framework. The framework addresses the problems of providing a reliable fault tolerance sys-tem and supporting direct communication between parallel tasks. The thesis includes a programming model for developing cycle stealing applications with direct inter-process communication and methods for optimising object locality on decentralised networks.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">cycle stealing, cycle scavenging, volunteer computing, peer-to-peer, fully de-centralised networking, pure p2p, distributed computing</field><field name="identifier">http://eprints.qut.edu.au/26039/</field><field name="validLink">True</field></doc><doc><field name="title">Assessing the potential of inter-organisational shared services</field><field name="creator">Yee, Hon Weng (Jonathan)</field><field name="description">Shared Services (SS) involves the convergence and streamlining of an organisation&#8217;s functions to ensure timely service delivery as effectively and efficiently as possible. As a management structure designed to promote value generation, cost savings and improved service delivery by leveraging on economies of scale, the idea of SS is driven by cost reduction and improvements in quality levels of service and efficiency. Current conventional wisdom is that the potential for SS is increasing due to the increasing costs of changing systems and business requirements for organisations and in implementing and running information systems. In addition, due to commoditisation of large information systems such as enterprise systems, many common, supporting functions across organisations are becoming more similar than not, leading to an increasing overlap in processes and fuelling the notion that it is possible for organisations to derive benefits from collaborating and sharing their common services through an inter-organisational shared services (IOSS) arrangement. While there is some research on traditional SS, very little research has been done on IOSS. In particular, it is unclear what are the potential drivers and inhibitors of IOSS. As the concepts of IOSS and SS are closely related to that of Outsourcing, and their distinction is sometimes blurred, this research has the first objective of seeking a clear conceptual understanding of the differences between SS and Outsourcing (in motivators, arrangements, benefits, disadvantages, etc) and based on this conceptual understanding, the second objective of this research is to develop a decision model (Shared Services Potential model) which would aid organisations in deciding which arrangement would be more appropriate for them to adopt in pursuit of process improvements for their operations. As the context of the study is on universities in higher education sharing administrative services common to or across them and with the assumption that such services were homogenous in nature, this thesis also reports on a case study. The case study involved face to face interviews from representatives of an Australian university to explore the potential for IOSS. Our key findings suggest that it is possible for universities to share services common across them as most of them were currently using the same systems although independently.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">shared services potential, outsourcing, inter-organisational shared services, financials, business process re-engineering, organisational design</field><field name="identifier">http://eprints.qut.edu.au/26040/</field><field name="validLink">True</field></doc><doc><field name="title">IT professionals' experience of ethics and its implications for IT education</field><field name="creator">Stoodley, Ian D.</field><field name="description">This study investigates variation in IT professionals' experience of ethics with a view to enhancing their formation and support. This is explored through an examination of the experience of IT, IT professional ethics and IT professional ethics education. The study's principal contribution is the empirical study and description of IT professionals' experience of ethics. The empirical phase is preceded by a review of conceptions of IT and followed by an application of the findings to IT education. The study's empirical findings are based on 30 semi-structured interviews with IT professionals who represent a wide demographic, experience and IT sub-discipline range. Their experience of ethics is depicted as five citizenships: Citizenship of my world, Citizenship of the corporate world, Citizenship of a shared world, Citizenship of the client's world and Citizenship of the wider world. These signify an expanding awareness, which progressively accords rights to others and defines responsibility in terms of others. The empirical findings inform a Model of Ethical IT. This maps an IT professional space increasingly oriented towards others. Such a model provides a conceptual tool, available to prompt discussion and reflection, and which may be employed in pursuing formation aimed at experiential change. Its usefulness for the education of IT professionals with respect to ethics is explored. The research approach employed in this study is phenomenography. This method seeks to elicit and represent variation of experience. It understands experience as a relationship between a subject (IT professionals) and an object (ethics), and describes this relationship in terms of its foci and boundaries. The study's findings culminate in three observations, that change is indicated in the formation and support of IT professionals in: 1. IT professionals' experience of their discipline, moving towards a focus on information users; 2. IT professionals' experience of professional ethics, moving towards the adoption of other-centred attitudes; and 3. IT professionals' experience of professional development, moving towards an emphasis on a change in lived experience. Based on these results, employers, educators and professional bodies may want to evaluate how they approach professional formation and support, if they aim to promote a comprehensive awareness of ethics in IT professionals.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">information technology, professionalism, ethics, phenomenography, variation theory, education</field><field name="identifier">http://eprints.qut.edu.au/26105/</field><field name="validLink">True</field></doc><doc><field name="title">Search engine content analysis</field><field name="creator">King, John D.</field><field name="description">Search engines have forever changed the way people access and discover knowledge, allowing information about almost any subject to be quickly and easily retrieved within seconds. As increasingly more material becomes available electronically the influence of search engines on our lives will continue to grow. This presents the problem of how to find what information is contained in each search engine, what bias a search engine may have, and how to select the best search engine for a particular information need. This research introduces a new method, search engine content analysis, in order to solve the above problem. Search engine content analysis is a new development of traditional information retrieval field called collection selection, which deals with general information repositories. Current research in collection selection relies on full access to the collection or estimations of the size of the collections. Also collection descriptions are often represented as term occurrence statistics. An automatic ontology learning method is developed for the search engine content analysis, which trains an ontology with world knowledge of hundreds of different subjects in a multilevel taxonomy. This ontology is then mined to find important classification rules, and these rules are used to perform an extensive analysis of the content of the largest general purpose Internet search engines in use today. Instead of representing collections as a set of terms, which commonly occurs in collection selection, they are represented as a set of subjects, leading to a more robust representation of information and a decrease of synonymy. The ontology based method was compared with ReDDE (Relevant Document Distribution Estimation method for resource selection) using the standard R-value metric, with encouraging results. ReDDE is the current state of the art collection selection method which relies on collection size estimation. The method was also used to analyse the content of the most popular search engines in use today, including Google and Yahoo. In addition several specialist search engines such as Pubmed and the U.S. Department of Agriculture were analysed. In conclusion, this research shows that the ontology based method mitigates the need for collection size estimation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">web intelligence, ontology, hierarchal classification, taxonomy, collection selection, search engines, data mining</field><field name="identifier">http://eprints.qut.edu.au/26241/</field><field name="validLink">True</field></doc><doc><field name="title">Mapping of indoor environments by robots using low-cost vision sensors</field><field name="creator">Taylor, Trevor</field><field name="description">For robots to operate in human environments they must be able to make their own maps because it is unrealistic to expect a user to enter a map into the robot&#8217;s memory; existing floorplans are often incorrect; and human environments tend to change. Traditionally robots have used sonar, infra-red or laser range finders to perform the mapping task. Digital cameras have become very cheap in recent years and they have opened up new possibilities as a sensor for robot perception. Any robot that must interact with humans can reasonably be expected to have a camera for tasks such as face recognition, so it makes sense to also use the camera for navigation. Cameras have advantages over other sensors such as colour information (not available with any other sensor), better immunity to noise (compared to sonar), and not being restricted to operating in a plane (like laser range finders). However, there are disadvantages too, with the principal one being the effect of perspective. This research investigated ways to use a single colour camera as a range sensor to guide an autonomous robot and allow it to build a map of its environment, a process referred to as Simultaneous Localization and Mapping (SLAM). An experimental system was built using a robot controlled via a wireless network connection. Using the on-board camera as the only sensor, the robot successfully explored and mapped indoor office environments. The quality of the resulting maps is comparable to those that have been reported in the literature for sonar or infra-red sensors. Although the maps are not as accurate as ones created with a laser range finder, the solution using a camera is significantly cheaper and is more appropriate for toys and early domestic robots.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">computer vision, Simultaneous Localization and Mapping (SLAM), Concurrent Mapping and Localization (CML), mobile robots</field><field name="identifier">http://eprints.qut.edu.au/26282/</field><field name="validLink">True</field></doc><doc><field name="title">Protocol engineering for protection against denial-of-service attacks</field><field name="creator">Tritilanunt, Suratose</field><field name="description">Denial-of-service attacks (DoS) and distributed denial-of-service attacks (DDoS) attempt to temporarily disrupt users or computer resources to cause service un- availability to legitimate users in the internetworking system. The most common type of DoS attack occurs when adversaries &#176;ood a large amount of bogus data to interfere or disrupt the service on the server. The attack can be either a single-source attack, which originates at only one host, or a multi-source attack, in which multiple hosts coordinate to &#176;ood a large number of packets to the server. Cryptographic mechanisms in authentication schemes are an example ap- proach to help the server to validate malicious tra&#177;c. Since authentication in key establishment protocols requires the veri&#175;er to spend some resources before successfully detecting the bogus messages, adversaries might be able to exploit this &#176;aw to mount an attack to overwhelm the server resources. The attacker is able to perform this kind of attack because many key establishment protocols incorporate strong authentication at the beginning phase before they can iden- tify the attacks. This is an example of DoS threats in most key establishment protocols because they have been implemented to support con&#175;dentiality and data integrity, but do not carefully consider other security objectives, such as availability. The main objective of this research is to design denial-of-service resistant mechanisms in key establishment protocols. In particular, we focus on the design of cryptographic protocols related to key establishment protocols that implement client puzzles to protect the server against resource exhaustion attacks. Another objective is to extend formal analysis techniques to include DoS- resistance. Basically, the formal analysis approach is used not only to analyse and verify the security of a cryptographic scheme carefully but also to help in the design stage of new protocols with a high level of security guarantee. In this research, we focus on an analysis technique of Meadows' cost-based framework, and we implement DoS-resistant model using Coloured Petri Nets. Meadows' cost-based framework is directly proposed to assess denial-of-service vulnerabil- ities in the cryptographic protocols using mathematical proof, while Coloured Petri Nets is used to model and verify the communication protocols using inter- active simulations. In addition, Coloured Petri Nets are able to help the protocol designer to clarify and reduce some inconsistency of the protocol speci&#175;cation. Therefore, the second objective of this research is to explore vulnerabilities in existing DoS-resistant protocols, as well as extend a formal analysis approach to our new framework for improving DoS-resistance and evaluating the performance of the new proposed mechanism. In summary, the speci&#175;c outcomes of this research include following results; 1. A taxonomy of denial-of-service resistant strategies and techniques used in key establishment protocols; 2. A critical analysis of existing DoS-resistant key exchange and key estab- lishment protocols; 3. An implementation of Meadows's cost-based framework using Coloured Petri Nets for modelling and evaluating DoS-resistant protocols; and 4. A development of new e&#177;cient and practical DoS-resistant mechanisms to improve the resistance to denial-of-service attacks in key establishment protocols.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">denial of service attacks, denial of service resistance, key establishment proto- cols, Host Identity Protocol (HIP), Meadows' cost-based framework, Coloured Petri Nets, CPN Tools, denial of service modelling</field><field name="identifier">http://eprints.qut.edu.au/26277/</field><field name="validLink">True</field></doc><doc><field name="title">Long-term trends in fine particle number concentrations in the urban atmosphere of Brisbane : the relevance of traffic emissions and new particle formation</field><field name="creator">Mejia, Jaime F.</field><field name="description">The measurement of submicrometre (&lt; 1.0 &#61549;m) and ultrafine particles (diameter &lt; 0.1 &#61549;m) number concentration have attracted attention since the last decade because the potential health impacts associated with exposure to these particles can be more significant than those due to exposure to larger particles. At present, ultrafine particles are not regularly monitored and they are yet to be incorporated into air quality monitoring programs. As a result, very few studies have analysed their long-term and spatial variations in ultrafine particle concentration, and none have been in Australia.
 
 To address this gap in scientific knowledge, the aim of this research was to investigate the long-term trends and seasonal variations in particle number concentrations in Brisbane, Australia. Data collected over a five-year period were analysed using weighted regression models. Monthly mean concentrations in the morning (6:00-10:00) and the afternoon (16:00-19:00) were plotted against time in months, using the monthly variance as the weights. During the five-year period, submicrometre and ultrafine particle concentrations increased in the morning by 105.7% and 81.5% respectively whereas in the afternoon there was no significant trend. The morning concentrations were associated with fresh traffic emissions and the afternoon concentrations with the background. The statistical tests applied to the seasonal models, on the other hand, indicated that there was no seasonal component. 
 
 The spatial variation in size distribution in a large urban area was investigated using particle number size distribution data collected at nine different locations during different campaigns. The size distributions were represented by the modal structures and cumulative size distributions. Particle number peaked at around 30 nm, except at an isolated site dominated by diesel trucks, where the particle number peaked at around 60 nm. It was found that ultrafine particles contributed to 82%-90% of the total particle number. At the sites dominated by petrol vehicles, nanoparticles (&lt; 50 nm) contributed 60%-70% of the total particle number, and at the site dominated by diesel trucks they contributed 50%. Although the sampling campaigns took place during different seasons and were of varying duration these variations did not have an effect on the particle size distributions. The results suggested that the distributions were rather affected by differences in traffic composition and distance to the road.
 
 To investigate the occurrence of nucleation events, that is, secondary particle formation from gaseous precursors, particle size distribution data collected over a 13 month period during 5 different campaigns were analysed. The study area was a complex urban environment influenced by anthropogenic and natural sources. The study introduced a new application of time series differencing for the identification of nucleation events. To evaluate the conditions favourable to nucleation, the meteorological conditions and gaseous concentrations prior to and during nucleation events were recorded. Gaseous concentrations did not exhibit a clear pattern of change in concentration. It was also found that nucleation was associated with sea breeze and long-range transport. The implications of this finding are that whilst vehicles are the most important source of ultrafine particles, sea breeze and aged gaseous emissions play a more important role in secondary particle formation in the study area.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">submicrometre particles, ultrafine particles, nanoparticles, number concentration, number size distribution, modal structure, number median diameter, nucleation, wind sector, brisbane, traffic, total concentration, trends, seasonality, secondary particle</field><field name="identifier">http://eprints.qut.edu.au/26283/</field><field name="validLink">True</field></doc><doc><field name="title">Exploring non-cancer pain conditions in a community sample : critiquing a current conceptual model of the acute to chronic pain transition and examining predictors of chronicity</field><field name="creator">Lang, Cathryne P.</field><field name="description">This program of research examines the experience of chronic pain in a community sample.  While, it is clear that like patient samples, chronic pain in non-patient samples is also associated with psychological distress and physical disability, the experience of pain across the total spectrum of pain conditions (including acute and episodic pain conditions) and during the early course of chronic pain is less clear.  Information about these aspects of the pain experience is important because effective early intervention for chronic pain relies on identification of people who are likely to progress to chronicity post-injury.  A conceptual model of the transition from acute to chronic pain was proposed by Gatchel (1991a).  In brief, Gatchel&#8217;s model describes three stages that individuals who have a serious pain experience move through, each with worsening psychological dysfunction and physical disability.  The aims of this program of research were to describe the experience of pain in a community sample in order to obtain pain-specific data on the problem of pain in Queensland, and to explore the usefulness of Gatchel&#8217;s Model in a non-clinical sample.  Additionally, five risk factors and six protective factors were proposed as possible extensions to Gatchel&#8217;s Model.  To address these aims, a prospective longitudinal mixed-method research design was used.  Quantitative data was collected in Phase 1 via a comprehensive postal questionnaire.  Phase 2 consisted of a follow-up questionnaire 3 months post-baseline.  Phase 3 consisted of semi-structured interviews with a subset of the original sample 12 months post follow-up, which used qualitative data to provide a further in-depth examination of the experience and process of chronic pain from respondents&#8217; point of view.  The results indicate chronic pain is associated with high levels of anxiety and depressive symptoms.  However, the levels of disability reported by this Queensland sample were generally lower than those reported by clinical samples and consistent with disability data reported in a New South Wales population-based study.  With regard to the second aim of this program of research, while some elements of the pain experience of this sample were consistent with that described by Gatchel&#8217;s Model, overall the model was not a good fit with the experience of this non-clinical sample.  The findings indicate that passive coping strategies (minimising activity), catastrophising, self efficacy, optimism, social support, active strategies (use of distraction) and the belief that emotions affect pain may be important to consider in understanding the processes that underlie the transition to and continuation of chronic pain.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">chronic pain, acute to chronic transition, community sample, mixed-methods, longitudinal</field><field name="identifier">http://eprints.qut.edu.au/26323/</field><field name="validLink">True</field></doc><doc><field name="title">Exploring the influence of a science content course incorporating explicit nature of science and argumentation instruction on preservice primary teachers' views of nature of science</field><field name="creator">McDonald, Christine</field><field name="description">There exists a general consensus in the science education literature around the goal of enhancing students. and teachers. views of nature of science (NOS). An emerging area of research in science education explores NOS and argumentation, and the aim of this study was to explore the effectiveness of a science content course incorporating explicit NOS and argumentation instruction on preservice primary teachers. views of NOS. A constructivist perspective guided the study, and the research strategy employed was case study research. Five preservice primary teachers were selected for intensive investigation in the study, which incorporated explicit NOS and argumentation instruction, and utilised scientific and socioscientific contexts for argumentation to provide opportunities for participants to apply their NOS understandings to their arguments. Four primary sources of data were used to provide evidence for the interpretations, recommendations, and implications that emerged from the study. These data sources included questionnaires and surveys, interviews, audio- and video-taped class sessions, and written artefacts. Data analysis involved the formation of various assertions that informed the major findings of the study, and a variety of validity and ethical protocols were considered during the analysis to ensure the findings and interpretations emerging from the data were valid. Results indicated that the science content course was effective in enabling four of the five participants. views of NOS to be changed. All of the participants expressed predominantly limited views of the majority of the examined NOS aspects at the commencement of the study. Many positive changes were evident at the end of the study with four of the five participants expressing partially informed and/or informed views of the majority of the examined NOS aspects. A critical analysis of the effectiveness of the various course components designed to facilitate the development of participants&#8223; views of NOS in the study, led to the identification of three factors that mediated the development of participants&#8223; NOS views: (a) contextual factors (including context of argumentation, and mode of argumentation), (b) task-specific factors (including argumentation scaffolds, epistemological probes, and consideration of alternative data and explanations), and (c) personal factors (including perceived previous knowledge about NOS, appreciation of the importance and utility value of NOS, and durability and persistence of pre-existing beliefs). A consideration of the above factors informs recommendations for future studies that seek to incorporate explicit NOS and argumentation instruction as a context for learning about NOS.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">nature of science (NOS), epistemology of science, argumentation, context of argumentation, preservice primary teachers</field><field name="identifier">http://eprints.qut.edu.au/26330/</field><field name="validLink">True</field></doc><doc><field name="title">SELinux policy management framework for HIS</field><field name="creator">Marin, Luis Franco</field><field name="description">Health Information Systems (HIS) make extensive use of Information and Communication Technologies (ICT). The use of ICT aids in improving the quality and efficiency of healthcare services by making healthcare information available at the point of care (Goldstein, Groen, Ponkshe, and Wine, 2007). The increasing availability of healthcare data presents security and privacy issues which have not yet been fully addressed (Liu, Caelli, May, and Croll, 2008a). Healthcare organisations have to comply with the security and privacy requirements stated in laws, regulations and ethical standards, while managing healthcare information. Protecting the security and privacy of healthcare information is a very complex task (Liu, May, Caelli and Croll, 2008b). In order to simplify the complexity of providing security and privacy in HIS, appropriate information security services and mechanisms have to be implemented. Solutions at the application layer have already been implemented in HIS such as those existing in healthcare web services (Weaver et al., 2003). In addition, Discretionary Access Control (DAC) is the most commonly implemented access control model to restrict access to resources at the OS layer (Liu, Caelli, May, Croll and Henricksen, 2007a). Nevertheless, the combination of application security mechanisms and DAC at the OS layer has been stated to be insufficient in satisfying security requirements in computer systems (Loscocco et al., 1998). This thesis investigates the feasibility of implementing Security Enhanced Linux (SELinux) to enforce a Role-Based Access Control (RBAC) policy to help protect resources at the Operating System (OS) layer. SELinux provides Mandatory Access Control (MAC) mechanisms at the OS layer. These mechanisms can contain the damage from compromised applications and restrict access to resources according to the security policy implemented. The main contribution of this research is to provide a modern framework to implement and manage SELinux in HIS. The proposed framework introduces SELinux Profiles to restrict access permissions over the system resources to authorised users. The feasibility of using SELinux profiles in HIS was demonstrated through the creation of a prototype, which was submitted to various attack scenarios. The prototype was also subjected to testing during emergency scenarios, where changes to the security policies had to be made on the spot. Attack scenarios were based on vulnerabilities common at the application layer. SELinux demonstrated that it could effectively contain attacks at the application layer and provide adequate flexibility during emergency situations. However, even with the use of current tools, the development of SELinux policies can be very complex. Further research has to be made in order to simplify the management of SELinux policies and access permissions. In addition, SELinux related technologies, such as the Policy Management Server by Tresys Technologies, need to be researched in order to provide solutions at different layers of protection.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">information security, security for health systems, health information systems, access control, security enhanced linux, mandatory access control, operating systems, trusted systems</field><field name="identifier">http://eprints.qut.edu.au/26358/</field><field name="validLink">True</field></doc><doc><field name="title">Investigating the links between muscle strength, sun exposure, dietary vitamin D intake and the vitamin D status of ambulatory older adults in South East Queensland</field><field name="creator">Borradale, David</field><field name="description">Vitamin D deficiency and insufficiency are now seen as a contemporary health problem in Australia with possible widespread health effects not limited to bone health1. Despite this, the Vitamin D status (measured as serum 25-hydroxyvitamin D (25(OH)D)) of ambulatory adults has been overlooked in this country. Serum 25(OH)D status is especially important among this group as studies have shown a link between Vitamin D and fall risk in older adults2. Limited data also exists on the contributions of sun exposure via ultraviolet radiation and dietary intake to serum 25(OH)D status in this population. The aims of this project were to assess the serum 25(OH)D status of a group of older ambulatory adults in South East Queensland, to assess the association between their serum 25(OH)D status and functional measures as possible indicators of fall risk, obtain data on the sources of Vitamin D in this population and assess whether this intake was related to serum 25(OH)D status and describe sun protection and exposure behaviors in this group and investigate whether a relationship existed between these and serum 25(OH)D status. The collection of this data assists in addressing key gaps identified in the literature with regard to this population group and their Vitamin D status in Australia. A representative convenience sample of participants (N=47) over 55 years of age was recruited for this cross-sectional, exploratory study which was undertaken in December 2007 in south-east Queensland (Brisbane and Sunshine coast). Participants were required to complete a sun exposure questionnaire in addition to a Calcium and Vitamin D food frequency questionnaire. Timed up and go and handgrip dynamometry tests were used to examine functional capacity. Serum 25(OH)D status and blood measures of Calcium, Phosphorus and Albumin were determined through blood tests. The Mean and Median serum 25-Hydroxyvitamin D (25(OH)D) for all participants in this study was 85.8nmol/L (Standard Deviation 29.7nmol/L) and 81.0nmol/L (Range 22-158nmol/L), respectively. Analysis at the bivariate level revealed a statistically significant relationship between serum 25(OH)D status and location, with participants living on the Sunshine Coast having a mean serum 25(OH)D status 21.3nmol/L higher than participants living in Brisbane (p=0.014). While at the descriptive level there was an apparent trend towards higher outdoor exposure and increasing levels of serum 25(OH)D, no statistically significant associations between the sun measures of outdoor exposure, sun protection behaviors and phenotypic characteristics and serum 25(OH)D status were observed. Intake of both Calcium and Vitamin D was low in this sample with sixty-eight (68%) of participants not meeting the Estimated Average Requirements (EAR) for Calcium (Median=771.0mg; Range=218.0-2616.0mg), while eighty-seven (87%) did not meet the Adequate Intake for Vitamin D (Median=4.46ug; Range=0.13-30.0ug). This raises the question of how realistic meeting the new Adequate Intakes for Vitamin D is, when there is such a low level of Vitamin D fortification in this country. However, participants meeting the Adequate Intake (AI) for Vitamin D were observed to have a significantly higher serum 25(OH)D status compared to those not meeting the AI for Vitamin D (p=0.036), showing that meeting the AI for Vitamin D may play a significant role in determining Vitamin D status in this population. By stratifying our data by categories of outdoor exposure time, a trend was observed between increased importance of Vitamin D dietary intake as a possible determinant of serum 25(OH)D status in participants with lower outdoor exposures.  While a trend towards higher Timed Up and Go scores in participants with higher 25(OH) D status was seen, this was only significant for females (p=0.014). Handgrip strength showed statistically significant association with serum 25(OH)D status. The high serum 25(OH)D status in our sample almost certainly explains the limited relationship between functional measures and serum 25(OH)D. However, the observation of an association between slower Time Up and Go speeds, and lower serum 25(OH)D levels, even with a small sample size, is significant as slower Timed Up and Go speeds have been associated with increased fall risk in older adults3. Multivariable regression analysis revealed Location as the only significant determinant of serum 25(OH)D status at p=0.014, with trends (p=&gt;0.1) for higher serum 25(OH)D being shown for participants that met the AI for Vitamin D and rated themselves as having a higher health status. The results of this exploratory study show that 93.6% of participants had adequate 25(OH)D status-possibly due to measurement being taken in the summer season and the convenience nature of the sample. However, many participants do not meet their dietary Calcium and Vitamin D requirements, which may indicate inadequate intake of these nutrients in older Australians and a higher risk of osteoporosis. The relationship between serum 25(OH)D and functional measures in this population also requires further study, especially in older adults displaying Vitamin D insufficiency or deficiency.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">vitamin D, serum 25-hydroxyviatmin D (25(OH)D), calcium, muscle strength, functional measures, handgrip strength, timed up and go test, food frequency questionnaire, sun exposure questionnaire</field><field name="identifier">http://eprints.qut.edu.au/26359/</field><field name="validLink">True</field></doc><doc><field name="title">Water uptake of aerosols with a focus on seeded aerosols and instrumentation techniques</field><field name="creator">Meyer, Nicholas Karl</field><field name="description">This thesis focuses on the volatile and hygroscopic properties of mixed aerosol species. In particular, the influence organic species of varying solubility have upon seed aerosols. Aerosol studies were conducted at the Paul Scherrer Institut Laboratory for Atmospheric Chemistry (PSI-LAC, Villigen, Switzerland) and at the Queensland University of Technology International Laboratory for Air Quality and Health (QUT-ILAQH, Brisbane, Australia). The primary measurement tool employed in this program was the Volatilisation and Hygroscopicity Tandem Differential Mobility Analyser (VHTDMA - Johnson et al. 2004). This system was initially developed at QUT within the ILAQH and was completely re-developed as part of this project (see Section 1.4 for a description of this process). The new VHTDMA was deployed to the PSI-LAC where an analysis of the volatile and hygroscopic properties of ammonium sulphate seeds coated with organic species formed from the photo-oxidation of &#225;-pinene was conducted. This investigation was driven by a desire to understand the influence of atmospherically prevalent organics upon water uptake by material with cloud forming capabilities. Of particular note from this campaign were observed influences of partially soluble organic coatings upon inorganic ammonium sulphate seeds above and below their deliquescence relative humidity (DRH). Above the DRH of the seed increasing the volume fraction of the organic component was shown to reduce the water uptake of the mixed particle. Below the DRH the organic was shown to activate the water uptake of the seed. This was the first time this effect had been observed for &#225;-pinene derived SOA. In contrast with the simulated aerosols generated at the PSI-LAC a case study of the volatile and hygroscopic properties of diesel emissions was undertaken. During this stage of the project ternary nucleation was shown, for the first time, to be one of the processes involved in formation of diesel particulate matter. Furthermore, these particles were shown to be coated with a volatile hydrophobic material which prevented the water uptake of the highly hygroscopic material below. This result was a first and indicated that previous studies into the hygroscopicity of diesel emission had erroneously reported the particles to be hydrophobic. Both of these results contradict the previously upheld Zdanovksii-Stokes-Robinson (ZSR) additive rule for water uptake by mixed species. This is an important contribution as it adds to the weight of evidence that limits the validity of this rule.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">aerosol, seeded, SOA, DPM, H-TDMA, VH-TDMA, hygroscopiscity, WSOC, combustion aerosols, organic coatings</field><field name="identifier">http://eprints.qut.edu.au/26361/</field><field name="validLink">True</field></doc><doc><field name="title">Relationships between employees and their nomadic, non-territorial work environment</field><field name="creator">Rho, Jung-Hee (Jenny)</field><field name="description">Recent and current socio-cultural trends are significant factors impacting on how business is conduced and correspondingly, on how work environments are designed. New communication technology is helping to break physical boundaries and change the way and speed of conducting business. One of the main characteristics of these new workplaces is non-permanency wherein the individual employee has no dedicated personally assigned office, work station, or desk. In this non-territorial, nomadic situation, employees undertake their work tasks in a wide variety of work settings inside and outside the office building. Such environments are understood to be must suitable where there is the need for high interaction with others as well as a high level of concentrated, independent work. This thesis reports on a project designed to develop a deeper understanding of the relationships between people (P) and their built environment (E) in the context of everyday work practice in a nomadic and non-territorial work environment. To achieve this, the study focuses on the experiences of employees as they understand them in relation to their work and the designed/ physical work environment. In this sense, the study is qualitative and grounded in nature. It does not assume any previously established theory nor test any presenting hypothesis. Instead it interviews the participants about their situations at work in their workplace, interprets natural interaction and creates a foundation for the development of theory informing workplace design, particularly theory that recognises the human nature of work and the need, as highlighted by several seminal researchers, for a greater understanding of how people manage and adapt in dynamic work environments.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">workplace design, non-territorial work environment, nomadic work environment, employees&#8217; experiences, a sense of control</field><field name="identifier">http://eprints.qut.edu.au/26368/</field><field name="validLink">True</field></doc><doc><field name="title">The place of writing in first grade Kuwaiti english education : a sociological case study</field><field name="creator">Mohammad, Elham A. A.</field><field name="description">A hybridized society, Kuwait meshes Islamic ideologies with western culture. Linguistically, English exists across both foreign language and second language nomenclatures in the country due to globalization and internationalization which has seen increasing use of English in Kuwait. Originally consisting of listening, speaking, reading and writing, the first grade English curriculum in Kuwait was narrowed in 2002 to focus only on the development of oral English skills, and to exclude writing. Since that time, both Kuwaiti teachers and parents have expressed dissatisfaction with this curriculum on the basis that this model disadvantages their children. In first grade however, the teaching of pre-writing has remained as part of the curriculum. This research analyses the parameters of English pre-writing and writing instruction in first grade in Kuwaiti classrooms, investigates first grade English pre-writing and writing teaching, and gathers insights from parents, teachers and students regarding the appropriateness of the current curriculum. Through interviews and classroom observations, and an analysis of curriculum documents, this case study found that the relationship between oral and written language is more complex than suggested by either the Kuwaiti curriculum reform, or international literature concerning the delayed teaching of writing. Intended curriculum integration across Kuwait subjects is also far more complex than first believed, due to a developmental mismatch between English pre-writing skills and Arabic language capabilities. Findings suggest an alternative approach to teaching writing may be more appropriate and more effective for first Grade students in the current Kuwait curriculum context. They contribute also to an emerging interest in the second and foreign language fields in the teaching of writing to young learners.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Young EFL learners, english as a foreign language, writing skills in EFL, discourse, Kuwait</field><field name="identifier">http://eprints.qut.edu.au/26369/</field><field name="validLink">True</field></doc><doc><field name="title">The exploration of consumer power in online brand communities : a comparison case study in Australia and China</field><field name="creator">Zhang, Jie (Olivia)</field><field name="description">Aided by the development of information technology, the balance of power in the market place is rapidly shifting from marketers towards consumers and nowhere is this more obvious than in the online environment (Denegri-Knott, Zwick, &amp; Schroeder, 2006; Moynagh &amp; Worsley, 2002; Newcomer, 2000; Samli, 2001). From the inception and continuous development of the Internet, consumers are becoming more empowered. They can choose what they want to click on the Internet, they can shop and transact payments, watch and download video, chat with others, be it friends or even total strangers. Especially in online communities, like-minded consumers share and exchange information, ideas and opinions. One form of online community is the online brand community, which gathers specific brand lovers. As with any social unit, people form different roles in the community and exert different effects on each other. Their interaction online can greatly influence the brand and marketers. A comprehensive understanding of the operation of this special group form is essential to advancing marketing thought and practice (Kozinets, 1999). While online communities have strongly shifted the balance of power from marketers to consumers, the current marketing literature is sparse on power theory (Merlo, Whitwell, &amp; Lukas, 2004). Some studies have been conducted from an economic point of view (Smith, 1987), however their application to marketing has been limited. Denegri-Knott (2006) explored power based on the struggle between consumers and marketers online and identified consumer power formats such as control over the relationship, information, aggregation and participation. Her study has built a foundation for future power studies in the online environment. This research project bridges the limited marketing literature on power theory with the growing recognition of online communities among marketing academics and practitioners. Specifically, this study extends and redefines consumer power by exploring the concept of power in online brand communities, in order to better understand power structure and distribution in this context. This research investigates the applicability of the factors of consumer power identified by Denegri-Knott (2006) to the online brand community. In addition, by acknowledging the model proposed by McAlexander, Schouten, &amp; Koenig (2002), which emphasized that community study should focus on the role of consumers and identifying multiple relationships among the community, this research further explores how member role changes will affect power relationships as well as consumer likings of the brand. As a further extension to the literature, this study also considers cultural differences and their effect on community member roles and power structure. Based on the study of Hofstede (1980), Australia and China were chosen as two distinct samples to represent differences in two cultural dimensions, namely individualism verses collectivism and high power distance verses low power distance. This contribution to the research also helps answer the research gap identified by Mu&#241;iz Jr &amp; O'Guinn (2001), who pointed out the lack of cross cultural studies within the online brand community context. This research adopts a case study methodology to investigate the issues identified above. Case study is an appropriate research strategy to answer &#8220;how&#8221; and &#8220;why&#8221; questions of a contemporary phenomenon in real-life context (Yin, 2003). The online brand communities of &#8220;Haloforum.net&#8221; in Australia and &#8220;NGA.cn&#8221; in China were selected as two cases. In-depth interviews were used as the primary data collection method. As a result of the geographical dispersion and the preference of a certain number of participants, online synchronic interviews via MSN messenger were utilized along with the face-to-face interviews. As a supplementary approach, online observation was carried over two months, covering a two week period prior to the interviews and a six week period following the interviews. Triangulation techniques were used to strengthen the credibility and validity of the research findings (Yin, 2003). The findings of this research study suggest a new definition of power in an online brand community. This research also redefines the consumer power types and broadens the brand community model developed by McAlexander et al. (2002) in an online context by extending the various relationships between brand and members. This presents a more complete picture of how the perceived power relationships are structured in the online brand community. A new member role is discovered in the Australian online brand community in addition to the four member roles identified by Kozinets (1999), in contrast however, all four roles do not exist in the Chinese online brand community. The research proposes a model which links the defined power types and identified member roles. Furthermore, given the results of the cross-cultural comparison between Australia and China showed certain discrepancies, the research suggests that power studies in the online brand community should be country-specific. This research contributes to the body of knowledge on online consumer power, by applying it to the context of an online brand community, as well as considering factors such as cross cultural difference. Importantly, it provides insights for marketing practitioners on how to best leverage consumer power to serve brand objective in online brand communities. This, in turn, should lead to more cost effective and successful communication strategies. Finally, the study proposes future research directions. The research should be extended to communities of different sizes, to different extents of marketer control over the community, to the connection between online and offline activities within the brand community, and (given the cross-cultural findings) to different countries. In addition, a greater amount of research in this area is recommended to determine the generalizability of this study.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">consumer power, online brand community, relationship marketing</field><field name="identifier">http://eprints.qut.edu.au/26373/</field><field name="validLink">True</field></doc><doc><field name="title">The synthesis and application of novel profluorescent nitroxides as probes for polymer degradation</field><field name="creator">Blinco, James Peter</field><field name="description">This PhD project has expanded the knowledge in the area of profluorescent nitroxides with regard to the synthesis and characterisations of novel profluorescent nitroxide probes as well as physical characterisation of the probe molecules in various polymer/physical environments. The synthesis of the first example of an azaphenalene-based fused aromatic nitroxide TMAO, [1,1,3,3-tetramethyl-2,3-dihydro-2-azaphenalen-2-yloxyl, was described. This novel nitroxide possesses some of the structural rigidity of the isoindoline class of nitroxides, as well as some properties akin to TEMPO nitroxides. Additionally, the integral aromatic ring imparts fluorescence that is switched on by radical scavenging reactions of the nitroxide, which makes it a sensitive probe for polymer degradation. In addition to the parent TMAO, 5 other azaphenalene derivatives were successfully synthesised. This new class of nitroxide was expected to have interesting redox properties when the structure was investigated by high-level ab initio molecular orbitals theory. This was expected to have implications with biological relevance as the calculated redox potentials for the azaphenalene ring class would make them potent antioxidant compounds. The redox potentials of 25 cyclic nitroxides from four different structural classes (pyrroline, piperidine, isoindoline and azaphenalene) were determined by cyclic voltammetry in acetonitrile. It was shown that potentials related to the one electron processes of the nitroxide were influenced by the type of ring system, ring substituents or groups surrounding the moiety. Favourable comparisons were found between theoretical and experimental potentials for pyrroline, piperidine and isoindoline ring classes. Substitution of these ring classes, were correctly calculated to have a small yet predictable effect on the potentials. The redox potentials of the azaphenalene ring class were underestimated by the calculations in all cases by at least a factor of two. This is believed to be due to another process influencing the redox potentials of the azaphenalene ring class which is not taken into account by the theoretical model.  It was also possible to demonstrate the use of both azaphenalene and isoindoline nitroxides as additives for monitoring radical mediated damage that occurs in polypropylene as well as in more commercially relevant polyester resins. Polymer sample doped with nitroxide were exposed to both thermo-and photo-oxidative conditions with all nitroxides showing a protective effect. It was found that isoindoline nitroxides were able to indicate radical formation in polypropylene aged at elevated temperatures via fluorescence build-up. The azaphenalene nitroxide TMAO showed no such build-up of fluorescence. This was believed to be due to the more labile bond between the nitroxide and macromolecule and the protection may occur through a classical Denisov cycle, as is expected for commercially available HAS units. Finally, A new profluorescent dinitroxide, BTMIOA (9,10-bis(1,1,3,3- tetramethylisoindolin-2-yloxyl-5-yl)anthracene), was synthesised and shown to be a powerful probe for detecting changes during the initial stages of thermo-oxidative degradation of polypropylene. This probe, which contains a 9,10-diphenylanthracene core linked to two nitroxides, possesses strongly suppressed fluorescence due to quenching by the two nitroxide groups. This molecule also showed the greatest protective effect on thermo-oxidativly aged polypropylene. Most importantly, BTMIOA was found to be a valuable tool for imaging and mapping free-radical generation in polypropylene using fluorescence microscopy.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">azaphenalene, cyclic voltammetry, fluorescence, fluorophore, free radical, hydroxylamine, isoindoline, nitroxide, oxidation, oxoammonium, paramagnetic, polymer degradation, polypropylene, photo-oxidation, profluorescent, thermooxidation, redox.</field><field name="identifier">http://eprints.qut.edu.au/26376/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation into the barriers to the implementation of automation and robotics technologies in the construction industry</field><field name="creator">Mahbub, Rohana</field><field name="description">The rising problems associated with construction such as decreasing quality and productivity, labour shortages, occupational safety, and inferior working conditions have opened the possibility of more revolutionary solutions within the industry. One prospective option is in the implementation of innovative technologies such as automation and robotics, which has the potential to improve the industry in terms of productivity, safety and quality. The construction work site could, theoretically, be contained in a safer environment, with more efficient execution of the work, greater consistency of the outcome and higher level of control over the production process. By identifying the barriers to construction automation and robotics implementation in construction, and investigating ways in which to overcome them, contributions could be made in terms of better understanding and facilitating, where relevant, greater use of these technologies in the construction industry so as to promote its efficiency. This research aims to ascertain and explain the barriers to construction automation and robotics implementation by exploring and establishing the relationship between characteristics of the construction industry and attributes of existing construction automation and robotics technologies to level of usage and implementation in three selected countries; Japan, Australia and Malaysia. These three countries were chosen as their construction industry characteristics provide contrast in terms of culture, gross domestic product, technology application, organisational structure and labour policies. This research uses a mixed method approach of gathering data, both quantitative and qualitative, by employing a questionnaire survey and an interview schedule; using a wide range of sample from management through to on-site users, working in a range of small (less than AUD0.2million) to large companies (more than AUD500million), and involved in a broad range of business types and construction sectors.  Detailed quantitative (statistical) and qualitative (content) data analysis is performed to provide a set of descriptions, relationships, and differences. The statistical tests selected for use include cross-tabulations, bivariate and multivariate analysis for investigating possible relationships between variables; and Kruskal-Wallis and Mann Whitney U test of independent samples for hypothesis testing and inferring the research sample to the construction industry population. Findings and conclusions arising from the research work which include the ranking schemes produced for four key areas of, the construction attributes on level of usage; barrier variables; differing levels of usage between countries; and future trends, have established a number of potential areas that could impact the level of implementation both globally and for individual countries.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">automation, robotics, mechanisation, construction industry, barriers, construction operations, construction process, implementation, Japan, Australia, Malaysia</field><field name="identifier">http://eprints.qut.edu.au/26377/</field><field name="validLink">True</field></doc><doc><field name="title">Teacher-child relationship quality for young children with parent reported language concerns</field><field name="creator">Hand, Kirstine Alicia</field><field name="description">Previous research has demonstrated the importance of the qualities of the teacher-child relationship on children&#8217;s development.  Close teacher-child relationships are especially important for children at risk. Positive relationships have been shown to have beneficial effects on children&#8217;s social and academic development (Birch &amp; Ladd, 1997; Pianta &amp; Stuhlman, 2004).  Children with language difficulties are likely to face increased risks with regard to long term social and academic outcomes.  The purpose of the current research was to gain greater understanding of the qualities of teacher-child relationships for young children with parent reported language concerns.
 The research analyses completed for this thesis involved the use of data from the public-access database of Growing Up in Australia: The Longitudinal Study of Australian Children (LSAC).  LSAC is a longitudinal study involving a nationally representative sample of 10,000 Australian children. Data are being collected biennially from 2004 (Wave 1 data collection) until 2010 (Wave 4 data collection).  LSAC has a cross-sequential research design involving two cohorts, an infant cohort (0-1 year at age of recruitment) and a kindergarten cohort (4-5 years at age of recruitment).  Two studies are reported in this thesis using data for the LSAC Kindergarten Cohort which had 4983 child participants at recruitment.
 Study 1 used Wave 1 data to identify the differences between teacher-child relationship qualities for children with parent reported language concerns and their peers.  Children identified by parents for whom concerns were held about their receptive and expressive language, as measured by items from the Parents&#8217; Evaluation of Developmental Status (PEDS) (Glascoe, 2000) were the target (at risk) group in the study (n = 210).  A matched case control group of peers (n = 210), matched on the child characteristics of sex, age, cultural and linguistic differences (CALD), and socio-economic positioning (SEP), were the comparison group for this analysis.  Teacher-child relationship quality was measured by teacher reports on the Closeness and Conflict scales from the short version of the Student-Teacher Relationship Scale (STRS) (Pianta, 2001). There were statistically significant differences in the levels of closeness and conflict between the two groups.  The target group had relationships with their teachers that had lower levels of closeness and higher levels of conflict than the control group.
 Study 2 reports analyses that examined the stability of the qualities of the teacher-child relationships at Wave 1 (4-5 years) and the qualities of the teacher-child relationships at Wave 2 (6-7 years). This time frame crosses the period of the children&#8217;s transition to school. The study examined whether early patterns in the qualities of the teacher-child relationship for children with parent reported language concerns at Wave 1 predicted the qualities of the teacher-child relationship outcomes in the early years of formal school.  The sample for this study consisted of the group of children identified with PEDS language concerns at Wave 1 who also had teacher report data at Wave 2 (n = 145).  Teacher-child relationship quality at Wave 1 and Wave 2 was again measured by the STRS scales of Closeness and Conflict. 
 Results from multiple regression models indicated that teacher-child relationship quality at Wave 1 significantly contributed to the prediction of the quality of the teacher-child relationship at Wave 2, beyond other predictor variables included in the regression models. Specifically, Wave 1 STRS Closeness scores were the most significant predictor for STRS Closeness scores at Wave 2, while Wave 1 STRS Conflict scores were the only significant predictor for Wave 2 STRS Conflict outcomes.  These results indicate that the qualities of the teacher-child relationship experienced prior to school by children with parent reported language concerns remained stable across transitions into formal schooling at which time the child had a different teacher.
 The results of these studies provide valuable insight into the nature of teacher-child relationship quality for young children with parent reported language concerns.  These children experienced teacher-child relationships of a lower quality when compared with peers and, additionally, the qualities of these relationships prior to formal schooling were predictive of the qualities of the relationships in the early years of formal schooling.  This raises concerns, given the increased risks of poorer social and academic outcomes already faced by children with language difficulties, that these early teacher-child relationships have an impact on future teacher-child relationships. Results of these studies are discussed with these considerations in mind and also discussed in terms of the implications for educational theory, policy and practice.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">teacher-child relationships, young children, language skills</field><field name="identifier">http://eprints.qut.edu.au/26379/</field><field name="validLink">True</field></doc><doc><field name="title">Investigating erythemal UV exposure and vitamin D production in the urban canyon</field><field name="creator">McKinley, Alex R.</field><field name="description">Exposure to ultraviolet radiation (UV) results in both damaging and beneficial health outcomes.  Excessive UV exposure has been linked to many skin and eye problems, but moderate exposure induces vitamin D production.  It has been reported that humans receive 90-95% of their vitamin D from production that starts after UV exposure.  Although it is possible to acquire vitamin D through dietary supplementation, the average person receives very little in this manner.  Therefore, since most people acquire their vitamin D from synthesis after exposure to UV from sunlight, it is very important to understand the different environments in which people encounter UV.
	This project measured UV radiation and in-vitro vitamin D production in the urban canyon and at a nearby suburban location.  The urban canyon is an environment consisting of tall buildings and tropospheric air pollution, which have an attenuating effect on UV. Typically, UV measurements are collected in areas outside the urban canyon, meaning that at times studies and public recommendations do not accurately represent the amount of UV reaching street-level in highly urbanized areas.  Understanding of UV exposure in urban canyons becomes increasingly important as the number of people working and living in large cities steadily increases worldwide.
	This study was conducted in the central business district (CBD) of Brisbane, Australia, which models the urban canyons of large cities around the world in that it boasts a great number of tall buildings, including many skyscrapers, meaning that most areas only see a small amount of direct sunlight each day.  During the winter of 2007 measurements of UV radiation and in-vitro vitamin D production were collected in the CBD and at a suburban site approximately 2.5km outside the CBD.  Air pollution data was obtained from a central CBD measurement site.  Data analysis showed that urban canyon measurements of both UV radiation and in-vitro vitamin D production were significantly lower than those collected at the suburban site.  These results will aid both future researchers and policy makers in better understanding human UV exposure in Brisbane&#8217;s CBD and other urban canyons around the world.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">human health, sun, urban canyon, UV, vitamin D</field><field name="identifier">http://eprints.qut.edu.au/26381/</field><field name="validLink">True</field></doc><doc><field name="title">Experience of problem-based learning (PBL) in virtual space : a phenomenographical study</field><field name="creator">Gibbings, Peter</field><field name="description">This thesis reports the outcomes of an investigation into students&#8217; experience of Problem-based learning (PBL) in virtual space.  PBL is increasingly being used in many fields including engineering education.  At the same time many engineering education providers are turning to online distance education.  Unfortunately there is a dearth of research into what constitutes an effective learning experience for adult learners who undertake PBL instruction through online distance education.  Research was therefore focussed on discovering the qualitatively different ways that students experience PBL in virtual space.
 
 Data was collected in an electronic environment from a course, which adopted the PBL strategy and was delivered entirely in virtual space.  Students in this course were asked to respond to open-ended questions designed to elicit their learning experience in the course.  Data was analysed using the phenomenographical approach.  This interpretative research method concentrated on mapping the qualitative differences in students&#8217; interpretations of their experience in the course.  Five qualitatively different ways of experiencing were discovered: Conception 1: &#8216;A necessary evil for program progression&#8217;; Conception 2: &#8216;Developing skills to understand, evaluate, and solve technical Engineering and Surveying problems&#8217;; Conception 3: &#8216;Developing skills to work effectively in teams in virtual space&#8217;; Conception 4: &#8216;A unique approach to learning how to learn&#8217;; Conception 5: &#8216;Enhancing personal growth&#8217;.
 
 Each conception reveals variation in how students attend to learning by PBL in virtual space.  Results indicate that the design of students&#8217; online learning experience was responsible for making students aware of deeper ways of experiencing PBL in virtual space.  Results also suggest that the quality and quantity of interaction with the team facilitator may have a significant impact on the student experience in virtual PBL courses.  The outcomes imply pedagogical strategies can be devised for shifting students&#8217; focus as they engage in the virtual PBL experience to effectively manage the student learning experience and thereby ensure that they gain maximum benefit.
 
 The results from this research hold important ramifications for graduates with respect to their ease of transition into professional work as well as their later professional competence in terms of problem solving, ability to transfer basic knowledge to real-life engineering scenarios, ability to adapt to changes and apply knowledge in unusual situations, ability to think critically and creatively, and a commitment to continuous life-long learning and self-improvement.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">problem based learning (PBL), distance education, online learning</field><field name="identifier">http://eprints.qut.edu.au/26423/</field><field name="validLink">True</field></doc><doc><field name="title">The effects of habitat fragmentation on the demography and population genetic structure of Uromys Caudimaculatus</field><field name="creator">Streatfeild, Craig Anthony</field><field name="description">Habitat fragmentation can have an impact on a wide variety of biological processes including abundance, life history strategies, mating system, inbreeding and genetic diversity levels of individual species. Although fragmented populations have received much attention, ecological and genetic responses of species to fragmentation have still not been fully resolved. The current study investigated the ecological factors that may influence the demographic and genetic structure of the giant white-tailed rat (Uromys caudimaculatus) within fragmented tropical rainforests. It is the first study to examine relationships between food resources, vegetation attributes and Uromys demography in a quantitative manner. Giant white-tailed rat densities were strongly correlated with specific suites of food resources rather than forest structure or other factors linked to fragmentation (i.e. fragment size). Several demographic parameters including the density of resident adults and juvenile recruitment showed similar patterns. Although data were limited, high quality food resources appear to initiate breeding in female Uromys. Where data were sufficient, influx of juveniles was significantly related to the density of high quality food resources that had fallen in the previous three months. Thus, availability of high quality food resources appear to be more important than either vegetation structure or fragment size in influencing giant white-tailed rat demography. These results support the suggestion that a species&#8217; response to fragmentation can be related to their specific habitat requirements and can vary in response to local ecological conditions. In contrast to demographic data, genetic data revealed a significant negative effect of habitat fragmentation on genetic diversity and effective population size in U. caudimaculatus. All three fragments showed lower levels of allelic richness, number of private alleles and expected heterozygosity compared with the unfragmented continuous rainforest site. Populations at all sites were significantly differentiated, suggesting restricted among population gene flow. The combined effects of reduced genetic diversity, lower effective population size and restricted gene flow suggest that long-term viability of small fragmented populations may be at risk, unless effective management is employed in the future.  A diverse range of genetic reproductive behaviours and sex-biased dispersal patterns were evident within U. caudimaculatus populations. Genetic paternity analyses revealed that the major mating system in U. caudimaculatus appeared to be polygyny at sites P1, P3 and C1. Evidence of genetic monogamy, however, was also found in the three fragmented sites, and was the dominant mating system in the remaining low density, small fragment (P2). High variability in reproductive skew and reproductive success was also found but was less pronounced when only resident Uromys were considered. Male body condition predicted which males sired offspring, however, neither body condition nor heterozygosity levels were accurate predictors of the number of offspring assigned to individual males or females. Genetic spatial autocorrelation analyses provided evidence for increased philopatry among females at site P1, but increased philopatry among males at site P3. This suggests that male-biased dispersal occurs at site P1 and female-biased dispersal at site P3, implying that in addition to mating systems, Uromys may also be able to adjust their dispersal behaviour to suit local ecological conditions. This study highlights the importance of examining the mechanisms that underlie population-level responses to habitat fragmentation using a combined ecological and genetic approach. The ecological data suggested that habitat quality (i.e. high quality food resources) rather than habitat quantity (i.e. fragment size) was relatively more important in influencing giant white-tailed rat demographics, at least for the populations studied here . Conversely, genetic data showed strong evidence that Uromys populations were affected adversely by habitat fragmentation and that management of isolated populations may be required for long-term viability of populations within isolated rainforest fragments.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">fragmentation, Uromys caudimaculatus, demography, microsatellite, genetic differentiation, assignment tests, genetic diversity, bottlenecks, effective population size, genetic autocorrelation, sex-biased dispersal, mating system</field><field name="identifier">http://eprints.qut.edu.au/26424/</field><field name="validLink">True</field></doc><doc><field name="title">Effective web service discovery using a combination of a semantic model and a data mining technique</field><field name="creator">Bose, Aishwarya</field><field name="description">With the advent of Service Oriented Architecture, Web Services have gained tremendous popularity. Due to the availability of a large number of Web services, finding an appropriate Web service according to the requirement of the user is a challenge. This warrants the need to establish an effective and reliable process of Web service discovery. A considerable body of research has emerged to develop methods to improve the accuracy of Web service discovery to match the best service. The process of Web service discovery results in suggesting many individual services that partially fulfil the user&#8217;s interest. By considering the semantic relationships of words used in describing the services as well as the use of input and output parameters can lead to accurate Web service discovery. Appropriate linking of individual matched services should fully satisfy the requirements which the user is looking for. This research proposes to integrate a semantic model and a data mining technique to enhance the accuracy of Web service discovery. A novel three-phase Web service discovery methodology has been proposed. The first phase performs match-making to find semantically similar Web services for a user query. In order to perform semantic analysis on the content present in the Web service description language document, the support-based latent semantic kernel is constructed using an innovative concept of binning and merging on the large quantity of text documents covering diverse areas of domain of knowledge. The use of a generic latent semantic kernel constructed with a large number of terms helps to find the hidden meaning of the query terms which otherwise could not be found. Sometimes a single Web service is unable to fully satisfy the requirement of the user. In such cases, a composition of multiple inter-related Web services is presented to the user. The task of checking the possibility of linking multiple Web services is done in the second phase. Once the feasibility of linking Web services is checked, the objective is to provide the user with the best composition of Web services. In the link analysis phase, the Web services are modelled as nodes of a graph and an allpair shortest-path algorithm is applied to find the optimum path at the minimum cost for traversal. The third phase which is the system integration, integrates the results from the preceding two phases by using an original fusion algorithm in the fusion engine. Finally, the recommendation engine which is an integral part of the system integration phase makes the final recommendations including individual and composite Web services to the user. In order to evaluate the performance of the proposed method, extensive experimentation has been performed. Results of the proposed support-based semantic kernel method of Web service discovery are compared with the results of the standard keyword-based information-retrieval method and a clustering-based machine-learning method of Web service discovery. The proposed method outperforms both information-retrieval and machine-learning based methods. Experimental results and statistical analysis also show that the best Web services compositions are obtained by considering 10 to 15 Web services that are found in phase-I for linking. Empirical results also ascertain that the fusion engine boosts the accuracy of Web service discovery by combining the inputs from both the semantic analysis (phase-I) and the link analysis (phase-II) in a systematic fashion. Overall, the accuracy of Web service discovery with the proposed method shows a significant improvement over traditional discovery methods.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">web service discovery, latent semantic kernel, support based kernel, link analysis, data mining</field><field name="identifier">http://eprints.qut.edu.au/26425/</field><field name="validLink">True</field></doc><doc><field name="title">Being ethical : how process drama assists pre-service drama teachers to reflect on professional ethics</field><field name="creator">Hogan, Sharon</field><field name="description">This research thesis focuses on the experiences of pre-service drama teachers and considers how process drama may assist them to reflect on key aspects of professional ethics such as mandatory codes or standards, principled moral reasoning, moral character, moral agency, and moral literacy. Research from higher education provides evidence that current pedagogical approaches used to prepare pre &#8211;professionals for practice in medicine, engineering, accountancy, business, psychology, counselling, nursing and education, rarely address the more holistic or affective dimensions of professional ethics such as moral character. Process drama, a form of educational drama, is a complex improvisational group experience that invites participants to create and assume roles, and select and manage symbols in order to create a fictional world exploring human experience. Many practitioners claim that process drama offers an aesthetic space to develop a deeper understanding of self and situations, expanding the participant&#8217;s consciousness and ways of knowing. However, little research has been conducted into the potential efficacy of process drama in professional ethics education for pre-professionals. This study utilizes practitioner research and case study to explore how process drama may contribute to the development of professional ethics education and pedagogy.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">drama education, process drama, professional ethics, professional ethics education, virtue and character, moral agency, moral literacy</field><field name="subject">Queensland College of Teachers (QCT), Queensland Studies Authority (QSA), Queensland Core Skills Test (QCS)</field><field name="identifier">http://eprints.qut.edu.au/26436/</field><field name="validLink">True</field></doc><doc><field name="title">Peer to peer English/Chinese cross-language information retrieval</field><field name="creator">Lu, Chengye</field><field name="description">Peer to peer systems have been widely used in the internet. However, most of the peer to peer information systems are still missing some of the important features, for example cross-language IR (Information Retrieval) and collection selection / fusion features. Cross-language IR is the state-of-art research area in IR research community. It has not been used in any real world IR systems yet. Cross-language IR has the ability to issue a query in one language and receive documents in other languages. In typical peer to peer environment, users are from multiple countries. Their collections are definitely in multiple languages. Cross-language IR can help users to find documents more easily. E.g. many Chinese researchers will search research papers in both Chinese and English. With Cross-language IR, they can do one query in Chinese and get documents in two languages. The Out Of Vocabulary (OOV) problem is one of the key research areas in crosslanguage information retrieval. In recent years, web mining was shown to be one of the effective approaches to solving this problem. However, how to extract Multiword Lexical Units (MLUs) from the web content and how to select the correct translations from the extracted candidate MLUs are still two difficult problems in web mining based automated translation approaches. Discovering resource descriptions and merging results obtained from remote search engines are two key issues in distributed information retrieval studies. In uncooperative environments, query-based sampling and normalized-score based merging strategies are well-known approaches to solve such problems. However, such approaches only consider the content of the remote database but do not consider the retrieval performance of the remote search engine. This thesis presents research on building a peer to peer IR system with crosslanguage IR and advance collection profiling technique for fusion features. Particularly, this thesis first presents a new Chinese term measurement and new Chinese MLU extraction process that works well on small corpora. An approach to selection of MLUs in a more accurate manner is also presented. After that, this thesis proposes a collection profiling strategy which can discover not only collection content but also retrieval performance of the remote search engine. Based on collection profiling, a web-based query classification method and two collection fusion approaches are developed and presented in this thesis. Our experiments show that the proposed strategies are effective in merging results in uncooperative peer to peer environments. Here, an uncooperative environment is defined as each peer in the system is autonomous. Peer like to share documents but they do not share collection statistics. This environment is a typical peer to peer IR environment. Finally, all those approaches are grouped together to build up a secure peer to peer multilingual IR system that cooperates through X.509 and email system.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">peer to peer system, distributed information retrieval, security, cross-language information retrieval, query translation, out of vocabulary problem, translation disambiguation, collection fusion, collection profiling</field><field name="identifier">http://eprints.qut.edu.au/26444/</field><field name="validLink">True</field></doc><doc><field name="title">Not like my mother : truth and the author in creative nonfiction</field><field name="creator">Alagic, Azra</field><field name="description">This exegesis examines how a writer can effectively negotiate the relationship between author, character, fact and truth, in a work of Creative Nonfiction. It was found that individual truths, in a work of Creative Nonfiction, are not necessarily universal truths due to individual, cultural, historical and religious circumstances. What was also identified, through the examination of published Creative Nonfiction, is a necessity to ensure there are clear demarcation lines between authorial truth and fiction. The Creative Nonfiction works examined, which established this framework for the reader, ensured an ethical relationship between author and audience. These strategies and frameworks were then applied to my own Creative Nonfiction.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">creative nonfiction, new journalism, truth, fact, narrative satisfaction, authorial truth, ethics, Balkans, war, Yugoslavia.</field><field name="identifier">http://eprints.qut.edu.au/26446/</field><field name="validLink">True</field></doc><doc><field name="title">Negotiating social and moral order in internet relay chat</field><field name="creator">Lawson, Danielle</field><field name="description">Although internet chat is a significant aspect of many internet users&#8217; lives, the manner in which participants in quasi-synchronous chat situations orient to issues of social and moral order remains to be studied in depth. The research presented here is therefore at the forefront of a continually developing area of study. This work contributes new insights into how members construct and make accountable the social and moral orders of an adult-oriented Internet Relay Chat (IRC) channel by addressing three questions: (1) What conversational resources do participants use in addressing matters of social and moral order? (2) How are these conversational resources deployed within IRC interaction? and (3) What interactional work is locally accomplished through use of these resources? 
 
 A survey of the literature reveals considerable research in the field of computer-mediated communication, exploring both asynchronous and quasi-synchronous discussion forums. The research discussed represents a range of communication interests including group and collaborative interaction, the linguistic construction of social identity, and the linguistic features of online interaction. It is suggested that the present research differs from previous studies in three ways: (1) it focuses on the interaction itself, rather than the ways in which the medium affects the interaction; (2) it offers turn-by-turn analysis of interaction in situ; and (3) it discusses membership categories only insofar as they are shown to be relevant by participants through their talk. Through consideration of the literature, the present study is firmly situated within the broader computer-mediated communication field.
 
 Ethnomethodology, conversation analysis and membership categorization analysis were adopted as appropriate methodological approaches to explore the research focus on interaction in situ, and in particular to investigate the ways in which participants negotiate and co-construct social and moral orders in the course of their interaction.  
 IRC logs collected from one chat room were analysed using a two-pass method, based on a modification of the approaches proposed by Pomerantz and Fehr (1997) and ten Have (1999). From this detailed examination of the data corpus three interaction topics are identified by means of which participants clearly orient to issues of social and moral order: challenges to rule violations, &#8216;trolling&#8217; for cybersex, and experiences regarding the 9/11 attacks. Instances of these interactional topics are subjected to fine-grained analysis, to demonstrate the ways in which participants draw upon various interactional resources in their negotiation and construction of channel social and moral orders. While these analytical topics stand alone in individual focus, together they illustrate different instances in which participants&#8217; talk serves to negotiate social and moral orders or collaboratively construct new orders.
 
 Building on the work of Vallis (2001), Chapter 5 illustrates three ways that rule violation is initiated as a channel discussion topic: (1) through a visible violation in open channel, (2) through an official warning or sanction by a channel operator regarding the violation, and (3) through a complaint or announcement of a rule violation by a non-channel operator participant. Once the topic has been initiated, it is shown to become available as a topic for others, including the perceived violator. The fine-grained analysis of challenges to rule violations ultimately demonstrates that channel participants orient to the rules as a resource in developing categorizations of both the rule violation and violator. These categorizations are contextual in that they are locally based and understood within specific contexts and practices. Thus, it is shown that compliance with rules and an orientation to rule violations as inappropriate within the social and moral orders of the channel serves two purposes: (1) to orient the speaker as a group member, and (2) to reinforce the social and moral orders of the group. 
 
 Chapter 6 explores a particular type of rule violation, solicitations for &#8216;cybersex&#8217; known in IRC parlance as &#8216;trolling&#8217;. In responding to trolling violations participants are demonstrated to use affiliative and aggressive humour, in particular irony, sarcasm and insults. These conversational resources perform solidarity building within the group, positioning non-Troll respondents as compliant group members. This solidarity work is shown to have three outcomes: (1) consensus building, (2) collaborative construction of group membership, and (3) the continued construction and negotiation of existing social and moral orders.
 
 Chapter 7, the final data analysis chapter, offers insight into how participants, in discussing the events of 9/11 on the actual day, collaboratively constructed new social and moral orders, while orienting to issues of appropriate and reasonable emotional responses. This analysis demonstrates how participants go about &#8216;doing being ordinary&#8217; (Sacks, 1992b) in formulating their &#8216;first thoughts&#8217; (Jefferson, 2004). Through sharing their initial impressions of the event, participants perform support work within the interaction, in essence working to normalize both the event and their initial misinterpretation of it. Normalising as a support work mechanism is also shown in relation to participants constructing the &#8216;quiet&#8217; following the event as unusual. Normalising is accomplished by reference to the indexical &#8216;it&#8217; and location formulations, which participants use both to negotiate who can claim to experience the &#8216;unnatural quiet&#8217; and to identify the extent of the quiet. Through their talk participants upgrade the quiet from something legitimately experienced by one person in a particular place to something that could be experienced &#8216;anywhere&#8217;, moving the phenomenon from local to global provenance.
 
 With its methodological design and detailed analysis and findings, this research contributes to existing knowledge in four ways. First, it shows how rules are used by participants as a resource in negotiating and constructing social and moral orders. Second, it demonstrates that irony, sarcasm and insults are three devices of humour which can be used to perform solidarity work and reinforce existing social and moral orders. Third, it demonstrates how new social and moral orders are collaboratively constructed in relation to extraordinary events, which serve to frame the event and evoke reasonable responses for participants. And last, the detailed analysis and findings further support the use of conversation analysis and membership categorization as valuable methods for approaching quasi-synchronous computer-mediated communication.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">internet relay chat, conversation analysis, membership categorization analysis, social order, moral order, rules, 9/11</field><field name="identifier">http://eprints.qut.edu.au/26515/</field><field name="validLink">True</field></doc><doc><field name="title">Electronic workplace surveillance and employee privacy : a comparative analysis of privacy protection in Australia and the United States</field><field name="creator">Watt, James Robert</field><field name="description">More than a century ago in their definitive work &#8220;The Right to Privacy&#8221; Samuel D. Warren and Louis D. Brandeis highlighted the challenges posed to individual privacy by advancing technology. Today&#8217;s workplace is characterised by its reliance on computer technology, particularly the use of email and the Internet to perform critical business functions. Increasingly these and other workplace activities are the focus of monitoring by employers.
 
 There is little formal regulation of electronic monitoring in Australian or United States workplaces. Without reasonable limits or controls, this has the potential to adversely affect employees&#8217; privacy rights. 
 
 Australia has a history of legislating to protect privacy rights, whereas the United States has relied on a combination of constitutional guarantees, federal and state statutes, and the common law. This thesis examines a number of existing and proposed statutory and other workplace privacy laws in Australia and the United States. 
 
 The analysis demonstrates that existing measures fail to adequately regulate monitoring or provide employees with suitable remedies where unjustifiable intrusions occur. The thesis ultimately supports the view that enacting uniform legislation at the national level provides a more effective and comprehensive solution for both employers and employees. 
 
 Chapter One provides a general introduction and briefly discusses issues relevant to electronic monitoring in the workplace. Chapter Two contains an overview of privacy law as it relates to electronic monitoring in Australian and United States workplaces. In Chapter Three there is an examination of the complaint process and remedies available to a hypothetical employee (Mary) who is concerned about protecting her privacy rights at work. Chapter Four provides an analysis of the major themes emerging from the research, and also discusses the draft national uniform legislation. Chapter Five details the proposed legislation in the form of the Workplace Surveillance and Monitoring Act, and Chapter Six contains the conclusion.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">workplace privacy, employee privacy rights, electronic monitoring, workplace surveillance, video surveillance, Internet and email monitoring, Privacy Act, information privacy, Fourth Amendment, Intrusion Upon Seclusion, technology and privacy</field><field name="subject">privacy tort, reasonable expectation of privacy, invasion of privacy, workplace privacy legislation</field><field name="identifier">http://eprints.qut.edu.au/26536/</field><field name="validLink">True</field></doc><doc><field name="title">Ex vivo investigation of novel wound healing therapies and development of a 3-D human skin equivalent wound model</field><field name="creator">Xie, Yan</field><field name="description">It has previously been found that complexes comprised of vitronectin and growth factors (VN:GF) enhance keratinocyte protein synthesis and migration. More specifically, these complexes have been shown to significantly enhance the migration of dermal keratinocytes derived from human skin. In view of this, it was thought that these complexes may hold potential as a novel therapy for healing chronic wounds. However, there was no evidence indicating that the VN:GF complexes would retain their effect on keratinocytes in the presence of chronic wound fluid. The studies in this thesis demonstrate for the first time that the VN:GF complexes not only stimulate proliferation and migration of keratinocytes, but also these effects are maintained in the presence of chronic wound fluid in a 2-dimensional (2-D) cell culture model. Whilst the 2-D culture system provided insights into how the cells might respond to the VN:GF complexes, this investigative approach is not ideal as skin is a 3-dimensional (3-D) tissue. In view of this, a 3-D human skin equivalent (HSE) model, which reflects more closely the in vivo environment, was used to test the VN:GF complexes on epidermopoiesis. These studies revealed that the VN:GF complexes enable keratinocytes to migrate, proliferate and differentiate on a de-epidermalised dermis (DED), ultimately forming a fully stratified epidermis. In addition, fibroblasts were seeded on DED and shown to migrate into the DED in the presence of the VN:GF complexes and hyaluronic acid, another important biological factor in the wound healing cascade. This HSE model was then further developed to enable studies examining the potential of the VN:GF complexes in epidermal wound healing. Specifically, a reproducible partial-thickness HSE wound model was created in fully-defined media and monitored as it healed. In this situation, the VN:GF complexes were shown to significantly enhance keratinocyte migration and proliferation, as well as differentiation. This model was also subsequently utilized to assess the wound healing potential of a synthetic fibrin-like gel that had previously been demonstrated to bind growth factors. Of note, keratinocyte re-epitheliasation was shown to be markedly improved in the presence of this 3-D matrix, highlighting its future potential for use as a delivery vehicle for the VN:GF complexes. Furthermore, this synthetic fibrin-like gel was injected into a 4 mm diameter full-thickness wound created in the HSE, both keratinocytes and fibroblasts were shown to migrate into this gel, as revealed by immunofluorescence. Interestingly, keratinocyte migration into this matrix was found to be dependent upon the presence of the fibroblasts. Taken together, these data indicate that reproducible wounds, as created in the HSEs, provide a relevant ex vivo tool to assess potential wound healing therapies. Moreover, the models will decrease our reliance on animals for scientific experimentation. Additionally, it is clear that these models will significantly assist in the development of novel treatments, such as the VN:GF complexes and the synthetic fibrin-like gel described herein, ultimately facilitating their clinical trial in the treatment of chronic wounds.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">chronic, differentiation, fibroblasts, growth factors, healing, hyaluronic acid, keratinocytes, migration, proliferation, skin, skin equivalent model, synthetic fibrin-like gel, vitronectin, wound healing</field><field name="identifier">http://eprints.qut.edu.au/26541/</field><field name="validLink">True</field></doc><doc><field name="title">Increased body temperature following subarachnoid haemorrhage : a retrospective correlational study</field><field name="creator">Clarke, Samantha A.</field><field name="description">Introduction:  Nursing clinicians are primarily responsible for the monitoring and treatment of increased body temperature.  The body temperature of patients during their acute care hospital stay is measured at regular repeated intervals.  In the event a patient is assessed with an elevated temperature, a multitude of decisions are required.  The action of instigating temperature reducing strategies is based upon the assumption that elevated temperature is harmful and that the strategy employed will have some beneficial effect.
 Background and Significance:  The potential harmful effects of increased body temperature (fever, hyperthermia) following neurological insult are well recognised.  Although few studies have investigated this phenomenon in the diagnostic population of non-traumatic subarachnoid haemorrhage, it has been demonstrated that increased body temperature occurs in 41 to 72% of patients with poor clinical outcome.  However, in the Australian context the frequency, or other characteristics of increased body temperature, as well as the association between increased body temperature with poor clinical outcome has not been established.
 Design:  This study used a correlational study design to:   describe the frequency, duration and timing of increased body temperature; determine the association between increased body temperature and clinical outcome; and describe the clinical interventions used to manage increased body temperature in patients with non-traumatic subarachnoid haemorrhage.  A retrospective clinical chart audit was conducted on 43 patients who met the inclusion criteria.
 Findings:  The major findings of this study were:  increased body temperature occurred frequently; persisted for a long time; and onset did not occur until 20 hours after primary insult; increased body temperature was associated with death or dependent outcome; and no intervention was recorded in many instances.  
 Conclusion:  This study has quantified in a non-traumatic subarachnoid haemorrhage patient population the characteristics of increased body temperature, established an association between increased body temperature with death or dependent outcome and described the current management of elevated temperatures in the Australian context to improve nursing practice, education and research.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">subarachnoid haemorrhage, increased body temperature, fever, hyperthermia</field><field name="identifier">http://eprints.qut.edu.au/26542/</field><field name="validLink">True</field></doc><doc><field name="title">Public knowledge beyond journalism : infotainment, satire and Australian television</field><field name="creator">Harrington, Stephen Matthew</field><field name="description">This thesis examines the changing relationships between television, politics, audiences and the public sphere. Premised on the notion that mediated politics is now understood &#8220;in new ways by new voices&#8221; (Jones, 2005: 4), and appropriating what McNair (2003) calls a &#8220;chaos theory&#8221; of journalism sociology, this thesis explores how two different contemporary Australian political television programs (Sunrise and The Chaser&#8217;s War on Everything) are viewed, understood, and used by audiences. In analysing these programs from textual, industry and audience perspectives, this thesis argues that journalism has been largely thought about in overly simplistic binary terms which have failed to reflect the reality of audiences&#8217; news consumption patterns. The findings of this thesis suggest that both &#8216;soft&#8217; infotainment (Sunrise) and &#8216;frivolous&#8217; satire (The Chaser&#8217;s War on Everything) are used by audiences in intricate ways as sources of political information, and thus these TV programs (and those like them) should be seen as legitimate and valuable forms of public knowledge production. It therefore might be more worthwhile for scholars to think about, research and teach journalism in the plural: as a series of complementary or antagonistic journalisms, rather than as a single coherent entity.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">news, journalism, television, politics, public sphere, media audiences, breakfast television, satire, cultural chaos, intertextuality, televisual sphere, Sunrise, The Chaser, The Daily Show, media ethnography</field><field name="identifier">http://eprints.qut.edu.au/26675/</field><field name="validLink">True</field></doc><doc><field name="title">Passive control of a bi-ventricular assist device : an experimental and numerical investigation</field><field name="creator">Gaddum, Nicholas Richard</field><field name="description">For the last two decades heart disease has been the highest single cause of death for the human population. With an alarming number of patients requiring heart transplant, and donations not able to satisfy the demand, treatment looks to mechanical alternatives. Rotary Ventricular Assist Devices, VADs, are miniature pumps which can be implanted alongside the heart to assist its pumping function. These constant flow devices are smaller, more efficient and promise a longer operational life than more traditional pulsatile VADs. The development of rotary VADs has focused on single pumps assisting the left ventricle only to supply blood for the body. In many patients however, failure of both ventricles demands that an additional pulsatile device be used to support the failing right ventricle. This condition renders them hospital bound while they wait for an unlikely heart donation. Reported attempts to use two rotary pumps to support both ventricles concurrently have warned of inherent haemodynamic instability. Poor balancing of the pumps&#8217; flow rates quickly leads to vascular congestion increasing the risk of oedema and ventricular &#8216;suckdown&#8217; occluding the inlet to the pump. This thesis introduces a novel Bi-Ventricular Assist Device (BiVAD) configuration where the pump outputs are passively balanced by vascular pressure. The BiVAD consists of two rotary pumps straddling the mechanical passive controller. Fluctuations in vascular pressure induce small deflections within both pumps adjusting their outputs allowing them to maintain arterial pressure. To optimise the passive controller&#8217;s interaction with the circulation, the controller&#8217;s dynamic response is optimised with a spring, mass, damper arrangement. This two part study presents a comprehensive assessment of the prototype&#8217;s &#8216;viability&#8217; as a support device. Its &#8216;viability&#8217; was considered based on its sensitivity to pathogenic haemodynamics and the ability of the passive response to maintain healthy circulation.  The first part of the study is an experimental investigation where a prototype device was designed and built, and then tested in a pulsatile mock circulation loop. The BiVAD was subjected to a range of haemodynamic imbalances as well as a dynamic analysis to assess the functionality of the mechanical damper. The second part introduces the development of a numerical program to simulate human circulation supported by the passively controlled BiVAD. Both investigations showed that the prototype was able to mimic the native baroreceptor response. Simulating hypertension, poor flow balancing and subsequent ventricular failure during BiVAD support allowed the passive controller&#8217;s response to be assessed. Triggered by the resulting pressure imbalance, the controller responded by passively adjusting the VAD outputs in order to maintain healthy arterial pressures. This baroreceptor-like response demonstrated the inherent stability of the auto regulating BiVAD prototype. Simulating pulmonary hypertension in the more observable numerical model, however, revealed a serious issue with the passive response. The subsequent decrease in venous return into the left heart went unnoticed by the passive controller. Meanwhile the coupled nature of the passive response not only decreased RVAD output to reduce pulmonary arterial pressure, but it also increased LVAD output. Consequently, the LVAD increased fluid evacuation from the left ventricle, LV, and so actually accelerated the onset of LV collapse. It was concluded that despite the inherently stable baroreceptor-like response of the passive controller, its lack of sensitivity to venous return made it unviable in its present configuration. The study revealed a number of other important findings. Perhaps the most significant was that the reduced pulse experienced during constant flow support unbalanced the ratio of effective resistances of both vascular circuits. Even during steady rotary support therefore, the resulting ventricle volume imbalance increased the likelihood of suckdown. Additionally, mechanical damping of the passive controller&#8217;s response successfully filtered out pressure fluctuations from residual ventricular function. Finally, the importance of recognising inertial contributions to blood flow in the atria and ventricles in a numerical simulation were highlighted. This thesis documents the first attempt to create a fully auto regulated rotary cardiac assist device. Initial results encourage development of an inlet configuration sensitive to low flow such as collapsible inlet cannulae. Combining this with the existing baroreceptor-like response of the passive controller will render a highly stable passively controlled BiVAD configuration. The prototype controller&#8217;s passive interaction with the vasculature is a significant step towards a highly stable new generation of artificial heart.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">passive control, bi-ventricular assist device, baroreceptor response, venous return, numerical simulation, rotary pump design</field><field name="identifier">http://eprints.qut.edu.au/26936/</field><field name="validLink">True</field></doc><doc><field name="title">Quality-based benefit design in health insurance : the impact of a product benefit design change on the utilisation of oral health services by members of a private health insurance fund in regional and rural New South Wales, Australia</field><field name="creator">Larkin, Shaun Maurice</field><field name="description">Objective: To examine the impact on dental utilisation following the introduction of a participating provider scheme (Regional and Rural Oral Health Program {RROHP)). In this model dentists receive higher third party payments from a private health insurance fund for delivering an agreed range of preventive and diagnostic benefits at no out-ofpocket cost to insured patients. Data source/Study setting: Hospitals Contribution Fund of Australia (HCF) dental claims for all members resident in New South Wales over the six financial years from l99811999 to 200312004. Study design: This cohort study involves before and after analyses of dental claims experience over a six year period for approximately 81,000 individuals in the intervention group (HCF members resident in regional and rural New South Wales, Australia) and 267,000 in the control group (HCF members resident in the Sydney area). Only claims for individuals who were members of HCF at 31 December 1997 were included. The analysis groups claims into the three years prior to the establishment of the RROHP and the three years subsequent to implementation. Data collection/Extraction methods: The analysis is based on all claims submitted by users of services for visits between 1 July 1988 and 30 June 2004. In these data approximately 1,000,000 services were provided to the intervention group and approximately 4,900,000 in the control group. Principal findings: Using Statistical Process Control (SPC) charts, special cause variation was identified in total utilisation rate of private dental services in the intervention group post implementation. No such variation was present in the control group. On average in the three years after implementation of the program the utilisation rate of dental services by regional and rural residents of New South Wales who where members of HCF grew by 12.6%, over eight times the growth rate of 1.5% observed in the control group (HCF members who were Sydney residents). The differences were even more pronounced in the areas of service that were the focus of the program: diagnostic and preventive services. 
 
 Conclusion: The implementation of a benefit design change, a participating provider scheme, that involved the removal of CO-payments on a defined range of preventive and diagnostic dental services combined with the establishment and promotion of a network of dentists, appears to have had a marked impact on HCF members' utilisation of dental services in regional and rural New South Wales, Australia.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">health insurance, dental economics, preventive health services, health promotion, oral health</field><field name="identifier">http://eprints.qut.edu.au/26735/</field><field name="validLink">True</field></doc><doc><field name="title">Abstracting and correlating heterogeneous events to detect complex scenarios</field><field name="creator">Panichprecha, Sorot</field><field name="description">The research presented in this thesis addresses inherent problems in signaturebased intrusion detection systems (IDSs) operating in heterogeneous environments. The research proposes a solution to address the difficulties associated with multistep attack scenario specification and detection for such environments. The research has focused on two distinct problems: the representation of events derived from heterogeneous sources and multi-step attack specification and detection. The first part of the research investigates the application of an event abstraction model to event logs collected from a heterogeneous environment. The event abstraction model comprises a hierarchy of events derived from different log sources such as system audit data, application logs, captured network traffic, and intrusion detection system alerts. Unlike existing event abstraction models where low-level information may be discarded during the abstraction process, the event abstraction model presented in this work preserves all low-level information as well as providing high-level information in the form of abstract events. The event abstraction model presented in this work was designed independently of any particular IDS and thus may be used by any IDS, intrusion forensic tools, or monitoring tools. The second part of the research investigates the use of unification for multi-step attack scenario specification and detection. Multi-step attack scenarios are hard to specify and detect as they often involve the correlation of events from multiple sources which may be affected by time uncertainty. The unification algorithm provides a simple and straightforward scenario matching mechanism by using variable instantiation where variables represent events as defined in the event abstraction model. The third part of the research looks into the solution to address time uncertainty. Clock synchronisation is crucial for detecting multi-step attack scenarios which involve logs from multiple hosts. Issues involving time uncertainty have been largely neglected by intrusion detection research. The system presented in this research introduces two techniques for addressing time uncertainty issues: clock skew compensation and clock drift modelling using linear regression. An off-line IDS prototype for detecting multi-step attacks has been implemented. The prototype comprises two modules: implementation of the abstract event system architecture (AESA) and of the scenario detection module. The scenario detection module implements our signature language developed based on the Python programming language syntax and the unification-based scenario detection engine. The prototype has been evaluated using a publicly available dataset of real attack traffic and event logs and a synthetic dataset. The distinct features of the public dataset are the fact that it contains multi-step attacks which involve multiple hosts with clock skew and clock drift. These features allow us to demonstrate the application and the advantages of the contributions of this research. All instances of multi-step attacks in the dataset have been correctly identified even though there exists a significant clock skew and drift in the dataset. Future work identified by this research would be to develop a refined unification algorithm suitable for processing streams of events to enable an on-line detection. In terms of time uncertainty, identified future work would be to develop mechanisms which allows automatic clock skew and clock drift identification and correction. The immediate application of the research presented in this thesis is the framework of an off-line IDS which processes events from heterogeneous sources using abstraction and which can detect multi-step attack scenarios which may involve time uncertainty.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">intrusion detection, signature-based intrusion detection, event correlation, event abstraction, time uncertainty, multi-step attack detection, unification</field><field name="identifier">http://eprints.qut.edu.au/26737/</field><field name="validLink">True</field></doc><doc><field name="title">Aging in China and its impact on vehicle design</field><field name="creator">Zhao, Chao</field><field name="description">This study contributes to the growth of design knowledge in China, where vehicle design for the local, older user is in its initial developmental stages. Therefore, this research has explored the travel needs of older Chinese vehicle users in order to assist designers to better understand users&#8217; current and future needs. A triangulation method consisting of interviews, logbook and co-discovery was used to collect multiple forms of data and so explore the research question. Grounded theory has been employed to analyze the research data. This study found that users&#8217; needs are reflected through various &#8216;meanings&#8217; that they attach to vehicles &#8211; meanings that give a tangible expression to their experiences. This study identified six older-user need categories: (i) safety, (ii) utility, (iii) comfort, (iv) identity, (v) emotion and (vi) spirituality. The interrelationships among these six categories are seen as an interactive structure, rather than as a linear or hierarchical arrangement. Chinese cultural values, which are generated from particular local context and users&#8217; social practice, will play a dynamic role in linking and shaping the travel needs of older vehicle users in the future. Moreover, this study structures the older-user needs model into three levels of meaning, to give guidance to vehicle design direction: (i) the practical meaning level, (ii) the social meaning level and (ii) the cultural meaning level. This study suggests that a more comprehensive explanation exists if designers can identify the vehicle&#8217;s meaning and property associated with the fulfilled older users&#8217; needs. However, these needs will vary, and must be related to particular technological, social, and cultural contexts. The significance of this study lies in its contributions to the body of knowledge in three areas: research methodology, theory and design. These theoretical contributions provide a series of methodological tools, models and approaches from a vehicle design perspective. These include a conditional/consequential matrix, a travel needs identification model, an older users&#8217; travel-related needs framework, a user information structure model, and an Older-User-Need-Based vehicle design approach. These models suggest a basic framework  for the new design process which might assist in the design of new vehicles to fulfil the needs of future, aging Chinese generations. The models have the potential to be transferred to other design domains and different cultural contexts.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Chinese culture, context, cultural meaning, dynamic user needs structure, future younger-old vehicle users, integrated vehicle design approach, older vehicle users, practical meaning, social meaning, travel needs, vehicle design, vehicle meaning</field><field name="identifier">http://eprints.qut.edu.au/26962/</field><field name="validLink">True</field></doc><doc><field name="title">Documentary practice in a participatory culture</field><field name="creator">Tarrant, Patrick Anthony</field><field name="description">Debates concerning the veracity, ethics and politics of the documentary form circle endlessly around the function of those who participate in it, and the meaning attributed to their participation. Great significance is attached to the way that documentary filmmakers do or do not participate in the world they seek to represent, just as great significance is attached to those subjects whose participation extends beyond playing the part of eyewitness or expert, such that they become part of the very filmmaking process itself.
 
 This Ph.D. explores the interface between documentary practice and participatory culture by looking at how their practices, discursive fields and histories intersect, but also by looking at how participating in one might mean participating in the other. In short, the research is an examination of participatory culture through the lens of documentary practice and documentary criticism. In the process, however, this examination of participatory culture will in turn shed light on documentary thinking, especially the meaning and function of &#8216;the participant&#8217; in contemporary documentary practice. 
 
 A number of ways of conceiving of participation in documentary practice are discussed in this research, but one of the ideas that gives purpose to that investigation is the notion that the participant in contemporary documentary practice is someone who belongs to a participatory culture in particular. Not only does this mean that those subjects who play a part in a documentary are already informed by their engagement with a range of everyday media practices before the documentary apparatus arrives, the audience for such films are similarly informed and engaged. This audience have their own expectations about how they should be addressed by media producers in general, a fact that feeds back into their expectations about participatory approaches to documentary practice too.
 
 It is the ambition of this research to get closer to understanding the relationship between participants in the audience, in documentary and ancillary media texts, as well as behind the camera, and to think about how these relationships constitute a context for the production and reception of documentary films, but also how this context might provide a model for thinking about participatory culture itself. 
 
 One way that documentary practice and participatory culture converge in this research is in the kind of participatory documentary that I call the &#8216;Camera Movie&#8217;, a narrow mode of documentary filmmaking that appeals directly to contemporary audiences&#8217; desires for innovation and participation, something that is achieved in this case by giving documentary subjects control of the camera. If there is a certain inevitability about this research having to contend with the notion of the &#8216;participatory documentary&#8217;, the &#8216;participatory camera&#8217; also emerges strongly in this context, especially as a conduit between producer and consumer. 
 
 Making up the creative component of this research are two documentaries about the reality television event Band In A Bubble, and participatory media practices more broadly. The single-screen film, Hubbub , gives form to the collective intelligence and polyphonous voice of contemporary audiences who must be addressed and solicited in increasingly innovative ways. One More Like That  is a split-screen, DVD-Video with alternate audio channels selected by a user who thereby chooses who listens and who speaks in the ongoing conversation between media producers and media consumers. 
 
 It should be clear from the description above that my own practice does not extend to highly interactive, multi-authored or web-enabled practices, nor the distributed practices one might associate with social media and online collaboration. Mine is fundamentally a single authored, documentary video practice that seeks to analyse and represent participatory culture on screen, and for this reason the Ph.D. refrains from a sustained discussion of the kinds of collaborative practices listed above. This is not to say that such practices don&#8217;t also represent an important intersection of documentary practice and participatory culture, they simply represent a different point of intersection. Being practice-led, this research takes its procedural cues from the nature of the practice itself, and sketches parameters that are most enabling of the idea that the practice sets the terms of its own investigation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">documentary practice, documentary criticism, film studies, participatory culture, metaculture, practice based research, media audiences, reception studies, media convergence, new media, found footage filmmaking, music culture, reality television</field><field name="identifier">http://eprints.qut.edu.au/26975/</field><field name="validLink">True</field></doc><doc><field name="title">Certainties and uncertainties : ethics and professional identities of early childhood educators</field><field name="creator">Thomas, Louise M.</field><field name="description">This study is an inquiry into the professional identity constructions of early childhood educators, where identity is conceptualised as social and contextual.  Through a genealogical analysis of narratives of four Queensland early childhood teachers, the thesis renders as problematic universal and fixed notions of what it is to be an early childhood professional.  The data are the four teachers&#8217; professional life history narratives recounted through a series of conversational interviews with each participant.  As they spoke about professionalism and ethics, these teachers struggled to locate themselves as professionals, as they drew on a number of dominant discourses available to them.  These dominant discourses were located and mapped through analysis of the participants&#8217; talk about relationships with parents, colleagues and authorities.  Genealogical analysis enabled multiple readings of the ways in which the participants&#8217; talk held together certainties and uncertainties, as they recounted their experiences and spoke of early childhood expertise, relational engagement and ethics.  The thesis concludes with suggestions for ways to support early childhood teachers and pre-service teachers to both engage with and resist normative processes and expectations of professional identity construction. In so doing, multiple and contextual opportunities can be made available when it comes to being professional and &#8216;doing&#8217; ethics.  The thesis makes an argument for new possibilities for thinking and speaking professional identities that include both certainty and uncertainty, comfort and discomfort, and these seemingly oppositional terms are held together in tension, with an insistence that both are necessary and true.  The use of provocations offers tools through which pre-service teachers, teachers and teacher educators can access new positions associated with certainties and uncertainties in professional identities.  These new positions call for work that supports experiences of &#8216;de-comfort&#8217; &#8211; that is, experiences that encourage early childhood educators to step away from the comfort zones that can become part of expertise, professional relationships and ethics embedded within normative representations of what it is to be an early childhood professional.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">identity, certainty, uncertainty, professional, ethics, early childhood education, teacher</field><field name="identifier">http://eprints.qut.edu.au/27648/</field><field name="validLink">True</field></doc><doc><field name="title">New insights into rebound effects : theory and empirical evidence</field><field name="creator">Murray, Cameron Keith</field><field name="description">The main objective of the thesis is to seek insights into the theory, and provide empirical evidence of rebound effects.  Rebound effects reduce the environmental benefits of environmental policies and household behaviour changes.  In particular, win-win demand side measures, in the form of energy efficiency and household consumption pattern changes, are seen as ways for households and businesses to save money and the environment.  However, these savings have environmental impacts when spent, which are known as rebound effects.  This is an area that has been widely neglected by policy makers.  
 
 This work extends the rebound effect literature in three important ways, (1) it incorporates the potential for variation of rebound effects with household income level, (2) it enables the isolation of direct and indirect effects for cases of energy efficient technology adoption, and examines the relationship between these two component effects, and (3) it expands the scope of rebound effect analysis to include government taxes and subsidies.  
 MACROBUTTON HTMLDirect 
 Using a case study approach it is found that the rebound effect from household consumption pattern changes targeted at electricity is between 5 and 10%.  For consumption pattern changes with reduced vehicle fuel use, the rebound effect is in the order of 20 to 30%.  Higher income households in general are found to have a lower total rebound effect; however the indirect effect becomes relatively more significant at higher household income levels.  In the win-lose case of domestic photovoltaic electricity generation, it is demonstrated that negative rebound effects can occur, which can potentially amplify the environmental benefits of this action. 
 
 The rebound effect from a carbon tax, which occurs due to the re-spending of raised revenues, was found to be in the range of 11-32%.  Taxes and transfers between households of different income levels also have environmental implications.  For example, a more progressive tax structure, with increased low income welfare payments is likely to increase greenhouse gas emissions.  Subsidies aimed at encouraging environmentally friendly consumption habits are also subject to rebound effects, as they constitute a substitution of government expenditure for household expenditure.  For policy makers, these findings point to the need to incorporate rebound effects in the environmental policy evaluation process.&#8217;</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">rebound effect, demand side management, direct rebound effect, indirect rebound effect, greenhouse gas emissions, CO2, household consumption patterns, efficiency, energy, conservation, natural resources</field><field name="identifier">http://eprints.qut.edu.au/27655/</field><field name="validLink">True</field></doc><doc><field name="title">The enactment of the New Basics Project in a special school</field><field name="creator">Gray, Brian</field><field name="description">This study investigates the impact of the New Basics Project on teachers at a special school for students with intellectual impairments. The study is aimed at exploring the complex nature of the work of special educators as they enact the New Basics curriculum with a particular focus on the teachers&#8217; opinions about challenges that arose for their curriculum, pedagogy and assessment practices. Attention is also paid to how the principal&#8217;s leadership supported the enactment of the New Basics in respect to what he did and why he used particular strategies.
 The nine teachers and their principal were involved in a series of in-depth, semi-structured interviews from one of only three special schools in phase one of the New Basics trial in Queensland, Australia. These interviews produced data from the special educators as they were confronted with a new curriculum that challenged their previous teaching practices. The enactment of the New Basics curriculum occurred within the context of a state-sanctioned mandate to provide alternative programs to those offered in mainstream schools, for students with special needs.
 This thesis explores these teachers' experiences using critical theory as a basis for analyzing their opinions on issues such as the role of the special educator, tensions between old and new curricula, pedagogical and assessment practices, and connections between the at-school learning experiences for intellectually impaired students and the realities of post-school life. The investigation also examines the leadership conduct of the principal in changing times at the school.
 The findings suggest that the New Basics has played a significant role in providing structures for developing communities of practice amongst teachers; in supporting special educators to focus more on the educational needs of the students (e.g., literacy, numeracy, financial planning) and less on their medical needs (e.g., toileting, feeding, personal hygiene); and supporting school leadership that empowers and listens critically to teachers as essential components of the successful enactment of curriculum reforms like the New Basics.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">special education, new basics, critical pedagogy, school reform, leadership</field><field name="identifier">http://eprints.qut.edu.au/27658/</field><field name="validLink">True</field></doc><doc><field name="title">Improvements in sustainable energy and water practice in the food processing industry : an in depth analysis of the manufacture of Ghee at the Butter Producers' Cooperative Federation Limited, Brisbane</field><field name="creator">Markwell, Darryl</field><field name="description">This thesis is a documented energy audit and long term study of energy and water reduction in a ghee factory. Global production of ghee exceeds 4 million tonnes annually. The factory in this study refines dairy products by non-traditional centrifugal separation and produces 99.9% pure, canned, crystallised Anhydrous Milk Fat (Ghee). Ghee is traditionally made by batch processing methods. The traditional method is less efficient, than centrifugal separation.
 
 An in depth systematic investigation was conducted of each item of major equipment including; ammonia refrigeration, a steam boiler, canning equipment, pumps, heat exchangers and compressed air were all fine-tuned. Continuous monitoring of electrical usage showed that not every initiative worked, others had pay back periods of less than a year. In 1994-95 energy consumption was 6,582GJ and in 2003-04 it was 5,552GJ down 16% for a similar output. 
 
 A significant reduction in water usage was achieved by reducing the airflow in the refrigeration evaporative condensers to match the refrigeration load. Water usage has fallen 68% from18ML in 1994-95 to 5.78ML in 2003-04.
 
 The methods reported in this thesis could be applied to other industries, which have similar equipment, and other ghee manufacturers.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">sustainable energy, water, food processing industry, manufacture, Brisbane</field><field name="identifier">http://eprints.qut.edu.au/27661/</field><field name="validLink">True</field></doc><doc><field name="title">Embodied vulnerabilities : responding to violent encounters through installation practices</field><field name="creator">Haynes, Rachael Anne</field><field name="description">This practice-led research was initiated in response to a series of violent encounters that occurred between my fragile installations and viewers. The central focus of this study was to recuperate my installation practice in the wake of such events. This led to the development of a &#8216;responsive practice&#8217; methodology, which reframed the installation process through an ethical lens developed from Emmanuel Levinas&#8217; ethical phenomenology. The central propositions of this research are the reconceptualisation of &#8216;violent encounters&#8217; in terms of difference whereby I accept viewers responses, even those which are violent, destructive or damaging, and secondly that the process operates as a generative excess for practice through which recuperative strategies can be found and implemented. By re-examining this process as it unfolded in the three phases of the practical component, I developed strategies whereby violated, destroyed or damaged works could be recuperated through the processes of reconfiguration, reparation and regeneration. Therefore my installations embody and articulate vulnerability but also demonstrate resilience and renewal.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">installation, ephemeral artworks, destruction and art, paper art, ethical response , responsive practice Eva Hesse , Emmanuel Levinas, Felix Gonzalez-Torres, Sarah Sze</field><field name="identifier">http://eprints.qut.edu.au/27663/</field><field name="validLink">True</field></doc><doc><field name="title">My place through my eyes : a social constructionist approach to researching the relationships between socioeconomic living contexts and physical activity</field><field name="creator">Carroll, Julie-Anne</field><field name="description">There is a growing evidence-base in the epidemiological literature that demonstrates significant associations between people&#8217;s living circumstances &#8211; including their place of residence &#8211; and their health-related practices and outcomes (Leslie, 2005; Karpati, Bassett, &amp; McCord, 2006; Monden, Van Lenthe, &amp; Mackenbach, 2006; Parkes &amp; Kearns, 2006; Cummins, Curtis, Diez-Roux, &amp; Macintyre, 2007; Turrell, Kavanagh, Draper, &amp; Subramanian, 2007). However, these findings raise questions about the ways in which living places, such as households and neighbourhoods, figure in the pathways connecting people and health (Frolich, Potvin, Chabot, &amp; Corin, 2002; Giles-Corti, 2006; Brown et al, 2006; Diez Roux, 2007). This thesis addressed these questions via a mixed methods investigation of the patterns and processes connecting people, place, and their propensity to be physically active. Specifically, the research in this thesis examines a group of lower-socioeconomic residents who had recently relocated from poorer suburbs to a new urban village with a range of health-related resources. Importantly, the study contrasts their historical relationship with physical activity with their reactions to, and everyday practices in, a new urban setting designed to encourage pedestrian mobility and autonomy. The study applies a phenomenological approach to understanding living contexts based on Berger and Luckman&#8217;s (1966) conceptual framework in The Social Construction of Reality. This framework enables a questioning of the concept of context itself, and a treatment of it beyond environmental factors to the processes via which experiences and interactions are made meaningful. This approach makes reference to people&#8217;s histories, habituations, and dispositions in an exploration between social contexts and human behaviour. This framework for thinking about context is used to generate an empirical focus on the ways in which this residential group interacts with various living contexts over time to create a particular construction of physical activity in their lives. A methodological approach suited to this thinking was found in Charmaz&#8217;s (1996; 2001; 2006) adoption of a social constructionist approach to grounded theory. This approach enabled a focus on people&#8217;s own constructions and versions of their experiences through a rigorous inductive method, which provided a systematic strategy for identifying patterns in the data. The findings of the study point to factors such as &#8216;childhood abuse and neglect&#8217;, &#8216;early homelessness&#8217;, &#8216;fear and mistrust&#8217;, &#8216;staying indoors and keeping to yourself&#8217;, &#8216;conflict and violence&#8217;, and &#8216;feeling fat and ugly&#8217; as contributors to an ongoing core category of &#8216;identity management&#8217;, which mediates the relationship between participants&#8217; living contexts and their physical activity levels. It identifies barriers at the individual, neighbourhood, and broader ecological levels that prevent this residential group from being more physically active, and which contribute to the ways in which they think about, or conceptualise, this health-related behaviour in relationship to their identity and sense of place &#8211; both geographic and societal. The challenges of living well and staying active in poorer neighbourhoods and in places where poverty is concentrated were highlighted in detail by participants. Participants&#8217; reactions to the new urban neighbourhood, and the depth of their engagement with the resources present, are revealed in the context of their previous life-experiences with both living places and physical activity. Moreover, an understanding of context as participants&#8217; psychological constructions of various social and living situations based on prior experience, attitudes, and beliefs was formulated with implications for how the relationship between socioeconomic contextual effects on health are studied in the future. More detailed findings are presented in three published papers with implications for health promotion, urban design, and health inequalities research. This thesis makes a substantive, conceptual, and methodological contribution to future research efforts interested in how physical activity is conceptualised and constructed within lower socioeconomic living contexts, and why this is. The data that was collected and analysed for this PhD generates knowledge about the psychosocial processes and mechanisms behind the patterns observed in epidemiological research regarding socioeconomic health inequalities. Further, it highlights the ways in which lower socioeconomic living contexts tend to shape dispositions, attitudes, and lifestyles, ultimately resulting in worse health and life chances for those who occupy them.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">socioeconomic, contexts, physical activity, urban, social constructionism, grounded theory</field><field name="identifier">http://eprints.qut.edu.au/27965/</field><field name="validLink">True</field></doc><doc><field name="title">Truck overloading study in developing countries and strategies to minimize its impact</field><field name="creator">Chan, Ying Chuen (Maple)</field><field name="description">Overloading truck traffic is an untenable problem around the world. The occurrence of overloaded truck traffic can be evidence of rapid development of an economy. Most of the developing countries emphasize the development of economy, thus supporting reform of infrastructure is limited. This research investigates the relationship between truck overloading and the condition of road damage. The objective of this research is to determine the amount of economic loss due to overloaded truck traffic is. Axle load will be used to calculate the total ESAL to pavement. This study intends to provide perspective on the relationship between change in axle load due to overloading and the resultant service life of pavement. It can then be used in the estimation of pavement damage in other developing countries facing the problem of truck overloading. In conclusion, economical loss was found, which include reduction of pavement life and increase in maintenance and rehabilitation (M&amp;R) cost. As a result, net present value (NPV) of pavement investment with overloading truck traffic is higher than normal truck traffic.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">truck overloading, road damage, developing countries, pavement service life</field><field name="identifier">http://eprints.qut.edu.au/28561/</field><field name="validLink">True</field></doc><doc><field name="title">Dopamine and visually regulated eye growth in chick</field><field name="creator">Peng, Chien-Chun</field><field name="description">Retinal image properties such as contrast and spatial frequency play important roles in the development of normal vision. For example, visual environments comprised solely of low contrast and/or low spatial frequencies induce myopia. The visual image is processed by the retina and it then locally controls eye growth. In terms of the retinal neurotransmitters that link visual stimuli to eye growth, there is strong evidence to suggest involvement of the retinal dopamine (DA) system. For example, effectively increasing retinal DA levels by using DA agonists can suppress the development of form-deprivation myopia (FDM). However, whether visual feedback controls eye growth by modulating retinal DA release, and/or some other factors, is still being elucidated. This thesis is chiefly concerned with the relationship between the dopaminergic system and retinal image properties in eye growth control. More specifically, whether the amount of retinal DA release reduces as the complexity of the image degrades was determined. For example, we investigated whether the level of retinal DA release decreased as image contrast decreased. In addition, the effects of spatial frequency, spatial energy distribution slope, and spatial phase on retinal DA release and eye growth were examined. When chicks were 8-days-old, a cone-lens imaging system was applied monocularly (+30 D, 3.3 cm cone). A short-term treatment period (6 hr) and a longer-term treatment period (4.5 days) were used. The short-term treatment tests for the acute reduction in DA release by the visual stimulus, as is seen with diffusers and lenses, whereas the 4.5 day point tests for reduction in DA release after more prolonged exposure to the visual stimulus. In the contrast study, 1.35 cyc/deg square wave grating targets of 95%, 67%, 45%, 12% or 4.2% contrast were used. Blank (0% contrast) targets were included for comparison. In the spatial frequency study, both sine and square wave grating targets with either 0.017 cyc/deg and 0.13 cyc/deg fundamental spatial frequencies and 95% contrast were used. In the spectral slope study, 30% root-mean-squared (RMS) contrast fractal noise targets with spectral fall-off of 1/f0.5, 1/f and 1/f2 were used. In the spatial alignment study, a structured Maltese cross (MX) target, a structured circular patterned (C) target and the scrambled versions of these two targets (SMX and SC) were used. Each treatment group comprised 6 chicks for ocular biometry (refraction and ocular dimension measurement) and 4 for analysis of retinal DA release. Vitreal dihydroxyphenylacetic acid (DOPAC) was analysed through ion-paired reversed phase high performance liquid chromatography with electrochemical detection (HPLC-ED), as a measure of retinal DA release. For the comparison between retinal DA release and eye growth, large reductions in retinal DA release possibly due to the decreased light level inside the cone-lens imaging system were observed across all treated eyes while only those exposed to low contrast, low spatial frequency sine wave grating, 1/f2, C and SC targets had myopic shifts in refraction. Amongst these treatment groups, no acute effect was observed and longer-term effects were only found in the low contrast and 1/f2 groups. These findings suggest that retinal DA release does not causally link visual stimuli properties to eye growth, and these target induced changes in refractive development are not dependent on the level of retinal DA release. Retinal dopaminergic cells might be affected indirectly via other retinal cells that immediately respond to changes in the image contrast of the retinal image.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">dopamine, eye growth, chick</field><field name="identifier">http://eprints.qut.edu.au/28556/</field><field name="validLink">True</field></doc><doc><field name="title">A 'deleterious' effect? : Australian legal education and the production of the legal identity</field><field name="creator">Ball, Matthew J.</field><field name="description">A body of critical legal scholarship argues that, by the time they have completed their studies, students who enter legal education holding social ideals and intending to use their legal education to achieve social change, have become cynical about the ability of the law to do so and no longer possess such ideals.  This is explained by critical scholars to be the result of a process of ideological indoctrination, aimed at ensuring that graduates uphold the narrow and conservative interests of the legal profession and capitalist society, being exercised by law schools acting as adjuncts of the legal profession, and exercised upon the passive body of the law student.
 
 By using Foucault&#8217;s work on knowledge, power, and the subject to interrogate the assumptions upon which this narrative is based, this thesis intends to suggest a way of thinking differently to the approach taken by many critical legal scholars.  It then uses an analytics of government (based on Foucault&#8217;s notion of &#8216;governmentality&#8217;) to consider the construction of the legal identity differently.  It examines the ways in which the governance of the legal identity is rationalised, programmed, and implemented, in three Queensland law schools.  It also looks at the way that five prescriptive texts to &#8216;surviving&#8217; law school suggest students establish and practise a relation to themselves in order to construct their own legal identities.
 
 Overall, this analysis shows that governance is not simply conducted in the profession&#8217;s interests, but occurs due to a complex arrangement of different practices, which can lead to the construction of skilled legal professional identities as well as ethical lawyer-citizens that hold an interest in justice.  The implications of such an analytics provide the basis for original ways of understanding legal education, and legal education scholarship.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">legal education, Australian law schools, Michel Foucault, governmentality, analytics of government, critical legal theory, critical legal narrative, governmental practices, practices of the self, discourse, power, subject, ethics</field><field name="identifier">http://eprints.qut.edu.au/28601/</field><field name="validLink">True</field></doc><doc><field name="title">Recommending best answer in a collaborative question answering system</field><field name="creator">Chen, Lin</field><field name="description">The World Wide Web has become a medium for people to share information. People use Web-based collaborative tools such as question answering (QA) portals, blogs/forums, email and instant messaging to acquire information and to form online-based communities. In an online QA portal, a user asks a question and other users can provide answers based on their knowledge, with the question usually being answered by many users. It can become overwhelming and/or time/resource consuming for a user to read all of the answers provided for a given question. Thus, there exists a need for a mechanism to rank the provided answers so users can focus on only reading good quality answers.  The majority of online QA systems use user feedback to rank users&#8217; answers and the user who asked the question can decide on the best answer. Other users who didn&#8217;t participate in answering the question can also vote to determine the best answer. However, ranking the best answer via this collaborative method is time consuming and requires an ongoing continuous involvement of users to provide the needed feedback. The objective of this research is to discover a way to recommend the best answer as part of a ranked list of answers for a posted question automatically, without the need for user feedback. 
 
 The proposed approach combines both a non-content-based reputation method and a content-based method to solve the problem of recommending the best answer to the user who posted the question. The non-content method assigns a score to each user which reflects the users&#8217; reputation level in using the QA portal system. Each user is assigned two types of non-content-based reputations cores: a local reputation score and a global reputation score. The local reputation score plays an important role in deciding the reputation level of a user for the category in which the question is asked. The global reputation score indicates the prestige of a user across all of the categories in the QA system.
 
 Due to the possibility of user cheating, such as awarding the best answer to a friend regardless of the answer quality, a content-based method for determining the quality of a given answer is proposed, alongside the non-content-based reputation method. Answers for a question from different users are compared with an ideal (or expert) answer using traditional Information Retrieval and Natural Language Processing techniques. Each answer provided for a question is assigned a content score according to how well it matched the ideal answer. 
 
 To evaluate the performance of the proposed methods, each recommended best answer is compared with the best answer determined by one of the most popular link analysis methods, Hyperlink-Induced Topic Search (HITS). The proposed methods are able to yield high accuracy, as shown by correlation scores: Kendall correlation and Spearman correlation. The reputation method outperforms the HITS method in terms of recommending the best answer.  The inclusion of the reputation score with the content score improves the overall performance, which is measured through the use of Top-n match scores.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">authority, collaborative social network, content analysis, link analysis, natural language processing, non-content analysis, online question answering portal, prestige, question answering system, recommending best answer, social network analysis</field><field name="subject">Yahoo! Answers</field><field name="identifier">http://eprints.qut.edu.au/30238/</field><field name="validLink">True</field></doc><doc><field name="title">A study of entrepreneurship : Taiwanese digital content companies in China</field><field name="creator">Chiu, Chihsuan</field><field name="description">China&#8217;s accession to the World Trade Organisation (WTO) has greatly enhanced global interest in investment in the Chinese media market, where demand for digital content is growing rapidly. The East Asian region is positioned as a growth area in many forms of digital content and digital service industries. China is attempting to catch up and take its place as a production centre to offset challenges from neighbouring countries. Meanwhile, Taiwan is seeking to use China both as an export market and as a production site for its digital content. 
 
 This research investigates entry strategies of Taiwanese digital content firms into the Chinese market. By examining the strategies of a sample of Taiwan-based companies, this study also explores the evolution of their market strategies. However, the focus is on how distinctive business practices such as guanxi are important to Taiwanese business and to relations with Mainland China. This research examines how entrepreneurs manage the characteristics of digital content products and in turn how digital content entrepreneurs adapt to changing market circumstances.
 
 This project selected five Taiwan-based digital content companies that have business operations in China: Wang Film, Artkey, CnYES, Somode and iPartment. The study involved a field trip, undertaken between November 2006 and March 2007 to Shanghai and Taiwan to conduct interviews and to gather documentation and archival reports. Six senior managers and nine experts were interviewed. Data were analysed according to Miller&#8217;s firm-level entrepreneurship theory, foreign direct investment theory, Life Cycle Model and guanxi philosophy.
 
 Most studies of SMEs have focused on free market (capitalist) environments. In contrast, this thesis examines how Taiwanese digital content firms&#8217; strategies apply in the Chinese market. I identified three main types of business strategy: cost-reduction, innovation and quality-enhancement; and four categories of functional strategies: product, marketing, resource acquisition and organizational restructuring.
 
 In this study, I introduce the concept of &#8216;entrepreneurial guanxi&#8217;, special relationships that imply mutual obligation, assurance and understanding to secure and exchange favors in entrepreneurial activities. While guanxi is a feature of many studies of business in Pan-Chinese society, it plays an important mediating role in digital content industries.
 
 In this thesis, I integrate the &#8216;Life Cycle Model&#8217; with the dynamic concept of strategy. I outline the significant differences in the evolution of strategy between two types of digital content companies: off-line firms (Wang Film and Artkey) and web-based firms (CnYES, Somode and iPartment). Off-line digital content firms tended to adopt &#8216;resource acquisition strategies&#8217; in their initial stages and &#8216;marketing strategies&#8217; in second and subsequent stages. In contrast, web-based digital content companies mainly adopted product and marketing strategies in the early stages, and would adopt innovative approaches towards product and marketing strategies in the whole process of their business development. Some web-based digital content companies also adopted organizational restructuring strategies in the final stage.
 
 Finally, I propose the &#8216;Taxonomy Matrix of Entrepreneurial Strategies&#8217; to emphasise the two dimensions of this matrix: innovation, and the firm&#8217;s resource acquisition for entrepreneurial strategy. This matrix is divided into four cells: Effective, Bounded, Conservative, and Impoverished.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">foreign direct investment, international entry strategies, entrepreneurship, strategy, digital content industry, Guanxi, Chinese market</field><field name="identifier">http://eprints.qut.edu.au/28386/</field><field name="validLink">True</field></doc><doc><field name="title">The genetic basis of human height : the role of estrogen</field><field name="creator">Carter, Shea L.</field><field name="description">Height is a complex physical trait that displays strong heritability. Adult height is related to length of the long bones, which is determined by growth at the epiphyseal growth plate. Longitudinal bone growth occurs via the process of endochondral ossification, where bone forms over the differentiating cartilage template at the growth plate. Estrogen plays a major role in regulating longitudinal bone growth and is responsible for inducing the pubertal growth spurt and fusion of the epiphyseal growth plate. However, the mechanism by which estrogen promotes epiphyseal fusion is poorly understood. It has been hypothesised that estrogen functions to regulate growth plate fusion by stimulating chondrocyte apoptosis, angiogenesis and bone cell invasion in the growth plate. Another theory has suggested that estrogen exposure exhausts the proliferative capacity of growth plate chondrocytes, which accelerates the process of chondrocyte senescence, leading to growth plate fusion. The overall objective of this study was to gain a greater understanding of the molecular mechanisms behind estrogen-mediated growth and height attainment by examining gene regulation in chondrocytes and the role of some of these genes in normal height inheritance. With the heritability of height so well established, the initial hypothesis was that genetic variation in candidate genes associated with longitudinal bone growth would be involved in normal adult height variation. The height-related genes FGFR3, CBFA1, ER and CBFA1 were screened for novel polymorphisms using denaturing HPLC and RFLP analysis. In total, 24 polymorphisms were identified. Two SNPs in ER (rs3757323 C&gt;T and rs1801132 G&gt;C) were strongly associated with adult male height and displayed an 8 cm and 9 cm height difference between homozygous genotypes, respectively. The TC haplotype of these SNPs was associated with a 6 cm decrease in height and remarkably, no homozygous carriers of the TC haplotype were identified in tall subjects. No significant associations with height were found for polymorphisms in the FGFR3, CBFA1 or VDR genes. In the epiphyseal growth plate, chondrocyte proliferation, matrix synthesis and chondrocyte hypertrophy are all major contributors to long bone growth. As estrogen plays such a significant role in both growth and final height attainment, another hypothesis of this study was that estrogen exerted its effects in the growth plate by influencing chondrocyte proliferation and mediating the expression of chondrocyte marker genes. The examination of genes regulated by estrogen in chondrocyte-like cells aimed to identify potential regulators of growth plate fusion, which may further elucidate mechanisms involved in the cessation of linear growth. While estrogen did not dramatically alter the proliferation of the SW1353 cell line, gene expression experiments identified several estrogen regulated genes. Sixteen chondrocyte marker genes were examined in response to estrogen concentrations ranging from 10-12 M to 10-8 M over varying time points. Of the genes analysed, IHH, FGFR3, collagen II and collagen X were not readily detectable and PTHrP, GHR, ER, BMP6, SOX9 and TGF1 mRNAs showed no significant response to estrogen treatments. However, the expression of MMP13, CBFA1, BCL-2 and BAX genes were significantly decreased. Interestingly, the majority of estrogen regulated genes in SW1353 cells are expressed in the hypertrophic zone of the growth plate. Estrogen is also known to regulate systemic GH secretion and local GH action. At the molecular level, estrogen functions to inhibit GH action by negatively regulating GH signalling. GH treated SW1353 cells displayed increases in MMP9 mRNA expression (4.4-fold) and MMP13 mRNA expression (64-fold) in SW1353 cells. Increases were also detected in their respective proteins. Treatment with AG490, an established JAK2 inhibitor, blocked the GH mediated stimulation of both MMP9 and MMP13 mRNA expression. The application of estrogen and GH to SW1353 cells attenuated GH-stimulated MMP13 levels, but did not affect MMP9 levels. Investigation of GH signalling revealed that SW1353 cells have high levels of activated JAK2 and exposure to GH, estrogen, AG490 and other signalling inhibitors did not affect JAK2 phosphorylation. Interestingly, AG490 treatment dramatically decreased ERK2 signalling, although GH did stimulate ERK2 phosphorylation above control levels. AG490 also decreased CBFA1 expression, a transcription factor known to activate MMP9 and MMP13. Finally, GH and estrogen treatment increased expression of SOCS3 mRNA, suggesting that SOCS3 may regulate JAK/STAT signalling in SW1353 cells. The modulation of GH-mediated MMP expression by estrogen in SW1353 cells represents a potentially novel mechanism by which estrogen may regulate longitudinal bone growth. However, further investigation is required in order to elucidate the precise mechanisms behind estrogen and GH regulation of MMP13 expression in SW1353 cells. This study has provided additional evidence that estrogen and the ER gene are major factors in the regulation of growth and the determination of adult height. Newly identified polymorphisms in the ER gene not only contribute to our understanding of the genetic basis of human height, but may also be useful in association studies examining other complex traits. This study also identified several estrogen regulated genes and indicated that estrogen modifies the expression of genes which are primarily expressed in the hypertrophic region of the epiphyseal growth plate. Furthermore, synergistic studies incorporating GH and estrogen have revealed the ability of estrogen to attenuate the effects of GH on MMP13 expression, revealing potential pathways by which estrogen may modulate growth plate fusion, longitudinal bone growth and even arthritis.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">estrogen, growth hormone, matrix metalloproteinase 13 (MMP13), chondrocytes, height, longitudinal bone growth, epiphyseal growth plate, single nucleotide polymorphism (SNP), chondrosarcoma, osteoarthritis</field><field name="identifier">http://eprints.qut.edu.au/28390/</field><field name="validLink">True</field></doc><doc><field name="title">Mutation frequency of non-ESBL phenotype SENTRY (Asia-Pacific) isolates of Klebsiella pneumoniae conversion to an ESBL positive phenotype</field><field name="creator">Dakh, Farshid</field><field name="description">Extended spectrum &#946;-lactamases or ESBLs, which are derived from non-ESBL precursors by point mutation of &#946;-lactamase genes (bla), are spreading rapidly all over the world and have caused considerable problems in the treatment of infections caused by bacteria which harbour them. The mechanism of this resistance is not fully understood and a better understanding of these mechanisms might significantly impact on choosing proper diagnostic and treatment strategies. Previous work on SHV &#946;-lactamase gene, blaSHV, has shown that only Klebsiella pneumoniae strains which contain plasmid-borne blaSHV are able to mutate to phenotypically ESBL-positive strains and there was also evidence of an increase in blaSHV copy number. Therefore, it was hypothesised that although specific point mutation is essential for acquisition of ESBL activity, it is not yet enough, and blaSHV copy number amplification is also essential for an ESBL-positive phenotype, with homologous recombination being the likely mechanism of blaSHV copy number expansion.  In this study, we investigated the mutation rate of non-ESBL expressing K. pneumoniae isolates to an ESBL-positive status by using the MSS-maximum likelihood method. Our data showed that blaSHV mutation rate of a non-ESBL expressing isolate is lower than the mutation rate of the other single base changes on the chromosome, even with a plasmid-borne blaSHV gene. On the other hand, mutation rate from a low MIC ESBL-positive (&#8804; 8 &#181;g/mL for cefotaxime) to high MIC ESBL-positive (&#8805;16 &#181;g/mL for cefotaxime) is very high. This is because only gene copy number increase is needed which is probably mediated by homologous recombination that typically takes place at a much higher frequencies than point mutations. Using a subinhibitory concentration of novobiocin, as a homologous recombination inhibitor, revealed that this is the case.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">&#946;-lactamase, extended spectrum &#946;-lactamase, ESBL, SENTRY, SHV, blaSHV, IS26, mutation frequency, mutation rate, Klebsiella pneumoniae, real-time PCR, MSS maximum likelihood</field><field name="identifier">http://eprints.qut.edu.au/28413/</field><field name="validLink">True</field></doc><doc><field name="title">"Theatre of the dancing language" : new possibilities in contemporary Australian playwrighting</field><field name="creator">Stewart, Lucy Claire</field><field name="description">This study focuses on trends in contemporary Australian playwrighting, discussing recent investigations into the playwrighting process. The study analyses the current state of this country&#8217;s playwrighting industry, with a particular focus on programming trends since 1998. It seeks to explore the implications of this current theatrical climate, in particular the types of work most commonly being favoured for production. It argues that Australian plays are under-represented (compared to non-Australian plays) on &#8216;mainstream&#8217; stages and that audiences might benefit from more challenging modes of writing than the popular three-act realist play models. The thesis argues that &#8216;New Lyricism&#8217; might fill this position of offering an innovative Australian playwrighting mode. New Lyricism is characterised by a set of common aesthetics, including a non-linear narrative structure, a poetic use of language and magic realism. Several Australian playwrights who have adopted this mode of writing are identified and their works examined. The author&#8217;s play Floodlands is presented as a case study and the author&#8217;s creative process is examined in light of the published critical discussions about experimental playwriting work.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Theatre, playwriting/ playwrighting, New Lyricism, magic realism, history of Australian theatre, contemporary Australian theatre, creative practice as research, playwriting structure, playwriting trends, postdramatic theatre</field><field name="identifier">http://eprints.qut.edu.au/28477/</field><field name="validLink">True</field></doc><doc><field name="title">Downtime reduction analysis of the Australia Post flat mail optical character reader</field><field name="creator">Fox, James P.</field><field name="description">Machine downtime, whether planned or unplanned, is intuitively costly to manufacturing organisations, but is often very difficult to quantify. The available literature showed that costing processes are rarely undertaken within manufacturing organisations. Where cost analyses have been undertaken, they generally have only valued a small proportion of the affected costs, leading to an overly conservative estimate. This thesis aimed to develop a cost of downtime model, with particular emphasis on the application of the model to Australia Post&#8217;s Flat Mail Optical Character Reader (FMOCR). The costing analysis determined a cost of downtime of $5,700,000 per annum, or an average cost of $138 per operational hour.
 
 The second section of this work focused on the use of the cost of downtime to objectively determine areas of opportunity for cost reduction on the FMOCR. This was the first time within Post that maintenance costs were considered along side of downtime for determining machine performance. Because of this, the results of the analysis revealed areas which have historically not been targeted for cost reduction. Further exploratory work was undertaken on the Flats Lift Module (FLM) and Auto Induction Station (AIS) Deceleration Belts through the comparison of the results against two additional FMOCR analysis programs. 
 
 This research has demonstrated the development of a methodical and quantifiable cost of downtime for the FMOCR. This has been the first time that Post has endeavoured to examine the cost of downtime. It is also one of the very few methodologies for valuing downtime costs that has been proposed in literature. The work undertaken has also demonstrated how the cost of downtime can be incorporated into machine performance analysis with specific application to identifying high costs modules. The outcome of this report has both been the methodology for costing downtime, as well as a list of areas for cost reduction. In doing so, this thesis has outlined the two key deliverables presented at the outset of the research.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">Australia post, flat mail optical character reader, large letter sorting, downtime, cost of downtime, maintenance analysis</field><field name="identifier">http://eprints.qut.edu.au/28479/</field><field name="validLink">True</field></doc><doc><field name="title">Cooperative learning in Thailand : professional development to enhance primary education</field><field name="creator">Nuntrakune, Tippawan</field><field name="description">The overall purpose of this study was to develop a model to inform the design of professional development programs and the implementation of cooperative learning within Thai primary school mathematics classrooms. Action research design, with interviews, surveys and observations, was used for this study. Survey questionnaires and classroom observations investigated the factors that influence the implementation of cooperative learning strategies and academic achievement in Thai primary school mathematics classrooms. The teachers&#8217; interviews and classroom observation also examined the factors that need to be addressed in teacher professional development programs in order to facilitate cooperative learning in Thai mathematics classrooms. The outcome of this study was a model consisting of two sets of criteria to inform the successful implementation of cooperative learning in Thai primary schools. The first set of criteria was for proposers and developers of professional development programs. This set consists of macro- and micro-level criteria. The macro-level criteria focus on the overall structure of professional development programs and how and when the professional development programs should be implemented. The micro-level criteria focused on the specific topics that need to be included in professional development programs. The second set of criteria was for Thai principals and teachers to facilitate the introduction of cooperative learning in their classrooms. The research outcome also indicated that the attainment of these cooperative learning strategies and skills had a positive impact on the students&#8217; learning of mathematics.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">cooperative learning, professional development, primary school, Thailand, mathematics.</field><field name="identifier">http://eprints.qut.edu.au/28481/</field><field name="validLink">True</field></doc><doc><field name="title">Seeing is understanding : the effect of visualisation in understanding programming concepts</field><field name="creator">Zagami, Jason Anthony</field><field name="description">How and why visualisations support learning was the subject of this qualitative instrumental collective case study. Five computer programming languages (PHP, Visual Basic, Alice, GameMaker, and RoboLab) supporting differing degrees of visualisation were used as cases to explore the effectiveness of software visualisation to develop fundamental computer programming concepts (sequence, iteration, selection, and modularity). Cognitive theories of visual and auditory processing, cognitive load, and mental models provided a framework in which student cognitive development was tracked and measured by thirty-one 15-17 year old students drawn from a Queensland metropolitan secondary private girls&#8217; school, as active participants in the research. Seventeen findings in three sections increase our understanding of the effects of visualisation on the learning process. The study extended the use of mental model theory to track the learning process, and demonstrated application of student research based metacognitive analysis on individual and peer cognitive development as a means to support research and as an approach to teaching. The findings also forward an explanation for failures in previous software visualisation studies, in particular the study has demonstrated that for the cases examined, where complex concepts are being developed, the mixing of auditory (or text) and visual elements can result in excessive cognitive load and impede learning. This finding provides a framework for selecting the most appropriate instructional programming language based on the cognitive complexity of the concepts under study.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Learning, visualisation, mental model, programming, cognitive load</field><field name="identifier">http://eprints.qut.edu.au/28482/</field><field name="validLink">True</field></doc><doc><field name="title">Incorporating interdependence in risk likelihood analysis to enhance diagnostics in condition monitoring</field><field name="creator">Wiliem, Leonard</field><field name="description">This research is aimed at addressing problems in the field of asset management relating to risk analysis and decision making based on data from a Supervisory Control and Data Acquisition (SCADA) system. It is apparent that determining risk likelihood in risk analysis is difficult, especially when historical information is unreliable. This relates to a problem in SCADA data analysis because of nested data. A further problem is in providing beneficial information from a SCADA system to a managerial level information system (e.g. Enterprise Resource Planning/ERP). A Hierarchical Model is developed to address the problems. The model is composed of three different Analyses: Hierarchical Analysis, Failure Mode and Effect Analysis, and Interdependence Analysis. The significant contributions from the model include: (a) a new risk analysis model, namely an Interdependence Risk Analysis Model which does not rely on the existence of historical information because it utilises Interdependence Relationships to determine the risk likelihood, (b) improvement of the SCADA data analysis problem by addressing the nested data problem through the Hierarchical Analysis, and (c) presentation of a framework to provide beneficial information from SCADA systems to ERP systems. The case study of a Water Treatment Plant is utilised for model validation.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">hierarchical analysis, failure mode and effect analysis, risk analysis, SCADA, ERP, interdependence analysis</field><field name="identifier">http://eprints.qut.edu.au/28559/</field><field name="validLink">True</field></doc><doc><field name="title">An exploration of knowledge management and intellectual capital in a nonprofit organisation context</field><field name="creator">Quink, Ute</field><field name="description">In recent years, practitioners and researchers alike have turned their attention to knowledge management (KM) in order to increase organisational performance (OP). As a result, many different approaches and strategies have been investigated and suggested for how knowledge should be managed to make organisations more effective and efficient. However, most research has been undertaken in the for-profit sector, with only a few studies focusing on the benefits nonprofit organisations might gain by managing knowledge. This study broadly investigates the impact of knowledge management on the organisational performance of nonprofit organisations. 
 
 Organisational performance can be evaluated through either financial or non-financial measurements. In order to evaluate knowledge management and organisational performance, non-financial measurements are argued to be more suitable given that knowledge is an intangible asset which often cannot be expressed through financial indicators. Non-financial measurement concepts of performance such as the balanced scorecard or the concept of Intellectual Capital (IC) are well accepted and used within the for-profit and nonprofit sectors to evaluate organisational performance. This study utilised the concept of IC as the method to evaluate KM and OP in the context of nonprofit organisations due to the close link between KM and IC: Indeed, KM is concerned with managing the KM processes of creating, storing, sharing and applying knowledge and the organisational KM infrastructure such as organisational culture or organisational structure to support these processes. On the other hand, IC measures the knowledge stocks in different ontological levels: at the individual level (human capital), at the group level (relational capital) and at the organisational level (structural capital). In other words, IC measures the value of the knowledge which has been managed through KM.
 
 As KM encompasses the different KM processes and the KM infrastructure facilitating these processes, previous research has investigated the relationship between KM infrastructure and KM processes. Organisational culture, organisational structure and the level of IT support have been identified as the main factors of the KM infrastructure influencing the KM processes of creating, storing, sharing and applying knowledge. Other research has focused on the link between KM and OP or organisational effectiveness. Based on existing literature, a theoretical model was developed to enable the investigation of the relation between KM (encompassing KM infrastructure and KM processes) and IC. The model assumes an association between KM infrastructure and KM processes, as well as an association between KM processes and the various levels of IC (human capital, structural capital and relational capital). As a result, five research questions (RQ) with respect to the various factors of the KM infrastructure as well as with respect to the relationship between KM infrastructure and IC were raised and included into the research model: 
 
 RQ 1	Do nonprofit organisations which have a Hierarchy culture have a stronger IT support than nonprofit organisations which have an Adhocracy culture?
 RQ 2	Do nonprofit organisations which have a centralised organisational structure have a stronger IT support than nonprofit organisations which have decentralised organisational structure?
 RQ 3	Do nonprofit organisations which have a stronger IT support have a higher value of Human Capital than nonprofit organisations which have a less strong IT support?
 RQ 4	Do nonprofit organisations which have a stronger IT support have a higher value of Structural Capital than nonprofit organisations which have a less strong IT support?
 RQ 5	Do nonprofit organisations which have a stronger IT support have a higher value of Relational Capital than nonprofit organisations which have a less strong IT support?
 
 In order to investigate the research questions, measurements for IC were developed which were linked to the main KM processes. The final KM/IC model contained four items for evaluating human capital, five items for evaluating structural capital and four items for evaluating relational capital.
 
 The research questions were investigated through empirical research using a case study approach with the focus on two nonprofit organisations providing trade promotions services through local offices worldwide. Data for the investigation of the assumptions were collected via qualitative as well as quantitative research methods. The qualitative study included interviews with representatives of the two participating organisations as well as in-depth document research. The purpose of the qualitative study was to investigate the factors of the KM infrastructure (organisational culture, organisational structure, IT support) of the organisations and how these factors were related to each other. On the other hand, the quantitative study was carried out through an online-survey amongst staff of the various local offices. The purpose of the quantitative study was to investigate which impact the level of IT support, as the main instrument of the KM infrastructure, had on IC. 
 
 Overall several key themes were found as a result of the study:
 &#8226;	Knowledge Management and Intellectual Capital were complementary with each other, which should be expressed through measurements of IC based on KM processes.
 &#8226;	The various factors of the KM infrastructure (organisational culture, organisational structure and level of IT support) are interdependent.
 &#8226;	IT was a primary instrument through which the different KM processes (creating, storing, sharing and applying knowledge) were performed.
 &#8226;	A high level of IT support was evident when participants reported higher level of IC (human capital, structural capital and relational capital).
 
 The study supported previous research in the field of KM and replicated the findings from other case studies in this area. The study also contributed to theory by placing the KM research within the nonprofit context and analysing the linkage between KM and IC. From the managerial perspective, the findings gave clear indications that would allow interested parties, such as nonprofit managers or consultants to understand more about the implications of KM on OP and to use this knowledge for implementing efficient and effective KM strategies within their organisations.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">knowledge management, intellectual capital, nonprofit organisations</field><field name="identifier">http://eprints.qut.edu.au/28598/</field><field name="validLink">True</field></doc><doc><field name="title">Adventures in cyberformance</field><field name="creator">Jamieson, Helen Varley</field><field name="description">This thesis examines the new theatrical form of cyberformance (live performance by remote players using internet technologies) and contextualises it within the broader fields of networked performance, digital performance and theatre. Poststructuralist theories that contest the binary distinction between reality and representation provide the analytical foundation for the thesis. A critical reflexive methodological approach is undertaken in order to highlight three themes. First, the essential qualities and criteria of cyberformance are identified, and illustrated with examples from the early 1990s to the present day. Second, two cyberformance groups &#8211; the Plaintext Players and Avatar Body Collision &#8211; and UpStage, a purpose-built application for cyberformance, are examined in more detailed case studies. Third, the specifics of the cyberformance audience are explored and commonalities are identified between theatre and online culture. In conclusion, this thesis suggests that theatre and the internet have much to offer each other in this current global state of transition, and that cyberformance offers one means by which to facilitate the incorporation of new technologies into our lives.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">theatre, performance, cyberformance, digital performance, networked performance, Avatar Body Collision, UpStage, The Plaintext Players, digital arts, digital media, cyber culture, internet art</field><field name="identifier">http://eprints.qut.edu.au/28544/</field><field name="validLink">True</field></doc><doc><field name="title">Investigating relationships between relationship quality, customer loyalty and cooperation : an empirical study of convenience stores' franchise chain systems in Taiwan</field><field name="creator">Huang, Chih-Hsuan</field><field name="description">Franchising has been widely accepted as an effective way to conduct and expand businesses. However, a franchise system is not a guarantee of success in the market. A successful franchise system should rely on a close and strong franchising relationship. Franchising is an important relationship management business. Franchising arrangements normally last for a number of years, so the franchisor and franchisee in the arrangement relationship are usually motivated to cooperate with each other. In addition, highly loyal franchisees may be obtained through a successful long-term franchising relationship. Over the last few decades, there has been a tremendous wave of interest in franchising relationships. However, little research has been conducted to determine the reasons for long-term franchising relationships. As a result, this study focuses on the important elements that might lead to a successful long-term franchising relationship.
 
 This study attempts to examine empirically three essential constructs (relationship quality, cooperation and customer loyalty), which might lead to successful long-term franchising relationships between franchisees and franchisors among the convenience stores in Taiwan. Mailed questionnaires were utilised to collect the research data. A total of 500 surveys were mailed randomly to the manager/supervisor of convenience stores&#8217; franchisees among the four main franchisors (7-ELEVEN, Family, Hi-Life and OK) in Taiwan. The final sample size is 120, yielding a response rate of 24 per cent. The results show that relationship quality positively influences the cooperative relationships between franchisors and franchisees. Relationship quality is also positively correlated with franchisees&#8217; loyalty. Additionally, the results indicate that the cooperative relationships between franchisors and franchisees are significantly associated with franchisees&#8217; loyalty.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">customer loyalty, franchise, convenience stores, Taiwan</field><field name="identifier">http://eprints.qut.edu.au/28566/</field><field name="validLink">True</field></doc><doc><field name="title">A framework for network RTK data processing based on grid computing</field><field name="creator">Yin, Deming</field><field name="description">Real-Time Kinematic (RTK) positioning is a technique used to provide precise positioning services at centimetre accuracy level in the context of Global Navigation Satellite Systems (GNSS). While a Network-based RTK (N-RTK) system involves multiple continuously operating reference stations (CORS), the simplest form of a NRTK system is a single-base RTK. In Australia there are several NRTK services operating in different states and over 1000 single-base RTK systems to support precise positioning applications for surveying, mining, agriculture, and civil construction in regional areas. Additionally, future generation GNSS constellations, including modernised GPS, Galileo, GLONASS, and Compass, with multiple frequencies have been either developed or will become fully operational in the next decade.  
 
 A trend of future development of RTK systems is to make use of various isolated operating network and single-base RTK systems and multiple GNSS constellations for extended service coverage and improved performance.  Several computational challenges have been identified for future NRTK services including:
 &#8226;	Multiple GNSS constellations and multiple frequencies
 &#8226;	Large scale, wide area NRTK services with a network of  networks
 &#8226;	Complex computation algorithms and processes
 &#8226;	Greater part of positioning processes shifting from user end to network centre with the ability to cope with hundreds of simultaneous users&#8217; requests (reverse RTK) 
 
 There are two major requirements for NRTK data processing based on the four challenges faced by future NRTK systems, expandable computing power and scalable data sharing/transferring capability. This research explores new approaches to address these future NRTK challenges and requirements using the Grid Computing facility, in particular for large data processing burdens and complex computation algorithms. A Grid Computing based NRTK framework is proposed in this research, which is a layered framework consisting of: 1) Client layer with the form of Grid portal; 2) Service layer; 3) Execution layer. The user&#8217;s request is passed through these layers, and scheduled to different Grid nodes in the network infrastructure.
 
 A proof-of-concept demonstration for the proposed framework is performed in a five-node Grid environment at QUT and also Grid Australia. The Networked Transport of RTCM via Internet Protocol (Ntrip) open source software is adopted to download real-time RTCM data from multiple reference stations through the Internet, followed by job scheduling and simplified RTK computing. The system performance has been analysed and the results have preliminarily demonstrated the concepts and functionality of the new NRTK framework based on Grid Computing, whilst some aspects of the performance of the system are yet to be improved in future work.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">network RTK data processing, grid computing</field><field name="identifier">http://eprints.qut.edu.au/28596/</field><field name="validLink">True</field></doc><doc><field name="title">Developing a best practice framework for implementing public private partnerships (PPP) in Hong Kong</field><field name="creator">Cheung, Esther</field><field name="description">Public Private Partnership (PPP) is a well established methodology for procuring public works projects.  By incorporating the private sector&#8217;s expertise, efficiency, innovation, business sense, risk sharing, financing etc. into public works projects, the quality of public services and facilities can be uplifted.  Like many jurisdictions, Hong Kong is also keen to take aboard this methodology which is so familiar but yet so distant.  Although they have been one of the first jurisdictions to utilise the private sector in public works projects, their comfortable financial reserves has meant that there has been no urge to push the movement until recently.  PPP has become increasingly popular amongst governments.  The Hong Kong Special Administrative Region (HKSAR) government is no exception.  Some of the more active works departments have commissioned studies to investigate the best ways to deliver these projects, others have even trialed the method themselves.  The efficiency Unit of the HKSAR government has also become an active arm in conducting research in this area.  Although so, the information that is currently available is still very broad.  Building from their works there is a need to develop a best practice framework for implementing PPP projects in Hong Kong by incorporating international experiences.
 
 To develop a best practice framework will require thorough investigation into the benefits, difficulties and critical success factor of PPP.  PPP should also be compared with other procurement methods.  In order to do so it is important to clearly understand the local situation by an analysis of projects conducted to date.  Lessons learnt can further be derived from other countries and incorporated to those derived locally.  Finally the best conditions in terms of project nature, complexity, types, and scales for adopting PPP should be derived.
 
 The aim and objectives of this study were achieved via a comprehensive literature review, in-depth case analyses, interview survey with experts from both Hong Kong and overseas, and finally a large scale data collection was conducted via a questionnaire survey with PPP practitioners.  These findings were further triangulated before they were used as the basis to form the best practice framework presented in this thesis.  The framework was then further validated by PPP experts to ensure it is comprehensive, objective, reliable and practical.
 
 This study has presented a methodology that can be adopted for future studies.  It has also updated our knowledge on the development trends of PPP as well as opened up the experiences of other jurisdictions.  The findings have shown that the local industry is familiar with &#8220;what&#8221; should be done in PPP projects but they are unsure of &#8220;how&#8221; these goals can be achieved.  This framework has allowed this further knowledge to be delivered to PPP practitioners.  As a result, the development of this framework can help to resolve the current economic crisis by encouraging more developments and business opportunities for the private sector.  In addition, the correct projects can be delivered by PPP, the advantages of PPP can be maximised, and the general public can benefit from the private sector&#8217;s participation.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">public private partnership (PPP), build operate transfer (BOT), infrastructure, procurement, public works, public sector, private sector, researcher, Hong Kong, Australia</field><field name="identifier">http://eprints.qut.edu.au/28597/</field><field name="validLink">True</field></doc><doc><field name="title">Bearing-only SLAM : a vision-based navigation system for autonomous robots</field><field name="creator">Huang, Henry</field><field name="description">To navigate successfully in a previously unexplored environment, a mobile robot must be able to estimate the spatial relationships of the objects of interest accurately. A Simultaneous Localization and Mapping (SLAM) sys- tem employs its sensors to build incrementally a map of its surroundings and to localize itself in the map simultaneously. The aim of this research project is to develop a SLAM system suitable for self propelled household lawnmowers. The proposed bearing-only SLAM system requires only an omnidirec- tional camera and some inexpensive landmarks. The main advantage of an omnidirectional camera is the panoramic view of all the landmarks in the scene. Placing landmarks in a lawn field to define the working domain is much easier and more flexible than installing the perimeter wire required by existing autonomous lawnmowers. The common approach of existing bearing-only SLAM methods relies on a motion model for predicting the robot&#8217;s pose and a sensor model for updating the pose. In the motion model, the error on the estimates of object positions is cumulated due mainly to the wheel slippage. Quantifying accu- rately the uncertainty of object positions is a fundamental requirement. In bearing-only SLAM, the Probability Density Function (PDF) of landmark position should be uniform along the observed bearing. Existing methods that approximate the PDF with a Gaussian estimation do not satisfy this uniformity requirement. This thesis introduces both geometric and proba- bilistic methods to address the above problems. The main novel contribu- tions of this thesis are: 1. A bearing-only SLAM method not requiring odometry. The proposed method relies solely on the sensor model (landmark bearings only) without relying on the motion model (odometry). The uncertainty of the estimated landmark positions depends on the vision error only, instead of the combination of both odometry and vision errors. 2. The transformation of the spatial uncertainty of objects. This thesis introduces a novel method for translating the spatial un- certainty of objects estimated from a moving frame attached to the robot into the global frame attached to the static landmarks in the environment. 3. The characterization of an improved PDF for representing landmark position in bearing-only SLAM. The proposed PDF is expressed in polar coordinates, and the marginal probability on range is constrained to be uniform. Compared to the PDF estimated from a mixture of Gaussians, the PDF developed here has far fewer parameters and can be easily adopted in a probabilistic framework, such as a particle filtering system. The main advantages of our proposed bearing-only SLAM system are its lower production cost and flexibility of use. The proposed system can be adopted in other domestic robots as well, such as vacuum cleaners or robotic toys when terrain is essentially 2D.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">robot navigation, mobile robot, autonomous lawnmower, household lawnmower, simultaneous localization and mapping, bearing-only SLAM, visual SLAM, landmark initialization, localization, mapping, omnidirectional camera, stereo vision</field><field name="subject">structure from motion, indistinguishable landmark, unknown data association, particle filtering, probability density function, object occlusion</field><field name="identifier">http://eprints.qut.edu.au/28599/</field><field name="validLink">True</field></doc><doc><field name="title">Host searching behaviour of Diachasmimorpha kraussii (Fullaway) (Hymenoptera: Braconidae: Opiinae), a polyphagous parasitoid of Dacinae fruit flies (Diptera: Tephritidae)</field><field name="creator">Ero, Mark Marakus</field><field name="description">Diachasmimorpha kraussii (Hymenoptera: Braconidae: Opiinae) is a koinobiont larval parasitoid of dacine fruit flies of the genus Bactrocera (Diptera: Tephritidae) in its native range (Australia, Papua New Guinea, Solomon Islands). The wasp is a potentially important control agent for pest fruit flies, having been considered for both classical and inundative biological control releases. I investigated the host searching, selection and utilisation mechanisms of the wasp against native host flies within its native range (Australia). Such studies are rare in opiine research where the majority of studies, because of the applied nature of the research, have been carried out using host flies and environments which are novel to the wasps. Diachasmimorpha kraussii oviposited equally into maggots of four fruit fly species, all of which coexist with the wasp in its native range (Australia), when tested in a choice trial using a uniform artificial diet media. While eggs laid into Bactrocera tryoni and B. jarvisi developed successfully through to adult wasps, eggs laid into B. cucumis and B. cacuminata were encapsulated. These results suggest that direct larval cues are not an important element in host selection by D. kraussii. Further exploring how D. kraussii locates suitable host larvae, I investigated the role of plant cues in host searching and selection. This was examined in a laboratory choice trial using uninfested fruit or fruit infested with either B. tryoni or B. jarvisi maggots. The results showed a consistent preference ranking among infested fruits by the wasp, with guava and peach most preferred, but with no response to uninfested fruits. Thus, it appears the wasp uses chemical cues emitted in response to fruit fly larval infestation for host location, but does not use cues from uninfested fruits. To further tease apart the role of (i) suitable and non-suitable maggots, (ii) infested and uninfested fruits of different plant species, and (iii) adult flies, in wasp host location and selection, I carried out a series of behavioural tests where I manipulated these attributes in a field cage. These trials confirmed that D. kraussii did not respond to cues in uninfested fruits, that there were consistent preferences by the wasps for different maggot infested fruits, that fruit preference did not vary depending on whether the maggots were physiologically suitable or not suitable for wasp offspring development, and finally, that adult flies appear to play a secondary role as indicators of larval infestation. To investigate wasp behaviour in an unrestrained environment, I concurrently observed diurnal foraging behaviours of both the wasp and one of its host fly in a small nectarine orchard. Wasp behaviour, both spatially and temporally, was not correlated with adult fruit fly behaviour or abundance. This study reinforced the point that infested fruit seems to be the primary cue used by foraging wasps. Wasp and fly feeding and mating was not observed in the orchard, implying these activities are occurring elsewhere. It is highly unlikely that these behaviours were happening within the orchard during the night as both insects are diurnal. As the final component of investigating host location, I carried out a habitat preference study for the wasp at the landscape scale. Using infested sentinel fruits, I tested the parasitism rate of B. tryoni in eucalyptus sclerophyll forest, rainforest and suburbia in South East Queensland. Although, rainforest is the likely endemic habitat of both B. tryoni and D. kraussii, B. tryoni abundance is significantly greater in suburban environments followed by eucalyptus sclerophyll forest. Parasitism rate was found to be higher in suburbia than in the eucalyptus sclerophyll forest, while no parasitism was recorded in the rainforest. This result suggests that wasps orient within the landscape towards areas of high host density and are not restricted by habitat types. Results from the different experiments suggest that host searching, selection and utilisation behaviour of D. kraussii are strongly influenced by cues associated with fruit fly larval feeding. Cues from uninfested fruits, the host larvae themselves, and the adult host flies play minimal roles. The discussion focuses on the fit of D. kraussii to Vinson&#8217;s classical parasitoid host location model and the implications of results for biological control, including recommendations for host and plant preference screening protocols and release regimes.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Diachasmimorpha kraussii, polyphagous parasitoid, Dacinae fruit flies</field><field name="identifier">http://eprints.qut.edu.au/28602/</field><field name="validLink">True</field></doc><doc><field name="title">Biochemical characterization of Aprataxin, the protein deficient in Ataxia with Oculomotor Apraxia type 1</field><field name="creator">Hancock, Janelle Louise</field><field name="description">Neurodegenerative disorders are heterogenous in nature and include a range of ataxias with oculomotor apraxia, which are characterised by a wide variety of neurological and ophthalmological features. This family includes recessive and dominant disorders. A subfamily of autosomal recessive cerebellar ataxias are characterised by defects in the cellular response to DNA damage. These include the well characterised disorders Ataxia-Telangiectasia (A-T) and Ataxia-Telangiectasia Like Disorder (A-TLD) as well as the recently identified diseases Spinocerebellar ataxia with axonal neuropathy Type 1 (SCAN1), Ataxia with Oculomotor Apraxia Type 2 (AOA2), as well as the subject of this thesis, Ataxia with Oculomotor Apraxia Type 1 (AOA1). AOA1 is caused by mutations in the APTX gene, which is located at chromosomal locus 9p13. This gene codes for the 342 amino acid protein Aprataxin. Mutations in APTX cause destabilization of Aprataxin, thus AOA1 is a result of Aprataxin deficiency. Aprataxin has three functional domains, an N-terminal Forkhead Associated (FHA) phosphoprotein interaction domain, a central Histidine Triad (HIT) nucleotide hydrolase domain and a C-terminal C2H2 zinc finger. Aprataxins FHA domain has homology to FHA domain of the DNA repair protein 5&#8217; polynucleotide kinase 3&#8217; phosphatase (PNKP). PNKP interacts with a range of DNA repair proteins via its FHA domain and plays a critical role in processing damaged DNA termini. The presence of this domain with a nucleotide hydrolase domain and a DNA binding motif implicated that Aprataxin may be involved in DNA repair and that AOA1 may be caused by a DNA repair deficit. This was substantiated by the interaction of Aprataxin with proteins involved in the repair of both single and double strand DNA breaks (XRay Cross-Complementing 1, XRCC4 and Poly-ADP Ribose Polymerase-1) and the hypersensitivity of AOA1 patient cell lines to single and double strand break inducing agents. At the commencement of this study little was known about the in vitro and in vivo properties of Aprataxin. Initially this study focused on generation of recombinant Aprataxin proteins to facilitate examination of the in vitro properties of Aprataxin. Using recombinant Aprataxin proteins I found that Aprataxin binds to double stranded DNA. Consistent with a role for Aprataxin as a DNA repair enzyme, this binding is not sequence specific. I also report that the HIT domain of Aprataxin hydrolyses adenosine derivatives and interestingly found that this activity is competitively inhibited by DNA. This provided initial evidence that DNA binds to the HIT domain of Aprataxin. The interaction of DNA with the nucleotide hydrolase domain of Aprataxin provided initial evidence that Aprataxin may be a DNA-processing factor. Following these studies, Aprataxin was found to hydrolyse 5&#8217;adenylated DNA, which can be generated by unscheduled ligation at DNA breaks with non-standard termini. I found that cell extracts from AOA1 patients do not have DNA-adenylate hydrolase activity indicating that Aprataxin is the only DNA-adenylate hydrolase in mammalian cells. I further characterised this activity by examining the contribution of the zinc finger and FHA domains to DNA-adenylate hydrolysis by the HIT domain. I found that deletion of the zinc finger ablated the activity of the HIT domain against adenylated DNA, indicating that the zinc finger may be required for the formation of a stable enzyme-substrate complex. Deletion of the FHA domain stimulated DNA-adenylate hydrolysis, which indicated that the activity of the HIT domain may be regulated by the FHA domain. Given that the FHA domain is involved in protein-protein interactions I propose that the activity of Aprataxins HIT domain may be regulated by proteins which interact with its FHA domain. We examined this possibility by measuring the DNA-adenylate hydrolase activity of extracts from cells deficient for the Aprataxin-interacting DNA repair proteins XRCC1 and PARP-1. XRCC1 deficiency did not affect Aprataxin activity but I found that Aprataxin is destabilized in the absence of PARP-1, resulting in a deficiency of DNA-adenylate hydrolase activity in PARP-1 knockout cells. This implies a critical role for PARP-1 in the stabilization of Aprataxin. Conversely I found that PARP-1 is destabilized in the absence of Aprataxin. PARP-1 is a central player in a number of DNA repair mechanisms and this implies that not only do AOA1 cells lack Aprataxin, they may also have defects in PARP-1 dependant cellular functions. Based on this I identified a defect in a PARP-1 dependant DNA repair mechanism in AOA1 cells.  Additionally, I identified elevated levels of oxidized DNA in AOA1 cells, which is indicative of a defect in Base Excision Repair (BER). I attribute this to the reduced level of the BER protein Apurinic Endonuclease 1 (APE1) I identified in Aprataxin deficient cells. This study has identified and characterised multiple DNA repair defects in AOA1 cells, indicating that Aprataxin deficiency has far-reaching cellular consequences. Consistent with the literature, I show that Aprataxin is a nuclear protein with nucleoplasmic and nucleolar distribution. Previous studies have shown that Aprataxin interacts with the nucleolar rRNA processing factor nucleolin and that AOA1 cells appear to have a mild defect in rRNA synthesis. Given the nucleolar localization of Aprataxin I examined the protein-protein interactions of Aprataxin and found that Aprataxin interacts with a number of rRNA transcription and processing factors. Based on this and the nucleolar localization of Aprataxin I proposed that Aprataxin may have an alternative role in the nucleolus. I therefore examined the transcriptional activity of Aprataxin deficient cells using nucleotide analogue incorporation. I found that AOA1 cells do not display a defect in basal levels of RNA synthesis, however they display defective transcriptional responses to DNA damage. In summary, this thesis demonstrates that Aprataxin is a DNA repair enzyme responsible for the repair of adenylated DNA termini and that it is required for stabilization of at least two other DNA repair proteins. Thus not only do AOA1 cells have no Aprataxin protein or activity, they have additional deficiencies in PolyADP Ribose Polymerase-1 and Apurinic Endonuclease 1 dependant DNA repair mechanisms. I additionally demonstrate DNA-damage inducible transcriptional defects in AOA1 cells, indicating that Aprataxin deficiency confers a broad range of cellular defects and highlighting the complexity of the cellular response to DNA damage and the multiple defects which result from Aprataxin deficiency. My detailed characterization of the cellular consequences of Aprataxin deficiency provides an important contribution to our understanding of interlinking DNA repair processes.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Ataxia with Oculomotor Apraxia Type 1 (AOA1), early onset ataxia with hypoalbuminemia (EAOH), autosomal recessive cerebellar ataxia (ARCA), DNA repair, Aprataxin, base excision repair (BER), single strand break repair (SSBR), APTX</field><field name="identifier">http://eprints.qut.edu.au/28603/</field><field name="validLink">True</field></doc><doc><field name="title">Modulation of the SHBG signalling axis</field><field name="creator">Sanchez, Washington</field><field name="description">Sex hormone-binding globulin (SHBG) is a homodimeric plasma glycoprotein that is the major sex steroid carrier-protein in the bloodstream and functions also as a key regulator of steroid bioavailability within target tissues, such as the prostate.  Additionally, SHBG binds to prostatic cell membranes via the putative and unidentified SHBG receptor (RSHBG), activating a signal transduction pathway implicated in stimulating both proliferation and expression of prostate specific antigen (PSA) in prostate cell lines in vitro.  A yeast-two hybrid assay suggested an interaction between SHBG and kallikrein-related protease (KLK) 4, which is a serine protease implicated in the progression of prostate cancer.  The potential interaction between these two proteins was investigated in this PhD thesis to determine whether SHBG is a proteolytic substrate of KLK4 and other members of the KLK family including KLK3/PSA, KLK7 and KLK14.  Furthermore, the effects from SHBG proteolytic degradation on SHBG-regulated steroid bioavailability and the activation of the putative RSHBG signal transduction pathway were examined in the LNCaP prostate cancer cell line.
 
 SHBG was found to be a proteolytic substrate of the trypsin-like KLK4 and KLK14 in vitro, yielding several proteolysis fragments.  Both chymotrypsin-like PSA and KLK7 displayed insignificant proteolytic activity against SHBG.  The kinetic parameters of SHBG proteolysis by KLK4 and KLK14 demonstrate a strong enzyme-substrate binding capacity, possessing a Km of 1.2 &#177; 0.7 &#181;M and 2.1 &#177; 0.6 &#181;M respectively.  The catalytic efficiencies (kcat/Km) of KLK4 and KLK14 proteolysis of SHBG were 1.6 x 104 M-1s-1 and 3.8 x 104 M-1s-1 respectively, which were comparable to parameters previously reported for peptide substrates.  N-terminal sequencing of the fragments revealed cleavage near the junction of the N- and C-terminal laminin globulin-like (G-like) domains of SHBG, resulting in the division of the two globulins and ultimately the full degradation of these fragments by KLK4 and KLK14 over time.  Proteolytic fragments that may retain steroid binding were rapidly degraded by both proteases, while fragments containing residues beyond the steroid binding pocket were less degraded over the same period of time.
 
 Degradation of SHBG was inhibited by the divalent metal cations calcium and zinc for KLK4, and calcium, zinc and magnesium for KLK14.  The human secreted serine protease inhibitors (serpins), &#945;1-antitrypsin and &#945;2-antiplasmin, inhibited KLK4 and KLK14 proteolysis of SHBG; &#945;1-antichymotrypsin inhibited KLK4 but not KLK14 activity.  The inhibition by these serpins was comparable and in some cases more effective than general trypsin protease inhibitors such as aprotinin and phenylmethanesulfonyl fluoride (PMSF).  
 
 The binding of 5&#945;-dihydrotestosterone (DHT) to SHBG modulated interactions with KLK4 and KLK14.  Steroid-free SHBG was more readily digested by both enzymes than DHT-bound SHBG.  Moreover, a binding interaction exists between SHBG and pro-KLK4 and pro-KLK14, with DHT strengthening the binding to pro-KLK4 only.  The inhibition of androgen uptake by cultured prostate cancer cells, mediated by SHBG steroid-binding, was examined to assess whether SHBG proteolysis by KLK4 and KLK14 modulated this process.  Proteolytic digestion eliminated the ability of SHBG to inhibit the uptake of DHT from conditioned media into LNCaP cells.  Therefore, the proteolysis of SHBG by KLK4 and KLK14 increased steroid bioavailability in vitro, leading to an increased uptake of androgens by prostate cancer cells.
 
 Interestingly, different transcriptional responses of PSA and KLK2, which are androgen-regulated genes, to DHT-bounsd SHBG treatment were observed between low and high passage number LNCaP cells (lpLNCaP and hpLNCaP respectively).  HpLNCaP cells treated with DHT-bound SHBG demonstrated a significant synergistic upregulation of PSA and KLK2 above DHT or SHBG treatment alone, which is similar to previously reported downstream responses from RSHBG-mediated signaling activation.  As this result was not seen in lpLNCaP cells, only hpLNCaP cells were further investigated to examine the modulation of potential RSHBG activity by KLK4 and KLK14 proteolysis of SHBG.  Contrary to reported results, no increase in intracellular cAMP was observed in hpLNCaP cells when treated with SHBG in the presence and absence of either DHT or estradiol.  As a result, the modulation of RSHBG-mediated signaling activation could not be determined.
 
 Finally, the identification of the RSHBG from both breast (MCF-7) and prostate cancer (LNCaP) cell lines was attempted.  Fluorescently labeled peptides corresponding to the putative receptor binding domain (RBD) of SHBG were shown to be internalized by MCF-7 cells.  Crosslinking of the RBD peptide to the cell surfaces of both MCF-7 and LNCaP cells, demonstrated the interaction of the peptide with several targets.  These targets were then captured using RBD peptides synthesized onto a hydrophilic scaffold and analysed by mass spectrometry.  The samples captured by the RBD peptide returned statistically significantly matches for cytokeratin 8, 18 and 19 as well as microtubule-actin crosslinking factor 1, which may indicate a novel interaction between SHBG and these proteins, but ultimately failed to detect a membrane receptor potentially responsible for the putative RSHBG-mediated signaling.  
 
 This PhD project has reported the proteolytic processing of SHBG by two members of the kallikrein family, KLK4 and KLK14.  The effect of SHBG proteolysis by KLK4 and KLK14 on RSHBG-mediated signaling activation was unable to be determined as the reported signal transduction pathway was not activated after treatment with SHBG, in combination with either DHT or estradiol.  However, the digestion of SHBG by these two proteases positively regulated androgen bioavailability to prostate cancer cells in vitro.  The increased uptake of androgens is deleterious in prostate cancer due to the promotion of proliferation, metastasis, invasion and the inhibition of apoptosis.  The increased bioavailability of androgens, from SHBG proteolysis by KLK4 and KLK14, may therefore promote both carcinogenesis and progression of prostate cancer.  Finally, this information may contribute to the development of therapeutic treatment strategies for prostate cancer by inhibiting the proteolysis of SHBG, by KLK4 and KLK14, to prevent the increased uptake of androgens by hormone-dependent cancerous tissues.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">SHBG signalling axis, modulation</field><field name="identifier">http://eprints.qut.edu.au/28604/</field><field name="validLink">True</field></doc><doc><field name="title">Effect of female sex hormones on Chlamydia trachomatis growth and gene expression</field><field name="creator">Amirshahi, Ashkan</field><field name="description">Transmissible diseases are re-emerging as a global problem, with Sexually Transmitted Diseases (STDs) becoming endemic. Chlamydia trachomatis is the leading cause of bacterially-acquired STD worldwide, with the Australian cost of infection estimated at $90 - $160 million annually. Studies using animal models of genital tract Chlamydia infection suggested that the hormonal status of the genital tract epithelium at the time of exposure may influence the outcome of infection. Oral contraceptive use also increased the risk of contracting chlamydial infections compared to women not using contraception. Generally it was suggested that the outcome of chlamydial infection is determined in part by the hormonal status of the epithelium at the time of exposure. Using the human endolmetrial cell line ECC-1 this study investigated the effects of C. trachomatis serovar D infection, in conjunction with the female sex hormones, 17&#946;-estradiol and progesterone, on chlamydial gene expression. While previous studies have examined the host response, this is the first study to examine C.trachomatis gene expression under different hormonal conditions. We have highlighted a basic model of C. trachomatis gene regulation in the presence of steroid hormones by identifying 60 genes that were regulated by addition of estradiol and/or progesterone. In addition, the third chapter of this thesis discussed and compared the significance of the current findings in the context of data from other research groups to improve our understanding of the molecular basis of chlamydial persistence under hormonal different conditions. In addition, this study analysed the effects of these female sex hormones and C. trachomatis Serovar D infection, on host susceptibility and bacterial growth. Our results clearly demonstrated that addition of steroid hormones not only had a great impact on the level of infectivity of epithelial cells with C.trachomatis serovar D, but also the morphology of chlamydial inclusions was affected by hormone supplementation.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">female sex hormones</field><field name="subject">chlamydia trachomatis</field><field name="subject">gene expression</field><field name="identifier">http://eprints.qut.edu.au/28607/</field><field name="validLink">True</field></doc><doc><field name="title">Revisiting the conceptualization and measurement of service quality</field><field name="creator">Yap, Zhi Wei (David)</field><field name="description">Since the 1980s, industries and researchers have sought to better understand the quality of services due to the rise in their importance (Brogowicz, Delene and Lyth 1990). More recent developments with online services, coupled with growing recognition of service quality (SQ) as a key contributor to national economies and as an increasingly important competitive differentiator, amplify the need to revisit our understanding of SQ and its measurement. Although &#8216;SQ&#8217; can be broadly defined as &#8220;a global overarching judgment or attitude relating to the overall excellence or superiority of a service&#8221; (Parasuraman, Berry and Zeithaml 1988), the term has many interpretations. There has been considerable progress on how to measure SQ perceptions, but little consensus has been achieved on what should be measured. There is agreement that SQ is multi-dimensional, but little agreement as to the nature or content of these dimensions (Brady and Cronin 2001). For example, within the banking sector, there exist multiple SQ models, each consisting of varying dimensions. The existence of multiple conceptions and the lack of a unifying theory bring the credibility of existing conceptions into question, and beg the question of whether it is possible at some higher level to define SQ broadly such that it spans all service types and industries. This research aims to explore the viability of a universal conception of SQ, primarily through a careful re-visitation of the services and SQ literature. The study analyses the strengths and weaknesses of the highly regarded and widely used global SQ model (SERVQUAL) which reflects a single-level approach to SQ measurement. The SERVQUAL model states that customers evaluate SQ (of each service encounter) based on five dimensions namely reliability, assurance, tangibles, empathy and responsibility. SERVQUAL, however, failed to address what needs to be reliable, assured, tangible, empathetic and responsible. This research also addresses a more recent global SQ model from Brady and Cronin (2001); the B&amp;C (2001) model, that has potential to be the successor of SERVQUAL in that it encompasses other global SQ models and addresses the &#8216;what&#8217; questions that SERVQUAL didn&#8217;t. The B&amp;C (2001) model conceives SQ as being multidimensional and multi-level; this hierarchical approach to SQ measurement better reflecting human perceptions. In-line with the initial intention of SERVQUAL, which was developed to be generalizable across industries and service types, this research aims to develop a conceptual understanding of SQ, via literature and reflection, that encompasses the content/nature of factors related to SQ; and addresses the benefits and weaknesses of various SQ measurement approaches (i.e. disconfirmation versus perceptions-only). Such understanding of SQ seeks to transcend industries and service types with the intention of extending our knowledge of SQ and assisting practitioners in understanding and evaluating SQ. The candidate&#8217;s research has been conducted within, and seeks to contribute to, the &#8216;IS-Impact&#8217; research track of the IT Professional Services (ITPS) Research Program at QUT. The vision of the track is &#8220;to develop the most widely employed model for benchmarking Information Systems in organizations for the joint benefit of research and practice.&#8221; The &#8216;IS-Impact&#8217; research track has developed an Information Systems (IS) success measurement model, the IS-Impact Model (Gable, Sedera and Chan 2008), which seeks to fulfill the track&#8217;s vision. Results of this study will help future researchers in the &#8216;IS-Impact&#8217; research track address questions such as: &#8226; Is SQ an antecedent or consequence of the IS-Impact model or both? &#8226; Has SQ already been addressed by existing measures of the IS-Impact model? &#8226; Is SQ a separate, new dimension of the IS-Impact model? &#8226; Is SQ an alternative conception of the IS? Results from the candidate&#8217;s research suggest that SQ dimensions can be classified at a higher level which is encompassed by the B&amp;C (2001) model&#8217;s 3 primary dimensions (interaction, physical environment and outcome). The candidate also notes that it might be viable to re-word the &#8216;physical environment quality&#8217; primary dimension to &#8216;environment quality&#8217; so as to better encompass both physical and virtual scenarios (E.g: web sites). The candidate does not rule out the global feasibility of the B&amp;C (2001) model&#8217;s nine sub-dimensions, however, acknowledges that more work has to be done to better define the sub-dimensions. The candidate observes that the &#8216;expertise&#8217;, &#8216;design&#8217; and &#8216;valence&#8217; sub-dimensions are supportive representations of the &#8216;interaction&#8217;, physical environment&#8217; and &#8216;outcome&#8217; primary dimensions respectively. The latter statement suggests that customers evaluate each primary dimension (or each higher level of SQ classification) namely &#8216;interaction&#8217;, physical environment&#8217; and &#8216;outcome&#8217; based on the &#8216;expertise&#8217;, &#8216;design&#8217; and &#8216;valence&#8217; sub-dimensions respectively. The ability to classify SQ dimensions at a higher level coupled with support for the measures that make up this higher level, leads the candidate to propose the B&amp;C (2001) model as a unifying theory that acts as a starting point to measuring SQ and the SQ of IS. The candidate also notes, in parallel with the continuing validation and generalization of the IS-Impact model, that there is value in alternatively conceptualizing the IS as a &#8216;service&#8217; and ultimately triangulating measures of IS SQ with the IS-Impact model. These further efforts are beyond the scope of the candidate&#8217;s study. Results from the candidate&#8217;s research also suggest that both the disconfirmation and perceptions-only approaches have their merits and the choice of approach would depend on the objective(s) of the study. Should the objective(s) be an overall evaluation of SQ, the perceptions-only approached is more appropriate as this approach is more straightforward and reduces administrative overheads in the process. However, should the objective(s) be to identify SQ gaps (shortfalls), the (measured) disconfirmation approach is more appropriate as this approach has the ability to identify areas that need improvement.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">service quality</field><field name="identifier">http://eprints.qut.edu.au/28608/</field><field name="validLink">True</field></doc><doc><field name="title">Alternative schooling programs for at risk youth : three case studies</field><field name="creator">Livock, Cheryl A.</field><field name="description">This thesis develops a critical realist explanatory critique of alternative schooling programs for youth at risk taking place at three case study sites. Throughout the thesis the author pursues the question, &#129;\Are alternative provisions of schooling working academically and socially for youth at risk?. The academic lens targets literacy learning and associated pedagogies. Social outcomes are posited as positive social behaviours and continued engagement in learning. A four phased analysis, drawing on critical realism, interpretive and subject specific theories is used to elicit explanations for the research question. An overall framework is a critical realist methodology as set out by Danermark, Ekstrom, Jakobsen and Karlsson (2002, p. 129). Consequently phase one describes the phenomena of alternative schooling programs taking place at three case study sites. This is reported first as staff narratives that are resolved into imaginable historical causal components of &#129;\generative events., &#129;\prior schooling structures., &#129;\models of alternative schooling., &#129;\purpose., &#129;\individual agency., and &#129;\relations with linked community organisations.. Then transcendental questions are posed about each component using retroduction to uncover structures, underlying mechanisms and powers, and individual agency. In the second phase the researcher uses modified grounded theory methodology to theoretically redescribe causal categories related to a &#129;\needed different teaching and administrative approach. that emerged from the previous critique. A transcendental question is then applied to this redescription. The research phenomena are again theoretically redescribed in the third phase, this time using three theoretically based constructs associated with literacy and literacy pedagogies; the NRS, the 4 Resources Model, and Productive Pedagogies. This redescription is again questioned in terms of its core or &#129;\necessary. components. The fourth phase makes an explanatory critique by comparing and critiquing all previous explanations, recontextualising them in a wider macro reality of alternative schooling. Through this critical realist explanatory critiquing process, a response emerges not only to whether alternative provisions of schooling are working, but also how they are working, and how they are not working, with realistically based implications for future improvement.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">at risk, youth, alternative schooling, alternative education programs, national reporting system, productive pedagogies, literacy, critical literacy, 4 resources model, critical realism, case study</field><field name="identifier">http://eprints.qut.edu.au/28898/</field><field name="validLink">True</field></doc><doc><field name="title">The failure of Australian legislation on indirect discrimination to detect the systemic racism which prevents Aboriginal people from fully participating in the workforce</field><field name="creator">de Plevitz, Loretta R.</field><field name="description">Government figures put the current indigenous unemployment rate at around 23%, 3 times the unemployment rate for other Australians. This thesis aims to assess whether Australian indirect discrimination legislation can provide a remedy for one of the causes of indigenous unemployment - the systemic discrimination which can result from the mere operation of established procedures of recruitment and hiring. The impact of those practices on indigenous people is examined in the context of an analysis of anti-discrimination legislation and cases from all Australian jurisdictions from the time of the passing of the Racial Discrimination Act by the Commonwealth in 1975 to the present. The thesis finds a number of reasons why the legislation fails to provide equality of opportunity for indigenous people seeking to enter the workforce. In nearly all jurisdictions it is obscurely drafted, used mainly by educated middle class white women, and provides remedies which tend to be compensatory damages rather than change to recruitment policy. White dominance of the legal process has produced legislative and judicial definitions of "race" and "Aboriginality" which focus on biology rather than cultural difference. In the commissions and tribunals complaints of racial discrimination are often rejected on the grounds of being "vexatious" or "frivolous", not reaching the required standard of proof, or not showing a causal connection between race and the conduct complained of. In all jurisdictions the cornerstone of liability is whether a particular employment term, condition or practice is reasonable. The thesis evaluates the approaches taken by appellate courts, including the High Court, and concludes that there is a trend towards an interpretation of reasonableness which favours employer arguments such as economic rationalism, the maintenance of good industrial relations, managerial prerogative to hire and fire, and the protection of majority rights. The thesis recommends that separate, clearly drafted legislation should be passed to address indigenous disadvantage and that indigenous people should be involved in all stages of the process.</field><field name="date">2000</field><field name="language" /><field name="relation" /><field name="subject">law,  indirect discrimination,  Australian anti-discrimination legislation,  systemic racism,  indigenous people,  Aboriginal people,  employment</field><field name="identifier">http://eprints.qut.edu.au/29025/</field><field name="validLink">True</field></doc><doc><field name="title">Boys 'doing' and 'undoing' media education : new possibilities for theory and practice</field><field name="creator">Dezuanni, Michael L.</field><field name="description">The purpose of this study is to investigate how secondary school media educators might best meet the needs of students who prefer practical production work to &#8216;theory&#8217; work in media studies classrooms. This is a significant problem for a curriculum area that claims to develop students&#8217; media literacies by providing them with critical frameworks and a metalanguage for thinking about the media. It is a problem that seems to have become more urgent with the availability of new media technologies and forms like video games. The study is located in the field of media education, which tends to draw on structuralist understandings of the relationships between young people and media and suggests that students can be empowered to resist media&#8217;s persuasive discourses. Recent theoretical developments suggest too little emphasis has been placed on the participatory aspects of young people playing with, creating and gaining pleasure from media. This study contributes to this &#8216;participatory&#8217; approach by bringing post structuralist perspectives to the field, which have been absent from studies of secondary school media education. I suggest theories of media learning must take account of the ongoing formation of students&#8217; subjectivities as they negotiate social, cultural and educational norms. Michel Foucault&#8217;s theory of &#8216;technologies of the self&#8217; and Judith Butler&#8217;s theories of performativity and recognition are used to develop an argument that media learning occurs in the context of students negotiating various &#8216;ethical systems&#8217; as they establish their social viability through achieving recognition within communities of practice. The concept of &#8216;ethical systems&#8217; has been developed for this study by drawing on Foucault&#8217;s theories of discourse and &#8216;truth regimes&#8217; and Butler&#8217;s updating of Althusser&#8217;s theory of interpellation. This post structuralist approach makes it possible to investigate the ways in which students productively repeat and vary norms to creatively &#8216;do&#8217; and &#8216;undo&#8217; the various media learning activities with which they are required to engage.  The study focuses on a group of year ten students in an all boys&#8217; Catholic urban school in Australia who undertook learning about video games in a three-week intensive &#8216;immersion&#8217; program. The analysis examines the ethical systems operating in the classroom, including formal systems of schooling, informal systems of popular cultural practice and systems of masculinity. It also examines the students&#8217; use of semiotic resources to repeat and/or vary norms while reflecting on, discussing, designing and producing video games. The key findings of the study are that students are motivated to learn technology skills and production processes rather than &#8216;theory&#8217; work. This motivation stems from the students&#8217; desire to become recognisable in communities of technological and masculine practice. However, student agency is not only possible through critical responses to media, but through performative variation of norms through creative ethical practices as students participate with new media technologies. Therefore, the opportunities exist for media educators to create the conditions for variation of norms through production activities. The study offers several implications for media education theory and practice including: the productive possibilities of post structuralism for informing ways of doing media education; the importance of media teachers having the autonomy to creatively plan curriculum; the advantages of media and technology teachers collaborating to draw on a broad range of resources to develop curriculum; the benefits of placing more emphasis on students&#8217; creative uses of media; and the advantages of blending formal classroom approaches to media education with less formal out of school experiences.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">media education, video games, agency, post structuralism, performativity, participatory culture, masculinities</field><field name="identifier">http://eprints.qut.edu.au/29137/</field><field name="validLink">True</field></doc><doc><field name="title">The relationship of loneliness and social anxiety with children's and adolescents' online communication</field><field name="creator">Bonetti, Luigi</field><field name="description">Children and adolescents are now using online communication to form and/or maintain relationships with strangers and/or friends. Relationships in real life are important for children and adolescents in identity formation and general development. However, social relationships can be difficult for those who experience feelings of loneliness and social anxiety. The current study aimed to replicate and extend research conducted by Valkenburg and Peter (2007b), by investigating differences in online communication patterns between children and adolescents with and without selfreported loneliness and social anxiety. Six hundred and twenty-six students aged 10-16 years completed a questionnaire survey about the amount of time they engaged in online communication, the topics they discussed, who they communicated with, and their purposes of online communication. Following Valkenburg and Peter (2007b), loneliness was measured with a shortened version of the UCLA Loneliness Scale (Version 3) developed by Russell (1996), whereas social anxiety was assessed with a sub-scale of the Social Anxiety Scale for Adolescents (La Greca &amp; Lopez, 1998). The sample was divided into four groups of children and adolescents: 220 were &#8220;non-socially anxious and non-lonely&#8221;, 139 were &#8220;socially anxious but not lonely&#8221;, 107 were &#8220;lonely but not socially anxious&#8221;, and 159 were &#8220;lonely and socially anxious&#8221;. A one-way ANOVA and chi-square tests were conducted to evaluate the aforementioned differences between these groups. The results indicated that children and adolescents who reported being lonely used online communication differently from those who did not report being lonely. Essentially, the former communicated online more frequently about personal things and intimate topics, but also to compensate for their weak social skills and to meet new people. Further analyses on gender differences within lonely children and adolescents revealed that boys and girls communicated online more frequently with different partners. It was concluded that for these vulnerable individuals online communication may fulfil needs of self-disclosure, identity exploration, and social interactions. However, future longitudinal studies combining a quantitative with a qualitative approach would better address the relationship between Internet use and psychosocial well-being. The findings also suggested the need for further exploration of how such troubled children and adolescents can use the Internet beneficially.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">adolescents, children, friends, Internet, loneliness, motives, online communication, relationships, social anxiety, well-being</field><field name="identifier">http://eprints.qut.edu.au/29140/</field><field name="validLink">True</field></doc><doc><field name="title">Simulation and development of a mock circulation loop with variable compliance</field><field name="creator">Gregory, Shaun David</field><field name="description">Heart disease is attributed as the highest cause of death in the world.  Although this could be alleviated by heart transplantation, there is a chronic shortage of donor hearts and so mechanical solutions are being considered.  Currently, many Ventricular Assist Devices (VADs) are being developed worldwide in an effort to increase life expectancy and quality of life for end stage heart failure patients.  Current pre-clinical testing methods for VADs involve laboratory testing using Mock Circulation Loops (MCLs), and in vivo testing in animal models. The research and development of highly accurate MCLs is vital to the continuous improvement of VAD performance.
 The first objective of this study was to develop and validate a mathematical model of a MCL.  This model could then be used in the design and construction of a variable compliance chamber to improve the performance of an existing MCL as well as form the basis for a new miniaturised MCL.
 An extensive review of literature was carried out on MCLs and mathematical modelling of their function.  A mathematical model of a MCL was then created in the MATLAB/SIMULINK environment.  This model included variable features such as resistance, fluid inertia and volumes (resulting from the pipe lengths and diameters); compliance of Windkessel chambers, atria and ventricles; density of both fluid and compressed air applied to the system; gravitational effects on vertical columns of fluid; and accurately modelled actuators controlling the ventricle contraction.  This model was then validated using the physical properties and pressure and flow traces produced from a previously developed MCL.  
 A variable compliance chamber was designed to reproduce parameters determined by the mathematical model.  The function of the variability was achieved by controlling the transmural pressure across a diaphragm to alter the compliance of the system. An initial prototype was tested in a previously developed MCL, and a variable level of arterial compliance was successfully produced; however, the complete range of compliance values required for accurate physiological representation was not able to be produced with this initial design.
 The mathematical model was then used to design a smaller physical mock circulation loop, with the tubing sizes adjusted to produce accurate pressure and flow traces whilst having an appropriate frequency response characteristic.
 The development of the mathematical model greatly assisted the general design of an in vitro cardiovascular device test rig, while the variable compliance chamber allowed simple and real-time manipulation of MCL compliance to allow accurate transition between a variety of physiological conditions. The newly developed MCL produced an accurate design of a mechanical representation of the human circulatory system for in vitro cardiovascular device testing and education purposes.  The continued improvement of VAD test rigs is essential if VAD design is to improve, and hence improve quality of life and life expectancy for heart failure patients.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">mock circulation loop, variable compliance, simulation</field><field name="identifier">http://eprints.qut.edu.au/29141/</field><field name="validLink">True</field></doc><doc><field name="title">Biotribological assessment for artificial synovial joints : the role of boundary lubrication</field><field name="creator">Gale, Lorne Raymond</field><field name="description">Biotribology, the study of lubrication, wear and friction within the body, has become a topic of high importance in recent times as we continue to encounter debilitating diseases and trauma that destroy function of the joints. A highly successful surgical procedure to replace the joint with an artificial equivalent alleviates dysfunction and pain. However, the wear of the bearing surfaces in prosthetic joints is a significant clinical problem and more patients are surviving longer than the life expectancy of the joint replacement. Revision surgery is associated with increased morbidity and mortality and has a far less successful outcome than primary joint replacement. As such, it is essential to ensure that everything possible is done to limit the rate of revision surgery. Past experience indicates that the survival rate of the implant will be influenced by many parameters, of primary importance, the material properties of the implant, the composition of the synovial fluid and the method of lubrication. In prosthetic joints, effective boundary lubrication is known to take place. The interaction of the boundary lubricant and the bearing material is of utmost importance. The identity of the vital active ingredient within synovial fluid (SF) to which we owe the near frictionless performance of our articulating joints has been the quest of researchers for many years. Once identified, tribo tests can determine what materials and more importantly what surfaces this fraction of SF can function most optimally with. Surface-Active Phospholipids (SAPL) have been implicated as the body&#8217;s natural load bearing lubricant. Studies in this thesis are the first to fully characterise the adsorbed SAPL detected on the surface of retrieved prostheses and the first to verify the presence of SAPL on knee prostheses. Rinsings from the bearing surfaces of both hip and knee prostheses removed from revision operations were analysed using High Performance Liquid Chromatography (HPLC) to determine the presence and profile of SAPL. Several common prosthetic materials along with a novel biomaterial were investigated to determine their tribological interaction with various SAPLs. A pin-on-flat tribometer was used to make comparative friction measurements between the various tribo-pairs. A novel material, Pyrolytic Carbon (PyC) was screened as a potential candidate as a load bearing prosthetic material. Friction measurements were also performed on explanted prostheses. SAPL was detected on all retrieved implant bearing surfaces. As a result of the study eight different species of phosphatidylcholines were identified. The relative concentrations of each species were also determined indicating that the unsaturated species are dominant. Initial tribo tests employed a saturated phosphatidylcholine (SPC) and the subsequent tests adopted the addition of the newly identified major constituents of SAPL, unsaturated phosphatidylcholine (USPC), as the test lubricant. All tribo tests showed a dramatic reduction in friction when synthetic SAPL was used as the lubricant under boundary lubrication conditions. Some tribopairs showed more of an affinity to SAPL than others. PyC performed superior to the other prosthetic materials. Friction measurements with explanted prostheses verified the presence and performance of SAPL. SAPL, in particular phosphatidylcholine, plays an essential role in the lubrication of prosthetic joints. Of particular interest was the ability of SAPLs to reduce friction and ultimately wear of the bearing materials. The identification and knowledge of the lubricating constituents of SF is invaluable for not only the future development of artificial joints but also in developing effective cures for several disease processes where lubrication may play a role. The tribological interaction of the various tribo-pairs and SAPL is extremely favourable in the context of reducing friction at the bearing interface. PyC is highly recommended as a future candidate material for use in load bearing prosthetic joints considering its impressive tribological performance.</field><field name="date">2007</field><field name="language" /><field name="relation" /><field name="subject">SAPL, orthopaedics, biotribology, boundary lubrication, prosthetics, total joint replacement, PC, USPC, PyC, Pyrolytic Carbon, surfactant, synovial fluid, SF, arthritis, joint disease, cartilage, artificial joints, BL.</field><field name="identifier">http://eprints.qut.edu.au/29159/</field><field name="validLink">True</field></doc><doc><field name="title">Synthesis of orchestrators from service choreographies</field><field name="creator">McIlvenna, Stephen</field><field name="description">With service interaction modelling, it is customary to distinguish between two types of models: choreographies and orchestrations. A choreography describes interactions within a collection of services from a global perspective, where no service plays a privileged role. Instead, services interact in a peer-to-peer manner. In contrast, an orchestration describes the interactions between one particular service, the orchestrator, and a number of partner services. The main proposition of this work is an approach to bridge these two modelling viewpoints by synthesising orchestrators from choreographies. To start with, choreographies are defined using a simple behaviour description language based on communicating finite state machines. From such a model, orchestrators are initially synthesised in the form of state machines. It turns out that state machines are not suitable for orchestration modelling, because orchestrators generally need to engage in concurrent interactions. To address this issue, a technique is proposed to transform state machines into process models in the Business Process Modelling Notation (BPMN). Orchestrations represented in BPMN can then be augmented with additional business logic to achieve value-adding mediation. In addition, techniques exist for refining BPMN models into executable process definitions. The transformation from state machines to BPMN relies on Petri nets as an intermediary representation and leverages techniques from theory of regions to identify concurrency in the initial Petri net. Once concurrency has been identified, the resulting Petri net is transformed into a BPMN model. The original contributions of this work are: an algorithm to synthesise orchestrators from choreographies and a rules-based transformation from Petri nets into BPMN.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">service composition, service protocol, choreography, orchestration, Petri nets, BPMN</field><field name="identifier">http://eprints.qut.edu.au/29162/</field><field name="validLink">True</field></doc><doc><field name="title">Information enrichment for quality recommender systems</field><field name="creator">Weng, Li-Tung</field><field name="description">The explosive growth of the World-Wide-Web and the emergence of ecommerce are the major two factors that have led to the development of recommender systems (Resnick and Varian, 1997). The main task of recommender systems is to learn from users and recommend items (e.g. information, products or books) that match the users&#8217; personal preferences. 
 Recommender systems have been an active research area for more than a decade. Many different techniques and systems with distinct strengths have been developed to generate better quality recommendations. One of the main factors that affect recommenders&#8217; recommendation quality is the amount of information resources that are available to the recommenders. The main feature of the recommender systems is their ability to make personalised recommendations for different individuals. However, for many ecommerce sites, it is difficult for them to obtain sufficient knowledge about their users. Hence, the recommendations they provided to their users are often poor and not personalised. This information insufficiency problem is commonly referred to as the cold-start problem. 
 Most existing research on recommender systems focus on developing techniques to better utilise the available information resources to achieve better recommendation quality. However, while the amount of available data and information remains insufficient, these techniques can only provide limited improvements to the overall recommendation quality. 
 In this thesis, a novel and intuitive approach towards improving recommendation quality and alleviating the cold-start problem is attempted. This approach is enriching the information resources. It can be easily observed that when there is sufficient information and knowledge base to support recommendation making, even the simplest recommender systems can outperform the sophisticated ones with limited information resources. Two possible strategies are suggested in this thesis to achieve the proposed information enrichment for recommenders:
 &#8226;	The first strategy suggests that information resources can be enriched by considering other information or data facets. Specifically, a taxonomy-based recommender, Hybrid Taxonomy Recommender (HTR), is presented in this thesis. HTR exploits the relationship between users&#8217; taxonomic preferences and item preferences from the combination of the widely available product taxonomic information and the existing user rating data, and it then utilises this taxonomic preference to item preference relation to generate high quality recommendations. 
 &#8226;	The second strategy suggests that information resources can be enriched simply by obtaining information resources from other parties. In this thesis, a distributed recommender framework, Ecommerce-oriented Distributed Recommender System (EDRS), is proposed. The proposed EDRS allows multiple recommenders from different parties (i.e. organisations or ecommerce sites) to share recommendations and information resources with each other in order to improve their recommendation quality.  
 Based on the results obtained from the experiments conducted in this thesis, the proposed systems and techniques have achieved great improvement in both making quality recommendations and alleviating the cold-start problem.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">collaborative filtering, cold-start problem, distributed systems, ecommerce, product taxonomy, recommendation novelty, recommender systems</field><field name="identifier">http://eprints.qut.edu.au/29165/</field><field name="validLink">True</field></doc><doc><field name="title">A re-examination of the Ghrelin and Ghrelin receptor genes</field><field name="creator">Seim, Inge</field><field name="description">The last few years have seen dramatic advances in genomics, including the discovery of a large number of non-coding and antisense transcripts. This has revolutionised our understanding of multifaceted transcript structures found within gene loci and their roles in the regulation of development, neurogenesis and other complex processes. The recent and continuing surge of knowledge has prompted researchers to reassess and further dissect gene loci. The ghrelin gene (GHRL) gives rise to preproghrelin, which in turn produces ghrelin, a 28 amino acid peptide hormone that acts via the ghrelin receptor (growth hormone secretagogue receptor/GHSR 1a). Ghrelin has many important physiological and pathophysiological roles, including the stimulation of growth hormone (GH) release, appetite regulation, and cancer development. A truncated receptor splice variant, GHSR 1b, does not bind ghrelin, but dimerises with GHSR 1a, and may act as a dominant negative receptor. The gene products of ghrelin and its receptor are frequently overexpressed in human cancer While it is well known that the ghrelin axis (ghrelin and its receptor) plays a range of important functional roles, little is known about the molecular structure and regulation of the ghrelin gene (GHRL) and ghrelin receptor gene (GHSR). This thesis reports the re-annotation of the ghrelin gene, discovery of alternative 5&#8217; exons and transcription start sites, as well as the description of a number of novel splice variants, including isoforms with a putative signal peptide. We also describe the discovery and characterisation of a ghrelin antisense gene (GHRLOS), and the discovery and expression of a ghrelin receptor (growth hormone secretagogue receptor/GHSR) antisense gene (GHSR-OS). We have identified numerous ghrelin-derived transcripts, including variants with extended 5' untranslated regions and putative secreted obestatin and C-ghrelin transcripts. These transcripts initiate from novel first exons, exon -1, exon 0 and a 5' extended 1, with multiple transcription start sites. We used comparative genomics to identify, and RT-PCR to experimentally verify, that the proximal exon 0 and 5' extended exon 1 are transcribed in the mouse ghrelin gene, which suggests the mouse and human proximal first exon architecture is conserved. We have identified numerous novel antisense transcripts in the ghrelin locus. A candidate non-coding endogenous natural antisense gene (GHRLOS) was cloned and demonstrates very low expression levels in the stomach and high levels in the thymus, testis and brain - all major tissues of non-coding RNA expression. Next, we examined if transcription occurs in the antisense orientation to the ghrelin receptor gene, GHSR. A novel gene (GHSR-OS) on the opposite strand of intron 1 of the GHSR gene was identified and characterised using strand-specific RT-PCR and rapid amplification of cDNA ends (RACE). GHSR-OS is differentially expressed and a candidate non-coding RNA gene. In summary, this study has characterised the ghrelin and ghrelin receptor loci and demonstrated natural antisense transcripts to ghrelin and its receptor. Our preliminary work shows that the ghrelin axis generates a broad and complex transcriptional repertoire. This study provides the basis for detailed functional studies of the the ghrelin and GHSR loci and future studies will be needed to further unravel the function, diagnostic and therapeutic potential of the ghrelin axis.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Ghrelin, GHRL, growth hormone secretagogue receptor, GHSR, gene, non-coding RNA, ncRNA, natural antisense transcript, cis-NAT, alternative splicing, splice variant, GHRLOS, GHSR-OS, genome, orthologue, comparative genomics</field><field name="identifier">http://eprints.qut.edu.au/29171/</field><field name="validLink">True</field></doc><doc><field name="title">Parent and child experiences of childhood cancer : an interpretative phenomenological analysis approach</field><field name="creator">Griffiths, Maya Richelle</field><field name="description">A diagnosis of cancer represents a significant crisis for the child and their family. As the treatment for childhood cancer has improved dramatically over the past three decades, most children diagnosed with cancer today survive this illness. However, it is still an illness which severely disrupts the lifestyle and typical functioning of the family unit. Most treatments for cancer involve lengthy hospital stays, the endurance of painful procedures and harsh side effects. Research has confirmed that to manage and adapt to such a crisis, families must undertake measures which assist their adjustment. Variables such as level of family support, quality of parents&#8217; marital relationship, coping of other family members, lack of other concurrent stresses and open communication within the family have been identified as influences on how well families adjust to a diagnosis of childhood cancer. Theoretical frameworks such as the Resiliency Model of Family Adjustment and Adaptation (McCubbin and McCubbin, 1993, 1996) and the Stress and Coping Model by Lazarus and Folkman (1984) have been used to explain how families and individuals adapt to crises or adverse circumstances. Developmental theories have also been posed to account for how children come to understand and learn about the concept of illness. However more descriptive information about how families and children in particular, experience and manage a diagnosis of cancer is still needed. There are still many unanswered questions surrounding how a child adapts to, understands and makes meaning from having a life-threatening illness. As a result, developing an understanding of the impact that such a serious illness has on the child and their family is crucial. A new approach to examining childhood illness such as cancer is currently underway which allows for a greater understanding of the experience of childhood cancer to be achieved. This new approach invites a phenomenological method to investigate the perspectives of those affected by childhood cancer. In the current study 9 families in which there was a diagnosis of childhood cancer were interviewed twice over a 12 month period. Using the qualitative methodology of Interpretative Phenomenological Analysis (IPA) a semi-structured interview was used to explicate the experience of childhood cancer from both the parent and child&#8217;s perspectives. A number of quantitative measures were also administered to gather specific information on the demographics of the sample population. The results of this study revealed a number of pertinent areas which need to be considered when treating such families. More importantly experiences were explicated which revealed vital phenomena that needs to be added to extend current theoretical frameworks. Parents identified the time of the diagnosis as the hardest part of their entire experience. Parents experienced an internal struggle when they were forced to come to the realization that they were not able to help their child get well. Families demonstrated an enormous ability to develop a new lifestyle which accommodated the needs of the sick child, as the sick child became the focus of their lives. Regarding the children, many of them accepted their diagnosis without complaint or question, and they were able to recognise and appreciate the support they received. Physical pain was definitely a component of the children&#8217;s experience however the emotional strain of loss of peer contact seemed just as severe. Changes over time were also noted as both parental and child experiences were often pertinent to the stage of treatment the child had reached. The approach used in this study allowed for rich and intimate detail about a sensitive issue to be revealed. Such an approach also allowed for the experience of childhood cancer on parents and the children to be more fully realised. Only now can a comprehensive and sensitive medical and psychosocial approach to the child and family be developed. For example, families may benefit from extra support at the time of diagnosis as this was identified as one of the most difficult periods. Parents may also require counselling support in coming to terms with their lack of ability to help their child heal. Given the ease at which children accepted their diagnosis, we need to question whether children are more receptive to adversity. Yet the emotional struggle children battled as a result of their illness also needs to be addressed.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">children, cancer, parent and child experiences</field><field name="identifier">http://eprints.qut.edu.au/29174/</field><field name="validLink">True</field></doc><doc><field name="title">Theoretical and numerical investigation of plasmon nanofocusing in metallic tapered rods and grooves</field><field name="creator">Vogel, Michael Werner</field><field name="description">Effective focusing of electromagnetic (EM) energy to nanoscale regions is one of the major challenges in nano-photonics and plasmonics. The strong localization of the optical energy into regions much smaller than allowed by the diffraction limit, also called nanofocusing, offers promising applications in nano-sensor technology, nanofabrication, near-field optics or spectroscopy. One of the most promising solutions to the problem of efficient nanofocusing is related to surface plasmon propagation in metallic structures. Metallic tapered rods, commonly used as probes in near field microscopy and spectroscopy, are of a particular interest. They can provide very strong EM field enhancement at the tip due to surface plasmons (SP&#8217;s) propagating towards the tip of the tapered metal rod. A large number of studies have been devoted to the manufacturing process of tapered rods or tapered fibers coated by a metal film. On the other hand, structures such as metallic V-grooves or metal wedges can also provide strong electric field enhancements but manufacturing of these structures is still a challenge. It has been shown, however, that the attainable electric field enhancement at the apex in the V-groove is higher than at the tip of a metal tapered rod when the dissipation level in the metal is strong. Metallic V-grooves also have very promising characteristics as plasmonic waveguides. This thesis will present a thorough theoretical and numerical investigation of nanofocusing during plasmon propagation along a metal tapered rod and into a metallic V-groove. Optimal structural parameters including optimal taper angle, taper length and shape of the taper are determined in order to achieve maximum field enhancement factors at the tip of the nanofocusing structure. An analytical investigation of plasmon nanofocusing by metal tapered rods is carried out by means of the geometric optics approximation (GOA), which is also called adiabatic nanofocusing. However, GOA is applicable only for analysing tapered structures with small taper angles and without considering a terminating tip structure in order to neglect reflections. Rigorous numerical methods are employed for analysing non-adiabatic nanofocusing, by tapered rod and V-grooves with larger taper angles and with a rounded tip. These structures cannot be studied by analytical methods due to the presence of reflected waves from the taper section, the tip and also from (artificial) computational boundaries. A new method is introduced to combine the advantages of GOA and rigorous numerical methods in order to reduce significantly the use of computational resources and yet achieve accurate results for the analysis of large tapered structures, within reasonable calculation time. Detailed comparison between GOA and rigorous numerical methods will be carried out in order to find the critical taper angle of the tapered structures at which GOA is still applicable. It will be demonstrated that optimal taper angles, at which maximum field enhancements occur, coincide with the critical angles, at which GOA is still applicable. It will be shown that the applicability of GOA can be substantially expanded to include structures which could be analysed previously by numerical methods only. The influence of the rounded tip, the taper angle and the role of dissipation onto the plasmon field distribution along the tapered rod and near the tip will be analysed analytically and numerically in detail. It will be demonstrated that electric field enhancement factors of up to ~ 2500 within nanoscale regions are predicted. These are sufficient, for instance, to detect single molecules using surface enhanced Raman spectroscopy (SERS) with the tip of a tapered rod, an approach also known as tip enhanced Raman spectroscopy or TERS. The results obtained in this project will be important for applications for which strong local field enhancement factors are crucial for the performance of devices such as near field microscopes or spectroscopy. The optimal design of nanofocusing structures, at which the delivery of electromagnetic energy to the nanometer region is most efficient, will lead to new applications in near field sensors, near field measuring technology, or generation of nanometer sized energy sources. This includes: applications in tip enhanced Raman spectroscopy (TERS); manipulation of nanoparticles and molecules; efficient coupling of optical energy into and out of plasmonic circuits; second harmonic generation in non-linear optics; or delivery of energy to quantum dots, for instance, for quantum computations.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">near field optics, nano-optics, plasmonics, surface plasmons, localised surface plasmons, film plasmons, gap plasmons, nanofocusing, adiabatic nanofocusing, non-adiabatic nanofocusing, local field enhancement, metallic V-groove, metal tapered rod</field><field name="identifier">http://eprints.qut.edu.au/29241/</field><field name="validLink">True</field></doc><doc><field name="title">Establishment of a mouse model of colitis and its use to evaluate the anti-inflammatory effects of two ghrelin peptides</field><field name="creator">Taufiq, Samia</field><field name="description">Ghrelin is a gut-brain peptide hormone that induces appetite, stimulates the release of growth hormone, and has recently been shown to ameliorate inflammation. Recent studies have suggested that ghrelin may play a potential role in inflammation-related diseases such as inflammatory bowel diseases (IBD). A previous study with ghrelin in the TNBS mouse model of colitis demonstrated that ghrelin treatment decreased the clinical severity of colitis and inflammation and prevented the recurrence of disease. Ghrelin may be acting at the immunological and epithelial level as the ghrelin receptor (GHSR) is expressed by immune cells and intestinal epithelial cells. The current project investigated the effect of ghrelin in a different mouse model of colitis using dextran sodium sulphate (DSS) &#8211; a luminal toxin. Two molecular weight forms of DSS were used as they give differing effects (5kDa and 40kDa). Ghrelin treatment significantly improved clinical colitis scores (p=0.012) in the C57BL/6 mouse strain with colitis induced by 2% DSS (5kDa). Treatment with ghrelin suppressed colitis in the proximal colon as indicated by reduced accumulative histopathology scores (p=0.03). Whilst there was a trend toward reduced scores in the mid and distal colon in these mice this did not reach significance. Ghrelin did not affect histopathology scores in the 40kDa model. There was no significant effect on the number of regulatory T cells or TNF-&#945; secretion from cultured lymph node cells from these mice.
 The discovery of C-terminal ghrelin peptides, for example, obestatin and the peptide derived from exon 4 deleted proghrelin (&#916;4 preproghrelin peptide) have raised questions regarding their potential role in biological functions. The current project investigated the effect of &#916;4 peptide in the DSS model of colitis however no significant suppression of colitis was observed. In vitro epithelial wound healing assays were also undertaken to determine the effect of ghrelin on intestinal epithelial cell migration. Ghrelin did not significantly improve wound healing in these assays. In conclusion, ghrelin treatment displays a mild anti-inflammatory effect in the 5kDa DSS model. The potential mechanisms behind this effect and the disparity between these results and those published previously will be discussed.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">ghrelin, GHSR, &#916;4 peptide, DSS, IBD</field><field name="identifier">http://eprints.qut.edu.au/29261/</field><field name="validLink">True</field></doc><doc><field name="title">The manipulation of apoptosis-related genes to generate resistance to Fusarium wilt and water stress in banana</field><field name="creator">Paul, Jean-Yves</field><field name="description">Bananas are susceptible to a diverse range of biotic and abiotic stresses, many of which cause serious production constraints worldwide. One of the most destructive banana diseases is Fusarium wilt caused by the soil-borne fungus, Fusarium oxysporum f. sp. cubense (Foc). No effective control strategy currently exists for this disease which threatens global banana production. Although disease resistance exists in some wild bananas, attempts to introduce resistance into commercially acceptable bananas by conventional breeding have been hampered by low fertility, long generation times and association of poor agronomical traits with resistance genes. With the advent of reliable banana transformation protocols, molecular breeding is now regarded as a viable alternative strategy to generate disease-resistant banana plants. Recently, a novel strategy involving the expression of anti-apoptosis genes in plants was shown to result in resistance against several necrotrophic fungi. Further, the transgenic plants showed increased resistance to a range of abiotic stresses. In this thesis, the use of anti-apoptosis genes to generate transgenic banana plants with resistance to Fusarium wilt was investigated. Since water stress is an important abiotic constraint to banana production, the resistance of the transgenic plants to water stress was also examined. Embryogenic cell suspensions (ECS) of two commercially important banana cultivars, Grand Naine (GN) and Lady Finger (LF), were transformed using Agrobacterium with the anti-apoptosis genes, Bcl-xL, Bcl-xL G138A, Ced-9 and Bcl- 2 3&#8217; UTR. An interesting, and potentially important, outcome was that the use of anti-apoptosis genes resulted in up to a 50-fold increase in Agrobacterium-mediated transformation efficiency of both LF and GN cells over vector controls. Regenerated plants were subjected to a complete molecular characterisation in order to detect the presence of the transgene (PCR), transcript (RT-PCR) and gene product (Western blot) and to determine the gene copy number (Southern blot). A total of 36 independently-transformed GN lines (8 x Bcl-xL, 5 x Bcl-xL G138A, 15 x Ced-9 and 8 x Bcl-2 3&#8217; UTR) and 41 independently-transformed LF lines (8 x Bcl-xL, 7 x BclxL G138A, 13 x Ced-9 and 13 x Bcl-2 3&#8217; UTR) were identified. The 41 transgenic LF lines were multiplied and clones from each line were acclimatised and grown under glasshouse conditions for 8 weeks to allow monitoring for phenotypic abnormalities. Plants derived from 3 x Bcl-xL, 2 x Ced-9 and 5 x Bcl-2 3&#8217; UTR lines displayed a variety of aberrant phenotypes. However, all but one of these abnormalities were off-types commonly observed in tissue-cultured, non-transgenic banana plants and were therefore unlikely to be transgene-related. Prior to determining the resistance of the transgenic plants to Foc race 1, the apoptotic effects of the fungus on both wild-type and Bcl-2 3&#8217; UTR-transgenic LF banana cells were investigated using rapid in vitro root assays. The results from these assays showed that apoptotic-like cell death was elicited in wild-type banana root cells as early as 6 hours post-exposure to fungal spores. In contrast, these effects were attenuated in the root cells of Bcl-2 3&#8217; UTR-transgenic lines that were exposed to fungal spores. Thirty eight of the 41 transgenic LF lines were subsequently assessed for resistance to Foc race 1 in small-plant glasshouse bioassays. To overcome inconsistencies in rating the internal (vascular discolouration) disease symptoms, a MatLab-based computer program was developed to accurately and reliably assess the level of vascular discolouration in banana corms. Of the transgenic LF banana lines challenged with Foc race 1, 2 x Bcl-xL, 3 x Ced-9, 2 x Bcl-2 3&#8217; UTR and 1 x Bcl-xL G138A-transgenic line were found to show significantly less external and internal symptoms than wild-type LF banana plants used as susceptible controls at 12 weeks post-inoculation. Of these lines, Bcl-2 3&#8217; UTR-transgenic line #6 appeared most resistant, displaying very mild symptoms similar to the wild-type Cavendish banana plants that were included as resistant controls. This line remained resistant for up to 23 weeks post-inoculation. Since anti-apoptosis genes have been shown to confer resistance to various abiotic stresses in other crops, the ability of these genes to confer resistance against water stress in banana was also investigated. Clonal plants derived from each of the 38 transgenic LF banana plants were subjected to water stress for a total of 32 days. Several different lines of transgenic plants transformed with either Bcl-xL, Bcl-xL G138A, Ced-9 or Bcl-2 3&#8217; UTR showed a delay in visual water stress symptoms compared with the wild-type control plants. These plants all began producing new growth from the pseudostem following daily rewatering for one month. In an attempt to determine whether the protective effect of anti-apoptosis genes in transgenic banana plants was linked with reactive oxygen species (ROS)-associated programmed cell death (PCD), the effect of the chloroplast-targeting, ROS-inducing herbicide, Paraquat, on wild-type and transgenic LF was investigated. When leaf discs from wild-type LF banana plants were exposed to 10 &#236;M Paraquat, complete decolourisation occurred after 48 hours which was confirmed to be associated with cell death and ROS production by trypan blue and 3,3-diaminobenzidine (DAB) staining, respectively. When leaf discs from the transgenic lines were exposed to Paraquat, those derived from some lines showed a delay in decolourisation, suggesting only a weak protective effect from the transgenes. Finally, the protective effect of anti-apoptosis genes against juglone, a ROS-inducing phytotoxin produced by the causal agent of black Sigatoka, Mycosphaerella fijiensis, was investigated. When leaf discs from wild-type LF banana plants were exposed to 25 ppm juglone, complete decolourisation occurred after 48 hours which was again confirmed to be associated with cell death and ROS production by trypan blue and DAB staining, respectively. Further, TdT-mediated dUTP nick-end labelling (TUNEL) assays on these discs suggested that the cell death was apoptotic. When leaf discs from the transgenic lines were exposed to juglone, discs from some lines showed a clear delay in decolourisation, suggesting a protective effect. Whether these plants are resistant to black Sigatoka is unknown and will require future glasshouse and field trials. The work presented in this thesis provides the first report of the use of anti-apoptosis genes as a strategy to confer resistance to Fusarium wilt and water stress in a nongraminaceous monocot, banana. Such a strategy may be exploited to generate resistance to necrotrophic pathogens and abiotic stresses in other economically important crop plants.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Fusarium wilt, water stress, banana, apoptosis-related genes</field><field name="identifier">http://eprints.qut.edu.au/29263/</field><field name="validLink">True</field></doc><doc><field name="title">Aural auteur : sound in the films of Rolf de Heer</field><field name="creator">Starrs, D. Bruno</field><field name="description">An interpretative methodology for understanding meaning in cinema since the 1950s, auteur analysis is an approach to film studies in which an individual, usually the director, is studied as the author of her or his films. The principal argument of this thesis is that proponents of auteurism have privileged examination of the visual components in a film-maker&#8217;s body of work, neglecting the potentially significant role played by sound. 
 
 The thesis seeks to address this problematic imbalance by interrogating the creative use of sound in the films written and directed by Rolf de Heer, asking the question, &#8220;Does his use of sound make Rolf de Heer an aural auteur?&#8221; In so far as the term &#8216;aural&#8217; encompasses everything in the film that is heard by the audience, the analysis seeks to discover if de Heer has, as Peter Wollen suggests of the auteur and her or his directing of the visual components (1968, 1972 and 1998), unconsciously left a detectable aural signature on his films.
 
 The thesis delivers an innovative outcome by demonstrating that auteur analysis that goes beyond the mise-en-sc&#232;ne (i.e. visuals) is productive and worthwhile as an interpretive response to film. De Heer&#8217;s use of the aural point of view and binaural sound recording, his interest in providing a &#8216;voice&#8217; for marginalised people, his self-penned song lyrics, his close and early collaboration with composer Graham Tardif and sound designer Jim Currie, his &#8216;hands-on&#8217; approach to sound recording and sound editing and his predilection for making films about sound are all shown to be examples of de Heer&#8217;s aural auteurism.
 
 As well as the three published (or accepted for publication) interviews with de Heer, Tardif and Currie, the dissertation consists of seven papers refereed and published (or accepted for publication) in journals and international conference proceedings, a literature review and a unifying essay. The papers presented are close textual analyses of de Heer&#8217;s films which, when considered as a whole, support the thesis&#8217; overall argument and serve as a comprehensive auteur analysis, the first such sustained study of his work, and the first with an emphasis on the aural.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Rolf de Heer, auteur analysis, aural auteur, auteurism, auteurist, authorship, textual analysis, film sound, Australian film, aural point of view, binaural sound recording, unlikely protagonist, non-hyper-masculine protagonist, psychoanalytic film theory</field><field name="subject">Graham Tardif, Jim Currie</field><field name="identifier">http://eprints.qut.edu.au/29302/</field><field name="validLink">True</field></doc><doc><field name="title">Behaviour and design of cold-formed steel compression members at elevated termperatures</field><field name="creator">Heva, Yasintha Bandula</field><field name="description">Cold-formed steel members have been widely used in residential, industrial and commercial buildings as primary load bearing structural elements and non-load bearing structural elements (partitions) due to their advantages such as higher strength to weight ratio over the other structural materials such as hot-rolled steel, timber and concrete. Cold-formed steel members are often made from thin steel sheets and hence they are more susceptible to various buckling modes. Generally short columns are susceptible to local or distortional buckling while long columns to flexural or flexural-torsional buckling. Fire safety design of building structures is an essential requirement as fire events can cause loss of property and lives. Therefore it is essential to understand the fire performance of light gauge cold-formed steel structures under fire conditions. The buckling behaviour of cold-formed steel compression members under fire conditions is not well investigated yet and hence there is a lack of knowledge on the fire performance of cold-formed steel compression members. Current cold-formed steel design standards do not provide adequate design guidelines for the fire design of cold-formed steel compression members. Therefore a research project based on extensive experimental and numerical studies was undertaken at the Queensland University of Technology to investigate the buckling behaviour of light gauge cold-formed steel compression members under simulated fire conditions. As the first phase of this research, a detailed review was undertaken on the mechanical properties of light gauge cold-formed steels at elevated temperatures and the most reliable predictive models for mechanical properties and stress-strain models based on detailed experimental investigations were identified. Their accuracy was verified experimentally by carrying out a series of tensile coupon tests at ambient and elevated temperatures. As the second phase of this research, local buckling behaviour was investigated based on the experimental and numerical investigations at ambient and elevated temperatures. First a series of 91 local buckling tests was carried out at ambient and elevated temperatures on lipped and unlipped channels made of G250-0.95, G550-0.95, G250-1.95 and G450-1.90 cold-formed steels. Suitable finite element models were then developed to simulate the experimental conditions. These models were converted to ideal finite element models to undertake detailed parametric study. Finally all the ultimate load capacity results for local buckling were compared with the available design methods based on AS/NZS 4600, BS 5950 Part 5, Eurocode 3 Part 1.2 and the direct strength method (DSM), and suitable recommendations were made for the fire design of cold-formed steel compression members subject to local buckling. As the third phase of this research, flexural-torsional buckling behaviour was investigated experimentally and numerically. Two series of 39 flexural-torsional buckling tests were undertaken at ambient and elevated temperatures. The first series consisted 2800 mm long columns of G550-0.95, G250-1.95 and G450-1.90 cold-formed steel lipped channel columns while the second series contained 1800 mm long lipped channel columns of the same steel thickness and strength grades. All the experimental tests were simulated using a suitable finite element model, and the same model was used in a detailed parametric study following validation. Based on the comparison of results from the experimental and parametric studies with the available design methods, suitable design recommendations were made. This thesis presents a detailed description of the experimental and numerical studies undertaken on the mechanical properties and the local and flexural-torsional bucking behaviour of cold-formed steel compression member at ambient and elevated temperatures. It also describes the currently available ambient temperature design methods and their accuracy when used for fire design with appropriately reduced mechanical properties at elevated temperatures. Available fire design methods are also included and their accuracy in predicting the ultimate load capacity at elevated temperatures was investigated. This research has shown that the current ambient temperature design methods are capable of predicting the local and flexural-torsional buckling capacities of cold-formed steel compression members at elevated temperatures with the use of reduced mechanical properties. However, the elevated temperature design method in Eurocode 3 Part 1.2 is overly conservative and hence unsuitable, particularly in the case of flexural-torsional buckling at elevated temperatures.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Light gauge cold-formed steel, local buckling, flexural-torsional buckling, compression members, elevated temperatures, axial compression load, reduced yield strength, reduced elasticity modulus, stress-strain model, fire safety design, fire test</field><field name="subject">finite element analysis</field><field name="identifier">http://eprints.qut.edu.au/29310/</field><field name="validLink">True</field></doc><doc><field name="title">Understanding how to enhance business creativity</field><field name="creator">Dew, Robert</field><field name="description">This PhD study examines some of what happens in an individual&#8217;s mind regarding creativity during problem solving within an organisational context. It presents innovations related to creative motivation, cognitive style and framing effects that can be applied by managers to enhance individual employee creativity within the organisation and thereby assist organisations to become more innovative.
 The project delivers an understanding of how to leverage natural changes in creative motivation levels during problem solving. This pattern of response is called Creative Resolve Response (CRR). The project also presents evidence of how framing effects can be used to influence decisions involving creative options in order to enhance the potential for managers get employees to select creative options more often for implementation.
 The study&#8217;s objectives are to understand:
 &#8226;	How creative motivation changes during problem solving
 &#8226;	How cognitive style moderates these creative motivation changes
 &#8226;	How framing effects apply to decisions involving creative options to solve problems
 &#8226;	How cognitive style moderate these framing effects
 The thesis presents the findings from three controlled experiments based around self reports during contrived problem solving and decision making situations.  The first experiment suggests that creative motivation varies in a predictable and systematic way during problem solving as a function of the problem solver&#8217;s perception of progress. The second experiment suggests that there are specific framing effects related to decisions involving creativity. It seems that simply describing an alternative as innovative may activate perceptual biases that overcome risk based framing effects. The third experiment suggests that cognitive style moderates decisions involving creativity in complex ways. It seems that in some contexts, decision makers will prefer a creative option, regardless of their cognitive style, if this option is both outside the bounds of what is officially allowed and yet ultimately safe.
 The thesis delivers innovation on three levels: theoretical, methodological and empirical. The highlights of these findings are outlined below:
 1.	Theoretical innovation with the conceptualisation of Creative Resolve Response based on an extension of Amabile&#8217;s research regarding creative motivation.
 2.	Theoretical innovation linking creative motivation and Kirton&#8217;s research on cognitive style.
 3.	Theoretical innovation linking both risk based and attribute framing effects to cognitive style.
 4.	Methodological innovation for defining and testing preferences for creative solution implementation in the form of operationalised creativity decision alternatives.
 5.	Methodological innovation to identify extreme decision options by applying Shafir&#8217;s findings regarding attribute framing effects in reverse to create a test.
 6.	Empirical innovation with statistically significant research findings which indicate creative motivation varies in a systematic way.
 7.	Empirical innovation with statistically significant research findings which identify innovation descriptor framing effects
 8.	Empirical innovation with statistically significant research findings which expand understanding of Kirton&#8217;s cognitive style descriptors including the importance of safe rule breaking.
 9.	Empirical innovation with statistically significant research findings which validate how framing effects do apply to decisions involving operationalised creativity.
 Drawing on previous research related to creative motivation, cognitive style, framing effects and supervisor interactions with employees, this study delivers insights which can assist managers to increase the production and implementation of creativity in organisations. Hopefully this will result in organisations which are more innovative. Such organisations have the potential to provide ongoing economic and social benefits.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">creativity, motivation, creative motivation, creative production, framing effects, cognitive style, operationalised creativity, organisational creativity, supervision</field><field name="identifier">http://eprints.qut.edu.au/29311/</field><field name="validLink">True</field></doc><doc><field name="title">Robot navigation in sensor space</field><field name="creator">Keeratipranon, Narongdech</field><field name="description">This thesis investigates the problem of robot navigation using only landmark bearings. The proposed system allows a robot to move to a ground target location specified by the sensor values observed at this ground target posi- tion. The control actions are computed based on the difference between the current landmark bearings and the target landmark bearings. No Cartesian coordinates with respect to the ground are computed by the control system. The robot navigates using solely information from the bearing sensor space. Most existing robot navigation systems require a ground frame (2D Cartesian coordinate system) in order to navigate from a ground point A to a ground point B. The commonly used sensors such as laser range scanner, sonar, infrared, and vision do not directly provide the 2D ground coordi- nates of the robot. The existing systems use the sensor measurements to localise the robot with respect to a map, a set of 2D coordinates of the objects of interest. It is more natural to navigate between the points in the sensor space corresponding to A and B without requiring the Cartesian map and the localisation process. Research on animals has revealed how insects are able to exploit very limited computational and memory resources to successfully navigate to a desired destination without computing Cartesian positions. For example, a honeybee balances the left and right optical flows to navigate in a nar- row corridor. Unlike many other ants, Cataglyphis bicolor does not secrete pheromone trails in order to find its way home but instead uses the sun as a compass to keep track of its home direction vector. The home vector can be inaccurate, so the ant also uses landmark recognition. More precisely, it takes snapshots and compass headings of some landmarks. To return home, the ant tries to line up the landmarks exactly as they were before it started wandering. This thesis introduces a navigation method based on reflex actions in sensor space. The sensor vector is made of the bearings of some landmarks, and the reflex action is a gradient descent with respect to the distance in sensor space between the current sensor vector and the target sensor vec- tor. Our theoretical analysis shows that except for some fully characterized pathological cases, any point is reachable from any other point by reflex action in the bearing sensor space provided the environment contains three landmarks and is free of obstacles. The trajectories of a robot using reflex navigation, like other image- based visual control strategies, do not correspond necessarily to the shortest paths on the ground, because the sensor error is minimized, not the moving distance on the ground. However, we show that the use of a sequence of waypoints in sensor space can address this problem. In order to identify relevant waypoints, we train a Self Organising Map (SOM) from a set of observations uniformly distributed with respect to the ground. This SOM provides a sense of location to the robot, and allows a form of path planning in sensor space. The navigation proposed system is analysed theoretically, and evaluated both in simulation and with experiments on a real robot.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">mobile robots, navigation in sensor space, visual homing, dimensionality re- duction, gradient descend method, dissimilarity measurement, Mahalanobis distance, SOM, visual servo, vision-based navigation, bearing-only naviga- tion, omnidirectional vision</field><field name="subject">topological map, localisation, SLAM, Khep- era, Delaunay triangulation, artificial intelligence, colour segmentation, nor- malised RGB</field><field name="identifier">http://eprints.qut.edu.au/29316/</field><field name="validLink">True</field></doc><doc><field name="title">Corona discharges on the surfaces of high voltage composite insulators</field><field name="creator">Hinde, David Derek</field><field name="description">The degradation of high voltage electrical insulation is a prime factor that can significantly influence the reliability performance and the costs of maintaining high voltage electricity networks. Little information is known about the system of localized degradation from corona discharges on the relatively new silicone rubber sheathed composite insulators that are now being widely used in high voltage applications.
 This current work focuses on the fundamental principles of electrical corona discharge phenomena to provide further insights to where damaging surface discharges may localize and examines how these discharges may degrade the silicone rubber material. Although water drop corona has been identified by many authors as a major cause of deterioration of silicone rubber high voltage insulation until now no thorough studies have been made of this phenomenon. 
 Results from systematic measurements taken using modern digital instrumentation to simultaneously record the discharge current pulses and visible images associated with corona discharges from between metal electrodes, metal electrodes and water drops, and between waters drops on the surface of silicone rubber insulation, using a range of 50 Hz voltages are inter compared. Visual images of wet electrodes show how water drops can play a part in encouraging flashover, and the first reproducible visual images of water drop corona at the triple junction of water air and silicone rubber insulation are presented.
 A study of the atomic emission spectra of the corona produced by the discharge from its onset up to and including spark-over, using a high resolution digital spectrometer with a fiber optic probe, provides further understanding of the roles of the active species of atoms and molecules produced by the discharge that may be responsible for not only for chemical changes of insulator surfaces, but may also contribute to the degradation of the metal fittings that support the high voltage insulators. 
 Examples of real insulators and further work specific to the electrical power industry are discussed. A new design concept to prevent/reduce the damaging effects of water drop corona is also presented.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">corona discharges, discharge current, onset voltage, point-plane, repetition rate, Trichel pulse, emission spectra, silicone rubber, water drop corona, high voltage insulators</field><field name="identifier">http://eprints.qut.edu.au/29320/</field><field name="validLink">True</field></doc><doc><field name="title">Groundwater flow model of the Logan river alluvial aquifer system Josephville, South East Queensland</field><field name="creator">Rudorfer, Vivien Ellen</field><field name="description">The study focuses on an alluvial plain situated within a large meander of the Logan River at Josephville near Beaudesert which supports a factory that processes gelatine. The plant draws water from on site bores, as well as the Logan River, for its production processes and produces approximately 1.5 ML per day (Douglas Partners, 2004) of waste water containing high levels of dissolved ions. At present a series of treatment ponds are used to aerate the waste water reducing the level of organic matter; the water is then used to irrigate grazing land around the site. Within the study the hydrogeology is investigated, a conceptual groundwater model is produced and a numerical groundwater flow model is developed from this. On the site are several bores that access groundwater, plus a network of monitoring bores. Assessment of drilling logs shows the area is formed from a mixture of poorly sorted Quaternary alluvial sediments with a laterally continuous aquifer comprised of coarse sands and fine gravels that is in contact with the river. This aquifer occurs at a depth of between 11 and 15 metres and is overlain by a heterogeneous mixture of silts, sands and clays. The study investigates the degree of interaction between the river and the groundwater within the fluvially derived sediments for reasons of both environmental monitoring and sustainability of the potential local groundwater resource. A conceptual hydrogeological model of the site proposes two hydrostratigraphic units, a basal aquifer of coarse-grained materials overlain by a thick semi-confining unit of finer materials. From this, a two-layer groundwater flow model and hydraulic conductivity distribution was developed based on bore monitoring and rainfall data using MODFLOW (McDonald and Harbaugh, 1988) and PEST (Doherty, 2004) based on GMS 6.5 software (EMSI, 2008). A second model was also considered with the alluvium represented as a single hydrogeological unit. Both models were calibrated to steady state conditions and sensitivity analyses of the parameters has demonstrated that both models are very stable for changes in the range of &#177; 10% for all parameters and still reasonably stable for changes up to &#177; 20% with RMS errors in the model always less that 10%. The preferred two-layer model was found to give the more realistic representation of the site, where water level variations and the numerical modeling showed that the basal layer of coarse sands and fine gravels is hydraulically connected to the river and the upper layer comprising a poorly sorted mixture of silt-rich clays and sands of very low permeability limits infiltration from the surface to the lower layer. The paucity of historical data has limited the numerical modelling to a steady state one based on groundwater levels during a drought period and forecasts for varying hydrological conditions (e.g. short term as well as prolonged dry and wet conditions) cannot reasonably be made from such a model. If future modelling is to be undertaken it is necessary to establish a regular program of groundwater monitoring and maintain a long term database of water levels to enable a transient model to be developed at a later stage. This will require a valid monitoring network to be designed with additional bores required for adequate coverage of the hydrogeological conditions at the Josephville site. Further investigations would also be enhanced by undertaking pump testing to investigate hydrogeological properties in the aquifer.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">groundwater flow model, Logan River, alluvial aquifer system, Josephville, Southeast Queensland</field><field name="identifier">http://eprints.qut.edu.au/29322/</field><field name="validLink">True</field></doc><doc><field name="title">Improved detection and tracking of objects in surveillance video</field><field name="creator">Denman, Simon Paul</field><field name="description">Surveillance networks are typically monitored by a few people, viewing several monitors displaying the camera feeds. It is then very dicult for a human op- erator to eectively detect events as they happen. Recently, computer vision research has begun to address ways to automatically process some of this data, to assist human operators. Object tracking, event recognition, crowd analysis and human identication at a distance are being pursued as a means to aid human operators and improve the security of areas such as transport hubs. The task of object tracking is key to the eective use of more advanced technolo- gies. To recognize an event people and objects must be tracked. Tracking also enhances the performance of tasks such as crowd analysis or human identication. Before an object can be tracked, it must be detected. Motion segmentation tech- niques, widely employed in tracking systems, produce a binary image in which objects can be located. However, these techniques are prone to errors caused by shadows and lighting changes. Detection routines often fail, either due to erro- neous motion caused by noise and lighting eects, or due to the detection routines being unable to split occluded regions into their component objects. Particle l- ters can be used as a self contained tracking system, and make it unnecessary for the task of detection to be carried out separately except for an initial (of- ten manual) detection to initialise the lter. Particle lters use one or more extracted features to evaluate the likelihood of an object existing at a given point each frame. Such systems however do not easily allow for multiple objects to be tracked robustly, and do not explicitly maintain the identity of tracked objects. This dissertation investigates improvements to the performance of object tracking algorithms through improved motion segmentation and the use of a particle lter. A novel hybrid motion segmentation / optical 
 ow algorithm, capable of simulta- neously extracting multiple layers of foreground and optical 
 ow in surveillance video frames is proposed. The algorithm is shown to perform well in the presence of adverse lighting conditions, and the optical 
 ow is capable of extracting a mov- ing object. The proposed algorithm is integrated within a tracking system and evaluated using the ETISEO (Evaluation du Traitement et de lInterpretation de Sequences vidEO - Evaluation for video understanding) database, and signi- cant improvement in detection and tracking performance is demonstrated when compared to a baseline system. A Scalable Condensation Filter (SCF), a particle lter designed to work within an existing tracking system, is also developed. The creation and deletion of modes and maintenance of identity is handled by the underlying tracking system; and the tracking system is able to benet from the improved performance in uncertain conditions arising from occlusion and noise provided by a particle lter. The system is evaluated using the ETISEO database. The dissertation then investigates fusion schemes for multi-spectral tracking sys- tems. Four fusion schemes for combining a thermal and visual colour modality are evaluated using the OTCBVS (Object Tracking and Classication in and Beyond the Visible Spectrum) database. It is shown that a middle fusion scheme yields the best results and demonstrates a signicant improvement in performance when compared to a system using either mode individually. Findings from the thesis contribute to improve the performance of semi- automated video processing and therefore improve security in areas under surveil- lance.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">object tracking, motion detection, optical flow, condensation filter, particle filter, thermal imagery, multi-sensor fusion, multi-spectral tracking</field><field name="identifier">http://eprints.qut.edu.au/29328/</field><field name="validLink">True</field></doc><doc><field name="title">International students using online information resources to learn</field><field name="creator">Hughes, Hilary E.</field><field name="description">This qualitative study views international students as information-using learners, through an information literacy lens. Focusing on the experiences of 25 international students at two Australian universities, the study investigates how international students use online information resources to learn, and identifies associated information literacy learning needs. 
 
 An expanded critical incident approach provided the methodological framework for the study. Building on critical incident technique, this approach integrated a variety of concepts and research strategies. The investigation centred on real-life critical incidents experienced by the international students whilst using online resources for assignment purposes. Data collection involved semi-structured interviews and an observed online resource-using task. Inductive data analysis and interpretation enabled the creation of a multifaceted word picture of international students using online resources and a set of critical findings about their information literacy learning needs.  
 
 The study&#8217;s key findings reveal:
 &#8226;	the complexity of the international students&#8217; experience of using online information resources to learn, which involves an interplay of their interactions with online resources, their affective and reflective responses to using them, and the cultural and linguistic dimensions of their information use. 
 &#8226;	the array of strengths as well as challenges that the international students experience in their information use and learning.
 &#8226;	an apparent information literacy imbalance between the international students&#8217; more developed information skills and less developed critical and strategic approaches to using information
 &#8226;	the need for enhanced information literacy education that responds to international students&#8217; identified information literacy needs. 
 
 Responding to the findings, the study proposes an inclusive informed learning approach to support reflective information use and inclusive information literacy learning in culturally diverse higher education environments.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Information literacy, informed learning, learning, information, information use,  online information use, reflective information use, online resources,  international students, international education, cultural diversity, linguistic diversity</field><field name="subject">inclusive learning, student experience, transition, higher education, university, library, qualitative research, critical incident technique, expanded critical incident approach</field><field name="identifier">http://eprints.qut.edu.au/29348/</field><field name="validLink">True</field></doc><doc><field name="title">Rough set-based reasoning and pattern mining for information filtering</field><field name="creator">Zhou, Xujuan</field><field name="description">An information filtering (IF) system monitors an incoming document stream to find the documents that match the information needs specified by the user profiles. To learn to use the user profiles effectively is one of the most challenging tasks when developing an IF system. With the document selection criteria better defined based on the users&#8217; needs, filtering large streams of information can be more efficient and effective. To learn the user profiles, term-based approaches have been widely used in the IF community because of their simplicity and directness. Term-based approaches are relatively well established. However, these approaches have problems when dealing with polysemy and synonymy, which often lead to an information overload problem. Recently, pattern-based approaches (or Pattern Taxonomy Models (PTM) [160]) have been proposed for IF by the data mining community. These approaches are better at capturing sematic information and have shown encouraging results for improving the effectiveness of the IF system. On the other hand, pattern discovery from large data streams is not computationally efficient. Also, these approaches had to deal with low frequency pattern issues. The measures used by the data mining technique (for example, &#8220;support&#8221; and &#8220;confidences&#8221;) to learn the profile have turned out to be not suitable for filtering. They can lead to a mismatch problem. This thesis uses the rough set-based reasoning (term-based) and pattern mining approach as a unified framework for information filtering to overcome the aforementioned problems. This system consists of two stages - topic filtering and pattern mining stages. The topic filtering stage is intended to minimize information overloading by filtering out the most likely irrelevant information based on the user profiles. A novel user-profiles learning method and a theoretical model of the threshold setting have been developed by using rough set decision theory. The second stage (pattern mining) aims at solving the problem of the information mismatch. This stage is precision-oriented. A new document-ranking function has been derived by exploiting the patterns in the pattern taxonomy. The most likely relevant documents were assigned higher scores by the ranking function. Because there is a relatively small amount of documents left after the first stage, the computational cost is markedly reduced; at the same time, pattern discoveries yield more accurate results. The overall performance of the system was improved significantly. The new two-stage information filtering model has been evaluated by extensive experiments. Tests were based on the well-known IR bench-marking processes, using the latest version of the Reuters dataset, namely, the Reuters Corpus Volume 1 (RCV1). The performance of the new two-stage model was compared with both the term-based and data mining-based IF models. The results demonstrate that the proposed information filtering system outperforms significantly the other IF systems, such as the traditional Rocchio IF model, the state-of-the-art term-based models, including the BM25, Support Vector Machines (SVM), and Pattern Taxonomy Model (PTM).</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">information filtering, information retrieval, rough set decision theory, user profile, threshold decision, machine learning, text classification, data mining, sequential pattern mining, pattern taxonomy model</field><field name="identifier">http://eprints.qut.edu.au/29350/</field><field name="validLink">True</field></doc><doc><field name="title">Intrusion detection techniques in wireless local area networks</field><field name="creator">Gill, Rupinder S.</field><field name="description">This research investigates wireless intrusion detection techniques for detecting attacks on IEEE 802.11i Robust Secure Networks (RSNs). Despite using a variety of comprehensive preventative security measures, the RSNs remain vulnerable to a number of attacks. Failure of preventative measures to address all RSN vulnerabilities dictates the need for a comprehensive monitoring capability to detect all attacks on RSNs and also to proactively address potential security vulnerabilities by detecting security policy violations in the WLAN. This research proposes novel wireless intrusion detection techniques to address these monitoring requirements and also studies correlation of the generated alarms across wireless intrusion detection system (WIDS) sensors and the detection techniques themselves for greater reliability and robustness. The specific outcomes of this research are:  A comprehensive review of the outstanding vulnerabilities and attacks in IEEE 802.11i RSNs.  A comprehensive review of the wireless intrusion detection techniques currently available for detecting attacks on RSNs.  Identification of the drawbacks and limitations of the currently available wireless intrusion detection techniques in detecting attacks on RSNs.  Development of three novel wireless intrusion detection techniques for detecting RSN attacks and security policy violations in RSNs.  Development of algorithms for each novel intrusion detection technique to correlate alarms across distributed sensors of a WIDS.  Development of an algorithm for automatic attack scenario detection using cross detection technique correlation.   Development of an algorithm to automatically assign priority to the detected attack scenario using cross detection technique correlation.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">wireless intrusion detection, 802.11 wireless networks, specification-based intrusion detection, anomaly-based intrusion detection, state transition modelling, security policy compliance monitoring, cross sensor correlation</field><field name="subject">cross detection technique correlation, automatic attack scenario recognition, attack scenario prioritization</field><field name="identifier">http://eprints.qut.edu.au/29351/</field><field name="validLink">True</field></doc><doc><field name="title">The present via the past : an archaelogical approach to analysing the design and use of a contemporary urban village</field><field name="creator">Garcia, Nicole</field><field name="description">This research applies an archaeological lens to an inner-city master planned development in order to investigate the tension between the design of space and the use of space. The chosen case study for this thesis is Kelvin Grove Urban Village (KGUV), located in inner city Brisbane, Australia. The site of this urban village has strong links to the past. KGUV draws on both the history of the place in particular along with more general mythologies of village life in its design and subsequent marketing approaches. The design and marketing approach depends upon notions of an imagined past where life in a place shaped like a traditional village was better and more socially sustainable than modern urban spaces. The appropriation of this urban village concept has been criticised as a shallow marketing ploy. The translation and applicability of the urban village model across time and space is therefore contentious. 
 
 KGUV was considered both in terms of its design and marketing and in terms of a reading of the actual use of this master planned place. Central to this analysis is the figure of the boundary and related themes of social heterogeneity, inclusion and exclusion. The refraction of history in the site is also an important theme. An interpretive archaeological approach was used overall as a novel method to derive this analysis.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">urban design, urban village, archaeology, heterogeneity, past and present, boundary, social sustainability</field><field name="identifier">http://eprints.qut.edu.au/29353/</field><field name="validLink">True</field></doc><doc><field name="title">Leadership construction : an exploratory case study of two exemplary female principals in urban primary schools in mainland China</field><field name="creator">Zhong, Wanjuan</field><field name="description">Worldwide, education systems have undergone unprecedented change due to a variety of economic, social, and political forces (Limerick, Cunnington &amp; Crowther, 2002). The People&#8217;s Republic of China (PRC) is no exception. Continuous educational reform at primary and secondary levels in Mainland China has created new challenges and accountabilities for school principals. The important role of principals in primary and secondary schools has been acknowledged in both policy documents and the broader literature (Central Committee of the Chinese Communist Party, 1985; F. Chen, 2005; Chu, 2003; W. Huang, 2005; T. Wang, 2003). Yet, most of the literature on primary and secondary school principals in Mainland China is prescriptive in nature, identifying from the perspectives of researchers and academics what principals should do and how they should enact leadership. Lacking in this research is an awareness of the daily practices and lived experiences of principals. Furthermore, within the small body of writing on primary and secondary school principals in Mainland China, gender is seldom given any attention. To date, only a small number of empirical studies have focused on female principals as a specific category of research (Zen, 2004; Zhong, 2004). This study aimed to explore the professional lives of two female exemplary school principals in urban primary schools in Mainland China. A qualitative exploratory case study was used. Semi-structured interviews with each individual female principal, with six teachers in each of the school sites and with the superintendent of each principal were conducted. Field observations and document analysis were also undertaken to obtain multiple insights about their leadership practices. The conceptual framework was based largely on the theory of Gronn (1999) and incorporated five core leadership practices (vision building, ethical considerations, teaching and learning, power utilisation, and dealing with risks and challenges) taken from the wider literature. The key findings of this study were twofold. Firstly, while the five leadership practices were evident in the leadership of the two principals, this study identified some subtle differences in the way they approached each of them. Secondly, contextual factors such as Chinese traditional culture, the contemporary societal context, and the school organisational context, in addition to the biographical experiences of each principal were significant factors in shaping the way in which they exercised their leadership practices in the schools.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">female leadership, school principal, case study, primary schools, Mainland China</field><field name="identifier">http://eprints.qut.edu.au/29357/</field><field name="validLink">True</field></doc><doc><field name="title">Girl in the Shadows and resilience and coping strategies in contemporary young adult fiction</field><field name="creator">Kimberley, Maree Ann</field><field name="description">The novel manuscript Girl in the Shadows tells the story of two teenage girls whose friendship, safety and sanity are pushed to the limits when an unexplained phenomenon invades their lives. Sixteen-year-old Tash has everything a teenage girl could want: good looks, brains and freedom from her busy parents. But when she looks into her mirror, a stranger&#8217;s face stares back at her. Her best friend Mal believes it&#8217;s an evil spirit and enters the world of the supernatural to find answers. But spell books and ouija boards cannot fix a problem that comes from deep within the soul. It will take a journey to the edge of madness for Tash to face the truth inside her heart and see the evil that lurks in her home. And Mal&#8217;s love and courage to pull her back into life. The exegesis examines resilience and coping strategies in adolescence, in particular, the relationship of trauma to brain development in children and teenagers. It draws on recent discoveries in neuroscience and psychology to provide a framework to examine the role of coping strategies in building resilience. Within this broader context, it analyses two works of contemporary young adult fiction, Freaky Green Eyes by Joyce Carol Oates and Sonya Hartnett&#8217;s Surrender, their use of the split persona as a coping mechanism within young adult fiction and the potential of young adult literature as a tool to help build resilience in teen readers.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">resilience, mental illness, adolescent brain development, trauma, child abuse, coping mechanisms, young adult literature, creative writing, thesis, masters</field><field name="identifier">http://eprints.qut.edu.au/29384/</field><field name="validLink">True</field></doc><doc><field name="title">The missing puzzle : birth of a format</field><field name="creator">Burum, Ivo John</field><field name="description">The art of storytelling is one of the oldest forms of creative discourse. Apart from finding stories, the most important job in television is the construction of stories to have a broad audience appeal.
 
 This first-hand review of Missing Persons Unit, hereafter referred to as MPU, a prime time program on the Nine Network in Australia with immense audience appeal, is an original work by the executive producer (development and series producer Series One, executive producer Series Two and Three) based on an overview of two-and-a-half years of production on three series.
 
 Through a case study approach, this Masters project explores how story is constructed into a television format. The thesis comprises two parts: the creative component (weighted 50%) is demonstrated through two programs of MPU (one program for evaluation) and the academic component through a written exegesis (50%).  
 
 This case study aims to demonstrate how observational hybrid series such as MPU can be managed to quick turn-around schedules with precise skill sets that cut across a number of traditional genre styles.
 
 With the advent of radio and then television, storytelling found a home and a series of labels called genres to help place them in a schedule for listeners and viewers to choose. Over recent years, with the advent of digital technology and the rush to collect the masses of content required to feed the growing television slate, storytelling has often been replaced by story gathering. 
 
 Today even in factual series where a clear story construct is important, third party &#8216;quick fix&#8217; specialists are hired to shape raw content shot by a field team, who never put their own work together and may never come into the edit suite during a project.
 
 This thesis explores the art of storytelling in fast turn-around television. In particular it explores the layer cake approach used in the production process of MPU, that enables producers of fast turn-around television to shepherd their own stories from field through to post-production.
 
 While each new hybrid series will require its own particular sets of skills, the exploration of the genesis of MPU will demonstrate the building blocks required to successfully produce this type of factual series. This study is also intended as a &#8216;road map&#8217; for producers who wish to develop similar series.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">storytelling, television, audience appeal</field><field name="identifier">http://eprints.qut.edu.au/29386/</field><field name="validLink">True</field></doc><doc><field name="title">An evaluation framework for educational reform projects for teacher quality improvements in developing countries : a case study of Egyptian education reform</field><field name="creator">Hashimoto, Kazuaki</field><field name="description">The role of the evaluation for Official Development Assistance (ODA) enterprises including educational development has become critical after increasing &#8220;aid fatigue&#8221; experienced by the international community in the 1990s. To date, however, monitoring and evaluating outcomes of the projects has been limited to the project life. Consequently these have been mainly through the international aid agencies. Furthermore, the monitoring and evaluation led by international aid agencies have paid little attention to aspects of the sustainability of technical cooperation in educational development. To sustain the impact of technical cooperation, the reinforcement of evaluation has drawn increasing attention in light of the emerging modalities in international development. Therefore this research was inspired to investigate alternative evaluation frameworks for an educational reform project for teacher quality improvement that may increase possibilities for long term sustainability. Importantly, the new modalities in international development and educational issues provide new options. In addition, the research reviewed theoretical and practical issues surrounding evaluation in general, and highlighted the evaluation of education reform projects. The research reported explored via case studies, the evaluation processes employed by the Egyptian education reform projects implemented by the Japan International Cooperation Agency (JICA) and the United Nations Children&#8217;s Fund (UNICEF). The case studies used three data sources (archival and relevant documents, a survey questionnaire and interviews) to illuminate the contextually-embedded evaluation processes. The research found that process evaluation is a potential alternative method since it is likely to be locally institutionalised, which may yield long-term sustainability of the projects.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">evaluation, educational reform, teacher quality improvement, capacity development, international assistance, developing countries</field><field name="identifier">http://eprints.qut.edu.au/29387/</field><field name="validLink">True</field></doc><doc><field name="title">Participation and social order in the playground</field><field name="creator">Theobald, Maryanne Agnes</field><field name="description">This study investigates the everyday practices of young children acting in their social worlds within the context of the school playground. It employs an ethnographic ethnomethodological approach using conversation analysis. In the context of child participation rights advanced by the United Nations Convention on the Rights of the Child (UNCRC) and childhood studies, the study considers children&#8217;s social worlds and their participation agendas. The participants of the study were a group of young children in a preparatory year setting in a Queensland school. These children, aged 4 to 6 years, were videorecorded as they participated in their day-to-day activities in the classroom and in the playground. Data collection took place over a period of three months, with a total of 26 hours of video data. Episodes of the video-recordings were shown to small groups of children and to the teacher to stimulate conversations about what they saw on the video. The conversations were audio-recorded. This method acknowledged the child&#8217;s standpoint and positioned children as active participants in accounting for their relationships with others. These accounts are discussed as interactionally built comments on past joint experiences and provided a starting place for analysis of the video-recorded interaction. Four data chapters are presented in this thesis. Each data chapter investigates a different topic of interaction. The topics include how children use &#8220;telling&#8221; as a tactical tool in the management of interactional trouble, how children use their &#8220;ideas&#8221; as possessables to gain ownership of a game and the interactional matters that follow, how children account for interactional matters and bid for ownership of &#8220;whose idea&#8221; for the game and finally, how a small group of girls orientated to a particular code of conduct when accounting for their actions in a pretend game of &#8220;school&#8221;. Four key themes emerged from the analysis. The first theme addresses two arenas of action operating in the social world of children, pretend and real: the &#8220;pretend&#8221;, as a player in a pretend game, and the &#8220;real&#8221;, as a classroom member. These two arenas are intertwined. Through inferences to explicit and implicit &#8220;codes of conduct&#8221;, moral obligations are invoked as children attempt to socially exclude one another, build alliances and enforce their own social positions. The second theme is the notion of shared history. This theme addresses the history that the children reconstructed, and acts as a thread that weaves through their interactions, with implications for present and future relationships. The third theme is around ownership. In a shared context, such as the playground, ownership is a highly contested issue. Children draw on resources such as rules, their ideas as possessables, and codes of behaviour as devices to construct particular social and moral orders around owners of the game. These themes have consequences for children&#8217;s participation in a social group. The fourth theme, methodological in nature, shows how the researcher was viewed as an outsider and novice and was used as a resource by the children. This theme is used to inform adult-child relationships. The study was situated within an interest in participation rights for children and perspectives of children as competent beings. Asking children to account for their participation in playground activities situates children as analysers of their own social worlds and offers adults further information for understanding how children themselves construct their social interactions. While reporting on the experiences of one group of children, this study opens up theoretical questions about children&#8217;s social orders and these influences on their everyday practices. This thesis uncovers how children both participate in, and shape, their everyday social worlds through talk and interaction. It investigates the consequences that taken-for-granted activities of &#8220;playing the game&#8221; have for their social participation in the wider culture of the classroom. Consideration of this significance may assist adults to better understand and appreciate the social worlds of young children in the school playground.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">child participation, social order, early years, ethnomethodology, conversation analysis, talk-in-interaction, social interaction, competence, children, playground, childhood, sociology of childhood, school, video, video-stimulated conversations, accounts</field><field name="subject">children&#8217;s perspectives, disputes, telling tales, ideas, ownership, pretend, moral order, shared history, code of conduct, play, children&#8217;s activities, early childhood education</field><field name="identifier">http://eprints.qut.edu.au/29618/</field><field name="validLink">True</field></doc><doc><field name="title">Bifocal lens control of myopia progression in children</field><field name="creator">Cheng, Desmond</field><field name="description">This research investigated underlying issues that were critical to the success of the bifocal trial and comprised of three studies.  The first study evaluated if Chinese-Canadian children were suitable subjects for the bifocal trial.  The high prevalence of myopia in Chinese children suggests that genetic input plays a role in myopia development, but the rapid increase in prevalence over the last few decades indicates environmental factors are also important. Since this bifocal trial was conducted in Canada, this work aimed to determine whether Chinese children who had migrated to Canada would still have high myopia prevalence and a high rate of myopia progression. The second study determined the optimal bifocal lens power for myopia treatment and the effect of incorporating base-in prism into the bifocal.  In the majority of published myopia control studies, the power of the prescribed near addition was usually predetermined in the belief that the near addition would always help to improve the near focus. In fact, the effect of near addition on the accommodative error might be quite different even for individuals in which the same magnitude of accommodation lag had been measured. Therefore, this work was necessary to guide the selection of bifocal and prism powers most suitable for the subsequent bifocal trial.  The third study, the ultimate goal of this research, was to conduct a longitudinal clinical trial to determine if bifocals and prismatic bifocals could control myopia progression in children.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">children, Chinese, myopia, prevalence, accommodation, bifocal, phoria</field><field name="identifier">http://eprints.qut.edu.au/29688/</field><field name="validLink">True</field></doc><doc><field name="title">Conceptions of school based youth health nursing : a phenomenographic study</field><field name="creator">Sendall, Marguerite Claire</field><field name="description">The School Based Youth Health Nurse Program was established in 1999 by the Queensland Government to fund school nurse positions in Queensland state high schools. Schools were required to apply for a School Based Youth Health Nurse during a five-phase recruitment process, managed by the health districts, and rolled out over four years. The only mandatory selection criterion for the position of School Based Youth Health Nurse was registration as a General Nurse and most School Based Youth Health Nurses are allocated to two state high schools. Currently, there are approximately 115 Full Time Equivalent School Based Youth Health Nurse positions across all Queensland state high schools. The literature review revealed an abundance of information about school nursing. Most of the literature came from the United Kingdom and the United States, who have a different model of school nursing to school based youth health nursing. However, there is literature to suggest school nursing is gradually moving from a disease-focused approach to a social view of health. The noticeable number of articles about, for example, drug and alcohol, mental health, and contemporary sexual health issues, is evidence of this change. Additionally, there is a significant the volume of literature about partnerships and collaboration, much of which is about health education, team teaching and how school nurses and schools do health business together. The surfacing of this literature is a good indication that school nursing is aligning with the broader national health priority areas. More particularly, the literature exposed a small but relevant and current body of research, predominantly from Queensland, about school based youth health nursing. However, there remain significant gaps in the knowledge about school based youth health nursing. In particular, there is a deficit about how School Based Youth Heath Nurses understand the experience of school based youth health nursing. This research aimed to reveal the meaning of the experience of school based youth health nursing. The research question was How do School Based Youth Health Nurses&#8217; understand the experience of school based youth health nursing? This enquiry was instigated because the researcher, who had a positive experience of school based youth health nursing, considered it important to validate other School Based Youth Health Nurses&#8217; experiences. Consequently, a comprehensive use of qualitative research was considered the most appropriate manner to explore this research question. Within this qualitative paradigm, the research framework consists of the epistemology of social constructionism, the theoretical perspective of interpretivism and the approach of phenomenography. After ethical approval was gained, purposeful and snowball sampling was used to recruit a sample of 16 participants. In-depth interviews, which were voluntary, confidential and anonymous, were mostly conducted in public venues and lasted from 40-75 minutes. The researcher also kept a researchers journal as another form of data collection. Data analysis was guided by Dahlgren and Fallsbergs&#8217; (1991, p. 152) seven phases of data analysis which includes familiarization, condensation, comparison, grouping, articulating, labelling and contrasting. The most important finding in this research is the outcome space, which represents the entirety of the experience of school based youth health nursing. The outcome space consists of two components: inside the school environment and outside the school environment. Metaphorically and considered as whole-in-themselves, these two components are not discreet but intertwined with each other. The outcome space consists of eight categories. Each category of description is comprised of several sub-categories of description but as a whole, is a conception of school based youth health nursing. The eight conceptions of school based youth health nursing are: 1. The conception of school based youth health nursing as out there all by yourself. 2. The conception of school based youth health nursing as no real backup. 3. The conception of school based youth health nursing as confronted by many barriers. 4. The conception of school based youth health nursing as hectic and full-on. 5. The conception of school based youth health nursing as working together. 6. The conception of school based youth health nursing as belonging to school. 7. The conception of school based youth health nursing as treated the same as others. 8. The conception of school based youth health nursing as the reason it&#8217;s all worthwhile.  These eight conceptions of school based youth health nursing are logically related and form a staged hierarchical relationship because they are not equally dependent on each other. The conceptions of school based youth health nursing are grouped according to negative, negative and positive and positive conceptions of school based youth health nursing. The conceptions of school based youth health nursing build on each other, from the bottom upwards, to reach the authorized, or the most desired, conception of school based youth health nursing. This research adds to the knowledge about school nursing in general but especially about school based youth health nursing specifically. Furthermore, this research has operational and strategic implications, highlighted in the negative conceptions of school based youth health nursing, for the School Based Youth Health Nurse Program. The researcher suggests the School Based Youth Health Nurse Program, as a priority, address the operational issues The researcher recommends a range of actions to tackle issues and problems associated with accommodation and information, consultations and referral pathways, confidentiality, health promotion and education, professional development, line management and School Based Youth Health Nurse Program support and school management and community. Strategically, the researcher proposes a variety of actions to address strategic issues, such as the School Based Youth Health Nurse Program vision, model and policy and practice framework, recruitment and retention rates and evaluation. Additionally, the researcher believes the findings of this research have the capacity to spawn a myriad of future research projects. The researcher has identified the most important areas for future research as confidentiality, information, qualifications and health outcomes.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">school nurse, school based youth health nurse, qualitative, phenomenography, in-depth interviews, categories of description, conceptions, outcome space</field><field name="identifier">http://eprints.qut.edu.au/29653/</field><field name="validLink">True</field></doc><doc><field name="title">Intelligent prognostics of machinery health utilising suspended condition monitoring data</field><field name="creator">Heng, Aiwina Soong Yin</field><field name="description">The ability to forecast machinery failure is vital to reducing maintenance costs, operation downtime and safety hazards. Recent advances in condition monitoring technologies have given rise to a number of prognostic models for forecasting machinery health based on condition data. Although these models have aided the advancement of the discipline, they have made only a limited contribution to developing an effective machinery health prognostic system. The literature review indicates that there is not yet a prognostic model that directly models and fully utilises suspended condition histories (which are very common in practice since organisations rarely allow their assets to run to failure); that effectively integrates population characteristics into prognostics for longer-range prediction in a probabilistic sense; which deduces the non-linear relationship between measured condition data and actual asset health; and which involves minimal assumptions and requirements. This work presents a novel approach to addressing the above-mentioned challenges. The proposed model consists of a feed-forward neural network, the training targets of which are asset survival probabilities estimated using a variation of the Kaplan-Meier estimator and a degradation-based failure probability density estimator. The adapted Kaplan-Meier estimator is able to model the actual survival status of individual failed units and estimate the survival probability of individual suspended units. The degradation-based failure probability density estimator, on the other hand, extracts population characteristics and computes conditional reliability from available condition histories instead of from reliability data. The estimated survival probability and the relevant condition histories are respectively presented as &#8220;training target&#8221; and &#8220;training input&#8221; to the neural network. The trained network is capable of estimating the future survival curve of a unit when a series of condition indices are inputted. Although the concept proposed may be applied to the prognosis of various machine components, rolling element bearings were chosen as the research object because rolling element bearing failure is one of the foremost causes of machinery breakdowns. Computer simulated and industry case study data were used to compare the prognostic performance of the proposed model and four control models, namely: two feed-forward neural networks with the same training function and structure as the proposed model, but neglected suspended histories; a time series prediction recurrent neural network; and a traditional Weibull distribution model. The results support the assertion that the proposed model performs better than the other four models and that it produces adaptive prediction outputs with useful representation of survival probabilities. This work presents a compelling concept for non-parametric data-driven prognosis, and for utilising available asset condition information more fully and accurately. It demonstrates that machinery health can indeed be forecasted. The proposed prognostic technique, together with ongoing advances in sensors and data-fusion techniques, and increasingly comprehensive databases of asset condition data, holds the promise for increased asset availability, maintenance cost effectiveness, operational safety and &#8211; ultimately &#8211; organisation competitiveness.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">artificial neural networks, condition-based maintenance, condition monitoring, prognostics, reliability, suspended data</field><field name="identifier">http://eprints.qut.edu.au/29715/</field><field name="validLink">True</field></doc><doc><field name="title">An investigation into how work-related road safety can be enhanced</field><field name="creator">Banks, Tamara Dee</field><field name="description">Despite the facts that vehicle incidents continue to be the most common mechanism for Australian compensated fatalities and that employers have statutory obligations to provide safe workplaces, very few organisations are proactively and comprehensively managing their work-related road risks. Unfortunately, limited guidance is provided in the existing literature to assist practitioners in managing work-related road risks. The current research addresses this gap in the literature. To explore how work-related road safety can be enhanced, three studies were conducted.  
 
 Study one explored the effectiveness of a range of risk management initiatives and whether comprehensive risk management practices were associated with safety outcomes. Study two explored barriers to, and facilitators for, accepting risk management initiatives. Study three explored the influence of organisational factors on road safety outcomes to identify optimal work environments for managing road risks. 
 
 To maximise the research sample and increase generalisability, the studies were designed to allow data collection to be conducted simultaneously drawing upon the same sample obtained from four Australian organisations. Data was collected via four methods. A structured document review of published articles was conducted to identify what outcomes have been observed in previously investigated work-related road safety initiatives. The documents reviewed collectively assessed the effectiveness of 19 work-related road safety initiatives. Audits of organisational practices and process operating within the four researched organisations were conducted to identify whether organisations with comprehensive work-related road risk management practices and processes have better safety outcomes than organisations with limited risk management practices and processes. Interviews were conducted with a sample of 24 participants, comprising 16 employees and eight managers. The interviews were conducted to identify what barriers and facilitators within organisations are involved in implementing work-related road safety initiatives and whether differences in fleet safety climate, stage of change and safety ownership relate to work-related road safety outcomes. Finally, questionnaires were administered to a sample of 679 participants. The questionnaires were conducted to identify which initiatives are perceived by employees to be effective in managing work-related road risks and whether differences in fleet safety climate, stage of change and safety ownership relate to work-related road safety outcomes.
 
 Seven research questions were addressed in the current research project. The key findings with respect to each of the research questions are presented below.
 
 Research question one: What outcomes have been observed in previously investigated work-related road safety initiatives? The structured document review indicated that initiatives found to be positively associated with occupational road safety both during and after the intervention period included: a pay rise; driver training; group discussions; enlisting employees as community road safety change agents; safety reminders; and group and individual rewards.
 
 Research question two: Which initiatives are perceived by employees to be effective in managing work-related road risks? Questionnaire findings revealed that employees believed occupational road risks could best be managed through making vehicle safety features standard, providing practical driver skills training and through investigating serious vehicle incidents. In comparison, employees believed initiatives including signing a promise card commitment to drive safely, advertising the organisation&#8217;s phone number on vehicles and consideration of driving competency in staff selection process would have limited effectiveness in managing occupational road safety. 
 
	Research question three: Do organisations with comprehensive work-related road risk management practices and processes have better safety outcomes than organisations with limited risk management practices and processes? The audit identified a difference among the organisations in their management of work-related road risks. Comprehensive risk management practices were associated with employees engaging in overall safer driving behaviours, committing less driving errors, and experiencing less fatigue and distraction issues when driving. Given that only four organisations participated in this research, these findings should only be considered as preliminary. Further research should be conducted to explore the relationship between comprehensiveness of risk management practices and road safety outcomes with a larger sample of organisations.
 
	Research question four: What barriers and facilitators within organisations are involved in implementing work-related road safety initiatives? The interviews identified that employees perceived six organisational characteristics as potential barriers to implementing work-related road safety initiatives. These included: prioritisation of production over safety; complacency towards work-related road risks; insufficient resources; diversity; limited employee input in safety decisions; and a perception that road safety initiatives were an unnecessary burden. In comparison, employees perceived three organisational characteristics as potential facilitators to implementing work-related road safety initiatives. These included: management commitment; the presence of existing systems that could support the implementation of initiatives; and supportive relationships.
 
 Research question five: Do differences in fleet safety climate relate to work-related road safety outcomes? The interviews and questionnaires identified that organisational climates with high management commitment, support for managing work demands, appropriate safety rules and safety communication were associated with employees who engaged in safer driving behaviours. Regression analyses indicated that as participants&#8217; perceptions of safety climate increased, the corresponding likelihood of them engaging in safer driving behaviours increased. Fleet safety climate was perceived to influence road safety outcomes through several avenues. Some of these included: the allocation of sufficient resources to manage occupational road risks; fostering a supportive environment of mutual responsibility; resolving safety issues openly and fairly; clearly communicating to employees that safety is the top priority; and developing appropriate work-related road safety policies and procedures. 
 
 Research question six: Do differences in stage of change relate to work-related road safety outcomes? The interviews and questionnaires identified that participants&#8217; perceptions of initiative effectiveness were found to vary with respect to their individual stage of readiness, with stage-matched initiatives being perceived most effective. In regards to safety outcomes, regression analyses identified that as participants&#8217; progress through the stages of change, the corresponding likelihood of them being involved in vehicle crashes decreases.
 
	Research question seven: Do differences in safety ownership relate to work-related road safety outcomes? The interviews and questionnaires revealed that management of road risks is often given less attention than other areas of health and safety management in organisations. In regards to safety outcomes, regression analyses identified that perceived authority and perceived shared ownership both emerged as significant independent predictors of self-reported driving behaviours pertaining to fatigue and distractions. The regression models indicated that as participants&#8217; perceptions of the authority of the person managing road risks increases, and perceptions of shared ownership of safety tasks increases, the corresponding likelihood of them engaging in driving while fatigued or multitasking while driving decreases. 
 
 Based on the findings from the current research, the author makes several recommendations to assist practitioners in developing proactive and comprehensive approaches to managing occupational road risks. The author also suggests several avenues for future research in the area of work-related road safety.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">work-related road safety, fleet safety, occupational road safety, workplace health and safety, initiatives, interventions, stages of change, transtheoretical model, fleet safety climate, safety ownership, change facilitators, change barriers</field><field name="identifier">http://eprints.qut.edu.au/29683/</field><field name="validLink">True</field></doc><doc><field name="title">Seismic performance of brick infilled RC frame structures in low and medium rise buildings in Bhutan</field><field name="creator">Dorji, Jigme</field><field name="description">The construction of reinforced concrete buildings with unreinforced infill is common practice even in seismically active country such as Bhutan, which is located in high seismic region of Eastern Himalaya. All buildings constructed prior 1998 were constructed without seismic provisions while those constructed after this period adopted seismic codes of neighbouring country, India. However, the codes have limited information on the design of infilled structures besides having differences in architectural requirements which may compound the structural problems. Although the influence of infill on the reinforced concrete framed structures is known, the present seismic codes do not consider it due to the lack of sufficient information. Time history analyses were performed to study the influence of infill on the performance of concrete framed structures. Important parameters were considered and the results presented in a manner that can be used by practitioners. The results show that the influence of infill on the structural performance is significant. The structural responses such as fundamental period, roof displacement, inter-storey drift ratio, stresses in infill wall and structural member forces of beams and column generally reduce, with incorporation of infill wall. The structures designed and constructed with or without seismic provision perform in a similar manner if the infills of high strength are used.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Infilled frames, seismic response, influence, RC buildings, stiffness, performance, infill, inter-storey drift ratios, fundamental period, soft-storey</field><field name="identifier">http://eprints.qut.edu.au/29689/</field><field name="validLink">True</field></doc><doc><field name="title">Investigation of molecular mechanisms regulating biomineralization of pearl oyster Pinctada maxima</field><field name="creator">Gardner, Luke David</field><field name="description">Biomineralization is a process encompassing all mineral containing tissues produced within an organism. The most dynamic example of this process is the formation of the mollusk shell, comprising a variety of crystal phases and microstructures. The organic component incorporated within the shell is said to dictate this remarkable architecture. Subsequently, for the past decade considerable research have been undertaken to identify and characterize the protein components involved in biomineralization. Despite these efforts the general understanding of the process remains ambiguous. This study employs a novel molecular approach to further the elucidation of the shell biomineralization. A microarray platform has been custom generated (PmaxArray 1.0) from the pearl oyster Pinctada maxima. PmaxArray 1.0 consists of 4992 expressed sequence tags (ESTs) originating from the mantle, an organ involved in shell formation. This microarray has been used as the primary tool for three separate investigations in an effort to associate transcriptional gene expression from P. maxima to the process of shell biomineralization. The first investigation analyzes the spatial expression of ESTs throughout the mantle organ. The mantle was dissected into five discrete regions and each analyzed for gene expression with PmaxArray 1.0. Over 2000 ESTs were differentially expressed among the tissue sections, identifying five major expression regions. Three of these regions have been proposed to have shell formation functions belonging to nacre, prismatic calcite and periostracum. The spatial gene expression map was confirmed by in situ hybridization, localizing a subset of ESTs from each expression region to the same mantle area. Comparative sequence analysis of ESTs expressed in the proposed shell formation regions with the BLAST tool, revealed a number of the transcripts were novel while others showed significant sequence similarities to previously characterized shell formation genes.  The second investigation correlates temporal EST expression during P. maxima larval ontogeny with transitions in shell mineralization during the same period. A timeline documenting the morphologicat microstructural and mineralogical shell characteristics of P. maxima throughout larval ontogeny has been established. Three different shell types were noted based on the physical characters and termed, prodissoconch I, prodissoconch 11 and dissoconch. PmaxArray 1.0 analyzed ESTs expression of animals throughout the larval development of P. maxima, noting up-regulation of 359 ESTs in association with the shell transitions from prodissoconch 1 to prodissoconch 11 to dissoconch. Comparative sequence analysis of these ESTs indicates a number of the transcripts are novel as well as showing significant sequence similarities between ESTs and known shell matrix associated genes and proteins. These ESTs are discussed in relation to the shell characters associated with their temporal expression. The third investigation uses PmaxArray 1.0 to analyze gene expression in the mantle tissue of P. maxima specimens exposed to sub-lethal concentrations of a shell-deforming toxin, tributyltin (TBT). The shell specific effects of TBT are used in this investigation to interpret differential expression of ESTs with respect to shell formation functions. A lethal and sublethal TBT concentration range was established for P. maxima, noting a concentration of 50 ng L- 1 TBT as sub-lethal over a 21 day period. Mantle tissue from P. maxima animals treated with 50 ng L- 1 TBT was assessed for differential EST expression with untreated control animals. A total of 102 ESTs were identified as differentially expressed in association with TBT exposure, comparative sequence identities included an up-regulation of immunity and detoxification related genes and down-regulation of several shell matrix genes. A number of transcripts encoding novel peptides were additionally identified. The potential actions of these genes are discussed with reference to TBT toxicity and shell biomineralization. This thesis has used a microarray platform to analyze gene expression in spatial, temporal and toxicity investigations, revealing the involvement of numerous gene transcripts in specific shell formation functions. Investigation of thousands of transcripts simultaneously has provided a holistic interpretation of the organic components regulating shell biomineralization.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">biomineralization, expression, gene, mantle, microarray, molecular, mollusk, Pinctada maxima, pearl oyster, shell, shell matrix</field><field name="identifier">http://eprints.qut.edu.au/29692/</field><field name="validLink">True</field></doc><doc><field name="title">Orchids : intersex and identity in documentary</field><field name="creator">Hart, Phoebe</field><field name="description">Orchids: Intersex and Identity in Documentary explores the creative practice challenges of working with bodies with intersex in the long-form auto/biographical documentary Orchids. Just as creative practice research challenges the dominant hegemony of quantitative and qualitative research, so does my creative work position itself as a nuanced piece, pushing the boundaries of traditional cultural studies theories, documentary film practice and creative practice method, through its distinctive distillation and celebration of a new form of discursive rupturing, the intersex voice.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">archival practice, art as therapy, audience,  the gaze and spectatorship, autobiography, creative practice as research, critical theory, cultural studies, documentary film/television, disability studies, ethics in documentary, ethnography in documentary</field><field name="subject">film aesthetics, filmic representation, film and television industries, gender identity, intersex</field><field name="identifier">http://eprints.qut.edu.au/29712/</field><field name="validLink">True</field></doc><doc><field name="title">Determining the psychosocial predictors of living, living-related, and posthumous organ donation</field><field name="creator">Hyde, Melissa Karen</field><field name="description">The worldwide organ shortage occurs despite people&#8217;s positive organ donation attitudes. The discrepancy between attitudes and behaviour is evident in Australia particularly, with widespread public support for organ donation but low donation and communication rates. This problem is compounded further by the paucity of theoretically based research to improve our understanding of people&#8217;s organ donation decisions. This program of research contributes to our knowledge of individual decision making processes for three aspects of organ donation: (1) posthumous (upon death) donation, (2) living donation (to a known and unknown recipient), and (3) providing consent for donation by communicating donation wishes on an organ donor consent register (registering) and discussing the donation decision with significant others (discussing). The research program used extended versions of the Theory of Planned Behaviour (TPB) and the Prototype/Willingness Model (PWM), incorporating additional influences (moral norm, self-identity, organ recipient prototypes), to explicate the relationship between people&#8217;s positive attitudes and low rates of organ donation behaviours. 
	Adopting the TPB and PWM (and their extensions) as a theoretical basis overcomes several key limitations of the extant organ donation literature including the often atheoretical nature of organ donation research, thefocus on individual difference factors to construct organ donor profiles and the omission of important psychosocial influences (e.g., control perceptions, moral values) that may impact on people&#8217;s decision-making in this context. In addition, the use of the TPB and PWM adds further to our understanding of the decision making process for communicating organ donation wishes. Specifically, the extent to which people&#8217;s registering and discussing decisions may be explained by a reasoned and/or a reactive decision making pathway is examined (Stage 3) with the novel application of the TPB augmented with the social reaction pathway in the PWM. 
	This program of research was conducted in three discrete stages: a qualitative stage (Stage 1), a quantitative stage with extended models (Stage 2), and a quantitative stage with augmented models (Stage 3). The findings of the research program are reported in nine papers which are presented according to the three aspects of organ donation examined (posthumous donation, living donation, and providing consent for donation by registering or discussing the donation preference). 
	 Stage One of the research program comprised qualitative focus groups/interviews with university students and community members (N = 54) (Papers 1 and 2). Drawing broadly on the TPB framework (Paper 1), content analysed responses revealed people&#8217;s commonly held beliefs about the advantages and disadvantages (e.g., prolonging/saving life), important people or groups (e.g., family), and barriers and motivators (e.g., a family&#8217;s objection to donation), related to living and posthumous organ donation. Guided by a PWM perspective, Paper Two identified people&#8217;s commonly held perceptions of organ donors (e.g., altruistic and giving), non-donors (e.g., self-absorbed and unaware), and transplant recipients (e.g., unfortunate, and in some cases responsible/blameworthy for their predicament).
	Stage Two encompassed quantitative examinations of people&#8217;s decision makingfor living (Papers 3 and 4) and posthumous (Paper 5) organ donation, and for registering and discussing donation wishes (Papers 6 to 8) to test extensions to both the TPB and PWM. Comparisons of health students&#8217; (N = 487) motivations and willingness for living related and anonymous donation (Paper 3) revealed that a person&#8217;s donor identity, attitude, past blood donation, and knowing a posthumous donor were four common determinants of willingness, with the results highlighting students&#8217; identification as a living donor as an important motive. 
	An extended PWM is presented in Papers Four and Five. University students&#8217; (N = 284) willingness for living related and anonymous donation was tested in Paper Four with attitude, subjective norm, donor prototype similarity, and moral norm (but not donor prototype favourability) predicting students&#8217; willingness to donate organs in both living situations. Students&#8217; and community members&#8217; (N = 471) posthumous organ donation willingness was assessed in Paper Five with attitude, subjective norm, past behaviour, moral norm, self-identity, and prior blood donation all significantly directly predicting posthumous donation willingness, with only an indirect role for organ donor prototype evaluations. 
	The results of two studies examining people&#8217;s decisions to register and/or discuss their organ donation wishes are reported in Paper Six. People&#8217;s (N = 24) commonly held beliefs about communicating their organ donation wishes were explored initially in a TPB based qualitative elicitation study. The TPB belief determinants of intentions to register and discuss the donation preference were then assessed for people who had not previously communicated their donation wishes (N = 123). Behavioural and normative beliefs were important determinants of registering and discussing intentions; however, control beliefs influenced people&#8217;s registering intentions only.  
	Paper Seven represented the first empirical test of the role of organ transplant recipient prototypes (i.e., perceptions of organ transplant recipients) in people&#8217;s (N = 465) decisions to register consent for organ donation. Two factors, Substance Use and Responsibility, were identified and Responsibility predicted people&#8217;s organ donor registration status. Results demonstrated that unregistered respondents were the most likely to evaluate transplant recipients negatively.	Paper Eight established the role of organ donor prototype evaluations, within an extended TPB model, in predicting students&#8217; and community members&#8217; registering (n = 359) and discussing (n = 282) decisions. Results supported the utility of an extended TPB and suggested a role for donor prototype evaluations in predicting people&#8217;s discussing intentions only. Strong intentions to discuss donation wishes increased the likelihood that respondents reported discussing their decision 1-month later. 
	Stage Three of the research program comprised an examination of augmented models (Paper 9). A test of the TPB augmented with elements from the social reaction pathway in the PWM, and extensions to these models was conducted to explore whether people&#8217;s registering (N = 339) and discussing (N = 315) decisions are explained via a reasoned (intention) and/or social reaction (willingness) pathway. Results suggested that people&#8217;s decisions to communicate their organ donation wishes may be better explained via the reasoned pathway, particularly for registering consent; however, discussing also involves reactive elements. 
	Overall, the current research program represents an important step toward clarifying the relationship between people&#8217;s positive organ donation attitudes but low rates of organ donation and communication behaviours. Support has been demonstrated for the use of extensions to two complementary theories, the TPB and PWM, which can inform future research aiming to explicate further the organ donation attitude-behaviour relationship. The focus on a range of organ donation behaviours enables the identification of key targets for future interventions encouraging people&#8217;s posthumous and living donation decisions, and communication of their organ donation preference.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">organ donation, living donation, posthumous donation, communication of donation wishes, theory of planned behaviour, prototype/willingness model</field><field name="identifier">http://eprints.qut.edu.au/29724/</field><field name="validLink">True</field></doc><doc><field name="title">Printmaking as an expanding field in contemporary art practice : a case study of Japan, Australia and Thailand</field><field name="creator">Kirker, Marjorie Anne</field><field name="description">This thesis proposes that contemporary printmaking, at its most significant, marks the present through reconstructing pasts and anticipating futures. It argues this through examples in the field, occurring in contexts beyond the Euramerican (Europe and North America). The arguments revolve around how the practice of a number of significant artists in Japan, Australia and Thailand has generated conceptual and formal innovations in printmaking that transcend local histories and conventions, whilst paradoxically, also building upon them and creating new meanings. The arguments do not portray the relations between contemporary and traditional art as necessarily antagonistic but rather, as productively dialectical.
 
 Furthermore, the case studies demonstrate that, in the 1980s and 1990s particularly, the studio practice of these printmakers was informed by other visual arts disciplines and reflected postmodern concerns. Departures from convention witnessed in these countries within the Asia-Pacific region shifted the field of the print into a heterogeneous and hybrid realm. The practitioners concerned (especially in Thailand) produced work that was more readily equated with performance and installation art than with printmaking per se. In Japan, the incursion of photography interrupted the decorative cast of printmaking and delivered it from a straightforward, craft-based aesthetic. In Australia, fixed notions of national identity were challenged by print practitioners through deliberate cultural rapprochements and technical contradictions (speaking across old and new languages).However time-honoured print methods were not jettisoned by any case study artists. Their re-alignment of the fundamental attributes of printmaking, in line with materialist formalism, is a core consideration of my arguments. 
 
 The artists selected for in-depth analysis from these three countries are all innovators whose geographical circumstances and creative praxis drew on local traditions whilst absorbing international trends. In their radical revisionism, they acknowledged the specificity of history and place, conditions of contingency and forces of globalisation. The transformational nature of their work during the late twentieth century connects it to the postmodern ethos and to a broader artistic and cultural nexus than has hitherto been recognised in literature on the print. Emerging from former guild-based practices, they ambitiously conceived their work to be part of a continually evolving visual arts vocabulary. 
 
 I argue in this thesis that artists from the Asia-Pacific region have historically broken with the hermetic and Euramerican focus that has generally characterised the field. Inadequate documentation and access to print activity outside the dominant centres of critical discourse imply that readings of postmodernism have been too limited in their scope of inquiry. Other locations offer complexities of artistic practice where re-alignments of customary boundaries are often the norm. By addressing innovative activity in Japan, Australia and Thailand, this thesis exposes the need for a more inclusive theoretical framework and wider global reach than currently exists for &#8216;printmaking&#8217;.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">printmaking, contemporary art practice, Japan, Australia, Thailand</field><field name="identifier">http://eprints.qut.edu.au/29746/</field><field name="validLink">True</field></doc><doc><field name="title">Krylov subspace methods for approximating functions of symmetric positive definite matrices with applications to applied statistics and anomalous diffusion</field><field name="creator">Simpson, Daniel Peter</field><field name="description">Matrix function approximation is a current focus of worldwide interest and finds application in a variety of areas of applied mathematics and statistics. In this thesis we focus on the approximation of A..=2b, where A 2 Rnn is a large, sparse symmetric positive definite matrix and b 2 Rn is a vector. In particular, we will focus on matrix function techniques for sampling from Gaussian Markov random fields in applied statistics and the solution of fractional-in-space partial differential equations. Gaussian Markov random fields (GMRFs) are multivariate normal random variables characterised by a sparse precision (inverse covariance) matrix. GMRFs are popular models in computational spatial statistics as the sparse structure can be exploited, typically through the use of the sparse Cholesky decomposition, to construct fast sampling methods. It is well known, however, that for sufficiently large problems, iterative methods for solving linear systems outperform direct methods. Fractional-in-space partial differential equations arise in models of processes undergoing anomalous diffusion. Unfortunately, as the fractional Laplacian is a non-local operator, numerical methods based on the direct discretisation of these equations typically requires the solution of dense linear systems, which is impractical for fine discretisations. In this thesis, novel applications of Krylov subspace approximations to matrix functions for both of these problems are investigated. Matrix functions arise when sampling from a GMRF by noting that the Cholesky decomposition A = LLT is, essentially, a `square root' of the precision matrix A. Therefore, we can replace the usual sampling method, which forms x = L..T z, with x = A..1=2z, where z is a vector of independent and identically distributed standard normal random variables. Similarly, the matrix transfer technique can be used to build solutions to the fractional Poisson equation of the form n = A..=2b, where A is the finite difference approximation to the Laplacian. Hence both applications require the approximation of f(A)b, where f(t) = t..=2 and A is sparse. In this thesis we will compare the Lanczos approximation, the shift-and-invert Lanczos approximation, the extended Krylov subspace method, rational approximations and the restarted Lanczos approximation for approximating matrix functions of this form. A number of new and novel results are presented in this thesis. Firstly, we prove the convergence of the matrix transfer technique for the solution of the fractional Poisson equation and we give conditions by which the finite difference discretisation can be replaced by other methods for discretising the Laplacian. We then investigate a number of methods for approximating matrix functions of the form A..=2b and investigate stopping criteria for these methods. In particular, we derive a new method for restarting the Lanczos approximation to f(A)b. We then apply these techniques to the problem of sampling from a GMRF and construct a full suite of methods for sampling conditioned on linear constraints and approximating the likelihood. Finally, we consider the problem of sampling from a generalised Matern random field, which combines our techniques for solving fractional-in-space partial differential equations with our method for sampling from GMRFs.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Fractional Laplacian, Fractional Poisson equation, Generalised Matern random field, Gaussian Markov random field, Krylov subspace, Lanczos approximation, M-Lanczos approximation, Matrix Functions, Matrix transfer technique, Restarted Lanczos approximation</field><field name="subject">Stieltjes transform</field><field name="identifier">http://eprints.qut.edu.au/29751/</field><field name="validLink">True</field></doc><doc><field name="title">Hypercapitalism : an investigation into the relationship between language, new media, and social perceptions of value 
</field><field name="creator">Graham, Philip W.</field><field name="description">Overall, this thesis purports to make two significant contributions to knowledge. The first is a foundational critique of political economy in the context of an emergent global knowledge economy. The second is a method for analysing evaluations in language. The relationships that give coherence to those two contributions are as follows. The widely-heralded emergence of a knowledge economy indicates that more intimate aspects of human activity have become exposed to commodification on a massive scale, specifically, activities associated with thought and language. Correspondingly, more abstract forms of value have developed as the products of thought and language have become dominant commodity forms. Historical investigation shows that value has moved from an objective category in political economy, pertaining to such substances as precious metals and land, to become situated today predominantly in &#8220;expert&#8221; expressions of language, or more precisely, their institutional contexts of production. These are now propagated and circulated on a global scale. Legal, political, and technological developments are key in the development of new, more abstract forms of labour and value, although the relationships connecting these are neither simple nor direct. They are, however, inseparably related in the trajectories that this thesis describes. Consequently they are dealt with inseparably throughout.</field><field name="date">2001</field><field name="language" /><field name="relation" /><field name="subject">capitalism, language, media, social perceptions of value</field><field name="identifier">http://eprints.qut.edu.au/29761/</field><field name="validLink">True</field></doc><doc><field name="title">A psychosocial approach to understanding young Australians' mobile phone behaviour</field><field name="creator">Walsh, Shari Poldi</field><field name="description">This thesis by publication contributes to our knowledge of psychological factors underlying a modern day phenomenon, young people&#8217;s mobile phone behaviour. Specifically, the thesis reports a PhD program of research which adopted a social psychological approach to explore mobile phone behaviour among young Australians aged between 15 and 24 years. A particular focus of the research program was to explore both the cognitive and behavioural aspects of young people&#8217;s mobile phone behaviour which for the purposes of this thesis is defined as mobile phone involvement. The research program comprised three separate stages which were developmental in nature, in that, the findings of each stage of the research program informed the next.
 The overarching goal of the program of research was to improve our understanding of the psychosocial factors influencing young people&#8217;s mobile phone behaviour. To achieve this overall goal, there were a number of aims to the research program which reflect the developmental nature of this thesis. Given the limited research into the mobile phone behaviour in Australia, the first two aims of the research program were to explore patterns of mobile phone behaviour among Australian youth and explore the social psychological factors relating to their mobile phone behaviour. Following this exploration, the research program sought to develop a measure which captures the cognitive and behavioural aspects of mobile phone behaviour. Finally, the research program aimed to examine and differentiate the psychosocial predictors of young people&#8217;s frequency of mobile phone use and their level of involvement with their mobile phone. 
 Both qualitative and quantitative methodologies were used throughout the program of research. Five papers prepared during the three stages of the research program form the bulk of this thesis. The first stage of the research program was a qualitative investigation of young people&#8217;s mobile phone behaviour. Thirty-two young Australians participated in a series of focus groups in which they discussed their mobile phone behaviour. Thematic data analysis explored patterns of mobile phone behaviour among young people, developed an understanding of psychological factors influencing their use of mobile phones, and identified that symptoms of addiction were emerging in young people&#8217;s mobile phone behaviour. Two papers (Papers 1 and 2) emanated from this first stage of the research program. 
 Paper 1 explored patterns of mobile phone behaviour and revealed that mobile phones were perceived as being highly beneficial to young people&#8217;s lives, with the ability to remain in constant contact with others being particularly valued. The paper also identified that symptoms of behavioural addiction including withdrawal, cognitive and behavioural salience, and loss of control, emerged in participants&#8217; descriptions of their mobile phone behaviour. Paper 2 explored how young people&#8217;s need to belong and their social identity (two constructs previously unexplored in the context of mobile phone behaviour) related to their mobile phone behaviour. It was revealed that young people use their mobile phones to facilitate social attachments. Additionally, friends and peers influenced young people&#8217;s mobile phone behaviour; for example, their choice of mobile phone carrier and their most frequent type of mobile phone use. These papers laid the foundation for the further investigation of addictive patterns of behaviour and the role of social psychological factors on young people&#8217;s mobile behaviour throughout the research program.
	Stage 2 of the research program focussed on developing a new parsimonious measure of mobile phone behaviour, the Mobile Phone Involvement Questionnaire (MPIQ), which captured the cognitive and behavioural aspects of mobile phone use. Additionally, the stage included a preliminary exploration of factors influencing young people&#8217;s mobile phone behaviour. Participants (N = 946) completed a questionnaire which included a pool of items assessing symptoms of behavioural addiction, the uses and gratifications relating to mobile phone use, and self-identity and validation from others in the context of mobile phone behaviour. Two papers (Papers 3 &amp; 4) emanated from the second stage of the research program. 
 Paper 3 provided an important link between the qualitative and quantitative components of the research program. Qualitative data from Stage 1 indicated the reasons young people use their mobile phones and identified addictive characteristics present in young people&#8217;s mobile phone behaviour. Results of the quantitative study conducted in Stage 2 of the research program revealed the uses and gratifications relating to young people&#8217;s mobile phone behaviour and the effect of these gratifications on young people&#8217;s frequency of mobile phone use and three indicators of addiction, withdrawal, salience, and loss of control. Three major uses and gratifications: self (such as feeling good or as a fashion item), social (such as contacting friends), and security (such as use in an emergency) were found to underlie much of young people&#8217;s mobile phone behaviour. Self and social gratifications predicted young people&#8217;s frequency of mobile phone use and the three indicators of addiction but security gratifications did not. These results provided an important foundation for the inclusion of more specific psychosocial predictors in the later stages of the research program.
 Paper 4 reported the development of the mobile phone involvement questionnaire and a preliminary exploration of the effect of self-identity and validation from others on young people&#8217;s mobile phone behaviour. The MPIQ assessed a unitary construct and was a reliable measure amongst this cohort. Results found that self-identity influenced the frequency of young people&#8217;s use whereas self-identity and validation from others influenced their level of mobile phone involvement. These findings provided an important indication that, in addition to self factors, other people have a strong influence on young people&#8217;s involvement with their mobile phone and that mobile phone involvement is conceptually different to frequency of mobile phone use. 
 Stage 3 of the research program empirically examined the psychosocial predictors of young people&#8217;s mobile behaviour and one paper, Paper 5, emanated from this stage. Young people (N = 292) from throughout Australia completed an online survey assessing the role of self-identity, ingroup norm, the need to belong, and self-esteem on their frequency of mobile phone use and their mobile phone involvement. Self-identity was the only psychosocial predictor of young people&#8217;s frequency of mobile phone use. In contrast, self-identity, ingroup norm, and need to belong all influenced young people&#8217;s level of involvement with their mobile phone. Additionally, the effect of self-esteem on young people&#8217;s mobile phone involvement was mediated by their need to belong. These results indicate that young people who perceive their mobile phone to be an integral part of their self-identity, who perceive that mobile phone is common amongst friends and peers, and who have a strong need for attachment to others, in some cases driven by a desire to enhance their self-esteem, are most likely to become highly involved with their mobile phones. 
 Overall, this PhD program of research has provided an important contribution to our understanding of young Australians&#8217; mobile phone behaviour. Results of the program have broadened our knowledge of factors influencing mobile phone behaviour beyond the approaches used in previous research. The use of various social psychological theories combined with a behavioural addiction framework provided a novel examination of young people&#8217;s mobile behaviour. In particular, the development of a new measure of mobile phone behaviour in the research program facilitated the differentiation of the psychosocial factors influencing frequency of young people&#8217;s mobile phone behaviour and their level of involvement with their mobile phone. Results of the research program indicate the important role that mobile phone behaviour plays in young people&#8217;s social development and also signals the characteristics of those people who may become highly involved with their mobile phone. Future research could build on this thesis by exploring whether mobile phones are affecting traditional social psychological processes and whether the results in this research program are generalisable to other cohorts and other communication technologies.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">mobile phone, Australia, youth, social psychology, self-identity, social identity, need to belong, self-esteem, addiction, behaviour</field><field name="identifier">http://eprints.qut.edu.au/29799/</field><field name="validLink">True</field></doc><doc><field name="title">Personalised ontology learning and mining for web information gathering</field><field name="creator">Tao, Xiaohui</field><field name="description">Over the last decade, the rapid growth and adoption of the World Wide Web has further exacerbated user needs for e&#177;cient mechanisms for information and knowledge location, selection, and retrieval. How to gather useful and meaningful information from the Web becomes challenging to users. The capture of user information needs is key to delivering users' desired information, and user pro&#175;les can help to capture information needs. However, e&#174;ectively acquiring user pro&#175;les is di&#177;cult. It is argued that if user background knowledge can be speci&#175;ed by ontolo- gies, more accurate user pro&#175;les can be acquired and thus information needs can be captured e&#174;ectively. Web users implicitly possess concept models that are obtained from their experience and education, and use the concept models in information gathering. Prior to this work, much research has attempted to use ontologies to specify user background knowledge and user concept models. However, these works have a drawback in that they cannot move beyond the subsumption of super - and sub-class structure to emphasising the speci&#175;c se- mantic relations in a single computational model. This has also been a challenge for years in the knowledge engineering community. Thus, using ontologies to represent user concept models and to acquire user pro&#175;les remains an unsolved problem in personalised Web information gathering and knowledge engineering. In this thesis, an ontology learning and mining model is proposed to acquire user pro&#175;les for personalised Web information gathering. The proposed compu- tational model emphasises the speci&#175;c is-a and part-of semantic relations in one computational model. The world knowledge and users' Local Instance Reposito- ries are used to attempt to discover and specify user background knowledge. From a world knowledge base, personalised ontologies are constructed by adopting au- tomatic or semi-automatic techniques to extract user interest concepts, focusing on user information needs. A multidimensional ontology mining method, Speci- &#175;city and Exhaustivity, is also introduced in this thesis for analysing the user background knowledge discovered and speci&#175;ed in user personalised ontologies. The ontology learning and mining model is evaluated by comparing with human- based and state-of-the-art computational models in experiments, using a large, standard data set. The experimental results are promising for evaluation. The proposed ontology learning and mining model in this thesis helps to develop a better understanding of user pro&#175;le acquisition, thus providing better design of personalised Web information gathering systems. The contributions are increasingly signi&#175;cant, given both the rapid explosion of Web information in recent years and today's accessibility to the Internet and the full text world.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">ontology, user information needs, user profiles, web personalisation, web information gathering, specificity, exhaustivity, semantic relations, is-a, part-of, related-to, Library of Congress subject headings, world knowledge, local instance repository</field><field name="identifier">http://eprints.qut.edu.au/30278/</field><field name="validLink">True</field></doc><doc><field name="title">Primary students' group metacognitive processes in a computer supported collaborative learning environment</field><field name="creator">Chalmers, Christina</field><field name="description">The current understanding of students&#8217; group metacognition is limited. The research on metacognition has focused mainly on the individual student. The aim of this study was to address the void by developing a conceptual model to inform the use of scaffolds to facilitate group metacognition during mathematical problem solving in computer supported collaborative learning (CSCL) environments. An initial conceptual framework based on the literature from metacognition, cooperative learning, cooperative group metacognition, and computer supported collaborative learning was used to inform the study. In order to achieve the study aim, a design research methodology incorporating two cycles was used. The first cycle focused on the within-group metacognition for sixteen groups of primary school students working together around the computer; the second cycle included between-group metacognition for six groups of primary school students working together on the Knowledge Forum&#174; CSCL environment. The study found that providing groups with group metacognitive scaffolds resulted in groups planning, monitoring, and evaluating the task and team aspects of their group work. The metacognitive scaffolds allowed students to focus on how their group was completing the problem-solving task and working together as a team. From these findings, a revised conceptual model to inform the use of scaffolds to facilitate group metacognition during mathematical problem solving in computer supported collaborative learning (CSCL) environments was generated.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">computer supported collaborative learning (CSCL), group learning, group metacognition, group problem solving, groups, Knowledge Forum&#174;, online teams, shared understanding, task, team</field><field name="identifier">http://eprints.qut.edu.au/29819/</field><field name="validLink">True</field></doc><doc><field name="title">Flexural behaviour and design of cold-formed steel beams with rectangular hollow flanges</field><field name="creator">Wanniarachchi, Somadasa</field><field name="description">Until recently, the hot-rolled steel members have been recognized as the most popular and widely used steel group, but in recent times, the use of cold-formed high strength steel members has rapidly increased. However, the structural behavior of light gauge high strength cold-formed steel members characterized by various buckling modes is not yet fully understood. The current cold-formed steel sections such as C- and Z-sections are commonly used because of their simple forming procedures and easy connections, but they suffer from certain buckling modes. It is therefore important that these buckling modes are either delayed or eliminated to increase the ultimate capacity of these members. This research is therefore aimed at developing a new cold-formed steel beam with two torsionally rigid rectangular hollow flanges and a slender web formed using intermittent screw fastening to enhance the flexural capacity while maintaining a minimum fabrication cost. This thesis describes a detailed investigation into the structural behavior of this new Rectangular Hollow Flange Beam (RHFB), subjected to flexural action The first phase of this research included experimental investigations using thirty full scale lateral buckling tests and twenty two section moment capacity tests using specially designed test rigs to simulate the required loading and support conditions. A detailed description of the experimental methods, RHFB failure modes including local, lateral distortional and lateral torsional buckling modes, and moment capacity results is presented. A comparison of experimental results with the predictions from the current design rules and other design methods is also given. The second phase of this research involved a methodical and comprehensive investigation aimed at widening the scope of finite element analysis to investigate the buckling and ultimate failure behaviours of RHFBs subjected to flexural actions. Accurate finite element models simulating the physical conditions of both lateral buckling and section moment capacity tests were developed. Comparison of experimental and finite element analysis results showed that the buckling and ultimate failure behaviour of RHFBs can be simulated well using appropriate finite element models. Finite element models simulating ideal simply supported boundary conditions and a uniform moment loading were also developed in order to use in a detailed parametric study. The parametric study results were used to review the current design rules and to develop new design formulae for RHFBs subjected to local, lateral distortional and lateral torsional buckling effects. Finite element analysis results indicate that the discontinuity due to screw fastening has a noticeable influence only for members in the intermediate slenderness region. Investigations into different combinations of thicknesses in the flange and web indicate that increasing the flange thickness is more effective than web thickness in enhancing the flexural capacity of RHFBs. The current steel design standards, AS 4100 (1998) and AS/NZS 4600 (1996) are found sufficient to predict the section moment capacity of RHFBs. However, the results indicate that the AS/NZS 4600 is more accurate for slender sections whereas AS 4100 is more accurate for compact sections. The finite element analysis results further indicate that the current design rules given in AS/NZS 4600 is adequate in predicting the member moment capacity of RHFBs subject to lateral torsional buckling effects. However, they were inadequate in predicting the capacities of RHFBs subject to lateral distortional buckling effects. This thesis has therefore developed a new design formula to predict the lateral distortional buckling strength of RHFBs. Overall, this thesis has demonstrated that the innovative RHFB sections can perform well as economically and structurally efficient flexural members. Structural engineers and designers should make use of the new design rules and the validated existing design rules to design the most optimum RHFB sections depending on the type of applications. Intermittent screw fastening method has also been shown to be structurally adequate that also minimises the fabrication cost. Product manufacturers and builders should be able to make use of this in their applications.</field><field name="date">2005</field><field name="language" /><field name="relation" /><field name="subject">flexural behavior, hollow flange beams, rectangular hollow flange beams, cold-formed steel beams, distortional buckling, lateral tortional buckling, buckling tests, section moment capacity, finite element analysis</field><field name="identifier">http://eprints.qut.edu.au/29810/</field><field name="validLink">True</field></doc><doc><field name="title">Divining the martyr : a multimedia installation presentation on contemporary makeover surgery</field><field name="creator">Tamayo y Ortiz, Renee Isabel</field><field name="description">Divining the Martyr is a project developed in order to achieve the Master of Arts (Research) degree. This is composed of 70% creative work displayed in an exhibition and 30% written work contained in this exegesis. The project was developed through practice-led research in order to answer the question &#8220;In what ways can creative practice synthesize and illuminate issues of martyrdom in contemporary makeover culture?&#8221; The question is answered using a postmodern framework about martyrdom as it is manifested in contemporary society. The themes analyzed throughout this exegesis relate to concepts about sainthood and makeover culture combined with actual examples of tragic cases of cosmetic procedures. The outcomes of this project fused three elements: Mexican cultural history, Mexican (Catholic) religious traditions, and cosmetic makeover surgery. The final outcomes were a series of installations integrating contemporary and traditional interdisciplinary media, such as sound, light, x-ray technology, sculpture, video and aspects of performance. These creative works complement each other in their presentation and concept, promoting an original contribution to the theme of contemporary martyrdom in makeover culture.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">cosmetic surgery, makeover culture, multimedia installation, creative practice as research, practice-led methodology, saints, pagan saints, martyrdom, Mexican religion and culture</field><field name="identifier">http://eprints.qut.edu.au/29815/</field><field name="validLink">True</field></doc><doc><field name="title">Radiological aspects of petroleum exploration and production in the sultanate of Oman</field><field name="creator">Al-Farsi, Afkar Nadhim</field><field name="description">This thesis is a study of naturally occurring radioactive materials (NORM) activity concentration, gamma dose rate and radon (222Rn) exhalation from the waste streams of large-scale onshore petroleum operations. Types of activities covered included; sludge recovery from separation tanks, sludge farming, NORM storage, scaling in oil tubulars, scaling in gas production and sedimentation in produced water evaporation ponds. Field work was conducted in the arid desert terrain of an operational oil exploration and production region in the Sultanate of Oman.
 
 The main radionuclides found were 226Ra and 210Pb (238U - series), 228Ra and 228Th (232Th - series), and 227Ac (235U - series), along with 40K. All activity concentrations were higher than the ambient soil level and varied over several orders of magnitude. The range of gamma dose rates at a 1 m height above ground for the farm treated sludge had a range of 0.06 0.43 &#181;Sv h 1, and an average close to the ambient soil mean of 0.086 &#177; 0.014 &#181;Sv h 1, whereas the untreated sludge gamma dose rates had a range of 0.07 1.78 &#181;Sv h 1, and a mean of 0.456 &#177; 0.303 &#181;Sv h 1. The geometric mean of ambient soil 222Rn exhalation rate for area surrounding the sludge was   mBq m 2 s 1. Radon exhalation rates reported in oil waste products were all higher than the ambient soil value and varied over three orders of magnitude.
 
 This study resulted in some unique findings including: (i) detection of radiotoxic 227Ac in the oil scales and sludge, (ii) need of a new empirical relation between petroleum sludge activity concentrations and gamma dose rates, and (iii) assessment of exhalation of 222Rn from oil sludge. Additionally the study investigated a method to determine oil scale and sludge age by the use of inherent behaviour of radionuclides as 228Ra:226Ra and 228Th:228Ra activity ratios.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">NORM, radiological, petroleum, mining, dating, sludge farming, separation tanks, radium, thorium, radon, lead-210, actinium, potassium, gamma spectroscopy, gamma dose rate, 222Rn exhalation, sludge, oil scales, gas scales, evaporation pond sediment</field><field name="subject">ambient soil, Oman</field><field name="identifier">http://eprints.qut.edu.au/29817/</field><field name="validLink">True</field></doc><doc><field name="title">Factors affecting reproductive performance of the prawn, Penaeus monodon</field><field name="creator">Marsden, Gay Elizabeth</field><field name="description">The growth of the Penaeus monodon prawn aquaculture industry in Australia is hampered by a reliance on wild-caught broodstock. This species has proven difficult to breed from if broodstock are reared in captivity. Studies were therefore carried out to investigate factors controlling reproduction and influencing egg quality. 
 
 Results of the studies revealed that patterns of nutrient accumulation during early ovary development are altered by captive conditions, possibly contributing to reduce larval quality. The sinus gland hormones were shown, together with the environment, to regulate two stages of ovary development. In a separate study it was further revealed that the hormone methyl farnesoate (MF) could negatively regulate the final stages of ovary development. Lastly it was shown that broodstock reared in captivity are less likely to mate and that this is due to inherent problems in both the male and the female prawns.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">Penaeus monodon, prawn reproduction, ovary, eggs, hepatopancreas, mating, methyl farnesoate, ablation, captivity, sinus gland hormones, fatty acids, lipid, protein</field><field name="identifier">http://eprints.qut.edu.au/29912/</field><field name="validLink">True</field></doc><doc><field name="title">Trends in demographic, health behaviour factors, and self-perceived weight status : influences on obesity in Australia from 1995 to 2005</field><field name="creator">Lee, Yi-Chen</field><field name="description">Overweight and obesity are two of the most important emerging public health issues in our time and regarded by the World Health Organisation [WHO] (1998) as a worldwide epidemic. The prevalence of obesity in the USA is the highest in the world, and Australian obesity rates fall into second place. Currently, about 60% of Australian adults are overweight (BMI &#8222;d 25kg/m2). The socio-demographic factors associated with overweight and/or obesity have been well demonstrated, but many of the existing studies only examined these relationships at one point of time, and did not examine whether significant relationships changed over time. Furthermore, only limited previous research has examined the issue of the relationship between perception of weight status and actual weight status, as well as factors that may impact on people&#161;&#166;s perception of their body weight status. Aims: The aims of the proposed research are to analyse the discrepancy between perceptions of weight status and actual weight status in Australian adults; to examine if there are trends in perceptions of weight status in adults between 1995 to 2004/5; and to propose a range of health promotion strategies and furth er research that may be useful in managing physical activity, healthy diet, and weight reduction. Hypotheses: Four alternate hypotheses are examined by the research: (1) there are associations between independent variables (e.g. socio -demographic factors, physical activity and dietary habits) and overweight and/or obesity; (2) there are associations between the same independent variables and the perception of overweight; (3) there are associations between the same independent variables and the discrepancy between weight status and perception of weight status; and (4) there are trends in overweight and/or obesity, perception of overweight, and the discrepancy in Australian adults from 1995 to 2004/5. Conceptual Framework and Methods: A conceptual framework is developed that shows the associations identified among socio -demographic factors, physical activity and dietary habits with actual weight status, as well as examining perception of weight status. The three latest National Health Survey data bases (1995 , 2001 and 2004/5) were used as the primary data sources. A total of 74,114 Australian adults aged 20 years and over were recruited from these databases. Descriptive statistics, bivariate analyses (One -Way ANOVA tests, unpaired t-tests and Pearson chi-square tests), and multinomial logistic regression modelling were used to analyse the data. Findings: This research reveals that gender, main language spoken at home, occupation status, household structure, private health insurance status, and exercise are related to the discrepancy between actual weight status and perception of weight status, but only gender and exercise are related to the discrepancy across the three time point s. The current research provides more knowledge about perception of weight status independently. Factors which affect perception of overweight are gender, age, language spoken at home, private health insurance status, and diet ary habits. The study also finds that many factors that impact overweight and/or obesity also have an effect on perception of overweight, such as age, language spoken at home, household structure, and exercise. However, some factors (i.e. private health insurance status and milk consumption) only impact on perception of overweight. Furthermore, factors that are rel ated to people&#8217;s overweight are not totally related to people&#8217;s underestimation of their body weight status in the study results. Thus, there are unknown factors which can affect people&#8217;s underestimation of their body weight status.  Conclusions: Health promotion and education activities should provide education about population health education and promotion and education for particular at risk sub -groups. Further research should take the form of a longitudinal study design ed to examine the causal relationship between overweight and/or obesity and underestimation of body weight status, it should also place more attention on the relationships between overweight and/or obesity and dietary habits, with a more comprehensive representation of SES. Moreover, further research that deals with identification of characteristics about perception of weight status, in particular the underestimation of body weight status should be undertaken.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">overweight, obesity, perception of weight status</field><field name="identifier">http://eprints.qut.edu.au/29883/</field><field name="validLink">True</field></doc><doc><field name="title">Kallikrein-related peptidase 4 activation of protease-activated receptor family members and association with prostate cancer</field><field name="creator">Ramsay, Andrew John</field><field name="description">Two areas of particular importance in prostate cancer progression are primary tumour development and metastasis. These processes involve a number of physiological events, the mediators of which are still being discovered and characterised. Serine proteases have been shown to play a major role in cancer invasion and metastasis. The recently discovered phenomenon of their activation of a receptor family known as the protease activated receptors (PARs) has extended their physiological role to that of signaling molecule. Several serine proteases are expressed by malignant prostate cancer cells, including members of the kallikreinrelated peptidase (KLK) serine protease family, and increasingly these are being shown to be associated with prostate cancer progression. KLK4 is highly expressed in the prostate and expression levels increase during prostate cancer progression. Critically, recent studies have implicated KLK4 in processes associated with cancer. For example, the ectopic over-expression of KLK4 in prostate cancer cell lines results in an increased ability of these cells to form colonies, proliferate and migrate. In addition, it has been demonstrated that KLK4 is a potential mediator of cellular interactions between prostate cancer cells and osteoblasts (bone forming cells). The ability of KLK4 to influence cellular behaviour is believed to be through the selective cleavage of specific substrates. Identification of relevant in vivo substrates of KLK4 is critical to understanding the pathophysiological roles of this enzyme. Significantly, recent reports have demonstrated that several members of the KLK family are able to activate PARs. The PARs are relatively new members of the seven transmembrane domain containing G protein coupled receptor (GPCR) family. PARs are activated through proteolytic cleavage of their N-terminus by serine proteases, the resulting nascent N-terminal binds intramolecularly to initiate receptor activation. PARs are involved in a number of patho-physiological processes, including vascular repair and inflammation, and a growing body of evidence suggests roles in cancer. While expression of PAR family members has been documented in several types of cancers, including prostate, the role of these GPCRs in prostate cancer development and progression is yet to be examined. Interestingly, several studies have suggested potential roles in cellular invasion through the induction of cytoskeletal reorganisation and expression of basement membrane-degrading enzymes. Accordingly, this program of research focussed on the activation of the PARs by the prostate cancer associated enzyme KLK4, cellular processing of activated PARs and the expression pattern of receptor and agonist in prostate cancer. For these studies KLK4 was purified from the conditioned media of stably transfected Sf9 insect cells expressing a construct containing the complete human KLK4 coding sequence in frame with a V5 epitope and poly-histidine encoding sequences. The first aspect of this study was the further characterisation of this recombinant zymogen form of KLK4. The recombinant KLK4 zymogen was demonstrated to be activatable by the metalloendopeptidase thermolysin and amino terminal sequencing indicated that thermolysin activated KLK4 had the predicted N-terminus of mature active KLK4 (31IINED). Critically, removal of the pro-region successfully generated a catalytically active enzyme, with comparable activity to a previously published recombinant KLK4 produced from S2 insect cells. The second aspect of this study was the activation of the PARs by KLK4 and the initiation of signal transduction. This study demonstrated that KLK4 can activate PAR-1 and PAR-2 to mobilise intracellular Ca2+, but failed to activate PAR-4. Further, KLK4 activated PAR-1 and PAR-2 over distinct concentration ranges, with KLK4 activation and mobilisation of Ca2+ demonstrating higher efficacy through PAR-2. Thus, the remainder of this study focussed on PAR-2. KLK4 was demonstrated to directly cleave a synthetic peptide that mimicked the PAR-2 Nterminal activation sequence. Further, KLK4 mediated Ca2+ mobilisation through PAR-2 was accompanied by the initiation of the extra-cellular regulated kinase (ERK) cascade. The specificity of intracellular signaling mediated through PAR-2 by KLK4 activation was demonstrated by siRNA mediated protein depletion, with a reduction in PAR-2 protein levels correlating to a reduction in KLK4 mediated Ca2+mobilisation and ERK phosphorylation. The third aspect of this study examined cellular processing of KLK4 activated PAR- 2 in a prostate cancer cell line. PAR-2 was demonstrated to be expressed by five prostate derived cell lines including the prostate cancer cell line PC-3. It was also demonstrated by flow cytometry and confocal microscopy analyses that activation of PC-3 cell surface PAR-2 by KLK4 leads to internalisation of this receptor in a time dependent manner. Critically, in vivo relevance of the interaction between KLK4 and PAR-2 was established by the observation of the co-expression of receptor and agonist in primary prostate cancer and prostate cancer bone lesion samples by immunohistochemical analysis. Based on the results of this study a number of exciting future studies have been proposed, including, delineating differences in KLK4 cellular signaling via PAR-1 and PAR-2 and the role of PAR-1 and PAR-2 activation by KLK4 in prostate cancer cells and bone cells in prostate cancer progression.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">prostate cancer, prostate cancer progression, bone metastasis, protease activated receptor (PAR), g protein coupled receptor (GPCR), kallikrein-related peptidase (KLK), serine protease, signal transduction, internalisation</field><field name="identifier">http://eprints.qut.edu.au/29886/</field><field name="validLink">True</field></doc><doc><field name="title">iLatin jazz! : a syncretic journey from Spain, Cuba, the United States and back</field><field name="creator">Gonzalez, Roger Oriol</field><field name="description">The creative work, &#161;Latin Jazz! is a 50 minute radio documentary to be broadcast on ABC Classic FM. It looks at the evolution of Latin jazz from Spain, Cuba and the United States. It examines the social effects on the style and specifically on the syncretic movement between the countries. The documentary traces my travel to Madrid, Spain and looks at Latin jazz through a deconstruction of the style, musical examples and interviews with prominent artists. Artists interviewed were Chano Dom&#237;nguez, a Spanish flamenco jazz pianist, Bobby Mart&#237;nez an American saxophonist, Alain P&#233;rez a Cuban bassist and Pepe Rivero a Cuban pianist. The exegesis supports the radio documentary by examining the style in more depth, and is broken into three main sections. First it traces the historical relationship that occurred through the Ida y Vuelta (To and Fro), the similarities and influences through the habanera, the dec&#237;ma and the religion of Santer&#237;a. This is followed by specific musical elements within Latin jazz such as instrumentation, clave, harmony and improvisation, whilst the third section looks at the influences of the new syncretic movement back to Spain.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">music, Latin jazz, rhythm, cross-cultural, Spain, Cuba, USA, percussion, clave</field><field name="identifier">http://eprints.qut.edu.au/29931/</field><field name="validLink">True</field></doc><doc><field name="title">Robot path planning in dynamic environments using a simulated annealing based approach</field><field name="creator">Miao, Hui</field><field name="description">Mobile robots are widely used in many industrial fields. Research on path planning for mobile robots is one of the most important aspects in mobile robots research. Path planning for a mobile robot is to find a collision-free route, through the robot&#8217;s environment with obstacles, from a specified start location to a desired goal destination while satisfying certain optimization criteria. Most of the existing path planning methods, such as the visibility graph, the cell decomposition, and the potential field are designed with the focus on static environments, in which there are only stationary obstacles. However, in practical systems such as Marine Science Research, Robots in Mining Industry, and RoboCup games, robots usually face dynamic environments, in which both moving and stationary obstacles exist. Because of the complexity of the dynamic environments, research on path planning in the environments with dynamic obstacles is limited. Limited numbers of papers have been published in this area in comparison with hundreds of reports on path planning in stationary environments in the open literature. 
 
 Recently, a genetic algorithm based approach has been introduced to plan the optimal path for a mobile robot in a dynamic environment with moving obstacles. However, with the increase of the number of the obstacles in the environment, and the changes of the moving speed and direction of the robot and obstacles, the size of the problem to be solved increases sharply. Consequently, the performance of the genetic algorithm based approach deteriorates significantly. This motivates the research of this work.
 
 This research develops and implements a simulated annealing algorithm based approach to find the optimal path for a mobile robot in a dynamic environment with moving obstacles. The simulated annealing algorithm is an optimization algorithm similar to the genetic algorithm in principle. However, our investigation and simulations have indicated that the simulated annealing algorithm based approach is simpler and easier to implement. Its performance is also shown to be superior to that of the genetic algorithm based approach in both online and offline processing times as well as in obtaining the optimal solution for path planning of the robot in the dynamic environment.
 
 The first step of many path planning methods is to search an initial feasible path for the robot. A commonly used method for searching the initial path is to randomly pick up some vertices of the obstacles in the search space. This is time consuming in both static and dynamic path planning, and has an important impact on the efficiency of the dynamic path planning. This research proposes a heuristic method to search the feasible initial path efficiently. Then, the heuristic method is incorporated into the proposed simulated annealing algorithm based approach for dynamic robot path planning. Simulation experiments have shown that with the incorporation of the heuristic method, the developed simulated annealing algorithm based approach requires much shorter processing time to get the optimal solutions in the dynamic path planning problem. Furthermore, the quality of the solution, as characterized by the length of the planned path, is also improved with the incorporated heuristic method in the simulated annealing based approach for both online and offline path planning.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">robots, path planning</field><field name="identifier">http://eprints.qut.edu.au/29911/</field><field name="validLink">True</field></doc><doc><field name="title">Complementarity and the uncertainty principle as aesthetic principles : the practice and performance of The Physics Project</field><field name="creator">Mercer, Leah Gwenyth</field><field name="description">Using the generative processes developed over two stages of creative development and the performance of The Physics Project at the Loft at the Creative Industries Precinct at the Queensland University of Technology (QUT) from 5th &#8211; 8th April 2006 as a case study, this exegesis considers how the principles of contemporary physics can be reframed as aesthetic principles in the creation of contemporary performance. The Physics Project is an original performance work that melds live performance, video and web-casting and overlaps an exploration of personal identity with the physics of space, time, light and complementarity. It considers the acts of translation between the language of physics and the language of contemporary performance that occur via process and form. This exegesis also examines the devices in contemporary performance making and contemporary performance that extend the reach of the performance, including the integration of the live and the mediated and the use of metanarratives.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">complementarity, contemporary performance, live and mediated performance, metanarrative, metaphor, prosthesis, quantum mechanics, synchronicity, transcendence, the uncertainty principle and zeitgeist</field><field name="identifier">http://eprints.qut.edu.au/29938/</field><field name="validLink">True</field></doc><doc><field name="title">The nature and extent of policing alcohol related crime and reducing violence in and around late night entertainment areas</field><field name="creator">Palk, Gavan Roger Mark</field><field name="description">The misuse of alcohol is well documented in Australia and has been associated with disorders and harms that often require police attention. The extent of alcohol-related incidents requiring police attention has been recorded as substantial in some Australian cities (Arro, Crook, &amp; Fenton, 1992; Davey &amp; French, 1995; Ireland &amp; Thommeny, 1993).  A significant proportion of harmful drinking occurs in and around licensed premises (Jochelson, 1997; Stockwell, Masters, Phillips, Daly, Gahegan, Midford, &amp; Philp, 1998; Borges, Cherpitel, &amp; Rosovsky, 1998) and most of these incidents are not reported to police (Bryant &amp; Williams, 2000; Lister, Hobbs, Hall, &amp; Winlow, 2000). Alcohol-related incidents have also been found to be concentrated in certain places at certain times (Jochelson, 1997) and therefore manipulating the context in which these incidents occur may provide a means to prevent and reduce the harm associated with alcohol misuse. 
 One of the major objectives of the present program of research was to investigate the occurrence and resource impact of alcohol-related incidents on operational (general duties) policing across a large geographical area. A second objective of the thesis was to examine the characteristics and temporal/spatial dynamics of police attended alcohol incidents in the context of Place Based theories of crime. It was envisaged that this approach would reveal the patterns of the most prevalent offences and demonstrate the relevance of Place Based theories of crime to understanding these patterns. In addition, the role of alcohol, time and place were also explored in order to examine the association between non criminal traffic offences and other types of criminal offences. A final objective of the thesis was to examine the impact of a situational crime prevention strategy that had been initiated to reduce the violence and disorder associated with late-night liquor trading premises. 
 The program of research in this doctorate thesis has been undertaken through the presentation of published papers. The research was conducted in three stages which produced six manuscripts, five of which were submitted to peer reviewed journals and one that was published in a peer reviewed conference proceedings. Stage One included two studies (Studies 1 &amp; 2) both of which involved a cross sectional approach to examine the prevalence and characteristics of alcohol-related incidents requiring police attendance across three large geographical areas that included metropolitan cities, provincial regions and rural areas. Stage Two of the program of research also comprised two cross sectional quantitative studies (Studies 3 &amp; 4) that investigated the temporal and spatial dynamics of the major offence categories attended by operational police in a specific Police District (Gold Coast). Stage Three of the program of research involved two studies (Studies 5 &amp; 6) that assessed the effectiveness of a situational crime prevention strategy. The studies employed a pre-post design to assess the impact on crime, disorder and violence by preventing patrons from entering late-night liquor trading premises between 3 a.m. and 5 a.m. (lockout policy). Although Study Five was solely quantitative in nature, Study Six included both quantitative and qualitative aspects. The approach adopted in Study Six, therefore facilitated not only a quantative comparison of the impact of the lockout policy on different policing areas, but also enabled the processes related to the implementation of the lockout policy to be examined.
 The thesis reports a program of research involving a common data collection method which then involved a series of studies being conducted to explore different aspects of the data. The data was collected from three sources. Firstly a pilot phase was undertaken to provide participants with training. Secondly a main study period was undertaken immediately following the pilot phase. The first and second sources of data were collected between 29th March 2004 and 2nd May 2004. Thirdly, additional data was collected between the 1st April 2005 and 31st May 2005. 
 Participants in the current program of research were first response operational police officers who completed a modified activity log over a 9 week period (4 week pilot phase &amp; 5 week survey study phase), identifying the type, prevalence and characteristics of alcohol-related incidents that were attended. During the study period police officers attended 31,090 alcohol-related incidents. Studies One and Two revealed that a substantial proportion of current police work involves attendance at alcohol-related incidents (i.e., 25% largely involving young males aged between 17 and 24 years).  The most common incidents police attended were vehicle and/or traffic matters, disturbances and offences against property. The major category of offences most likely to involve alcohol included vehicle/traffic matters, disturbances and offences against the person (e.g., common &amp; serious assaults).   These events were most likely to occur in the late evenings and early hours of the morning on the weekends, and importantly, usually took longer for police to complete than non alcohol-related incidents.
 The findings in Studies Three and Four suggest that serious traffic offences, disturbances and offences against the person share similar characteristics and occur in concentrated places at similar times. In addition, it was found that time, place and incident type all have an influence on whether an incident attended by a police officer is alcohol-related.  Alcohol-related incidents are more likely to occur in particular locations in the late evenings and early mornings on the weekends. In particular, there was a strong association between the occurrence of alcohol-related disturbances and alcohol-related serious traffic offences in regards to place and time.  In general, stealing and property offences were not alcohol-related and occurred in daylight hours during weekdays.
 The results of Studies Five and Six were mixed. A number of alcohol-related offences requiring police attention were significantly reduced for some policing areas and for some types of offences following the implementation of the lockout policy. However, in some locations the lockout policy appeared to have a negative or minimal impact. Interviews with licensees revealed that although all were initially opposed to the lockout policy as they believed it would have a negative impact on business, most perceived some benefits from its introduction. Some of the benefits included, improved patron safety and the development of better business strategies to increase patron numbers.
 In conclusion, the overall findings of the six studies highlight the pervasive nature of alcohol across a range of criminal incidents, demonstrating the tremendous impact alcohol-related incidents have on police. The findings also demonstrate the importance of time and place in predicting the occurrence of alcohol-related offences. Although this program of research did not set out to test Place Based theories of crime, these theories were used to inform the interpretation of findings. The findings in the current research program provide evidence for the relevance of Place Based theories of crime to understanding the factors contributing to violence and disorder, and designing relevant crime prevention strategies. For instance, the results in Studies Five and Six provide supportive evidence that this novel lockout initiative can be beneficial for public safety by reducing some types of offences in particular areas in and around late-night liquor trading premises. Finally, intelligent-led policing initiatives based on problem oriented policing, such as the lockout policy examined in this thesis, have potential as a major crime prevention technique to reduce specific types of alcohol-related offences.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">policing, alcohol-related incidents, crime prevention, place based theories, problem oriented policing, lockout policy, late-night liquor trading</field><field name="identifier">http://eprints.qut.edu.au/29963/</field><field name="validLink">True</field></doc><doc><field name="title">Geological control of physiography in Southeast Queensland : a mult-scale analysis using GIS</field><field name="creator">Hodgkinson, Jane Helen</field><field name="description">The study reported here, constitutes a full review of the major geological events that have influenced the morphological development of the southeast Queensland region. Most importantly, it provides evidence that the region&#8217;s physiography continues to be geologically &#8216;active&#8217; and although earthquakes are presently few and of low magnitude, many past events and tectonic regimes continue to be strongly influential over drainage, morphology and topography. Southeast Queensland is typified by highland terrain of metasedimentary and igneous rocks that are parallel and close to younger, lowland coastal terrain. The region is currently situated in a passive margin tectonic setting that is now under compressive stress, although in the past, the region was subject to alternating extensional and compressive regimes. As part of the investigation, the effects of many past geological events upon landscape morphology have been assessed at multiple scales using features such as the location and orientation of drainage channels, topography, faults, fractures, scarps, cleavage, volcanic centres and deposits, and recent earthquake activity. A number of hypotheses for local geological evolution are proposed and discussed. This study has also utilised a geographic information system (GIS) approach that successfully amalgamates the various types and scales of datasets used. A new method of stream ordination has been developed and is used to compare the orientation of channels of similar orders with rock fabric, in a topologically controlled approach that other ordering systems are unable to achieve. Stream pattern analysis has been performed and the results provide evidence that many drainage systems in southeast Queensland are controlled by known geological structures and by past geological events. The results conclude that drainage at a fine scale is controlled by cleavage, joints and faults, and at a broader scale, large river valleys, such as those of the Brisbane River and North Pine River, closely follow the location of faults. These rivers appear to have become entrenched by differential weathering along these planes of weakness. Significantly, stream pattern analysis has also identified some &#8216;anomalous&#8217; drainage that suggests the orientations of these watercourses are geologically controlled, but by unknown causes. To the north of Brisbane, a &#8216;coastal drainage divide&#8217; has been recognized and is described here. The divide crosses several lithological units of different age, continues parallel to the coast and prevents drainage from the highlands flowing directly to the coast for its entire length. Diversion of low order streams away from the divide may be evidence that a more recent process may be the driving force. Although there is no conclusive evidence for this at present, it is postulated that the divide may have been generated by uplift or doming associated with mid-Cenozoic volcanism or a blind thrust at depth. Also north of Brisbane, on the D&#8217;Aguilar Range, an elevated valley (the &#8216;Kilcoy Gap&#8217;) has been identified that may have once drained towards the coast and now displays reversed drainage that may have resulted from uplift along the coastal drainage divide and of the D&#8217;Aguilar blocks. An assessment of the distribution and intensity of recent earthquakes in the region indicates that activity may be associated with ancient faults. However, recent movement on these faults during these events would have been unlikely, given that earthquakes in the region are characteristically of low magnitude. There is, however, evidence that compressive stress is building and being released periodically and ancient faults may be a likely place for this stress to be released. The relationship between ancient fault systems and the Tweed Shield Volcano has also been discussed and it is suggested here that the volcanic activity was associated with renewed faulting on the Great Moreton Fault System during the Cenozoic. The geomorphology and drainage patterns of southeast Queensland have been compared with expected morphological characteristics found at passive and other tectonic settings, both in Australia and globally. Of note are the comparisons with the East Brazilian Highlands, the Gulf of Mexico and the Blue Ridge Escarpment, for example. In conclusion, the results of the study clearly show that, although the region is described as a passive margin, its complex, past geological history and present compressive stress regime provide a more intricate and varied landscape than would be expected along typical passive continental margins. The literature review provides background to the subject and discusses previous work and methods, whilst the findings are presented in three peer-reviewed, published papers. The methods, hypotheses, suggestions and evidence are discussed at length in the final chapter.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">geomorphology, GIS, drainage patterns, stream-ordering, Southeast Queensland, passive margin, earthquake distribution</field><field name="identifier">http://eprints.qut.edu.au/29968/</field><field name="validLink">True</field></doc><doc><field name="title">The impact of usability on clinician acceptance of a health information system</field><field name="creator">Croll, Jasmine</field><field name="description">The two longitudinal case studies that make up this dissertation sought to explain and predict the relationship between usability and clinician acceptance of a health information system. The overall aim of the research study was to determine what role usability plays in the acceptance or rejection of systems used by clinicians in a healthcare context. The focus was on the end users (the clinicians) rather than the views of the system designers and managers responsible for implementation and the clients of the clinicians.
 A mixed methods approach was adopted that drew on both qualitative and quantitative research methods. This study followed the implementation of a community health information system from early beginnings to its established practice. Users were drawn from different health service departments with distinctly different organisational cultures and attitudes to information and communication technology used in this context. 
 This study provided evidence that a usability analysis in this context would not necessarily be valid when the users have prior reservations on acceptance. Investigation was made on the initial training and post-implementation support together with a study on the nature of the clinicians to determine factors that may influence their attitude. 
 This research identified that acceptance of a system is not necessarily a measure of its quality, capability and usability, is influenced by the user&#8217;s attitude which is determined by outside factors, and the nature and quality of training. The need to recognise the limitations of the current methodologies for analysing usability and acceptance was explored to lay the foundations for further research.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">usability, acceptance, health information systems, training, evaluation, electronic health record, nature of clinician, case study, technology acceptance model, information and communication technologies</field><field name="identifier">http://eprints.qut.edu.au/29973/</field><field name="validLink">True</field></doc><doc><field name="title">Employee engagement : the development of a three dimensional model of engagement; and an exploration of its relationship with affective leader behaviours</field><field name="creator">De Lacy, Jonnie Catherine</field><field name="description">This study was designed to examine affective leader behaviours, and their impact on cognitive, affective and behavioural engagement.  Researchers (e.g., Cropanzano &amp; Mitchell, 2005; Moorman et al., 1998) have called for more research to be directed toward modelling and testing sets of relationships which better approximate the complexity associated with contemporary organisational experience. This research has attempted to do this by clarifying and defining the construct of engagement, and then by examining how each of the engagement dimensions are impacted by affective leader behaviours.  
 Specifically, a model was tested that identifies leader behaviour antecedents of cognitive, affective and behavioural engagement.  Data was collected from five public-sector organisations. Structural equation modelling was used to identify the relationships between the engagement dimensions and leader behaviours. The results suggested that affective leader behaviours had a substantial direct impact on cognitive engagement, which in turn influenced affective engagement, which then influenced intent to stay and extra-role performance. The results indicated a directional process for engagement, but particularly highlighted the significant impact of affective leader behaviours as an antecedent to engagement. 
 In general terms, the findings will provide a platform from which to develop a robust measure of engagement, and will be helpful to human resource practitioners interested in understanding the directional process of engagement and the importance of affective leadership as an antecedent to engagement.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">employee engagement, leadership</field><field name="identifier">http://eprints.qut.edu.au/29977/</field><field name="validLink">True</field></doc><doc><field name="title">Internetalisation : the Internet's influence on international market growth in the firm's outward internationalisation process</field><field name="creator">Mathews, Shane William</field><field name="description">It has been suggested that the Internet is the most significant driver of international trade in recent years to the extent that the term =internetalisation&#8216; has been coined (Bell, Deans, Ibbotson &amp; Sinkovics, 2001; Buttriss &amp; Wilkinson, 2003). This term is used to describe the Internet&#8216;s affect on the internationalisation process of the firm. Consequently, researchers have argued that the internationalisation process of the firm has altered due to the Internet, hence is in need of further investigation. However, as there is limited research and understanding, ambiguity remains in how the Internet has influenced international market growth. Thus, the purpose of this study was to explore how the Internet influences firms&#8216; internationalisation process, specifically, international market growth. To this end, Internet marketing and international market growth theories are used to illuminate this ambiguity in the body of knowledge. Thus, the research problem =How and why does the Internet influence international market growth of the firm&#8217; is justified for investigation. To explore the research question a two-stage approach is used. Firstly, twelve case studies were used to evaluate key concepts, generate hypotheses and to develop a model of Internetalisation for testing. The participants held key positions within their firm, so that rich data could be drawn from international market growth decision makers. Secondly, a quantitative confirmation process analysed the identified themes or constructs, using two hundred and twenty four valid responses. Constructs were evaluated through an exploratory factor analysis, confirmatory factor analysis and structural equation modelling process. Structural equation modelling was used to test the model of =internetalisation&#8216; to examine the interrelationships between the internationalisation process components: information availability, information usage, interaction communication, international mindset, business relationship usage, psychic distance, the Internet intensity of the firm and international market growth. This study found that the Internet intensity of the firm mediates information availability, information usage, international mindset, and business relationships when firms grow in international markets. Therefore, these results provide empirical evidence that the Internet has a positive influence on international information, knowledge, entrepreneurship and networks and these in turn influence international market growth. The theoretical contributions are three fold. Firstly, the study identifies a holistic model of the impact the Internet has had on the outward internationalisation of the firm. This contribution extends the body of knowledge pertaining to Internet international marketing by mapping and confirming interrelationships between the Internet, internationalisation and growth concepts. Secondly, the study highlights the broad scope and accelerated rate of international market growth of firms. Evidence that the Internet influences the traditional and virtual networks for the pursuit of international market growth extends the current understanding. Thirdly, this study confirms that international information, knowledge, entrepreneurship and network concepts are valid in a single model. Thus, these three contributions identify constructs, measure constructs in a multi-item capacity, map interrelationships and confirm single holistic model of &#8215;internetalisation&#8216;. The main practical contribution is that the findings identified information, knowledge and entrepreneurial opportunities for firms wishing to maximise international market growth. To capitalise on these opportunities suggestions are offered to assist firms to develop greater Internet intensity and internationalisation capabilities. From a policy perspective, educational institutions and government bodies need to promote more applied programs for Internet international marketing. The study provides future researchers with a platform of identified constructs and interrelationships related to internetalisation, with which to investigate. However, a single study has limitations of generalisability; thus, future research should replicate this study. Such replication or cross validation will assist in the verification of scales used in this research and enhance the validity of causal predications. Furthermore, this study was undertaken in the Australian outward-bound context. Research in other nations, as well as research into inbound internationalisation would be fruitful.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">international markets, growth, Internet, firms</field><field name="identifier">http://eprints.qut.edu.au/29979/</field><field name="validLink">True</field></doc><doc><field name="title">Characterisation of soluble components and PAH in PM10 atmospheric particulate matter in Brisbane</field><field name="creator">Kumar, Annakkarage</field><field name="description">Fours sets of PM10 samples were collected in three sites in SEQ from December 2002 to August 2004. Three of these sets of samples were collected by QLD EPA as a part of their regular air monitoring program at Woolloongabba, Rocklea and Eagle Farm. Half of the samples were used in this study for the analysis of water-soluble ions, which are Na+, K+, Mg2+, Ca2+, NH4 +, Cl-, NO3 -, SO4 2-, F-, Br-, NO2 -, PO4 -3 and the other half was retained by QLD EPA. The fourth set of samples was collected at Rocklea, specifically for this study. A quarter of the samples obtained from this set of samples were used to analyse water-soluble ions; a quarter of the sample was used to analyse Pb, Cu, Al, Fe, Mn and Zn; and the rests were used to analyse US EPA 16 priority PAHs. The water-soluble ions were extracted ultrasonically with water and the major watersoluble anions as well as NH4 + were analysed using IC. Na+, K+, Mg2+, Ca2+ Pb, Cu, Al, Fe, Mn and Zn were analysed using ICP-AES while PAHs were extracted by acetonitrile and analysed using HPLC. Of the analysed water-soluble ions, Cl-, NO3 -, SO4 2-, Na+, K+, Mg2+ and Ca2+ were high in concentration and determined in all the samples. F-, Br-, NO2 -, PO4 -3 and NH4 + ions were lower in concentration and determined only in some samples. Na+ and Cl- were high in all samples indicating the importance of a marine source. Principal Component Analysis (PCA) was used to examine the temporal variations of the water-soluble ions at the three sites. The results indicated that there was no major difference between the three sites. However, comparing the average concentrations of ions and Cl-/Na+ it was concluded that Woolloongabba had more marine influence than the other sites. Al, Fe and Zn were detected in all samples. Al and Fe were high in all samples indicating the significance of a source of crustal matter. Cu, Mn and Pb were in low concentrations and were determined only in some samples. The lower Pb concentrations observed in the study than in previous studies indicate that the phasing-out of leaded petrol had an appreciable impact on Pb levels in SEQ.  This study reports for the first time, simultaneous data on the water-soluble, metal ion and PAH levels of PM10 aerosols in Brisbane, and provides information on the most likely sources of these chemical species. Such information can be used alongside those that already exist to formulate PM10 pollution reduction strategies for SEQ in order to protect the community from the adverse effects of PM pollution.</field><field name="date">2008</field><field name="language" /><field name="relation" /><field name="subject">PM10, water-soluble ions, metal ions, Pb, Cu, Zn, Al, Fe, Mn, PAH, ion chromatography, HPLC, ICP-AES, PCA, diagnostic ratios</field><field name="identifier">http://eprints.qut.edu.au/30069/</field><field name="validLink">True</field></doc><doc><field name="title">Accounts of the visual art classroom : catering for artistically talented students</field><field name="creator">Vicig, Fiona Joy Ballantyne</field><field name="description">Inclusive education practices call for the diverse and individual needs of all students to be met satisfactorily. The needs and experiences of artistically talented students in Australian visual art classrooms are currently unknown. This study addresses this gap in research through an inquiry into the experiences of artistically talented students and their teachers in visual art classrooms, by examining the accounts of a group of students and teachers at one high school in South East Queensland. This study is significant as it provides teachers, parents and others involved in the education of artistically talented students with additional means to plan and cater for the educational needs of artistically talented students. Teacher and student accounts of the visual art classroom in this study indicated that identification processes for artistically talented students are unclear and contradictory. Furthermore, teacher and student accounts of their experiences presented a wide variety of conceptions of the visual art classroom and point towards an individualised approach to learning for artistically talented students. This study also discovered a mismatch between assessment practices in the subject visual art and assessment of art in the &#8216;real world&#8217;. Specifically, this study proposes a renewal of programs for artistically talented students, and recommends a revision of current procedures for the identification of artistically talented students in visual art classrooms.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">visual arts, classroom teaching, artistically talented students</field><field name="identifier">http://eprints.qut.edu.au/30129/</field><field name="validLink">True</field></doc><doc><field name="title">A phenomenological study of contemplative experiences : implications for interior design</field><field name="creator">Shah, Rinkle</field><field name="description">This research reports on a project concerned with the relationship between the person and the environment in the context of achieving a contemplative or existential state &#8211; a state which can be experienced either consciously or subconsciously. The need for such a study originated with the desire to contribute to the design of multicultural spaces which could be used for a range of activities within the public and the personal arena, activities including contemplation, meditation and prayer. The concept of &#8216;sacred&#8217; is explored in the literature review and in primary interviews with the participants of this study. Given that the word &#8216;sacred&#8217; is highly value-laden and potentially alienating for some people, it was decided to use the more accessible term &#8216;contemplative&#8217;. The outcomes of the study inform the practice of interior design and architecture which tends currently to neglect the potential for all spaces to be existentially meaningful. Informed by phenomenological methodology, data were collected from a diverse group of people, using photo-elicitation and interviews. The technique of photo-elicitation proved to be highly effective in helping people reveal their everyday lived experience of contemplative spaces. Reflective analysis (Van Manen 2000) was used to explore the data collected. The initial stage of analysis produced three categories of data: varying conceptions of contemplation, aspects of the person involved in the contemplation, and aspects of environment involved in contemplation. From this, it was found that achieving a state of contemplation involves both the person and the environment in a dialectic process of unfolding. The unfolding has various physical, psycho-social, and existential dimensions or qualities which operate sequentially and simultaneously. Two concepts emerged as being central to unfolding: &#8216;Cleansing&#8217; and &#8216;Nothingness&#8217;. Unfolding is found to comprise the Core; Distinction; Manifestation; Cleansing; Creation; and Sharing. This has a parallel with Mircea Eliade&#8217;s (1959) definition of sacred as something that manifests itself as different from the profane. The power of design, re-contextualization through utility and purpose, and the existential engagements between the person and environment are used as a basis for establishing the potential contribution of the study to interior design. In this way, the study makes a contribution to our understanding of how space and its elements inspire, support and sustain person environment interaction &#8211; particularly at the existential level &#8211; as well as to our understanding of the multi-dimensional and holistic nature of this interaction. In addition, it points to the need for a phenomenological re-conceptualisation of the design/client relationship. In summary, the contributions of this research are: the exploration of contemplative experience as sacred experience; an understanding of the design of space as creating engagement between person and environment; a rationale for the introduction of a phenomenological approach to the relationship between designer and clients; and raising awareness of the spiritual in a holistic approach to design.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">contemplative experience, phenomenology, existential experience, sacredness, sacred space experience, the unfolding, core, distinction, manifestation, creation, sharing, person-environment relationships, interior design</field><field name="identifier">http://eprints.qut.edu.au/30132/</field><field name="validLink">True</field></doc><doc><field name="title">The phenomenology of utopia : reimagining the political</field><field name="creator">Bahnisch, Mark Stefan</field><field name="description">This thesis argues that the end of Soviet Marxism and a bipolar global political imaginary at the dissolution of the short Twentieth Century poses an obstacle for anti-systemic political action. Such a blockage of alternate political imaginaries can be discerned by reading the work of Francis Fukuyama and "Endism" as performative invocations of the closure of political alternatives, and thus as an ideological proclamation which enables and constrains forms of social action.  It is contended that the search through dialectical thought for a competing universal to posit against "liberal democracy" is a fruitless one, because it reinscribes the terms of teleological theories of history which work to effect closure.
 
 Rather, constructing a phenomenological analytic of the political conjuncture, the thesis suggests that the figure of messianism without a Messiah is central to a deconstructive reframing of the possibilities of political action - a reframing attentive to the rhetorical tone of texts. The project of recovering the political is viewed through a phenomenological lens. An agonistic political distinction must be made so as to memorialise the remainders and ghosts of progress, and thus to gesture towards an indeconstructible justice which would serve as a horizon for the articulation of an empty universal.
 
 This project is furthered by a return to a certain phenomenology inspired by Cornelius Castoriadis, Claude Lefort, Maurice Merleau-Ponty and Ernesto Laclau. The thesis provides a reading of Jacques Derrida and Walter Benjamin as thinkers of a minor universalism, a non-prescriptive utopia, and places their work in the context of new understandings of religion and the political as quasi-transcendentals which can be utilised to think through the aporias of political time in order to grasp shards of meaning. Derrida and Chantal Mouffe's deconstructive critique and supplement to Carl Schmitt's concept of the political is read as suggestive of a reframing of political thought which would leave the political question open and thus enable the articulation of social imaginary significations able to inscribe meaning in the field of political action. Thus, the thesis gestures towards a form of thought which enables rather than constrains action under the sign of justice.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">political, political theory, sociology, phenomenology, global politics, neoliberalism, political imaginary, philosophy, universalism, Marxism, Cornelius Castoriadis, Jacques Derrida, Claude Lefort, Maurice Merleau-Ponty, Carl Schmitt, Chantal Mouffe, late</field><field name="identifier">http://eprints.qut.edu.au/30134/</field><field name="validLink">True</field></doc><doc><field name="title">Learning in the third space : a sociocultural perspective on learning with analogies</field><field name="creator">Bellocchi, Alberto</field><field name="description">Research on analogies in science education has focussed on student interpretation of teacher and textbook analogies, psychological aspects of learning with analogies and structured approaches for teaching with analogies.  Few studies have investigated how analogies might be pivotal in students&#8217; growing participation in chemical discourse.  To study analogies in this way requires a sociocultural perspective on learning that focuses on ways in which language, signs, symbols and practices mediate participation in chemical discourse.  This study reports research findings from a teacher-research study of two analogy-writing activities in a chemistry class.  The study began with a theoretical model, Third Space, which informed analyses and interpretation of data.  Third Space was operationalized into two sub-constructs called Dialogical Interactions and Hybrid Discourses.  The aims of this study were to investigate sociocultural aspects of learning chemistry with analogies in order to identify classroom activities where students generate Dialogical Interactions and Hybrid Discourses, and to refine the operationalization of Third Space.
 These aims were addressed through three research questions.  The research questions were studied through an instrumental case study design.  The study was conducted in my Year 11 chemistry class at City State High School for the duration of one Semester.  Data were generated through a range of data collection methods and analysed through discourse analysis using the Dialogical Interactions and Hybrid Discourse sub-constructs as coding categories.  Results indicated that student interactions differed between analogical activities and mathematical problem-solving activities.  Specifically, students drew on discourses other than school chemical discourse to construct analogies and their growing participation in chemical discourse was tracked using the Third Space model as an interpretive lens.
 Results of this study led to modification of the theoretical model adopted at the beginning of the study to a new model called Merged Discourse.  Merged Discourse represents the mutual relationship that formed during analogical activities between the Analog Discourse and the Target Discourse.  This model can be used for interpreting and analysing classroom discourse centred on analogical activities from sociocultural perspectives.  That is, it can be used to code classroom discourse to reveal students&#8217; growing participation with chemical (or scientific) discourse consistent with sociocultural perspectives on learning.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">analogies, metaphor, chemistry, science education, discourse, hybridity, hybridization, Third Space, merge, merged discourse, post-colonial, cultural theory, sociocultural</field><field name="identifier">http://eprints.qut.edu.au/30136/</field><field name="validLink">True</field></doc><doc><field name="title">Industrial playwriting : forms, strategies, and methods for creative production</field><field name="creator">Brook, Simon Richard</field><field name="description">This study, in its exploration of the attached play scripts and their method of development, evaluates the forms, strategies, and methods of an organised model of formalised playwriting. Through the examination, reflection and reaction to a perceived crisis in playwriting in the Australian theatre sector, the notion of Industrial Playwriting is arrived at: a practice whereby plays are designed and constructed, and where the process of writing becomes central to the efficient creation of new work and the improvement of the writer&#8217;s skill and knowledge base.
 
 Using a practice-led methodology and action research the study examines a system of play construction appropriate to and addressing the challenges of the contemporary Australian theatre sector.  Specifically, using the action research methodology known as design-based research a conceptual framework was constructed to form the basis of the notion of Industrial Playwriting.  From this two plays were constructed using a case study method and the process recorded and used to create a practical, step-by-step system of Industrial Playwriting. In the creative practice of manufacturing a single authored play, and then a group-devised play, Industrial Playwriting was tested and found to also offer a valid alternative approach to playwriting in the training of new and even emerging playwrights. Finally, it offered insight into how Industrial Playwriting could be used to greatly facilitate theatre companies&#8217; ongoing need to have access to new writers and new Australian works, and how it might form the basis of a cost effective writer development model.  This study of the methods of formalised writing as a means to confront some of the challenges of the Australian theatre sector, the practice of playwriting and the history associated with it, makes an original and important contribution to contemporary playwriting practice.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">playwriting, industrial playwriting, writer development models, Australian theatre history, new play production</field><field name="identifier">http://eprints.qut.edu.au/30137/</field><field name="validLink">True</field></doc><doc><field name="title">Reciprocity : where art meets the community : action research in response to artistic encounters and relationships</field><field name="creator">Filardo, Giuseppe</field><field name="description">This practice-led research project examines some of the factors and issues facing artists working in the public domain who wish to engage with the community as audience. Using the methodology of action research, the three major creative projects in this study use art as a socio-political tool with the aim of providing an effective vehicle for broadening awareness, understanding forms of social protest and increasing tolerance for diversity. The three projects: Floodline November 7, 2004, Look in, Look out, and The Urban Terrorist Project, dealt with issues of marginalisation of communities, audiences and graffiti artists respectively. The artist/researcher is outlined as both creator and collaborator in the work. Processes included ephemeral elements, such as temporary installation and performance, as well as interactive elements that encouraged direct audience involvement as part of the work. In addition to the roles of creator and collaborator, both of which included audience as well as artist, the presence of an outside entity was evident. Whether local, legal authorities or prevailing attitudes, outside entities had an unavoidable impact on the processes and outcomes of the work. Each project elicited a range of responses from their respective audiences; however, the overarching concept of reciprocity was seen to be the crucial factor in conception, artistic methods and outcomes.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">hit, graf, piece, bomb, tag, taggers, urban terrorist, community, flooding, mural, public art, Artforce, street art, writer, reciprocity, action, response, encounter, artistic, journey, engage</field><field name="identifier">http://eprints.qut.edu.au/30153/</field><field name="validLink">True</field></doc><doc><field name="title">Introducing Mr Perky : subverting the fantasy trope of immortality in contemporary speculative fiction</field><field name="creator">Ryan, Jennifer Joan</field><field name="description">The Tide Lords series of fantasy novels set out to examine the issue of immortality. Its purpose was to look at the desirability of immortality, specifically why people actively seek it. It was meant to examine the practicality of immortality, specifically &#8212; having got there, what does one do to pass the time with eternity to fill? I also wished to examine the notion of true immortality &#8212; immortals who could not be killed.
 
 What I did not anticipate when embarking upon this series, and what did not become apparent until after the series had been sold to two major publishing houses in Australia and the US, was the strength of the immortality tropes. This series was intended to fly in the face of these tropes, but confronted with the reality of such a work, the Australian publishers baulked at the ideas presented, requesting the series be re-written with the tropes taken into consideration. They wanted immortals who could die, mortals who wanted to be immortal. And a hero with a sense of humour.
 
 This exegesis aims to explore where these tropes originated. It will also discuss the ways I negotiated a way around the tropes, and was eventually able to please the publishers by appearing to adhere to the tropes, while still staying true to the story I wanted to tell. As such, this discussion is, in part, an analysis of how an author negotiates the tensions around writing within a genre while trying to innovate within it.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Key Words fantasy, immortal, immortality, fantasy tropes, immortality tropes, desire for immortality, fiction, genre fiction, publishing, ways to kill immortals, plot device, Fallon, Canavan, Tolkien</field><field name="identifier">http://eprints.qut.edu.au/30242/</field><field name="validLink">True</field></doc><doc><field name="title">Modelling water droplet movement on a leaf surface</field><field name="creator">Oqielat, Moa'ath Nasser</field><field name="description">The central aim for the research undertaken in this PhD thesis is the development of a model for simulating water droplet movement on a leaf surface and to compare the model behavior with experimental observations. A series of five papers has been presented to explain systematically the way in which this droplet modelling work has been realised. Knowing the path of the droplet on the leaf surface is important for understanding how a droplet of water, pesticide, or nutrient will be absorbed through the leaf surface. An important aspect of the research is the generation of a leaf surface representation that acts as the foundation of the droplet model. Initially a laser scanner is used to capture the surface characteristics for two types of leaves in the form of a large scattered data set. After the identification of the leaf surface boundary, a set of internal points is chosen over which a triangulation of the surface is constructed. We present a novel hybrid approach for leaf surface fitting on this triangulation that combines Clough-Tocher (CT) and radial basis function (RBF) methods to achieve a surface with a continuously turning normal. The accuracy of the hybrid technique is assessed using numerical experimentation. The hybrid CT-RBF method is shown to give good representations of Frangipani and Anthurium leaves. Such leaf models facilitate an understanding of plant development and permit the modelling of the interaction of plants with their environment. The motion of a droplet traversing this virtual leaf surface is affected by various forces including gravity, friction and resistance between the surface and the droplet. The innovation of our model is the use of thin-film theory in the context of droplet movement to determine the thickness of the droplet as it moves on the surface. Experimental verification shows that the droplet model captures reality quite well and produces realistic droplet motion on the leaf surface. Most importantly, we observed that the simulated droplet motion follows the contours of the surface and spreads as a thin film. In the future, the model may be applied to determine the path of a droplet of pesticide along a leaf surface before it falls from or comes to a standstill on the surface. It will also be used to study the paths of many droplets of water or pesticide moving and colliding on the surface.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">surface fitting, finite elements methods, radial basis functions, Clough-Tocher method, Interpolation method, extrapolation method, virtual leaf, virtual plants, truncated Taylor series, weighted least squares, physical based modelling</field><field name="subject">thin-film approximation</field><field name="identifier">http://eprints.qut.edu.au/30232/</field><field name="validLink">True</field></doc><doc><field name="title">The effect of Amblyopia on motor and psychosocial skills in children</field><field name="creator">Webber, Ann Louise</field><field name="description">Background/Aims:  In an investigation of the functional impact of amblyopia on children, the fine motor skills, perceived self-esteem and eye movements of amblyopic children were compared with that of age-matched controls.  The influence of amblyogenic condition or treatment factors that might predict any decrement in outcome measures was investigated.  
 The relationship between indirect measures of eye movements that are used clinically and eye movement characteristics recorded during reading was examined and the relevance of proficiency in fine motor skills to performance on standardised educational tests was explored in a sub-group of the control children.
 Methods: Children with amblyopia (n=82; age 8.2 &#177; 1.3 years) from differing causes (infantile esotropia n=17, acquired strabismus n=28, anisometropia n=15, mixed n=13 and deprivation n=9), and a control group of children (n=106; age 9.5 &#177; 1.2 years) participated in this study. Measures of visual function included monocular logMAR visual acuity (VA) and stereopsis assessed with the Randot Preschool Stereoacuity test, while fine motor skills were measured using the Visual-Motor Control (VMC) and Upper Limb Speed and Dexterity (ULSD) subtests of the Brunicks-Oseretsky Test of Motor Proficiency. Perceived self esteem was assessed for those children from grade 3 school level with the Harter Self Perception Profile for Children and for those in younger grades (preschool to grade 2) with the Pictorial Scale of Perceived Competence and Acceptance for Young Children. A clinical measure of eye movements was made with the Developmental Eye Movement (DEM) test for those children aged eight years and above.  For appropriate case-control comparison of data, the results from amblyopic children were compared with age-matched sub-samples drawn from the group of children with normal vision who completed the tests.  Eye movements during reading for comprehension were recorded by the Visagraph infra-red recording system and results of standardised tests of educational performance were also obtained for a sub-set of the control group. 
 Results   Amblyopic children (n=82; age 8.2 &#177; 1.7 years) performed significantly poorer than age-matched control children (n=37; age 8.3 &#177; 1.3 years) on 9 of 16 fine motor skills sub-items and for the overall age-standardised scores for both VMC and ULSD items (p&lt;0.05); differences were most evident on timed manual dexterity tasks. The underlying aetiology of amblyopia and level of stereoacuity significantly affected fine motor skill performance on both items. However, when examined in a multiple regression model that took into account the inter-correlation between visual characteristics, poorer fine motor skills performance was only associated with strabismus (F1,75  = 5.428; p =0. 022), and not with the level of stereoacuity, refractive error or visual acuity in either eye.
 Amblyopic children from grade 3 school level and above (n=47; age 9.2 &#177; 1.3 years), particularly those with acquired strabismus, had significantly lower social acceptance scores than age-matched control children (n=52; age 9.4 &#177; 0.5 years) (F(5,93) = 3.14; p = 0.012).  However, the scores of the amblyopic children were not significantly different to controls for other areas related to self-esteem, including scholastic competence, physical appearance, athletic competence, behavioural conduct and global self worth. A lower social acceptance score was independently associated with a history of treatment with patching but not with a history of strabismus or wearing glasses. Amblyopic children from pre-school to grade 2 school level (n=29; age = 6.6 &#177; 0.6 years) had similar self-perception scores to their age-matched peers (n=20; age = 6.4 &#177; 0.5 years).
 There were no significant differences between the amblyopic (n=39; age 9.1 &#177; 0.9 years) and age-matched control (n = 42; age = 9.3 &#177; 0.38 years) groups for any of the DEM outcome measures (Vertical Time, Horizontal Time, Number of Errors and Ratio (Horizontal time/Vertical time)).  Performance on the DEM did not significantly relate to measures of VA in either eye, level of binocular function, history of strabismus or refractive error.  
 Developmental Eye Movement test outcome measures Horizontal Time and Vertical Time were significantly correlated with reading rates measured by the Visagraph for both reading for comprehension and naming numbers (r&gt;0.5).  Some moderate correlations were also seen between the DEM Ratio and word reading rates as recorded by Visagraph (r=0.37). 
 In children with normal vision, academic scores in mathematics, spelling and reading were associated with measures of fine motor skills.  Strongest effect sizes were seen with the timed manual dexterity domain, Upper Limb Speed and Dexterity.    
 Conclusions Amblyopia may have a negative impact on a child&#8217;s fine motor skills and an older child&#8217;s sense of acceptance by their peers may be influenced by treatment that includes eye patching.  Clinical measures of eye movements were not affected in amblyopic children.  
 A number of the outcome measures of the DEM are associated with objective recordings of reading rates, supporting its clinical use for identification of children with slower reading rates.  In children with normal vision, proficiency on clinical measures of fine motor skill are associated with outcomes on standardised measures of educational performance.  Scores on timed manual dexterity tasks had the strongest association with educational performance. 
 Collectively, the results of this study indicate that, in addition to the reduction in visual acuity and binocular function that define the condition, amblyopes have functional impairment in childhood development skills that underlie proficiency in everyday activities. The study provides support for strategies aimed at early identification and remediation of amblyopia and the co-morbidities that arise from abnormal visual neurodevelopment.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">amblyopia, strabismus, anisometropia, fine motor skills, eye movements, self-esteem, psychosocial, stereopsis, visual acuity, education</field><field name="identifier">http://eprints.qut.edu.au/30211/</field><field name="validLink">True</field></doc><doc><field name="title">A brush with the real world : the future of inertial motion capture in live performance</field><field name="creator">Haag, John Christopher</field><field name="description">3D Motion capture is a medium that plots motion, typically human motion, converting it into a form that can be represented digitally. It is a fast evolving field and recent inertial technology may provide new artistic possibilities for its use in live performance. Although not often used in this context, motion capture has a combination of attributes that can provide unique forms of collaboration with performance arts. The inertial motion capture suit used for this study has orientation sensors placed at strategic points on the body to map body motion.  Its portability, real-time performance, ease of use, and its immunity from line-of-sight problems inherent in optical systems suggest it would work well as a live performance technology. Many animation techniques can be used in real-time. This research examines a broad cross-section of these techniques using four practice-led cases to assess the suitability of inertial motion capture to live performance. Although each case explores different visual possibilities, all make use of the performativity of the medium, using either an improvisational format or interactivity among stage, audience and screen that would be difficult to emulate any other way.  
 
 A real-time environment is not capable of reproducing the depth and sophistication of animation people have come to expect through media. These environments take many hours to render. In time the combination of what can be produced in real-time and the tools available in a 3D environment will no doubt create their own tree of aesthetic directions in live performance. The case study looks at the potential of interactivity that this technology offers.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">motion capture, performance animation, performance capture, real-time, inertial, live, liveness, spectacle, virtual reality, paralanguage, improvisation</field><field name="identifier">http://eprints.qut.edu.au/30213/</field><field name="validLink">True</field></doc><doc><field name="title">Leading indigenous education in a remote location : reflections on teaching to be "proud and deadly"</field><field name="creator">Douglas, Angela Marie</field><field name="description">This thesis is a critical reflection of the author&#8217;s time as a Principal of an Indigenous state school from 2003-2004. The purpose is to reassess the impact of her principalship in terms of the staff, students and Community change that affected learning outcomes at the school and to reanalyse to what actions and to whom positive changes could be attributed. This thesis reflects and identifies, in light of the literature, strategies which were effective in enhancing student learning outcomes. The focus of this thesis was the Doongal State School*, its students, staff and facilities. The author will attempt to draw out theoretical frameworks in terms of: (1) what changed educationally in Doongal State School, (2) what seemed to be important in the Principal&#8217;s role, (3) the processes that took place, and (4) the effect of being non- Indigenous and a female. Overall, the author undertook this critical reflection in order to understand and embrace educational practices that will (a) lessen the gap between the academic outcomes achieved by Indigenous and non-Indigenous students, and (b) enhance life choices for Indigenous children. The findings indicate that principal leadership is critical for success in Indigenous schools and is the centrepiece of the models developed to explain improvement at Doongal State School. School factors, Principal Leadership factors, Change factors and factors relating to being a non-Indigenous female principal, which, when implemented, will lead to improved educational outcomes for Indigenous students, have evolved as a result of this thesis. Principal Leadership factors were found to be the enablers for the effective implementation of the key components for success.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">leadership, Indigenous education, professional learning, Indigenous community partnerships, Aboriginal, pride, self worth, high expectations, challenging behaviour</field><field name="identifier">http://eprints.qut.edu.au/30275/</field><field name="validLink">True</field></doc><doc><field name="title">Stochastic modelling of financial time series with memory and multifractal scaling</field><field name="creator">Snguanyat, Ongorn</field><field name="description">Financial processes may possess long memory and their probability densities may display heavy tails. Many models have been developed to deal with this tail behaviour, which reflects the jumps in the sample paths. On the other hand, the presence of long memory, which contradicts the efficient market hypothesis, is still an issue for further debates. These difficulties present challenges with the problems of memory detection and modelling the co-presence of long memory and heavy tails. This PhD project aims to respond to these challenges. The first part aims to detect memory in a large number of financial time series on stock prices and exchange rates using their scaling properties. Since financial time series often exhibit stochastic trends, a common form of nonstationarity, strong trends in the data can lead to false detection of memory. We will take advantage of a technique known as multifractal detrended fluctuation analysis (MF-DFA) that can systematically eliminate trends of different orders. This method is based on the identification of scaling of the q-th-order moments and is a generalisation of the standard detrended fluctuation analysis (DFA) which uses only the second moment; that is, q = 2. We also consider the rescaled range R/S analysis and the periodogram method to detect memory in financial time series and compare their results with the MF-DFA. An interesting finding is that short memory is detected for stock prices of the American Stock Exchange (AMEX) and long memory is found present in the time series of two exchange rates, namely the French franc and the Deutsche mark. Electricity price series of the five states of Australia are also found to possess long memory. For these electricity price series, heavy tails are also pronounced in their probability densities. The second part of the thesis develops models to represent short-memory and longmemory financial processes as detected in Part I. These models take the form of continuous-time AR(&#8734;) -type equations whose kernel is the Laplace transform of a finite Borel measure. By imposing appropriate conditions on this measure, short memory or long memory in the dynamics of the solution will result. A specific form of the models, which has a good MA(&#8734;) -type representation, is presented for the short memory case.  Parameter estimation of this type of models is performed via least squares, and the models are applied to the stock prices in the AMEX, which have been established in Part I to possess short memory. By selecting the kernel in the continuous-time AR(&#8734;) -type equations to have the form of Riemann-Liouville fractional derivative, we obtain a fractional stochastic differential equation driven by Brownian motion. This type of equations is used to represent financial processes with long memory, whose dynamics is described by the fractional derivative in the equation. These models are estimated via quasi-likelihood, namely via a continuoustime version of the Gauss-Whittle method. The models are applied to the exchange rates and the electricity prices of Part I with the aim of confirming their possible long-range dependence established by MF-DFA. The third part of the thesis provides an application of the results established in Parts I and II to characterise and classify financial markets. We will pay attention to the New York Stock Exchange (NYSE), the American Stock Exchange (AMEX), the NASDAQ Stock Exchange (NASDAQ) and the Toronto Stock Exchange (TSX). The parameters from MF-DFA and those of the short-memory AR(&#8734;) -type models will be employed in this classification. We propose the Fisher discriminant algorithm to find a classifier in the two and three-dimensional spaces of data sets and then provide cross-validation to verify discriminant accuracies. This classification is useful for understanding and predicting the behaviour of different processes within the same market. The fourth part of the thesis investigates the heavy-tailed behaviour of financial processes which may also possess long memory. We consider fractional stochastic differential equations driven by stable noise to model financial processes such as electricity prices. The long memory of electricity prices is represented by a fractional derivative, while the stable noise input models their non-Gaussianity via the tails of their probability density. A method using the empirical densities and MF-DFA will be provided to estimate all the parameters of the model and simulate sample paths of the equation. The method is then applied to analyse daily spot prices for five states of Australia. Comparison with the results obtained from the R/S analysis, periodogram method and MF-DFA are provided. The results from fractional SDEs agree with those from MF-DFA, which are based on multifractal scaling, while those from the periodograms, which are based on the second order, seem to underestimate the long memory dynamics of the process. This highlights the need and usefulness of fractal methods in modelling non-Gaussian financial processes with long memory.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">Stock prices, electricity prices, exchange rates, financial stochastic, long-range dependence, short-range dependence, non-Gaussianity, heavy tails, &#945;-stable distribution, fractional stochastic differential equation, Levy noise</field><field name="subject">the Gauss-Whittle contrast function, multifractal scaling, the continuous-time AR(&#8734;) -type equations, Fisher's discriminant analysis, classification</field><field name="identifier">http://eprints.qut.edu.au/30240/</field><field name="validLink">True</field></doc><doc><field name="title">Utilisation of seed resources by small mammals : a two-way interaction</field><field name="creator">Elmouttie, David</field><field name="description">Within the Australian wet tropics bioregion, only 900 000 hectares of once continuous rainforest habitat between Townsville and Cooktown now remains. While on the Atherton Tableland, only 4% of the rainforest that once occurred there remains today with remnant vegetation now forming a matrix of rainforest dispersed within agricultural land (sugarcane, banana, orchard crops, townships and pastoral land). Some biologists have suggested that remnants often support both faunal and floral communities that differ significantly from remaining continuous forest. Australian tropical forests possess a relatively high diversity of native small mammal species particularly rodents, which unlike larger mammalian and avian frugivores elsewhere, have been shown to be resilient to the effects of fragmentation, patch isolation and reduction in patch size. While small mammals often become the dominant mammalian frugivores, in terms of their relative abundance, the relationship that exists between habitat diversity and structure, and the impacts of small mammal foraging within fragmented habitat patches in Australia, is still poorly understood. The relationship between foraging behaviour and demography of two small mammal species, Rattus fuscipes and Melomys cervinipes, and food resources in fragmented rainforest sites, were investigated in the current study. Population densities of both species were strongly related with overall density of seed resources in all rainforest fragments. The distribution of both mammal species however, was found to be independent of the distribution of seed resources. Seed utilisation trials indicated that M.cervinipes and R.fuscipes had less impact on seed resources (extent of seed harvesting) than did other rainforest frugivores. Experimental feeding trials demonstrated that in 85% of fruit species tested, rodent feeding increased seed germination by a factor of 3.5 suggesting that in Australian tropical rainforest remnants, small mammals may play a significant role in enhancing germination of large seeded fruits. This study has emphasised the role of small mammals in tropical rainforest systems in north eastern Australia, in particular, the role that they play within isolated forest fragments where larger frugivorous species may be absent.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">small mammals, food sources, seed</field><field name="identifier">http://eprints.qut.edu.au/30239/</field><field name="validLink">True</field></doc><doc><field name="title">New insights into appetite, inflammation and the use of fish oil in hemodialysis patients</field><field name="creator">Zabel, Rachel Eve</field><field name="description">Protein-energy wasting (PEW) is commonly seen in patients with chronic kidney disease (CKD). The condition is characterised by chronic, systemic low-grade inflammation which affects nutritional status by a variety of mechanisms including reducing appetite and food intake and increasing muscle catabolism. PEW is linked with co-morbidities such as cardiovascular disease, and is associated with lower quality of life, increased hospitalisations and a 6-fold increase in risk of death1. Significant gender differences have been found in the severity and effects of several markers of PEW. There have been limited studies testing the ability of anti-inflammatory agents or nutritional interventions to reduce the effects of PEW in dialysis patients. This thesis makes a significant contribution to the understanding of PEW in dialysis patients. It advances understanding of measurement techniques for two of the key components, appetite and inflammation, and explores the effect of fish oil, an anti-inflammatory agent, on markers of PEW in dialysis patients. The first part of the thesis consists of two methodological studies conducted using baseline data. The first study aims to validate retrospective ratings of hunger, desire to eat and fullness on visual analog scales (VAS) (paper and pen and electronic) as a new method of measuring appetite in dialysis patients. The second methodological study aims to assess the ability of a variety of methods available in routine practice to detect the presence of inflammation. The second part of the thesis aims to explore the effect of 12 weeks supplementation with 2g per day of Eicosapentaenoic Acid (EPA), a longchain fatty acid found in fish oil, on markers of PEW. A combination of biomarkers and psychomarkers of appetite and inflammation are the main outcomes being explored, with nutritional status, dietary intake and quality of life included as secondary outcomes. A lead in phase of 3 months prior to baseline was used so that each person acts as their own historical control.  The study also examines whether there are gender differences in response to the treatment. Being an exploratory study, an important part of the work is to test the feasibility of the intervention, thus the level of adherence and factors associated with adherence are also presented. The studies were conducted at the hemodialysis unit of the Wesley Hospital. Participants met the following criteria: adult, stage 5 CKD on hemodialysis for at least 3 months, not expected to receive a transplant or switch to another dialysis modality during the study, absence of intellectual impairment or mental illness impairing ability to follow instructions or complete the intervention. A range of intermediate, clinical and patient-centred outcome measures were collected at baseline and 12 weeks. Inflammation was measured using five biomarkers: c-reactive protein (CRP), interleukin-6 (IL6), intercellular adhesion molecule (sICAM-1), vascular cell adhesion molecule (sVCAM-1) and white cell count (WCC). Subjective appetite was measured using the first question from the Appetite and Dietary Assessment (ADAT) tool and VAS for measurements of hunger, desire to eat and fullness. A novel feature of the study was the assessment of the appetite peptides leptin, ghrelin and peptide YY as biomarkers of appetite. Nutritional status/inflammation was assessed using the Malnutrition-Inflammation Score (MIS) and the Patient-Generated Subjective Global Assessment (PG-SGA). Dietary intake was measured using 3-day records. Quality of life was measured using the Kidney Disease Quality of Life Short Form version 1.3 (KDQOL-SF&#8482; v1.3 &#169; RAND University), which combines the Short-Form 36 (SF36) with a kidney-disease specific module2. A smaller range of these variables was available for analysis during the control phase (CRP, ADAT, dietary intake and nutritional status). Statistical analysis was carried out using SPSS version 14 (SPSS Inc, Chicago IL, USA). Analysis of the first part of the thesis involved descriptive and bivariate statistics, as well as Bland-Altman plots to assess agreement between methods, and sensitivity analysis/ROC curves to test the ability of methods to predict the presence of inflammation. The unadjusted (paired ttests) and adjusted (linear mixed model) change over time is presented for the main outcome variables of inflammation and appetite. Results are shown for the whole group followed by analyses according to gender and adherence to treatment. Due to the exploratory nature of the study, trends and clinical significance were considered as important as statistical significance. Twenty-eight patients (mean age 61&#177;17y, 50% male, dialysis vintage 19.5 (4- 101) months) underwent baseline assessment. Seven out of 28 patients (25%) reported sub-optimal appetite (self-reported as fair, poor or very poor) despite all being well nourished (100% SGA A). Using the VAS, ratings of hunger, but not desire to eat or fullness, were significantly (p&lt;0.05) associated with a range of relevant clinical variables including age (r=-0.376), comorbidities (r=-0.380) nutritional status (PG-SGA score, r=-0.451), inflammatory markers (CRP r=-0.383; sICAM-1 r=-0.387) and seven domains of quality of life. Patients expressed a preference for the paper and pen method of administering VAS. None of the tools (appetite, MIS, PG-SGA, albumin or iron) showed an acceptable ability to detect patients who are inflamed. It is recommended that CRP should be tested more frequently as a matter of course rather than seeking alternative methods of measuring inflammation. 27 patients completed the 12 week intervention. 20 patients were considered adherent based on changes in % plasma EPA, which rose from 1.3 (0.94)% to 5.2 (1.1)%, p&lt;0.001, in this group. The major barriers to adherence were forgetting to take the tablets as well as their size. At 12 weeks, inflammatory markers remained steady apart from the white cell count which decreased (7.6(2.5) vs 7.0(2.2) x109/L, p=0.058) and sVCAM-1 which increased (1685(654) vs 2249(925) ng/mL, p=0.001). Subjective appetite using VAS increased (51mm to 57mm, +12%) and there was a trend towards reduction in peptide YY (660(31) vs 600(30) pg/mL, p=0.078). There were some gender differences apparent, with the following adjusted change between baseline and week 12: CRP (males -3% vs females +17%, p=0.19), IL6 (males +17% vs females +48%, p=0.77), sICAM-1 (males -5% vs females +11%, p=0.07), sVCAM-1 (males +54% vs females +19%, p=0.08) and hunger ratings (males 20% vs females -5%, p=0.18). On balance, males experienced a maintainence or reduction in three inflammatory markers and an improvement in hunger ratings, and therefore appeared to have responded better to the intervention. Compared to those who didn&#8217;t adhere, adherent patients maintained weight (mean(SE) change: +0.5(1.6) vs - 0.8(1.2) kg, p=0.052) and fat-free mass (-0.1 (1.6) vs -1.8 (1.8) kg, p=0.045). There was no difference in change between the intervention and control phase for CRP, appetite, nutritional status or dietary intake. The thesis makes a significant contribution to the evidence base for understanding of PEW in dialysis patients. It has advanced knowledge of methods of assessing inflammation and appetite. Retrospective ratings of hunger on a VAS appear to be a valid method of assessing appetite although samples which include patients with very poor appetite are required to confirm this. Supplementation with fish oil appeared to improve subjective appetite and dampen the inflammatory response. The effectiveness of the intervention is influenced by gender and adherence. Males appear to be more responsive to the primary outcome variables than females, and the quality of response is improved with better adherence. These results provide evidence to support future interventions aimed at reducing the effects of PEW in dialysis patients.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">chronic kidney disease, inflammation, anti-inflammatory agents, fish oil</field><field name="identifier">http://eprints.qut.edu.au/30248/</field><field name="validLink">True</field></doc><doc><field name="title">Value-mapping for major economic infrastructure projects</field><field name="creator">Kraatz, Judy Ann</field><field name="description">The establishment of corporate objectives regarding economic, environmental, social, and ethical responsibilities, to inform business practice, has been gaining credibility in the business sector since the early 1990&#8217;s.  This is witnessed through (i) the formation of international forums for sustainable and accountable development, (ii) the emergence of standards, systems, and frameworks to provide common ground for regulatory and corporate dialogue, and (iii) the significant quantum of relevant popular and academic literature in a diverse range of disciplines. How then has this move towards greater corporate responsibility become evident in the provision of major urban infrastructure projects? 
 The gap identified, in both academic literature and industry practice, is a structured and auditable link between corporate intent and project outcomes. Limited literature has been discovered which makes a link between corporate responsibility; project performance indicators (or critical success factors) and major infrastructure provision. This search revealed that a comprehensive mapping framework, from an organisation&#8217;s corporate objectives through to intended, anticipated and actual outcomes and impacts has not yet been developed for the delivery of such projects. The research problem thus explored is &#8216;the need to better identify, map and account for the outcomes, impacts and risks associated with economic, environmental, social and ethical outcomes and impacts which arise from major economic infrastructure projects, both now, and into the future&#8217;. 
 The methodology being used to undertake this research is based on Checkland&#8217;s soft system methodology, engaging in action research on three collaborative case studies. 
 A key outcome of this research is a value-mapping framework applicable to Australian public sector agencies. This is a decision-making methodology which will enable project teams responsible for delivering major projects, to better identify and align project objectives and impacts with stated corporate objectives.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">value-mapping, corporate responsibility, urban infrastructure, construction innovation, corporate reporting</field><field name="identifier">http://eprints.qut.edu.au/30246/</field><field name="validLink">True</field></doc><doc><field name="title">Recombinant protein production using a Tobacco yellow dwarf virus-based episomal expression vector : control of Rep activity</field><field name="creator">Chanson, Aurelie Heitiare</field><field name="description">Over the past decade, plants have been used as expression hosts for the production of pharmaceutically important and commercially valuable proteins. Plants offer many advantages over other expression systems such as lower production costs, rapid scale up of production, similar post-translational modification as animals and the low likelihood of contamination with animal pathogens, microbial toxins or oncogenic sequences. However, improving recombinant protein yield remains one of the greatest challenges to molecular farming. In-Plant Activation (InPAct) is a newly developed technology that offers activatable and high-level expression of heterologous proteins in plants. InPAct vectors contain the geminivirus cis elements essential for rolling circle replication (RCR) and are arranged such that the gene of interest is only expressed in the presence of the cognate viral replication-associated protein (Rep). The expression of Rep in planta may be controlled by a tissue-specific, developmentally regulated or chemically inducible promoter such that heterologous protein accumulation can be spatially and temporally controlled. One of the challenges for the successful exploitation of InPAct technology is the control of Rep expression as even very low levels of this protein can reduce transformation efficiency, cause abnormal phenotypes and premature activation of the InPAct vector in regenerated plants. Tight regulation over transgene expression is also essential if expressing cytotoxic products. Unfortunately, many tissue-specific and inducible promoters are unsuitable for controlling expression of Rep due to low basal activity in the absence of inducer or in tissues other than the target tissue. This PhD aimed to control Rep activity through the production of single chain variable fragments (scFvs) specific to the motif III of Tobacco yellow dwarf virus (TbYDV) Rep. Due to the important role played by the conserved motif III in the RCR, it was postulated that such scFvs can be used to neutralise the activity of the low amount of Rep expressed from a &#8220;leaky&#8221; inducible promoter, thus preventing activation of the TbYDV-based InPAct vector until intentional induction. Such scFvs could also offer the potential to confer partial or complete resistance to TbYDV, and possibly heterologous viruses as motif III is conserved between geminiviruses.  Studies were first undertaken to determine the levels of TbYDV Rep and TbYDV replication-associated protein A (RepA) required for optimal transgene expression from a TbYDV-based InPAct vector. Transient assays in a non-regenerable Nicotiana tabacum (NT-1) cell line were undertaken using a TbYDV-based InPAct vector containing the uidA reporter gene (encoding GUS) in combination with TbYDV Rep and RepA under the control of promoters with high (CaMV 35S) or low (Banana bunchy top virus DNA-R, BT1) activity. The replication enhancer protein of Tomato leaf curl begomovirus (ToLCV), REn, was also used in some co-bombardment experiments to examine whether RepA could be substituted by a replication enhancer from another geminivirus genus. GUS expression was observed both quantitatively and qualitatively by fluorometric and histochemical assays, respectively. GUS expression from the TbYDV-based InPAct vector was found to be greater when Rep was expected to be expressed at low levels (BT1 promoter) rather than high levels (35S promoter). GUS expression was further enhanced when Rep and RepA were co-bombarded with a low ratio of Rep to RepA. Substituting TbYDV RepA with ToLCV REn also enhanced GUS expression but more importantly highest GUS expression was observed when cells were co-transformed with expression vectors directing low levels of Rep and high levels of RepA irrespective of the level of REn. In this case, GUS expression was approximately 74-fold higher than that from a non-replicating vector. The use of different terminators, namely CaMV 35S and Nos terminators, in InPAct vectors was found to influence GUS expression. In the presence of Rep, GUS expression was greater using pInPActGUS-Nos rather than pInPActGUS-35S. The only instance of GUS expression being greater from vectors containing the 35S terminator was when comparing expression from cells transformed with Rep, RepA and REnexpressing vectors and either non-replicating vectors, p35SGS-Nos or p35SGS-35S. This difference was most likely caused by an interaction of viral replication proteins with each other and the terminators. These results indicated that (i) the level of replication associated proteins is critical to high transgene expression, (ii) the choice of terminator within the InPAct vector may affect expression levels and (iii) very low levels of Rep can activate InPAct vectors hence controlling its activity is critical. Prior to generating recombinant scFvs, a recombinant TbYDV Rep was produced in E. coli to act as a control to enable the screening for Rep-specific antibodies. A bacterial expression vector was constructed to express recombinant TbYDV Rep with an Nterminal His-tag (N-His-Rep). Despite investigating several purification techniques including Ni-NTA, anion exchange, hydrophobic interaction and size exclusion chromatography, N-His-Rep could only be partially purified using a Ni-NTA column under native conditions. Although it was not certain that this recombinant N-His-Rep had the same conformation as the native TbYDV Rep and was functional, results from an electromobility shift assay (EMSA) showed that N-His-Rep was able to interact with the TbYDV LIR and was, therefore, possibly functional. Two hybridoma cell lines from mice, immunised with a synthetic peptide containing the TbYDV Rep motif III amino acid sequence, were generated by GenScript (USA). Monoclonal antibodies secreted by the two hybridoma cell lines were first screened against denatured N-His-Rep in Western analysis. After demonstrating their ability to bind N-His-Rep, two scFvs (scFv1 and scFv2) were generated using a PCR-based approach. Whereas the variable heavy chain (VH) from both cell lines could be amplified, only the variable light chain (VL) from cell line 2 was amplified. As a result, scFv1 contained VH and VL from cell line 1, whereas scFv2 contained VH from cell line 2 and VL from cell line 1. Both scFvs were first expressed in E. coli in order to evaluate their affinity to the recombinant TbYDV N-His-Rep. The preliminary results demonstrated that both scFvs were able to bind to the denatured N-His-Rep. However, EMSAs revealed that only scFv2 was able to bind to native N-His-Rep and prevent it from interacting with the TbYDV LIR. Each scFv was cloned into plant expression vectors and co-bombarded into NT-1 cells with the TbYDV-based InPAct GUS expression vector and pBT1-Rep to examine whether the scFvs could prevent Rep from mediating RCR. Although it was expected that the addition of the scFvs would result in decreased GUS expression, GUS expression was found to slightly increase. This increase was even more pronounced when the scFvs were targeted to the cell nucleus by the inclusion of the Simian virus 40 large T antigen (SV40) nuclear localisation signal (NLS). It was postulated that the scFvs were binding to a proportion of Rep, leaving a small amount available to mediate RCR.  The outcomes of this project provide evidence that very high levels of recombinant protein can theoretically be expressed using InPAct vectors with judicious selection and control of viral replication proteins. However, the question of whether the scFvs generated in this project have sufficient affinity for TbYDV Rep to prevent its activity in a stably transformed plant remains unknown. It may be that other scFvs with different combinations of VH and VL may have greater affinity for TbYDV Rep. Such scFvs, when expressed at high levels in planta, might also confer resistance to TbYDV and possibly heterologous geminiviruses.</field><field name="date">2009</field><field name="language" /><field name="relation" /><field name="subject">recombinant protein production, tobacco yellow dwarf virus, episomal expression vector, Rep activity</field><field name="identifier">http://eprints.qut.edu.au/30290/</field><field name="validLink">True</field></doc></add>